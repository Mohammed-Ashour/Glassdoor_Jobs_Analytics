Job Title,Salary Estimate,Job Description,Rating,Company Name,Location,Headquarters,Size,Founded,Type of ownership,Industry,Sector,Revenue,Competitors
Machine Learning Engineer,"$72K-$124K
(Glassdoor est.)","We love programming and the excitement that comes with building something people use. We are the kind of people that love talking to users and can find the balance between solving a problem quickly and thinking about how your code will work in the future. We love to move fast, keep learning and get stuff done.

Our data science team is still in its early days and you'll have a big impact on our direction and how we operate. You'll be central to researching, developing and shipping products that help our customers learn and grow from their data. For this role, we're looking for people who have developed split brains--software engineers who have become great at writing machine learning code or data scientists who have become great software developers.

Technologies we use (not comprehensive!):
Python

Numpy, Scipy, Pandas

Aurora, Cassandra, Kafka

HTML, JavaScript, React

SageMaker

How you will make a difference:


Analyze large data sets (we're collecting billions of individual actions every month).
Build products that enable our customers to grow faster and communicate more effectively with their customers.
Develop machine learning models and pipelines for research and production.

Who You Are:


Have experience implementing machine learning models, data pipelines and testing frameworks for research and production use.
Have demonstrated a measurable impact based on the models you've created. It's not always easy getting a model correct, we love talking about places we got stuck and work as a team to think through ideas that could unblock us.
Have experience processing cloud-scale data using parallel, elastic, streaming and similar techniques.
Enjoy tuning and validating machine learning models and take a rigorous approach.
Understand how to profile code and optimize performance.
Aspire to correctness (e.g. in your code, in drawing conclusions from data)
Have a bachelor's or advanced degree in computer science, applied math, statistics or other relevant quantitative discipline, or equivalent industry experience.

Get to know Klaviyo

Klaviyo is the world's leading owned marketing platform known for accelerating revenue for online businesses using the channels they own like email, web, and mobile. Enabling companies to leverage these owned marketing channels, Klaviyo makes it easy to store, access, analyze and use transactional and behavioral data to power highly-targeted customer and prospect communications. And unlike other marketing platforms, Klaviyo doesn't force companies to compromise between advanced functionality or ease of use - so companies of all sizes are able to maximize their sales quickly. That's why over 28,000+ innovative companies like Unilever, Custom Ink and Eventbrite sell more with Klaviyo.",4.8,"Klaviyo
4.8","Boston, MA","Boston, MA",201 to 500 employees,2012,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Software Engineer (Remote),-1,"About you:
Care deeply about democratizing access to data.
Passionate about big data and are excited by seemingly-impossible challenges.
At least 80% of people who have worked with you put you in the top 10% of the people they have worked with.
You think life is too short to work with B-players.
You are entrepreneurial and want to work in a super fast-paced environment where the solutions aren't already predefined.
You live in the U.S. or Canada and are comfortable working remotely.
About SafeGraph:
SafeGraph is a B2B data company that sells to data scientists and machine learning engineers.
SafeGraph's goal is to be the place for all information about physical Places
SafeGraph currently has 30+ people and has raised a $20 million Series A. CEO previously was founder and CEO of LiveRamp (NYSE:RAMP).
Company is growing fast, over $10M ARR, and is currently profitable.
Company is based in San Francisco but more than 50% of the team is remote. We get the entire company together in the same place every month (when possible).
We have been moving very quickly in the current pandemic, building up new products and releasing up-to-date dashboards to the general public. We are providing our aggregated and anonymized location data at no cost for non-commercial use, to anyone with the shared goal of fighting to prevent the spread of COVID-19 and helping to get the economy moving in its aftermath. We now have a vibrant community of 2000+ organizations in this Consortium. You can see the publications here.

About the role:
Core software engineer.
Reporting to SafeGraph's VP Engineering.
Work as an individual contributor.
Opportunities for future leadership.

Requirements:
No Resume? No Problem! A LinkedIn is all you need to apply!
You have at least 3 years of relevant work experience.
Proficiency writing production-quality code, preferably in Scala, Java, or Python.
Strong familiarity with distributed system, or map/reduce data processing.
Deep understanding of all things ""data"" - schema design, modeling, optimization, scalability, etc.
You are authorized to work where you are.
Excellent communication skills.
You are amazingly entrepreneurial.
You want to help build a massive company.
Nice to haves:
Experience using Apache Spark to solve production-scale problems.
Experience with AWS.
Experience with building ML models from the ground up.
Experience working with huge data sets.
Python, Database and Systems Design, Scala, Data Science, Apache Spark, Hadoop MapReduce.
Good reading on how we are thinking:
SafeGraph Vision and Values
Open Information to Power Innovation
Where Should Machines go to Learn
Data-As-A-Service Bible: Everything You Wanted to Know About Running DaaS Companies
Don't fit this description perfectly but still think this is the role for you? Apply and let us know why!",4.5,"SafeGraph
4.5",Remote,"San Francisco, CA",1 to 50 employees,2016,Company - Private,Internet,Information Technology,$10 to $25 million (USD),-1
Data Science Software Engineer,"$86K-$125K
(Glassdoor est.)","We love programming and the excitement that comes with building something people use. We are the kind of people that love talking to users and can find the balance between solving a problem quickly and thinking about how your code will work in the future. We love to move fast, keep learning and get stuff done.

Our data science team is still in its early days and you'll have a big impact on our direction and how we operate. You'll be central to researching, developing and shipping products that help our customers learn and grow from their data. For this role, we're looking for people who have developed split brains--software engineers who have become great at writing machine learning code or data scientists who have become great software developers.

Technologies we use (not comprehensive!):
Python

Numpy, Scipy, Pandas

Aurora, Cassandra, Kafka

HTML, JavaScript, React

SageMaker

How you will make a difference:


Analyze large data sets (we're collecting billions of individual actions every month).
Build products that enable our customers to grow faster and communicate more effectively with their customers.
Develop machine learning models and pipelines for research and production.

Who You Are:


Have experience implementing machine learning models, data pipelines and testing frameworks for research and production use.
Have demonstrated a measurable impact based on the models you've created. It's not always easy getting a model correct, we love talking about places we got stuck and work as a team to think through ideas that could unblock us.
Have experience processing cloud-scale data using parallel, elastic, streaming and similar techniques.
Enjoy tuning and validating machine learning models and take a rigorous approach.
Understand how to profile code and optimize performance.
Aspire to correctness (e.g. in your code, in drawing conclusions from data)
Have a bachelor's or advanced degree in computer science, applied math, statistics or other relevant quantitative discipline, or equivalent industry experience.

Get to know Klaviyo

Klaviyo is the world's leading owned marketing platform known for accelerating revenue for online businesses using the channels they own like email, web, and mobile. Enabling companies to leverage these owned marketing channels, Klaviyo makes it easy to store, access, analyze and use transactional and behavioral data to power highly-targeted customer and prospect communications. And unlike other marketing platforms, Klaviyo doesn't force companies to compromise between advanced functionality or ease of use - so companies of all sizes are able to maximize their sales quickly. That's why over 28,000+ innovative companies like Unilever, Custom Ink and Eventbrite sell more with Klaviyo.",4.8,"Klaviyo
4.8","Boston, MA","Boston, MA",201 to 500 employees,2012,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
"Software Engineer, Machine Learning","$135K-$165K
(Glassdoor est.)","The opportunity


Grammarly empowers people to thrive and connect, whenever and wherever they communicate. More than 20 million people around the world use our AI-powered writing assistant every day. All of this begins with our team collaborating in a values-driven and learning-oriented environment.

To achieve our ambitious goals, we're looking for a Software Engineer focused on machine learning to join our team. This individual will be responsible for building end-to-end intelligence systems that solve complex user problems, including applying ML to solve new problems as well as building the infrastructure and systems that will enable this to operate effectively at scale. The role will have the opportunity to provide feedback about the systems and tools in place to facilitate the creation and improvement of a machine learning platform that can increase the efficacy of the engineering team.

Grammarly's engineers and researchers have the freedom to innovate and uncover breakthroughs—and, in turn, influence our product roadmap. The complexity of our technical challenges is growing rapidly as we scale our interfaces, algorithms, and infrastructure. Read more about our stack or hear from our team on our technical blog.

Your impact


The Software Engineer for machine learning will need to stay up-to-date on the quickly evolving field of NLP while also focusing on building production systems. The majority of the problems we're tackling haven't already been solved elsewhere, which provides the opportunity for creativity and innovative problem-solving.

Working on the Machine Learning team requires close partnership with analytical linguists, computational linguists, and research scientists. You will have the chance to deepen your skills in machine learning and deep learning while increasing breadth in related areas to up-level our entire team.

In this role, you will:
Build end-to-end machine learning solutions to solve complex customer problems.
Collaborate with applied researchers to ensure they are well-calibrated on the constraints of the production system, ensuring their research proceeds along practical pathways as they explore novel techniques to tackle previously unsolved problems.
Effectively communicate technical machine learning results in a business context where most people are not machine learning experts.
Build the systems to help applied researchers scale their models in a production environment.
Design experiments, including for offline prototypes in a statistically sound way that will provide actionable data and enable us to make reliable decisions as we iterate on a project.
Promote excellence and best practices across the machine learning team in regards to research, implementation, tooling, and system design.
Work cross-functionally across multiple partner teams to get new features shipped across our many interfaces.
We're looking for someone who
Embodies our EAGER values—is ethical, adaptable, gritty, empathetic, and remarkable.
Understands traditional machine learning algorithms and how to use them effectively in practice.
Is familiar with deep learning and its applications in industry.
Has a strong working knowledge of statistics as it relates to sampling methodologies and designing experiments
Understands data structures and algorithms at a level sufficient to write performant code when working with large datasets or large incoming data streams.
Is aware of NLP techniques to effectively work with very high-dimensional, sparse data.
Has enough experience with academic research to be comfortable reading and implementing papers to reproduce their results.\
Support for you, professionally and personally
Professional growth: We hire people we trust, and we give team members autonomy to do their best work. We also support professional development with training, coaching, and regular feedback.
A connected team: Grammarly builds products that help people connect, and we apply this mindset to our own team. We have a highly collaborative culture supported by our EAGER values. We also take time to celebrate our colleagues and accomplishments with global, local, and team-specific events and programs.
Comprehensive benefits: Grammarly offers all team members competitive pay along with a benefits package that includes superior health care. We also offer ample and defined time off, catered lunches, gym and recreation stipends, admission discounts, and more.
We encourage you to apply


At Grammarly, we value our differences, and we encourage all—especially those whose identities are traditionally underrepresented in tech organizations—to apply. We do not discriminate on the basis of race, religion, color, gender expression or identity, sexual orientation, national origin, citizenship, age, marital status, veteran status, disability status, or any other characteristic protected by law. Grammarly will consider qualified applicants with criminal histories in a manner consistent with the San Francisco Fair Chance Ordinance. Grammarly is an equal opportunity employer and participant in the U.S. Federal E-Verify program.",5.0,"Grammarly
5.0","San Francisco, CA","San Francisco, CA",201 to 500 employees,2009,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Machine Learning Engineer/Scientist,"$137K-$146K
(Glassdoor est.)","At GenapSys we are working to power the world of healthcare and diagnostics with advanced DNA sequencing technology. Our sequencing instrument platform leverages a proprietary electrical microfluidic sequencing chip with a scalable number of detectors, enabling a wide range of applications including targeted sequencing in oncology, pharmacogenomics and genome-wide sequencing in microbiology and others. We believe in a world where every researcher has a compact, scalable, and affordable sequencer in their own lab, empowering the democratization of genetic sequencing. Our novel sequencing method is revolutionizing genomics discovery, biomedical research, healthcare, diagnostics, agriculture, and a variety of other fields.

Our team brings together an incredibly diverse and multidisciplinary set of backgrounds and skills – from electrical and mechanical engineers, physicists, chemists, microfluidic engineers, molecular biologists, bioinformaticians, mathematicians and more. It is a super exciting time to join GenapSys as we recently launched our first product which is generating a tremendous amount of interest.

About the Role:

Machine learning approaches are at the core of GenapSys' methods for generating high quality DNA sequencing data. As a machine learning engineer, you will join forces in the development of cutting-edge machine learning methods that solve key problems in the DNA sequencing, base calling, and variant calling processes. You will work closely with a cross-functional team of life scientists, bioengineers, and data scientists to identify areas where machine learning can make a difference, to conceptualize and develop biological datasets using cutting edge, high throughput platforms, and to analyze these data sets using the best machine learning methods, applied at scale.

Qualifications:
MS, or Ph.D. in computer science, statistics, mathematics, physics, engineering, or equivalent practical experience.
Expertise in Python and with version control practices and tools, especially Git/Github.
Demonstrated ability to write high-quality, production-ready code (readable, well-tested, with well-designed APIs).
1- 4 years of real-world work experience in software development for high-end machine learning algorithms.
Significant experience with Tensorflow.
Demonstrated prior experience with time series data analysis.
Demonstrated hands-on experience with development of Deep Learning models, various Neural Network concepts, classification algorithms that go beyond putting together of existing code, and to apply troubleshooting and problem-solving skills to complex issues.
Ability to communicate effectively and collaborate with people of diverse backgrounds and job functions.
Bonus Points If:
Experience with biological data (DNA sequences, RNAseq, proteomics, microscopy images, etc.).
Proficiency in Linux environment (including shell scripting), experience with database languages (e.g., SQL, No-SQL).
Familiarity with cloud computing services (AWS or GCP).
Experience with scalable machine learning, including the application to large datasets.
What we offer (US based-employees)*:
Competitive compensation and generous stock options.
Comprehensive, industry-leading medical, dental and vision benefits for employees and dependents.
Pre-tax savings plans for health care, child care, elder care, public transportation and parking expenses.
401(k) retirement plan with matching employer contribution.
Free daily catered gourmet lunches and snacks.
For those emergency moments - long and short term disability, life insurance (2x salary) and an employee assistance program.
Work with driven and enthusiastic colleagues in a fast-paced and entrepreneurial environment, the opportunity to work on problems that matter in a highly collaborative environment.
*Eligible international employees' benefits are specific to their location and dependent on their employer of record

GenapSys does not accept unsolicited agency resumes. Please do not forward unsolicited agency resumes to our website or to any GenapSys employee. GenapSys will not pay fees to any third party agency or firm and will not be responsible for any agency fees absent a formal agreement.

A diverse and inclusive workplace where we learn from each other is an integral part of GenapSys' culture. We actively welcome people of different backgrounds, experiences, abilities and perspectives. We are an equal opportunity employer and a great place to work. Join us and help us achieve our mission!",3.8,"GenapSys, Inc.
3.8","Redwood City, CA","Redwood City, CA",51 to 200 employees,2010,Company - Private,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,Less than $1 million (USD),"Illumina, Thermo Fisher Scientific, Oxford Nanopore Technologies"
Data Scientist- Machine Learning Software Engineer,"$76K-$124K
(Glassdoor est.)","We are looking for the right people — people who want to innovate, achieve, grow and lead. We attract and retain the best talent by investing in our employees and empowering them to develop themselves and their careers. Experience the challenges, rewards and opportunity of working for one of the world’s largest providers of products and services to the global energy industry.

Overview:

As a data scientist and machine learning software engineer on Halliburton Digital Solution team, you are responsible to deliver digital solutions which can achieve measurable business results through collaborating with subject matter experts in businesses, applying common open source libraries for building data analytics models, prototyping data driven digital tools to tackle business problems. We are looking for top talents who enjoy learning and contributing to our team through creative and innovative thinking.

Job Responsibilities:
Efficiently extract large scale complex business data (time series data, structured/unstructured) from various data sources and prepare them for data analytics.
Partner with product experts, leverage common open source Machine Learning/Deep Learning packages for identifying data patterns/trends or building predictive models.
Deploy solutions to business units using software technologies to generate measurable values for businesses.
Grasp the application of the latest machine learning & artificial intelligence open source packages, cloud and distributed computing technologies to ensure the best technologies are implemented to meet businesses’ data challenges.


Required Qualifications:
Undergraduate degree in Data Science, Computer Science, or Math, or Statistics.
For candidates who hold an engineering degree, we require candidates have taken data science classes already.
7 years of experiences with a minimum of 2 years experiences in extracting the data, using common classification or regression open source packages through R or Python.
Has basic knowledge with big data platforms like Hadoop, Hive, or Phoenix, as well as knowledge in parallel programming, and distributed computing frameworks like Spark.
Preferred Qualifications:
Advanced degree in in Data Science, Math, Statistics, Computer Science, or Engineering:
5 years of experiences with a Master’s degree.
2 years of experiences with a PhD degree.
Has experience with open source machine learning packages and deep learning packages provided by Microsoft Azure, Amazon AWS, or Google GCP (such as Scikit-learn, Azure ML, TensorFlow, Sagemaker).
Interview process:

Potential candidates are required to pass a data challenge test before on-site interview can be scheduled.

Halliburton is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, disability, genetic information, pregnancy, citizenship, marital status, sex/gender, sexual preference/ orientation, gender identity, age, veteran status, national origin, or any other status protected by law or regulation.

Location

3000 N. Sam Houston Parkway E., Houston, Texas, 77032, United States

Job Details

Requisition Number: 87825
Experience Level: Experienced Hire
Job Family: Engineering/Science/Technology
Product Service Line: Global R&D
Full Time / Part Time: Full Time

Additional Locations for this position:

Compensation Information
Compensation is competitive and commensurate with experience.",3.5,"Halliburton
3.5","Houston, TX","Houston, TX",10000+ employees,1919,Company - Public,Oil & Gas Services,"Oil, Gas, Energy & Utilities",$10+ billion (USD),"Weatherford, Schlumberger"
Machine Learning Engineer - Think Tank Team,"$101K-$175K
(Glassdoor est.)","Title: Machine Learning Engineer

Company: Samsung Research America (SRA)

Lab: Think Tank Team

Location: Mountain View, CA

Lab Summary:

The Think Tank Team is an interdisciplinary collective of researchers, designers, scientists and engineers located in Mountain View, CA. Our mandate is to explore what's next for Samsung by applying bleeding-edge advances in software, machine learning, computer-human interaction, sensor and display technologies to solve real-world challenges that will transform users' experiences in ways we can only just glimpse on the horizon today.

TTT began as a small team in 2012 and brought its first concept -- the Samsung Gear watch -- to market one year later. Since then we have released several projects such as the Beyond 3D/360/4k camera for AR/VR cinematography, the BotChef cooking robot, the Ballie personalized companion, and others. We work on a wide variety of time scales, advancing science and applying it to create new products and experiences that will impact the lives of millions.

Our team members represent a diverse skillset, including electrical engineering, computer engineering, signal processing, machine learning, computer vision, visual design, interaction design, industrial design, optics, physics, and more from institutions such as MIT, Caltech, Stanford, CMU, Oxford and others. We believe that the best way to show is to design and build prototypes, and that the best products come from teams collaborating to understand and solve a problem from multiple perspectives. We believe that design and creativity are core duties of every member of our team.

Qualifications & Skills

You must be passionate about creating new devices and technologies, and ready to learn on the fly, solve complex problems, work closely with others, and creatively approach design and engineering tasks at all scales. We believe a person's work speaks for itself, and welcome everyone with the right drive, attitude, and skills.
BS/MS/PhD degree in Computer Science or related technical field or equivalent practical experience.
2 years of work experience in Machine Learning or Artificial Intelligence in real-world settings.
Strong C++ and/or Python skills.
Ability to rapidly prototype with leading ML frameworks.
Experience with current state-of-the-art methods from machine learning & deep learning libraries such as TensorFlow, Caffe, Scikit-Learn, Scipy, Pandas, Torch and others.
Experience with a multitude of machine learning methods such as SVMs, logistic regression, boosting, decision trees, clustering, HMMs etc.
Experience with CV libraries such as OpenCV
Experience in multiple forms of machine leaning, from the very simple to the most complex.
Experience in creation of novel custom features and pre-processing approaches to improve baseline algorithms. Work should go beyond using standard libraries.
Solid understanding of proper evaluation including folds, cross-validation and metrics.
Experience with one or more of the following: Natural Language Processing, GANs, autoencoders, Reinforcement Learning, CNNs, and others.
Flexibility to deal with rapidly changing environment.
Prior experience with signal processing from sensor data is a plus.
Responsibilities
Participate in cutting edge research in machine intelligence and machine learning applications. Leverage expertise from ML research and develop novel predictive models/algorithms
Develop solutions and algorithms that can be applied in variety of real-world applications and devices.
Work closely with researchers and engineers from variety of disciplines to develop new algorithms, product concepts and core-technologies that will bring new business opportunities to Samsung.
If this is something you would love to do, let us know. Show us what you have built, and tell us what you would like to build next!

Samsung is an EEO/Veterans/Disabled/LGBT employer. We welcome and encourage diversity as we strive to create an inclusive workplace.",3.5,"Samsung Research America
3.5","Mountain View, CA","Mountain View, CA",1001 to 5000 employees,1988,Subsidiary or Business Segment,Computer Hardware & Software,Information Technology,$50 to $100 million (USD),"Sony, LG Electronics, Nokia"
Principal Software Engineer,"$108K-$211K
(Glassdoor est.)","The Pindrop engineering team solves tough problems and invents new ways to battle fraud using big data and machine learning in the cloud. We are looking for a Principal Backend Software Engineer to join the Data Analytics team as we continue to develop new ways to fight fraud and improve security in voice channels.

The team is responsible for services that process billions of non-audio data events and contribute to our fraud detection and authentication capabilities. Key responsibilities include:
Designing, developing, testing, deploying, and monitoring high-performance, scalable APIs consumed by both cloud and on premise clients
Working with research scientists to design, develop, and deploy state-of-the-art machine learning models to detect fraudsters and positively identify genuine actors
Applying experience and knowledge of industry best practices to support and continuously improve the performance, efficiency, and maintainability of existing applications
what you'll do
Work with a growing team to design, develop, test, deploy, maintain and improve brand new software components and microservices
Refactor existing systems and architect new solutions
Develop applications in Golang and Python on top of a modern cloud focused platform
Maintain and manage services running in our Kubernetes platform
Develop and maintain AWS native services using products such as Kinesis, DynamoDB, and S3
Deliver production ready code from start to finish
Continuously improve service architecture
Create and maintain DataDog monitors
Review code to maintain quality with an eye towards performance, scale, and security
Work with multiple teams to implement company wide solutions
Assist in leading the full development life cycle of projects within the team
Identify and evaluate new technologies for implementation
Contribute to establishing and improving software engineering best practices
Help team members grow their technical expertise through mentoring and coaching
Be a role-model to engineers throughout the Engineering department
who you are
10+ Years of Software engineering experience
Strong expertise in multiple programming languages such Python, Go, Java or C++
Experience building Distributed and Scalable architectures
Expertise in Data Structures, Algorithms and Concurrency
Experience building microservices and RESTful APIs
Knowledge of different Data Storage technologies such as Redis, MySQL, etc.
Knowledge of Docker and container orchestration frameworks such as Kubernetes
Experience with AWS managed services such as S3, ElastiCache and DynamoDB
Experience with service monitoring solutions such as DataDog
Proven track record of providing stable and secure code in production environments
what we offer


As a part of Pindrop, you'll have a direct impact on our growing list of products and thus the future of security in the voice driven economy. We hire great people and take care of them. Here's a snapshot of benefits we offer:
Competitive salary
Paid Parental Leave
Company holidays
Paid time off
Pick your own Apple MacBook Pro
Retirement plan with 401k match
Health plans
Continued education budget (certifications, conferences, etc.)
Flex schedules
Best in class tools
Paid commuter options
Fun outings to celebrate our accomplishments as a team
All the good karma you can rack up for fighting bad guys (our conference rooms are named after the ones we've busted)
who we are


Pindrop is a company founded on research and continues to innovate new ideas to market. Our solutions are leading the way to the future of voice by establishing the standard for security, identity, and trust. Pindrop products secure the future of voice, making technology more human from the call center to IoT devices.

what we live by


Pindrop is driven by our DEPTH values. These are reflected in our goals and the base of our team's peer awards.

Act with Deliberate urgency.
Create Evangelical customers.
Passionate about the fight.
Playing for the Team.
Make Hard easy.

Pindrop is an Equal Opportunity Employer.

Here at Pindrop, it is our mission to create and maintain a diverse and inclusive work environment. As an equal opportunity employer all qualified applicants receive consideration for employment without regard to race, color, age, religion, sex, gender, gender identity or expression, sexual orientation, national origin, genetic information, disability, marital and/or veteran status.",4.0,"Pindrop
4.0","Atlanta, GA","Atlanta, GA",201 to 500 employees,2011,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
"Data Scientist, Two Sigma Private Investments","$116K-$152K
(Glassdoor est.)","Sightway Capital is a Two Sigma company focused on private equity investments. We employ a principal mindset and flexible capital approach to building successful business platforms with experienced operators and strategic partners. The team at Sightway Capital thinks long-term, targeting business opportunities that we believe afford both asymmetric risk rewards and enterprise value creation over time. Sightway’s unique platform building approach affords team members the opportunity to participate in each investment’s growth and success from an early stage. Data science is key to Sightway’s strategy, and we aim to leverage Two Sigma’s expertise, data sources and analytical models in order to make informed investment decisions, and create enterprise value and positive outcomes for our portfolio companies.

Sightway Capital is building a world class data science team in order to execute on this vision. The team has a multifaceted data driven private investment strategy that encompasses private equity deal sourcing, due diligence, and portfolio company value creation. This role includes working with business analysts to gather business needs and requirements from our portfolio companies; forming creative data driven hypotheses to solve these needs; using a range of statistical and machine learning methods using a range of different data sources in order to build models that prove or disprove these hypotheses; communicate findings to management and work with software engineers to craft solutions based on the models you build.

You will take on the following responsibilities:

Design and implement models that explore, predict, and optimize a range of key business drivers such as lead generation, customer risk, revenue, pricing
Work with business analysts to extract business needs from portfolio company management teams
Perform data exploration and visualization in order to uncover insights from data
Brainstorm hypotheses to solve business needs
Work with Data Strategy team to source and on-board new data sets and portfolio company technical teams to on-board company data
Build models using a range of analytical techniques in order to prove or disprove hypotheses
Prepare and present findings to TSPI management, portfolio executive team
Work with software engineers to engineer tools that use production models to deliver impact for the portfolio company
You should possess the following qualifications:
1-5+ years of experience in applied data analysis & prediction, preferably in an industry setting
Experience solving business problems using data science by directly interfacing with a client’s management team would be ideal
Degree in a technical or quantitative disciplines, like statistics, mathematics, physics, electrical engineering, or computer science
Demonstrably strong data science modeling intuition and feature engineering creativity
Intimate familiarity with the potential flaws & fallacies in the applications of specific statistical methods
Experience specifying & managing requirements for datasets leveraged in your analyses
Working knowledge of SQL and common data science toolkits : Python, R, Spark, Matlab
Strong written & verbal communication and presentation skills, with experience crafting a compelling narrative supported by data
A portfolio of open-data analyses or data-driven research publications would be ideal
You will enjoy the following benefits:
Core Benefits: Fully paid medical and dental insurance premiums for employees and dependents, competitive 401k match, employer-paid life & disability insurance
Perks: Onsite gyms with laundry service, wellness activities, casual dress, snacks, game rooms
Learning: Tuition reimbursement, conference and training sponsorship
Time Off: Generous vacation and unlimited sick days, competitive paid caregiver leaves
We are proud to be an equal opportunity workplace. We do not discriminate based upon race, religion, color, national origin, sex, sexual orientation, gender identity/expression, age, status as a protected veteran, status as an individual with a disability, or any other applicable legally protected characteristics.",4.4,"Two Sigma
4.4","New York, NY","New York, NY",1001 to 5000 employees,2001,Company - Private,Investment Banking & Asset Management,Finance,Unknown / Non-Applicable,-1
"Senior Data Engineer, Ingestion","$121K-$218K
(Glassdoor est.)","Chime is the largest and fastest-growing player in the challenger-banking space, providing mobile and online banking technology in the U.S. on behalf of partner banks and facilitating over 10M accounts with no physical branches. We're a technology company relentlessly focused on helping our members achieve financial peace of mind. That's why we offer access to an award-winning bank account that doesn't charge a ton of traditional bank fees, can give members early access to their paychecks, and enables members to grow their savings automatically. And we're just getting started. We are proud of our mission, devoted to our members, and passionate about applying technology to the challenge of making financial health a reality for everyone.

We have one of the most experienced management teams in Fintech and have raised over $800M in funding from DST, General Atlantic, Iconiq, Coatue, Dragoneer, Menlo, Access, Forerunner, and others. If you're looking to join a fast-growing company with a beloved, daily-use product and an authentic mission that puts people first, we want to meet you.

About the Role

In this role, you'll be responsible overseeing the design, development and operations of large-scale, real-time data systems. The ideal candidate will be excited by the prospect of owning, optimizing or even re-designing our company's data architecture and building out a team to support our next generation of products and data initiatives. The data engineering team will support our software developers, database architects, data analysts, data scientists, and machine learning engineers on back-end data initiatives.

Responsibilities

We're looking for a leader who is self-directed and comfortable supporting the data needs of multiple teams, systems and products. Your responsibilities will include:
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS 'big data' technologies
Work with stakeholders including the Analytics, Risk, Machine Learning, and Technical Operations teams to assist with data-related technical issues and support their data infrastructure needs
Participate in key technical and design discussions with technical leads in the team as a hands-on manager
Act as a project manager for the projects that your team is responsible for
Provide technical leadership to your team by giving guidance on designs and coding when time allows
Help manage and consult in designing our data governance initiatives
Requirements
6+ years of experience in designing, implementing, optimizing and operationalizing real-time big data analytics systems including data-pipelines, data warehouses and enterprise wide data-flows
You've earned a bachelor's degree in Computer Science or other technical field
Understanding of the tradeoffs between different big data solutions
Strong analytic skills related to working with unstructured datasets
Experience with a variety of traditional, streaming, and big data tools such as:
Hadoop ecosystem: Hadoop, Hive, Spark
Kafka, Sqoop, Flume
Airflow or other workflow scheduler
Data Warehouses: Redshift, Snowflake (preferred)
SQL databases, including MySQL, Postgres
AWS cloud services: EC2, EMR, RDS
Stream-processing systems: Storm or Spark-Streaming or equivalent.
Advanced SQL, Python, Java and/or Scala
What we offer
Competitive salary based on experience, with medical and dental benefits.
Free snacks and drinks, plus weekly catered lunches.
Flexible vacation policy.
Monthly happy hours and company events.
A challenging and fulfilling opportunity to join one of the most experienced teams in FinTech and help create a completely new kind of banking service.
We know great work isn't done alone. We're building a team of individuals to Chime in with their different strengths to benefit our employees and members. We strongly believe that different backgrounds and ideas are a competitive advantage; we hire candidates of any race, color, ancestry, religion, sex, national origin, sexual orientation, gender identity, age, marital or family status, disability, Veteran status, and any other status. Chime is proud to be an Equal Opportunity Employer and will consider qualified applicants with criminal histories in a manner consistent with the San Francisco Fair Chance Ordinance. If you have a disability or special need that requires accommodation, please let us know. To learn more about how Chime collects and uses your personal information during the application process, please see the Chime Applicant Privacy Notice.",4.8,"Chime
4.8","San Francisco, CA","San Francisco, CA",201 to 500 employees,2013,Company - Private,Banks & Credit Unions,Finance,Unknown / Non-Applicable,-1
Data Engineer – Full-Time,"$105K-$121K
(Glassdoor est.)","Job Description

Data Engineers are tasked with building and maintaining our bespoke enterprise data pipelines. They take ownership of our data pipelines, starting with how we ingest data from the outside world, to transforming that information into actionable insights, to ultimately designing the interfaces and APIs that our analysts and quants use to monetize that information. Throughout that process our data engineers work side-by-side with investment professionals and data scientists to design systems that are solving our must challenging problems and answering the most difficult questions in the hedge fund industry.

Key Responsibilities:


· Develop solutions that enable internal analysts to efficiently extract insights from data. This includes owning the ingestion (web scrapes, S3/FTP sync, bespoke processes), transformations (Python, Perl) and interface (API, schema design, events, etc.)

· Build tooling and automation around data pipelines that improve the efficiency, quality and resiliency of our data platform

· Partner with internal analysts, quants and data scientists to design, develop, test and deploy solutions that answer fundamental questions about financial markets.

· Take on an entrepreneurial mentality by building and selling your own ideas. We work in an evolving space and we expect you to help design our evolution by challenging the status quo and independently identifying opportunities to improve the entire data organization.

Required Skills

· A deep passion for working with data and developing software to address data processing challenges

· Bachelor’s, Master’s or PhD degree in Computer Science or equivalent experience

·Proficiency within one or more programming languages like Java, Python, Perl or JavaScript.

· Proficiency with RDBMS, or NoSQL

· Experience with some of the following areas: Distributed Computing, Natural Language Processing, Machine Learning or Software Architecture

· Experience with any of the following systems: Apache Airflow, AWS/GCP/Azure, Jupyter, Kafka, Docker, Nomad/Kubernetes

· Strong written and verbal communications skills

· Ability to manage multiple tasks and thrive in a fast-paced team environment

About Citadel


Citadel is a global investment firm built around world-class talent, sound risk management, and innovative leading-edge technology. For a quarter of a century, Citadel’s hedge funds have delivered meaningful and measurable results to top-tier investors around the world, including sovereign wealth funds, public institutions, corporate pensions, endowments and foundations.

With an unparalleled ability to identify and execute on great ideas, Citadel’s team of more than 675 investment professionals, operating from offices including Chicago, New York, San Francisco, London, Hong Kong and Shanghai, deploy capital across all major asset classes, in all major financial markets.

Apply Now",3.8,"Citadel
3.8","New York, NY","Chicago, IL",1001 to 5000 employees,1990,Company - Private,-1,-1,$50 to $100 million (USD),"Soros Fund Management, D. E. Shaw & Co. - Investment Firm, Fortress Investment Group"
Data Science All Star Program - Data Engineer Track,"$64K-$81K
(Glassdoor est.)","Data Science All Star Program - Data Engineer Track

Job Title

Data Science All Star Program - Data Engineer Track

Job
ID

27260177

Duration

Location

Columbia,

MD

Other Location

Description

Dynamic, Fast-growing, Entrepreneurial Data Science Solutions Company seeking data Engineers! If you’ve got entrepreneurial spirit and passion, are driven by results, and want to be a part of significant growth, we’re looking for you!

BLEND360 is a multi-award winning Marketing Company who is privileged to provide our services to some of the most respected and recognized brands in the world. At BLEND360 it is all about advancing our clients marketing capabilities and performance.

If you are ready to ignite the fire for digital marketing and join our team, please keep reading!

*************************************************************************************

Our Data Science All Stars Program is a 6-month consultant training program for master’s graduates in Analytics, Statistics, Computer Science and other quantitative programs. Participants will have the opportunity to learn from top Data Scientists, work on real-world analytics projects, and gain experience with Fortune 500 clients across a variety of verticals. They will work alongside our Data Scientists to get data into proper shape, perform statistical analyses and develop predictive models to solve our clients’ business problems.

The primary objective of this program is to develop participants into productive, client engaged BLEND360 employees and set the foundation to build a fast track career in one of 4 areas:

Data Science

Data Engineering

Marketing- Adobe Cloud

Marketing Analytics .

The All-Star focused on Data Engineering will:
Work with business leaders to solve clients’ business challenges and improve clients’ business results using advanced analytics techniques. We contribute our Advanced Data Science subject matter expertise to the recommendations and solutions delivered to our clients.
Spend most of their time on getting data into proper shape, performing statistical analyses, developing predictive models and machine learning algorithms to solve clients’ business problems. We evaluate different sources of data, discover patterns hidden within raw data, create insightful variables, and develop competing models with different machine learning algorithms. We validate and cross validate our recommendations to make sure our recommendations will perform well over time.
Partner with client technical resources as well as BLEND360 team members, providing guidance and solutions for data architectures, data conversions, ETL and implementation of models in a production environment. The ideal candidate has retail experience and can provide technical expertise working with cloud based platforms as well as traditional data warehouse environments.
Main Responsibilities
Work with practice leaders and clients to understand how to make data accessible and usable throughout the organization.
Defines data environment design for the reporting and modeling/machine learning use cases that is consistent, maintainable and flexible.
Works with client and BLEND360 teams to identify use cases and functional requirements that drive the reporting and modeling data solutions.
Designs the database structure including tables, views, synonyms, sequences, triggers, procedures, functions, indexes and materialized views as relevant.
Provides the framework for integrating source systems with the reporting and modeling data environments – develops the ERD and data dictionaries
Implements business rules via stored procedures, middleware, or other technologies.
Develops strategies for flexibility and scalability, and defines the future technical architecture direction for the business intelligence reporting and analytical environments.
Problem solve with practice leaders to understand how to build the data pipelines that can support the business, formulate different approaches, outline pros and cons for each approach.
Work with practice leaders to get client feedback, get alignment on approaches, deliverables, and overall timeline
Document data flow, infrastructure and processes.
Turn models and machine learning algorithms into implementable production code
The Details:
Location: Columbia, MD
Duration:Full-time
Travel Requirements:Up to 25% (could be as much as (30% - 40% depending on projects)
Benefits:Health, Vision, Dental, 401K plan, Life Insurance, Pretax Commuter Benefits, and an incredibly supportive team cheering you on!
Qualifications:

o MS or PhD degree in Operation Research, Advanced Analytics, Computer Sciences, Engineering

o 1+ years’ professional experience in Data Engineering practices, such as:
data warehousing, optimization, and productionalization with examples of increased responsibility and evolving technologies.
developing code and/or applications using software such as Pyspark, Python, SQL, Scala, Java, etc.
deploying machine learning and data science pipelines into production using model management solutions and leveraging CICD solutions (e.g., Jenkins) for automation
configuring cloud platforms and configuring elastic compute environments in a cloud platform
Familiarity with and understanding of modern machine learning approaches, algorithms, libraries, and processes for feature selection / engineering
Experience building containerized applications and deploying those applications using solutions like Kubernetes
Experience with structured or un-structured data processing tools (SQL, Hadoop, Spark, NoSQL, MySQL, MariaDB, Hive, Pig, etc)
Comfortable with cloud-based platforms (AWS, Azure, Databricks, Google)",4.6,"Blend360
4.6","Columbia, MD","Columbia, MD",51 to 200 employees,2002,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,-1
Computer Vision Software Engineer,"$99K-$174K
(Glassdoor est.)","Introduction

iRobot is looking to hire a Computer Vision Software Engineer on our Perception team who will play a vital role in developing the next generation of Robots that will live in millions of homes across the world. If you are a consumer centric pioneer eager to build innovative robot products, please apply now or reach out to one of our recruiters on LinkedIn.
What you will do
Develop algorithms for computer vision, SLAM, and related disciplines in challenging and dynamic environments
Design, implement, test, and document software and algorithms for desktop and embedded platforms, in C/C++ and other languages
Collaborate closely with team members on developing systems from prototypes to production level. Take solutions “over the wall” through manufacturing and customer deployment

To Be Successful You Will Have
Experience in state-of-the-art geometric computer vision and SLAM technologies
Hands-on experience developing computer vision systems
Solid understanding of computer vision fundamentals
Experience studying and implementing research papers from conferences such as CVPR, ICCV, ECCV, NIPS, ICPR, ICML
Excellence at writing embedded C/C++ and familiarity with a Linux Environment
Understanding and experience in design patterns, data structures and advanced programming techniques
BS in Computer Science, Electrical Engineering, or related field
Beneficial: M.S in Computer Science, Robotics, Computer Vision, or related field
In Return You Can Expect
To work on exciting problems in computer vision and SLAM deployed on the largest installed base of consumer robots
Be an integral part of a team dedicated to building the next generation of robots
Opportunities to continuously learn and collaborate with our innovative and knowledgeable technical staff including leading scientists in Computer vision, machine learning, and SLAM.
An attractive salary package with good benefits
Excellent career growth opportunities",3.5,"iRobot
3.5","Pasadena, CA","Bedford, MA",1001 to 5000 employees,1990,Company - Public,Consumer Electronics & Appliances Stores,Retail,$1 to $2 billion (USD),-1
"Senior Software Engineer, Data","$96K-$187K
(Glassdoor est.)","The Opportunity


Simply stated, Livongo exists to empower people with chronic conditions to live better and healthier lives. Livongo is seeking an engineer with an emphasis on data processing, transformation, fidelity and scalability. The applicant should have a strong interest in the interface between real-time and reporting systems, pulling data from multiple sources into central data storage, and collaborating with internal Livongo teams to help provide for their data needs.

What makes a Senior Data Engineer at Livongo different?
It is engineering! Members are why we come to work every day and our engineers design and developing the product, product features, and tools for members to have a best in class health consumer experience throughout their journey with Livongo
Strong communication skills especially around collaboration with internal Livongo teams
After our Members, data is pretty significant at Livongo and our engineers design and develop data pipelines to manage how data flows between our disparate systems
Develop real time member registration with our CRM, integrating data systems across businesses like MyStrength, Retrofit, Livongo, etc.
Work with Scala, Python, Tensorflow, Keras, SKL (or Scala/DL4J) to build production-grade machine learning (ML) pipelines and tools
Create tools and data sets to assist data science
Perform continuous integration to ensure that every step of an ML pipeline is testable and automated
Assist in maintaining data integrity in production systems
Use trained models to enable rapid experimentation
Participate in Agile planning around data feature requests and advocate for the best data engineering projects in priority planning.
Collaborating closely with Livongo's ML experts, Data Scientists, Product Managers and clinical researchers to build products that help people live better lives
Candidate Profile
Experience with big data technologies such as Hadoop and Spark, and a strong depth of expertise with at least one of these
Unshakeable (nearly innate) grasp of software engineering fundamentals
Specific experience creating and maintaining production pipelines
Keen attention to detail and a knack for prioritizing competing objectives
The ability to solve real-life business problems with data
A passion for using your work to improve lives
BS degree in Engineering, Computer Science or a related field. In lieu of degree, relevant work experience and/or trade school is acceptable
7+ years' experience in software development
3+ years in a data engineering role
Strong SQL development experience (Postgres / AWS Redshift/MySQL)
Expertise in Scala, Java, or Python
People and culture are Livongo's greatest and most valued assets! We've built a culture we are proud of that reflects our values of diversity and inclusion where everyone's voice is equally important.

Our Benefits Include
Competitive compensation packages
Comprehensive medical, dental, vision and 401K
Generous PTO policy
10 paid holidays each year
Lunch provided Monday through Thursday (in office)
An endless variety of healthy snacks and beverages to fuel your creativity
Employee Stock Purchase Plan
Employee Referral Bonus Program
Team events and social gatherings
Pet-friendly environment in Mountain View, CA and Denver
Diabetes Care Prescription Reimbursement
Discount/Subsidy program for gym membership
Provide the full line of Livongo programs and services to all employees and their families
The Opportunity


The Transformative Name in Healthcare: The transformative industry forces in Community, Content and Commerce are now household names. As Amazon is to Commerce, Livongo is to Healthcare. With our Applied Health Signals engine, AI+AI, we've transformed how care is delivered.

Our Work Truly Matters: Livongo's proprietary, consumer-first technology is revolutionizing the experience of living with a chronic health condition. Our data-driven digital health engine enables our Members to seamlessly manage multiple health conditions on one empowering platform. We use smart, connected devices, personalized digital guidance, and 24x7x365 access to health professionals to make it easier for people to stay healthier.

Make an Impact: Do you want to accomplish something meaningful? To create results that matter? Livongo's innovative solution produces industry-leading member satisfaction, measurable clinical outcomes and proven healthcare costs savings. Here you can truly improve lives.

The Largest Digital Health IPO in History: We are at a milestone period in our history. On July 25, 2019 we took our company public, in order to elevate and expand the way the industry views us, thus ushering us into a whole new set of mission-critical conversations that will help us accomplish the work still to be done. As we reach new levels of achievement, we accelerate our ability to deliver life-changing services.

Focus on PEOPLE: Livongo has been voted one of the Best Places to Work in healthcare, by Fortune Magazine and Best Place to Work! Talented, passionate individuals make the difference, in this fast-moving, collaborative and inspiring environment.

Diversity and Inclusion: At Livongo we believe that personal and professional diversity is the key to innovation. We hire based solely on your strengths and qualifications, and the way in which those strengths can directly contribute to your success in your new position.

Growth and Innovation: We've already made healthcare history, yet we remain on the threshold of very big things. Leading the industry with our Applied Health Signals category, we have cracked the code to transforming healthcare. Come grow with us and support our mission to make a tangible difference in the lives of our Members.

See photos, watch videos and learn more about Livongo: follow us on Glassdoor.

#LivongoIPO #appliedhealthsignals

As an Equal Opportunity Employer, we never have and never will discriminate against any job candidate or employee due to age, race, religion, color, ethnicity, national origin, gender, gender identity/expression, sexual orientation, membership in an employee organization, medical condition, family history, genetic information, veteran status, marital status, parental status or pregnancy (including breastfeeding we have a mother's room in both our offices). In our innovative and inclusive workplace, we prohibit discrimination and harassment of any kind.",4.6,"Livongo
4.6","Denver, CO","Mountain View, CA",501 to 1000 employees,2014,Company - Public,Health Care Services & Hospitals,Health Care,Unknown / Non-Applicable,-1
Machine Learning Engineer - Data Plus Math,"$121K-$204K
(Glassdoor est.)","Machine Learning Engineer - Data Plus Math

LiveRamp is the trusted platform that makes data accessible and meaningful. Our services power people-based customer experiences that improve the relevance of marketing and allow consumers to better connect with the brands and products they love. We thrive on solving the toughest technical and customer challenges, and we're always looking for smart, compassionate people to help us blaze a trail.

Mission: LiveRamp makes it safe and easy for businesses to use data effectively.

We are looking for an experienced Machine Learning Engineer to join our team and help us revolutionize the way TV advertising is measured. The ideal candidate is someone with experience working closely with data scientists and turning their models into scalable production code and systems. You will support and interface with our scientists, data engineers, architects and analysts to ensure optimal data delivery architecture is consistent throughout ongoing projects. You must be self-directed and comfortable supporting the data needs of multiple teams, systems and products.

You will:
Work hand-in-hand with our data science team to help them iterate over new models and new data sets rapidly and make those models operational for production.
Design self-running software to automate predictive models.
Design, develop and maintain the machine learning infrastructure that will power the next generation of our research and production.
Build infrastructure required for optimal ingestion, transformation, and loading of data from a wide variety of data sources using SQL and cloud agnostic technologies.
Your team will:

Consist of a cross-functional mix of Software Engineers and Data Scientists working closely to develop the next generation models that will power our TV Measurement platform.

About you:
5+ years of experience in an engineering capacity
Master's degree or higher, preferably, with a concentration in a computational field such as Computer Science, Mathematics, Statistics, Physics or other Engineering discipline
Advanced math skills (linear algebra, Bayesian statistics, group theory)
Experience implementing machine learning models, data pipelines and testing frameworks for research and production use.
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases
Experience with object-oriented/object-functional scripting languages: Python, Java, Scala, etc.
Experience processing large datasets using parallel, elastic, streaming and/or batch techniques (e.g. experience with Spark and or Presto a big plus).
Experience working on multiple clouds a plus (AWS, GCP, Azure)
Strong analytic skills related to working with unstructured data sets.
Bonus Points:
Experience with machine learning frameworks such as TensorFlow, Scikit-Learn, PyTorch or Keras
Good understanding of database internals, query processing and query optimization
Experience using object-relational mapping (ORM) frameworks
A desire to solve business problems with technology.
Great communication skills and the ability to influence stakeholders.
Strong interpersonal skills and exceptional character
Interest, willingness and demonstrated ability to quickly pick up new technology quickly
A self-starter who brings energy, passion, and creativity to work every day
Benefits:
People: work with talented, collaborative, and friendly people who love what they do.
Food: enjoy catered meals, boundless snacks, and the occasional food truck.
Fun: we host in-person and virtual events such as game nights, happy hours, camping trips, and sports leagues.
Work/Life Harmony: flexible paid time off, remote work opportunities, and paid parental leave.
Stock: every employee is a stakeholder in our future.
Whole Health Package: medical, dental, vision, and disability insurance. Plus mental health support (via Talkspace) and fitness reimbursement up to $100 per month.
Savings: our 401K matching plan helps you plan ahead.
Commuter Subsidy: $75 per month to be used toward commuter cards, monthly parking, rideshare pools, or metro/bus passes.
Location: work in the heart of Boston
More about us:

LiveRamp's mission is to connect data in ways that matter, and doing so starts with our people. We know that inspired teams enlist people from a blend of backgrounds and experiences. And we know that individuals do their best when they not only bring their full selves to work but feel like they truly belong. Connecting LiveRampers to new ideas and one another is one of our guiding principles—one that that informs how we hire, train, and grow our global team across eight countries and four continents.

LiveRamp is an affirmative action and equal opportunity employer (AA/EOE/W/M/Vet/Disabled) and does not discriminate in recruiting, hiring, training, promotion or other employment of associates or the awarding of subcontracts because of a person's race, color, sex, age, religion, national origin, protected veteran, disability, sexual orientation, gender identity, genetics or other protected status. Qualified applicants with arrest and conviction records will be considered for the position in accordance with the San Francisco Fair Chance Ordinance.

California residents: Please see our California Personnel Privacy Policy for more information regarding how we collect, use, and disclose the personal information you provide during the job application process.


To all recruitment agencies: LiveRamp does not accept agency resumes. Please do not forward resumes to our jobs alias, LiveRamp employees or any other company location. LiveRamp is not responsible for any fees related to unsolicited resumes.",4.6,"LiveRamp
4.6","Boston, MA","San Francisco, CA",1001 to 5000 employees,2005,Company - Public,Computer Hardware & Software,Information Technology,$100 to $500 million (USD),-1
Machine Learning Engineer,-1,"Machine Learning Engineer
Are you a Data Scientist with a strong Machine Learning background and want to join a profitable start-up? If so, please read on!

Based in the Palo Alto area, we are a leading AI SaaS Company! Our cutting edge software suite empowers businesses of all sizes to optimize their data on a secure platform! We are using the latest Machine Learning and Data Science technologies to help our clients see anywhere from 30-40% performance improvement over traditional methods! With these off-the-chart metrics, the demand for our innovative software solutions and services has gone through the roof! We now have an urgent need for talented Machine Learning Engineers to join our team!
Top Reasons to Work with Us
1. We are dedicated to building meaningful products that are changing lives!
2. Talented Technical Team utilizing the the latest technologies
3. Tons of room for career growth and Industry stability!
What You Will Be Doing
Join our collaborative team of talented Engineers as we continue to build and enhance new features for our dynamic applications!
- Work closely with cross-functional teams on generating ideas that you will then turn into efficient and functional code (python)
- Build and implement ML and statistical models based on pricing and behavioral analytics
-Develop design experiments, optimization systems and A/B testing
- Serve as the go-to resource for all data science related questions
What You Need for this Position
- 3+ years of professional experience in Data Science or Machine Learning
- Proficiency with Python and/or R
- Preferred experience with A/B Testing and Experiment Design
- Experience building practical Machine Learning solutions (ie. Neural Networks, xgboost, Gradient Boosted Decision Trees, Regression, etc.)
- Strong background in Pricing, Behavioral Economics and/or Demand Models
- Advanced Degree in Computer Science or related field
What's In It for You
EXCELLENT benefits including:
- Competitive salaries (DOE)
- Vacation/PTO
- Medical, Dental, Vision
- 401(k) and matching
- Catered meals and much more!
So, if you're a Machine Learning Engineer with strong experience, please apply today!

OR send your resume AND salary requirements to me directly at: brenna.boies@cybercoders.com
-
Applicants must be authorized to work in the U.S.


CyberCoders, Inc is proud to be an Equal Opportunity Employer

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, protected veteran status, or any other characteristic protected by law.

Your Right to Work In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification document form upon hire.",4.2,"CyberCoders
4.2","San Jose, CA","Irvine, CA",201 to 500 employees,1999,Subsidiary or Business Segment,Staffing & Outsourcing,Business Services,$100 to $500 million (USD),-1
Data Analyst/Data Scientist,-1,"Sr. Software Engineer – (Discovery Module)
About Privacera
Founded in 2016 by the creators of Apache Ranger™ and Apache Atlas™, Privacera’s mission is to empower enterprises building data platforms in the cloud to balance data governance and security with data access, discovery, and analytics. Often described as “Apache Ranger in the Cloud”, Privacera provides centralized access control that extends Ranger’s capabilities beyond traditional Big Data environments to cloud-native services and leading analytics platforms such as AWS, Azure, GCP and Databricks. Privacera enables IT and data platform teams to make as much data as possible available to the business for analytics while ensuring it is used ethically and in compliance with privacy regulations. Privacera offices are located in Fremont, California and Mumbai. To learn more, visit www.privacera.com
If you are a Data Scientist with a passion for solving major problems with Machine Learning and Big Data Analytics, this is a great opportunity to work with one of the industry’s leading security architects.
Principal Responsibilities:
· Development and implementation of Machine Learning algorithms in Big Data environment
· Work with Data Analysis Engineers, R&D and Product Management to solve complex customer problems and highlight opportunities
· Develop and communicate descriptive, diagnostic, predictive and prescriptive insights/algorithms
· Use machine learning and statistical modeling techniques
Minimum Requirements:
· Master or equivalent degree in a computational science
· 4+ years experience with Machine Learning
· Experience with traditional as well as modern statistical techniques, including Regression, Support Vector Machines, Regularization, Boosting, Random Forests and other ensemble methods
· Strong Analytical skills
· Proficiency in SQL and one or more of JAVA, Python and Scale
· In depth knowledge of statistical methods, data analysis and data mining
· Tuning PID loops for controllers a plus.",5.0,"Privacera
5.0","Fremont, CA","Fremont, CA",1 to 50 employees,-1,Unknown,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Principal Machine Learning Engineer,"$150K-$253K
(Glassdoor est.)","Principal Machine Learning Engineer

Cloud Solutions | US Austin Office

About the company:

In today's highly connected digital world, understanding, managing and securing the identity of individuals and things is essential to safety and success of both businesses and their customers. Billions of people connect from anywhere, use a wide variety of devices and expect a seamless yet secure experience.

The ForgeRock mission is to provide the most simple and comprehensive Identity and Access Management Platform to help our customers deepen their relationships with their consumers and improve the productivity and connectivity of their employees and partners. Our identity solution enables great digital experiences and is embedded with a rich set of security, privacy and consent features. We deliver our platform through both cloud services and on-premises software.

Our customers are some of the biggest companies, organizations, and even countries in the world. On any given day, it's likely that the ForgeRock Identity Platform helped keep your data safe, gave you access to stuff, and supported trusted relationships between you, companies and the devices you were using.

ForgeRock is headquartered in San Francisco, but we are a global company with offices in the following cities: Vancouver, WA; Austin, TX; Munich, Germany; London & Bristol, UK; Grenoble & Paris, FR; Oslo, NO; Singapore and Sydney, Australia. Please read more about us at forgerock.com or follow ForgeRock on Twitter at http://www.twitter.com/forgerock.

The Role:

We are looking for a highly motivated,Principal Machine Learning Engineer to build out the next generation Identity platform. This role requires someone to develop the technology and platform for data processing, feature engineering and analysis to propel company transformation into a data insight driven organization. Work with peers in cloud engineering, SRE to drive data driven insight through the enterprise. Work on complex, high scale machine learning models in production and develop cutting edge algorithms that are deployed directly to customers in real-time. If you are self-driven, passionate about learning, work well in a collaborative environment and have effective communication skills, then we'd love to hear from you!

Responsibilities:
Provide architectural leadership; conduct regular reviews of project work and peer review.
Help in development and scaling of data pipelines, feature pipelines and data lakes to support large scale processing of millions of data events.
Develop an industry view of analytics and design-driven problem solving. Use academic and competitor research to understand recent advances and best practices and inform our approach to developing solutions.
Required Skills and Qualifications:
Masters or PhD degree in computer science, mathematics, statistics, physics, or related quantitative field
Ten years of progressive experience in a data engineering or quantitative role.
Business acumen to work with business partners and understand their domains, processes, and issues to identify strategies to optimize and innovate
Ability to leverage data visualizations to highlight insights to business partners and make a business case for a recommended action or innovation opportunity
Proficient in the language of statistics with an advanced understanding of mathematical statistics, including combinatorics, probability, common discrete and continuous distributions, univariate and multivariate distributions, conditional probability, random variables, expectation, variance, convergence, estimation (bias, MSE, consistency, sufficiency, maximum likelihood, moments, etc.), hypothesis testing, and confidence intervals.
Ability to collaborate effectively with Data Scientists, product management, engineering, UI/UX
Theoretical and practical understanding of a range of machine learning techniques including unsupervised learning (e.g. clustering, outlier detection, PCA, ICA, NNMF, SVD, etc.), supervised learning (e.g., regression techniques, naive bayes, support vector machines, LDA, decision trees, neural networks, etc.), reinforcement learning (e.g., Q-learning, neural networks, etc.), and meta-methods (e.g., boosting, bagging)
Written communication skills to engage partners, document methodology and results, and publish research
Organizational and project management skills for overall project planning and task management
Solid understanding of (1) data structures, (2) sequential algorithms, (3) distributed algorithms, (4) runtime and space complexity
Knowledge of information technology integration and deployment patterns to design and implement solutions
Advanced proficiency in one of the programming languages like Java, Scala or Python.
Advanced proficiency in data processing frameworks like Pandas.
Advanced proficiency in TensorFlow, Keras, Cloud based ML frameworks, external ML libraries and NLP libraries.
Nice to haves:
Project and/or program management experience.
Experience in representing company in International ML conferences.
Proficiency in cloud and ML deployment strategies.
Docker, Kubernetes and VM experience
Life at ForgeRock:

We believe in and facilitate a flexible, collaborative work environment. We've grown enormously, but remain true to the innovative, can-do startup values that got us here. Most important of all, we keep hiring talented, smart, fun, and genuinely nice people because that's who we want to succeed with every day. Below are just a few of the great things we have to offer at ForgeRock:
A great team of smart, fun and genuinely nice individuals.
Awesome company culture focused around providing a flexible and collaborative work environment
Regular office bonding events, from lunches and happy hours to group offsites and hack-days
Well-stocked fridges, whether you're hungry or thirsty
Competitive benefits and perks
We're Mac-friendly!
Generous employee referral bonus program
Amazing offices across the globe San Francisco HQ; Vancouver, WA; Austin, TX; Munich, Germany; London & Bristol, UK; Grenoble & Paris, FR; Oslo, NO; Singapore, Australia & counting!
ForgeRock is the collective sum of all our individual experiences, backgrounds and influences and we pride ourselves in growing and learning together. We are committed to building an inclusive and diverse environment where everyone's individuality is respected and everyone has an Identity. In recruiting for new colleagues, we welcome the unique contributions you can bring and encourage you to be your best self.

ForgeRock is an Equal Opportunity/Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex including sexual orientation and gender identity, national origin, disability, protected Veteran Status, or any other characteristic protected by applicable federal, state, or local law.",3.9,"ForgeRock
3.9","Austin, TX","San Francisco, CA",501 to 1000 employees,2010,Company - Private,Enterprise Software & Network Solutions,Information Technology,$50 to $100 million (USD),"Okta, Ping Identity, Oracle"
"Software Engineer, Machine Learning - Search and Recs","$108K-$182K
(Glassdoor est.)","Company Description

As an Etsy employee, you can do the work you love, be yourself, and make an impact in the lives of millions. Our commitments to diversity and inclusion, team culture and the spaces where we work all reflect our mission to keep commerce human.

Job Description

About the Team

Our teams are responsible for search ranking and recommendations. Our aim is to present the best of Etsy's inventory. As an engineer on our team, you will play a major role in improving the shopping experience for millions of Etsy buyers. We're a cross-functional group of engineers, data scientists, product managers, designers, and researchers.

With your help, we are giving our buyers better tools to find what they are looking for and to help them form a connection with our sellers. In this role, you will put your skills to use by helping us improve the ranking and suggestions of localized results through machine learning algorithms. You will also create workflows and pipelines to effectively transform data into appropriate results for our buyers. You will join a talented team of engineers to collaborate on all of these projects.

In this role, you will have the opportunity to work with our Data Science and ML team, Data Platform team and many more product squads. We're a growing team with a huge impact that builds tools and platform capabilities for data scientists and ML engineers to access feature data, build machine learning models, test hypotheses and productionize them on our ML platform hosted in Google Cloud. We value empathy, communication and technical skills equally. Here's a taste of the problems we're solving:
How can we help someone find that perfect item, even when they don't know what they're looking for?
How do we rank millions of search results in a matter of milliseconds, so that we're always surfacing the best of Etsy?
How can we maximize the relevance of search results over an enormous range of queries and buyers?
How can the search experience make Etsy come to life and feel as vibrant as the community of makers that's behind it?
How can we understand buyer's motives and interests to personalize their experience?
How can we help buyers to explore the breadth of Etsy's inventory?
Our production systems rely on PHP, JavaScript, Java, Python and Scala; we are proud to have an engineering culture that encourages career growth and learning. You can learn more about our philosophies, tools, and some of the challenges we've been solving on our Engineering blog: http://codeascraft.com/

We are language-agnostic in our approach to interviewing.

This role is located in our Brooklyn HQ.

Qualifications
Experience with objective-oriented programming languages: Python, Java, Scala, etc.
Familiarity with machine learning and deep learning solutions across the entire machine learning stack, from data collection to evaluation
Experience with machine learning frameworks (like PySpark, Scalding, etc.)
Strong verbal and written communication skills.
About the Role

In this role you will:
Contribute at all levels of Etsy's search and recommendations stacks, ranging from application back-end technologies (PHP, Java, Python, MySQL, Scala, Vertica) as well as machine learning stack (PySpark, Scalding, Airflow).
Work cross-functionally with various engineering teams (e.g. machine learning infrastructure, data science, search experience), participating in design, prioritization and implementation.
Develop and train machine learning data sources and models, both to iterate on existing features and develop new features.
Use feature engineering tools and principles to clean and transform data into signals driving listing quality
Deploy models to production, sometimes including application development for your feature.
Provide detailed and constructive design and code reviews.
Empathy, communication, and technical skill are valued equally.
About You

You will do well in this role if you:
Enjoy thinking about the implications of your work on end users.
You are comfortable collaborating with Product Managers, Data Analysts, and Designers to ensure that you're delivering impactful product features.
Have experience operating within a large codebase and working to create simplicity from complex systems, including using experiments and data to drive decision making.
Are an analytical thinker and understand how to wield data to make informed decisions about your work.
Write understandable, testable code with an eye towards maintainability.
You turn ideas into deeply reliable and well tested code that other people - or you, six months into the future - will find easy to comprehend and modify.
You have worked with machine learning and understand the needs of data scientists and ML engineers.
You have solid engineering and coding skills, data structure knowledge and ability to write high performance production quality code.
Additional Information

At Etsy, we believe that a diverse, equitable and inclusive workplace makes us a more relevant, more competitive, and more resilient company. We welcome people from all backgrounds, ethnicities, cultures, and experiences. Etsy is an equal opportunity employer. We do not discriminate on the basis of race, color, ancestry, religion, national origin, sexual orientation, age, citizenship, marital or family status, disability, gender identity or expression, veteran status, or any other legally protected status. We will ensure that individuals with disabilities are provided a reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. While Etsy supports visa sponsorship, sponsorship opportunities may be limited to certain roles and skillsets.",3.6,"Etsy
3.6","Brooklyn, NY","Brooklyn, NY",501 to 1000 employees,2005,Company - Public,Other Retail Stores,Retail,$100 to $500 million (USD),"Airbnb, Warby Parker, Kickstarter"
Machine Learning/Data Engineer,"$69K-$120K
(Glassdoor est.)","WHO WE ARE:

We're passionate about food and driven by data.

Do you want to impact our future through data, analytics and innovative technology? Do you thrive on leading big things and making it happen? Bring your passion, expertise and problem-solving skills to the table and make an impact.

General Mills is reshaping the future, and technology & data play an important role for us. Your technology experience will help us get the right data and solutions at the right time, every time. As one of the world's leading food companies,

General Mills operates across the globe with more than 100 recognizable consumer brands, including: Cheerios, LÄRABAR, Pillsbury, Yoplait, Annie's Homegrown, Totino's, Epic Provisions and Blue Buffalo.

WHAT YOU'LL DO

As a Machine Learning / Data Engineer, you will work closely with a multidisciplinary agile team to build high quality data pipelines driving analytic solutions. These solutions will generate insights from our connected data, enabling General Mills to advance the data-driven decision-making capabilities of our enterprise. This role requires deep understanding of data architecture, data engineering, data analysis, reporting, and a basic understanding of data science techniques and workflows. This team is amid transitioning data engineers into machine learning engineers. In addition, we are moving from Hadoop to Google Cloud. In this role you will:
Increase the Team's ability to understand, train, and develop ML models and supporting data pipelines
Utilize machine learning models as APIs or software libraries to be integrated into a cloud application
Establish scalable, efficient, automated processes for large scale data analyses, model development, validation, and implementation.
Design, develop, optimize, and maintain data architecture and pipelines that adhere to ETL principles and business goals.
Solve complex data problems to deliver insights that helps our business to achieve their goals
Create data products for analytics and data scientist team members to improve their productivity
Advise, consult, mentor and coach other data and analytic professionals on data standards and practices
Foster a culture of sharing, re-use, design for scale stability, and operational efficiency of data and analytical solutions
Lead evaluation, implementation and deployment of emerging tools & process for analytic data engineering to improve our productivity as a team
Develop and deliver communication & education plans on analytic data engineering capabilities, standards, and processes
Partner with business analysts and solutions architects to develop technical architectures for strategic enterprise projects and initiatives.
Learn about machine learning, data science, computer vision, artificial intelligence, statistics, and/or applied mathematics
WHO YOU ARE
Bachelor's Degree
Two (2+) or more years of professional experience in data engineering, software development/engineering, or data science
Two (2+) or more years of hands on development with frameworks such as Python, Java, Scala
Experience of developing, deploying, maintaining and debugging ML / Data Science models in a production environment
Expertise in SQL and data analysis and experience
Experience developing and maintaining data warehouses in big data solutions
Exposure to machine learning, data science, computer vision, artificial intelligence, statistics, and/or applied mathematics
Big Data development experience using Hadoop, Hive, BigQuery, Impala, Spark and familiarity with Kafka
Experience working with BI tools such as Tableau, Power BI, Looker, Shiny
Conceptual knowledge of data and analytics, such as dimensional modeling, ETL, reporting tools, data governance, data warehousing, structured and unstructured data.
Exposure to machine learning, data science, computer vision, artificial intelligence, statistics, and/or applied mathematics
Passion for agile software processes, data-driven development, reliability, and experimentation
Experience working on a collaborative agile product team
Excellent communication, listening, and influencing skills
WHAT'S NICE TO HAVE
Bachelor's degree in Computer Science, MIS, or Engineering
5+ years applicable work experience
Experience with developing solutions on cloud computing services and infrastructure in the data and analytics space
Familiarity with the Linux operating system
Experience with OLAP such as AtScale, SSAS, SAP BW, Essbase
Knowledge of Data Preparation, Data Wrangling, and Feature Engineering
Experience work with Google's cloud data ecosystem",3.8,"General Mills, Inc.
3.8","Minneapolis, MN","Minneapolis, MN",10000+ employees,1866,Company - Public,Food & Beverage Manufacturing,Manufacturing,$10+ billion (USD),-1
Machine Learning Engineer,"$108K-$186K
(Glassdoor est.)","CircleUp harnesses the power of machine learning and predictive analytics to discover some of the fastest-growing companies in the consumer & retail sector. We are building a predictive data system called ""Helio"" to bring the data-driven revolution that has occurred in the public markets to the private markets, starting with consumer & retail.

We are working on challenging problems in information retrieval, entity resolution, and developing an in-depth knowledge graph of all private companies. We are mining vast amounts of data to successfully rewrite the rules on how private companies are evaluated.

With a background in both software development and machine learning, you will collaborate with software engineers, data scientists, PMs, and domain experts in consumer investing to develop & ship predictive data products in support of CircleUp's mission - helping entrepreneurs thrive by connecting them with the capital & resources they need.

You are a passionate software engineer who is comfortable working across the full stack & lifecycle of predictive data products - prototyping, feature engineering, validation, and productionalization.

Responsibilities:
Collect and refine structured and unstructured data on private companies
Build out our entity resolution platform that can identify references to companies, brands and products in highly unstructured digital documents and link them back to real world entities
Build scalable production systems for data collection, data transformation, feature extraction, model training, and scoring, using distributed software tools
Build end to end algorithms for objectively measuring the quality of private consumer companies
Contribute to all phases of algorithm development including ideation, prototyping, design and production
We're looking for teammates who have:
Bachelor's degree or higher in Computer Science, Information retrieval, Natural Language processing, Math, Statistics or related technical field
2+ years of experience in machine learning, NLP and/or information retrieval
Broad knowledge of machine learning APIs, tools, and open source libraries
Excellent coding skills and strong fundamentals in algorithms, data structures, predictive modeling and big data concepts
Experience putting models into production systems is a huge plus
If you got to this point, we hope you’re feeling excited about the job description you just read! Even if you feel that you don't meet all of the requirements and qualifications, we still encourage you to apply. We’re eager to speak with those who share our passion to help entrepreneurs thrive - not just those who match every bullet point in our job descriptions.

CircleUp is an equal opportunity employer. We do not discriminate based upon race, religious creed, color, national origin, ancestry, physical or mental disability, medical condition, genetic information, marital status (including registered domestic partnership status), sex and gender (including pregnancy, childbirth, lactation and related medical conditions), gender identity and gender expression (including transgender individuals who are transitioning, have transitioned, or are perceived to be transitioning to the gender with which they identify), age, sexual orientation, Civil Air Patrol status, military and veteran status and any other consideration protected by federal, state or local law. We encourage those who really want to make an impact to apply for our open positions.",4.5,"CircleUp
4.5","San Francisco, CA","San Francisco, CA",51 to 200 employees,2012,Company - Private,Venture Capital & Private Equity,Finance,Unknown / Non-Applicable,-1
"Machine Learning Engineer, Conversations","$127K-$208K
(Glassdoor est.)","Square builds common business tools in unconventional ways so more people can start, run, and grow their businesses. When Square started, it was difficult and expensive (or just plain impossible) for some businesses to take credit cards. Square made credit card payments possible for all by turning a mobile phone into a credit card reader. Since then Square has been building an entire business toolkit of both hardware and software products including Square Capital, Square Terminal, Square Payroll, and more. We're working to find new and better ways to help businesses succeed on their own terms-and we're looking for people like you to help shape tomorrow at Square.The Conversations team at Square is building Square Assistant -- a virtual assistant to help merchants serve their customers. Today, Square Assistant responds to customers asking for help with their appointments, including cancellations, confirmations, and conversational rescheduling of appointments; as well as, of course, answering common questions. Looking into 2021 we're excited to expand Square Assistant with new skills to save merchants as much time as we can, and we're excited to bring Square Assistant to the phone: adding voice capabilities to the bot. The team itself was created in mid-2019 with the acquisition of Eloquent Labs.We're looking for NLP engineers and research scientists, particularly those with an interest in dialog systems, speech, and/or textual entailmentYou will...* Help design and develop novel dialog systems within Square* Build AI systems to handle millions of conversations* Work with Backend, iOS, and web engineers to ship features.* Work cross collaboratively with product managers and designers to improve and define product scope and design.* Ship cutting-edge AI to businesses that traditionally haven't had access to itYou have* Experience with machine learning, with a specialization in natural language processing* Experience with Python and PyTorch is recommended* Experience in Java is a plus* Interest to help shape the mission and roadmap of a team, and rallying others to join you* Eagerness to share your ideas, and openness to those of othersLanguages and technologies we use (and teach)...* Python and Java for development* PyTorch for training ML models* SQL for storing and processing analytics data from the bot* AWS for training and serving ML modelsAt Square, we value diversity and always treat all employees and job applicants based on merit, qualifications, competence, and talent. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. We will consider for employment qualified applicants with criminal histories in a manner consistent with the requirements of the San Francisco Fair Chance Ordinance. Applicants in need of special assistance or accommodation during the interview process or in accessing our website may contact us by sending an email to assistance(at)squareup.com. We will treat your request as confidentially as possible. In your email, please include your name and preferred method of contact, and we will respond as soon as possible.PerksAt Square, we want you to be well and thrive. Our global benefits package includes:* Healthcare coverage* Retirement Plans* Employee Stock Purchase Program* Wellness perks* Paid parental leave* Flexible time off* Learning and Development resources",4.0,"Square
4.0","Redwood City, CA","San Francisco, CA",1001 to 5000 employees,2009,Company - Public,Computer Hardware & Software,Information Technology,$1 to $2 billion (USD),-1
Machine Learning / Data Scientist,-1,"Job Description
Our client is a digital invention agency focused on machine learning methodologies, enterprise mobile and web applications, eCommerce, augmented reality and IoT. They look to innovatively make this world a better place with each and every product, system, idea and app they release.

Job Summary

Our client is looking for a machine learning engineer to join our existing ML team in developing and refining a predictive application.

The ideal candidate is adept at using large data sets to find opportunities for product and process optimization and using models to test the effectiveness of different courses of action.

You must have strong experience using a variety of data mining/data analysis methods, using a variety of data tools, building and implementing models, using/creating algorithms and creating/running simulations. You must have a proven ability to drive business results with their data-based insights. You must be comfortable working with a wide range of stakeholders and functional teams. The right candidate will have a passion for discovering solutions hidden in large data sets and working with stakeholders to improve business outcomes.

As a ML Engineer, you will:
Work with stakeholders throughout the organization to identify opportunities for leveraging data to drive business solutions
Mine and analyze data from databases to drive optimization and improvement of product development, marketing techniques and business strategies
Assess the effectiveness and accuracy of new data sources and data gathering techniques
Develop custom data models and algorithms to apply to data sets
Use predictive modeling to increase and optimize customer experiences, revenue generation, ad targeting and other business outcomes
Coordinate with different functional teams to implement models and monitor outcomes
Develop processes and tools to monitor and analyze model performance and data accuracy
For this role you will need:
Strong with Statistics and can code in either R, Python, Java and Scala
Experience with designing and building using micro-services architectural pattern, web APIs using dotnet core & C#
Experience and passion for simulations, optimization, neural networks, artificial intelligence (deep learning and machine learning)
Experience with distributed data/computing tools: Map/Reduce, Hadoop, Hive, Spark, GIT, SQL, etc.
Able to understand statistical solutions and execute similar activities
Experience in data wrangling and advanced analytic modeling
Strong communication and organizational skills and has the ability to deal with ambiguity while juggling multiple priorities and projects at the same time
Experience visualizing/presenting data for stakeholders using: Seaborn, Business Objects, D3, ggplot, etc.
Ability to investigate the feasibility and data requirements necessary to develop an ML solution for a given problem
Ability to design, build and test production ready ML-based products while interpreting and explaining the basis for predictions generated by ML models
The perfect candidate will have:
Knowledge and experience using one or more of the following, or similar, machine learning software frameworks: CAFFE, Torch 7, Keras and Tensorflow
Experience building production-ready NLP or information retrieval systems
Hands-on experience with NLP tools, libraries and corpora (e.g. NLTK, Stanford CoreNLP, Wikipedia corpus, etc.)
PROPRIUS is an AI Industry recruiting firm. We’re lucky enough to recruit the best candidates into the most exciting companies all over the United States. We deliver performance.
LI-Y",5.0,"PROPRIUS
5.0","San Francisco, CA","London, United Kingdom",1 to 50 employees,-1,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
"Machine Learning Engineer, Data Science","$122K-$209K
(Glassdoor est.)","Atlassian is continuing to hire with all interviewing and on-boarding done virtually due to COVID-19. Everyone new to the team, along with our current staff, will temporarily work from home until it is safe to return to our offices.

Do you have a passion for crafting products and insights with data? Do you love the idea of rapidly iterating on new features and finding the ones which move the needle and hit customer engagement out of the ballpark? Would you like to drive real change at the world’s hottest SaaS company?
Atlassian is looking for a Machine Learning Engineer to join our Data Science team based in Mountain View CA. We are looking for someone passionate about data science and its applications to create business value. You enjoy working with cutting edge technology, and you relish the opportunity to make an impact to the way millions of users use our products in their day-to-day work. You are able to work effectively with a variety of other disciplines across the company.

In a data-hungry place like Atlassian experiencing rapid growth, business opportunities from the application of data science abound. Join us for the opportunity to do groundbreaking applied machine learning work that will help shape the Atlassian user experience!
In this role, you'll get to
Construct and refine AI algorithms to optimize our marketing and on-boarding funnels
Craft machine learning and predictive models to drive intelligent product features
Work with our seriously large volume of analytics data
Define and build out scalable distributed infrastructure to support our vision of optimized real-time personalization across the portfolio of Atlassian products
Extend existing ML libraries and frameworks
Research and implement appropriate ML algorithms and tools
Provide technical leadership and influence data-driven optimization efforts.
Challenge and enrich yourself in an environment of like-minded engineers and data scientists, and most importantly have fun!
On the first day, we'll expect you to have
MS or PhD in Computer Science or a related quantitive field
5+ years of related industry experience in a data science or engineering domain
Development experience in a Python/ Java/ Scala
Experience working in an Agile environment
Extensive data modeling and data architecture skills
Knowledge of Spark or other distributed cloud computing systems
Experience developing, building and scaling machine learning models in business applications using large amounts of data
Strong written and verbal communication skills

It's great, but not required, if you have
Experience working in an enterprise or B2B space, as well as the consumer or B2C space
Working knowledge of DataBricks environment
Experience with ML platforms such as MLflow, MLeap, MichelAngelo
Knowledge of A/B experimentation
This team is being built within the broader Analytics group and tasked to pursue business opportunities that can generate revenue or MAU improvements. The team works multi-functionally across the organization, using insights generated by marketing and product analytics that can be scaled or automated to generate business value. The team will be highly nimble, with a focus on velocity between ideation and initial output, and laser-focused on business impact.

More about our benefits

Whether you work in an office or a distributed team, Atlassian is highly collaborative and yes, fun! To support you at work (and play) we offer some fantastic perks: ample time off to relax and recharge, flexible working options, five paid volunteer days a year for your favourite cause, an annual allowance to support your learning & growth, unique ShipIt days, a company paid trip after five years and lots more.

More about Atlassian

Creating software that empowers everyone from small startups to the who’s who of tech is why we’re here. We build tools like Jira, Confluence, Bitbucket, and Trello to help teams across the world become more nimble, creative, and aligned—collaboration is the heart of every product we dream of at Atlassian. From Amsterdam and Austin, to Sydney and San Francisco, we’re looking for people who want to write the future and who believe that we can accomplish so much more together than apart. At Atlassian, we’re committed to an environment where everyone has the autonomy and freedom to thrive, as well as the support of like-minded colleagues who are motivated by a common goal to: Unleash the potential of every team.

Additional Information

We believe that the unique contributions of all Atlassians is the driver of our success. To make sure that our products and culture continue to incorporate everyone's perspectives and experience we never discriminate on the basis of race, religion, national origin, gender identity or expression, sexual orientation, age, or marital, veteran, or disability status.

All your information will be kept confidential according to EEO guidelines.",4.4,"Atlassian
4.4","Mountain View, CA","Sydney, Australia",1001 to 5000 employees,2002,Company - Public,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,GitHub
eCom Full Stack Senior Engineer,"$89K-$153K
(Glassdoor est.)","Auto req ID: 213130BR
Job Description


The next great shift in consumer behavior driven by technological disruption is underway, and it’s happening in the food & beverage industry.

As other sectors have shifted to eCommerce-first business models in recent years, food & beverage has continued to rely predominantly on traditional brick & mortar models, but this is changing rapidly. New technologies are transforming every aspect of reaching consumers, from the rise of digital marketing and online grocery platforms to the creation of supply chain tools that enable speedy at-home delivery. According to the Food Marketing Institute, 70% of U.S. consumers will shop online for groceries by 2024, with an estimated annual spend of $100 billion.

To deepen our efforts to seize this opportunity and lead the food & beverage industry into its remarkable next chapter, PepsiCo – a global company with powerhouse brands including Frito-Lay, Gatorade, Pepsi-Cola, Quaker, and Tropicana – is expanding its Global eCommerce Team. We’re looking for the greatest minds in software engineering, data & analytics, machine learning and next-generation supply chain. Given PepsiCo’s incredible reach (our foods and beverages are enjoyed more than one billion times a day in more than 200 countries and territories, leveraging a value chain involving diverse partners ranging from farmers and food scientists to retailers and logistics specialists), the challenges we’re addressing are complex and the solutions will be deeply impactful.

Although PepsiCo is a large multinational, the PepsiCo Global eCommerce Team prides itself on having the entrepreneurial, action-oriented culture of an exciting startup business. Our group includes startup founders, Silicon Valley veterans, food & beverage experts, and seasoned executives from digital transformation leaders such as Amazon and Walmart. Our goal is to build the technological products and capabilities that will reinvent our industry and make us the #1 food & beverage business in eCommerce for decades to come.

We're looking for a Full Stack Engineer to join our growing engineering team and assist us in driving product initiatives forward while upholding our high engineering standards.

In this role you will have several distinct responsibilities and priorities:
You will own application development end-to-end, spanning data models, testing, scalability, operability, and ongoing metrics.
We work in Elixir: however, languages can be learned. We put more emphasis on your general engineering skill and willingness to learn than knowledge of a particular language or framework.
We need you to be versatile, display leadership qualities, and be enthusiastic to take on new problems across the full-stack as we continue to push technology forward.
You will work directly with designers to implement and build fully-featured modern web applications.
Some technologies that we use - we don't expect you to know all of these but some familiarity would be great:
Functional programming e.g. Elixir, Clojure or Haskell
Ruby on Rails
Python
PostgreSQL
Qualifications/Requirements
Bachelor’s Degree in Computer Science or related field
Preferred Qualifications:
Experience defining system architectures and exploring technical feasibility tradeoffs
6+ years of professional experience in software development
3+ years of professional experience with HTML/CSS (Sass) and javascript
Knowledge of professional software engineering practices & best practices for the full software development life cycle, including coding standards, code reviews, source control management, continuous integrations, testing, and operations
Hands-on experience with cloud-based platform capabilities
Ability to transform a design into a working product
Bonus Qualifications:
Experience with Elixir and the Phoenix web framework
Extra bonus points if you’ve used Phoenix LiveView
Experience deploying applications to Kubernetes
Relocation Eligible: Not Applicable
Job Type: Regular

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, or disability status.

PepsiCo is an Equal Opportunity Employer: Female / Minority / Disability / Protected Veteran / Sexual Orientation / Gender Identity

Our Company will consider for employment qualified applicants with criminal histories in a manner consistent with the requirements of the Fair Credit Reporting Act, and all other applicable laws, including but not limited to, San Francisco Police Code Sections 4901 - 4919, commonly referred to as the San Francisco Fair Chance Ordinance; and Chapter XVII, Article 9 of the Los Angeles Municipal Code, commonly referred to as the Fair Chance Initiative for Hiring Ordinance.

If you'd like more information about your EEO rights as an applicant under the law, please download the available EEO is the Law & EEO is the Law Supplement documents. View PepsiCo EEO Policy

Please view our Pay Transparency Statement",3.7,"PepsiCo
3.7","San Francisco, CA","Purchase, NY",10000+ employees,1965,Company - Public,Food & Beverage Manufacturing,Manufacturing,$10+ billion (USD),"Unilever, Mondelēz International, Amazon"
Machine Learning Engineer,"$72K-$124K
(Glassdoor est.)","We love programming and the excitement that comes with building something people use. We are the kind of people that love talking to users and can find the balance between solving a problem quickly and thinking about how your code will work in the future. We love to move fast, keep learning and get stuff done.

Our data science team is still in its early days and you'll have a big impact on our direction and how we operate. You'll be central to researching, developing and shipping products that help our customers learn and grow from their data. For this role, we're looking for people who have developed split brains--software engineers who have become great at writing machine learning code or data scientists who have become great software developers.

Technologies we use (not comprehensive!):
Python

Numpy, Scipy, Pandas

Aurora, Cassandra, Kafka

HTML, JavaScript, React

SageMaker

How you will make a difference:


Analyze large data sets (we're collecting billions of individual actions every month).
Build products that enable our customers to grow faster and communicate more effectively with their customers.
Develop machine learning models and pipelines for research and production.

Who You Are:


Have experience implementing machine learning models, data pipelines and testing frameworks for research and production use.
Have demonstrated a measurable impact based on the models you've created. It's not always easy getting a model correct, we love talking about places we got stuck and work as a team to think through ideas that could unblock us.
Have experience processing cloud-scale data using parallel, elastic, streaming and similar techniques.
Enjoy tuning and validating machine learning models and take a rigorous approach.
Understand how to profile code and optimize performance.
Aspire to correctness (e.g. in your code, in drawing conclusions from data)
Have a bachelor's or advanced degree in computer science, applied math, statistics or other relevant quantitative discipline, or equivalent industry experience.

Get to know Klaviyo

Klaviyo is the world's leading owned marketing platform known for accelerating revenue for online businesses using the channels they own like email, web, and mobile. Enabling companies to leverage these owned marketing channels, Klaviyo makes it easy to store, access, analyze and use transactional and behavioral data to power highly-targeted customer and prospect communications. And unlike other marketing platforms, Klaviyo doesn't force companies to compromise between advanced functionality or ease of use - so companies of all sizes are able to maximize their sales quickly. That's why over 28,000+ innovative companies like Unilever, Custom Ink and Eventbrite sell more with Klaviyo.",4.8,"Klaviyo
4.8","Boston, MA","Boston, MA",201 to 500 employees,2012,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Science Software Engineer,"$86K-$125K
(Glassdoor est.)","We love programming and the excitement that comes with building something people use. We are the kind of people that love talking to users and can find the balance between solving a problem quickly and thinking about how your code will work in the future. We love to move fast, keep learning and get stuff done.

Our data science team is still in its early days and you'll have a big impact on our direction and how we operate. You'll be central to researching, developing and shipping products that help our customers learn and grow from their data. For this role, we're looking for people who have developed split brains--software engineers who have become great at writing machine learning code or data scientists who have become great software developers.

Technologies we use (not comprehensive!):
Python

Numpy, Scipy, Pandas

Aurora, Cassandra, Kafka

HTML, JavaScript, React

SageMaker

How you will make a difference:


Analyze large data sets (we're collecting billions of individual actions every month).
Build products that enable our customers to grow faster and communicate more effectively with their customers.
Develop machine learning models and pipelines for research and production.

Who You Are:


Have experience implementing machine learning models, data pipelines and testing frameworks for research and production use.
Have demonstrated a measurable impact based on the models you've created. It's not always easy getting a model correct, we love talking about places we got stuck and work as a team to think through ideas that could unblock us.
Have experience processing cloud-scale data using parallel, elastic, streaming and similar techniques.
Enjoy tuning and validating machine learning models and take a rigorous approach.
Understand how to profile code and optimize performance.
Aspire to correctness (e.g. in your code, in drawing conclusions from data)
Have a bachelor's or advanced degree in computer science, applied math, statistics or other relevant quantitative discipline, or equivalent industry experience.

Get to know Klaviyo

Klaviyo is the world's leading owned marketing platform known for accelerating revenue for online businesses using the channels they own like email, web, and mobile. Enabling companies to leverage these owned marketing channels, Klaviyo makes it easy to store, access, analyze and use transactional and behavioral data to power highly-targeted customer and prospect communications. And unlike other marketing platforms, Klaviyo doesn't force companies to compromise between advanced functionality or ease of use - so companies of all sizes are able to maximize their sales quickly. That's why over 28,000+ innovative companies like Unilever, Custom Ink and Eventbrite sell more with Klaviyo.",4.8,"Klaviyo
4.8","Boston, MA","Boston, MA",201 to 500 employees,2012,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Software Engineer (Remote),-1,"About you:
Care deeply about democratizing access to data.
Passionate about big data and are excited by seemingly-impossible challenges.
At least 80% of people who have worked with you put you in the top 10% of the people they have worked with.
You think life is too short to work with B-players.
You are entrepreneurial and want to work in a super fast-paced environment where the solutions aren't already predefined.
You live in the U.S. or Canada and are comfortable working remotely.
About SafeGraph:
SafeGraph is a B2B data company that sells to data scientists and machine learning engineers.
SafeGraph's goal is to be the place for all information about physical Places
SafeGraph currently has 30+ people and has raised a $20 million Series A. CEO previously was founder and CEO of LiveRamp (NYSE:RAMP).
Company is growing fast, over $10M ARR, and is currently profitable.
Company is based in San Francisco but more than 50% of the team is remote. We get the entire company together in the same place every month (when possible).
We have been moving very quickly in the current pandemic, building up new products and releasing up-to-date dashboards to the general public. We are providing our aggregated and anonymized location data at no cost for non-commercial use, to anyone with the shared goal of fighting to prevent the spread of COVID-19 and helping to get the economy moving in its aftermath. We now have a vibrant community of 2000+ organizations in this Consortium. You can see the publications here.

About the role:
Core software engineer.
Reporting to SafeGraph's VP Engineering.
Work as an individual contributor.
Opportunities for future leadership.

Requirements:
No Resume? No Problem! A LinkedIn is all you need to apply!
You have at least 3 years of relevant work experience.
Proficiency writing production-quality code, preferably in Scala, Java, or Python.
Strong familiarity with distributed system, or map/reduce data processing.
Deep understanding of all things ""data"" - schema design, modeling, optimization, scalability, etc.
You are authorized to work where you are.
Excellent communication skills.
You are amazingly entrepreneurial.
You want to help build a massive company.
Nice to haves:
Experience using Apache Spark to solve production-scale problems.
Experience with AWS.
Experience with building ML models from the ground up.
Experience working with huge data sets.
Python, Database and Systems Design, Scala, Data Science, Apache Spark, Hadoop MapReduce.
Good reading on how we are thinking:
SafeGraph Vision and Values
Open Information to Power Innovation
Where Should Machines go to Learn
Data-As-A-Service Bible: Everything You Wanted to Know About Running DaaS Companies
Don't fit this description perfectly but still think this is the role for you? Apply and let us know why!",4.5,"SafeGraph
4.5",Remote,"San Francisco, CA",1 to 50 employees,2016,Company - Private,Internet,Information Technology,$10 to $25 million (USD),-1
Machine Learning Engineer/Scientist,"$137K-$146K
(Glassdoor est.)","At GenapSys we are working to power the world of healthcare and diagnostics with advanced DNA sequencing technology. Our sequencing instrument platform leverages a proprietary electrical microfluidic sequencing chip with a scalable number of detectors, enabling a wide range of applications including targeted sequencing in oncology, pharmacogenomics and genome-wide sequencing in microbiology and others. We believe in a world where every researcher has a compact, scalable, and affordable sequencer in their own lab, empowering the democratization of genetic sequencing. Our novel sequencing method is revolutionizing genomics discovery, biomedical research, healthcare, diagnostics, agriculture, and a variety of other fields.

Our team brings together an incredibly diverse and multidisciplinary set of backgrounds and skills – from electrical and mechanical engineers, physicists, chemists, microfluidic engineers, molecular biologists, bioinformaticians, mathematicians and more. It is a super exciting time to join GenapSys as we recently launched our first product which is generating a tremendous amount of interest.

About the Role:

Machine learning approaches are at the core of GenapSys' methods for generating high quality DNA sequencing data. As a machine learning engineer, you will join forces in the development of cutting-edge machine learning methods that solve key problems in the DNA sequencing, base calling, and variant calling processes. You will work closely with a cross-functional team of life scientists, bioengineers, and data scientists to identify areas where machine learning can make a difference, to conceptualize and develop biological datasets using cutting edge, high throughput platforms, and to analyze these data sets using the best machine learning methods, applied at scale.

Qualifications:
MS, or Ph.D. in computer science, statistics, mathematics, physics, engineering, or equivalent practical experience.
Expertise in Python and with version control practices and tools, especially Git/Github.
Demonstrated ability to write high-quality, production-ready code (readable, well-tested, with well-designed APIs).
1- 4 years of real-world work experience in software development for high-end machine learning algorithms.
Significant experience with Tensorflow.
Demonstrated prior experience with time series data analysis.
Demonstrated hands-on experience with development of Deep Learning models, various Neural Network concepts, classification algorithms that go beyond putting together of existing code, and to apply troubleshooting and problem-solving skills to complex issues.
Ability to communicate effectively and collaborate with people of diverse backgrounds and job functions.
Bonus Points If:
Experience with biological data (DNA sequences, RNAseq, proteomics, microscopy images, etc.).
Proficiency in Linux environment (including shell scripting), experience with database languages (e.g., SQL, No-SQL).
Familiarity with cloud computing services (AWS or GCP).
Experience with scalable machine learning, including the application to large datasets.
What we offer (US based-employees)*:
Competitive compensation and generous stock options.
Comprehensive, industry-leading medical, dental and vision benefits for employees and dependents.
Pre-tax savings plans for health care, child care, elder care, public transportation and parking expenses.
401(k) retirement plan with matching employer contribution.
Free daily catered gourmet lunches and snacks.
For those emergency moments - long and short term disability, life insurance (2x salary) and an employee assistance program.
Work with driven and enthusiastic colleagues in a fast-paced and entrepreneurial environment, the opportunity to work on problems that matter in a highly collaborative environment.
*Eligible international employees' benefits are specific to their location and dependent on their employer of record

GenapSys does not accept unsolicited agency resumes. Please do not forward unsolicited agency resumes to our website or to any GenapSys employee. GenapSys will not pay fees to any third party agency or firm and will not be responsible for any agency fees absent a formal agreement.

A diverse and inclusive workplace where we learn from each other is an integral part of GenapSys' culture. We actively welcome people of different backgrounds, experiences, abilities and perspectives. We are an equal opportunity employer and a great place to work. Join us and help us achieve our mission!",3.8,"GenapSys, Inc.
3.8","Redwood City, CA","Redwood City, CA",51 to 200 employees,2010,Company - Private,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,Less than $1 million (USD),"Illumina, Thermo Fisher Scientific, Oxford Nanopore Technologies"
"Software Engineer, Machine Learning","$135K-$165K
(Glassdoor est.)","The opportunity


Grammarly empowers people to thrive and connect, whenever and wherever they communicate. More than 20 million people around the world use our AI-powered writing assistant every day. All of this begins with our team collaborating in a values-driven and learning-oriented environment.

To achieve our ambitious goals, we're looking for a Software Engineer focused on machine learning to join our team. This individual will be responsible for building end-to-end intelligence systems that solve complex user problems, including applying ML to solve new problems as well as building the infrastructure and systems that will enable this to operate effectively at scale. The role will have the opportunity to provide feedback about the systems and tools in place to facilitate the creation and improvement of a machine learning platform that can increase the efficacy of the engineering team.

Grammarly's engineers and researchers have the freedom to innovate and uncover breakthroughs—and, in turn, influence our product roadmap. The complexity of our technical challenges is growing rapidly as we scale our interfaces, algorithms, and infrastructure. Read more about our stack or hear from our team on our technical blog.

Your impact


The Software Engineer for machine learning will need to stay up-to-date on the quickly evolving field of NLP while also focusing on building production systems. The majority of the problems we're tackling haven't already been solved elsewhere, which provides the opportunity for creativity and innovative problem-solving.

Working on the Machine Learning team requires close partnership with analytical linguists, computational linguists, and research scientists. You will have the chance to deepen your skills in machine learning and deep learning while increasing breadth in related areas to up-level our entire team.

In this role, you will:
Build end-to-end machine learning solutions to solve complex customer problems.
Collaborate with applied researchers to ensure they are well-calibrated on the constraints of the production system, ensuring their research proceeds along practical pathways as they explore novel techniques to tackle previously unsolved problems.
Effectively communicate technical machine learning results in a business context where most people are not machine learning experts.
Build the systems to help applied researchers scale their models in a production environment.
Design experiments, including for offline prototypes in a statistically sound way that will provide actionable data and enable us to make reliable decisions as we iterate on a project.
Promote excellence and best practices across the machine learning team in regards to research, implementation, tooling, and system design.
Work cross-functionally across multiple partner teams to get new features shipped across our many interfaces.
We're looking for someone who
Embodies our EAGER values—is ethical, adaptable, gritty, empathetic, and remarkable.
Understands traditional machine learning algorithms and how to use them effectively in practice.
Is familiar with deep learning and its applications in industry.
Has a strong working knowledge of statistics as it relates to sampling methodologies and designing experiments
Understands data structures and algorithms at a level sufficient to write performant code when working with large datasets or large incoming data streams.
Is aware of NLP techniques to effectively work with very high-dimensional, sparse data.
Has enough experience with academic research to be comfortable reading and implementing papers to reproduce their results.\
Support for you, professionally and personally
Professional growth: We hire people we trust, and we give team members autonomy to do their best work. We also support professional development with training, coaching, and regular feedback.
A connected team: Grammarly builds products that help people connect, and we apply this mindset to our own team. We have a highly collaborative culture supported by our EAGER values. We also take time to celebrate our colleagues and accomplishments with global, local, and team-specific events and programs.
Comprehensive benefits: Grammarly offers all team members competitive pay along with a benefits package that includes superior health care. We also offer ample and defined time off, catered lunches, gym and recreation stipends, admission discounts, and more.
We encourage you to apply


At Grammarly, we value our differences, and we encourage all—especially those whose identities are traditionally underrepresented in tech organizations—to apply. We do not discriminate on the basis of race, religion, color, gender expression or identity, sexual orientation, national origin, citizenship, age, marital status, veteran status, disability status, or any other characteristic protected by law. Grammarly will consider qualified applicants with criminal histories in a manner consistent with the San Francisco Fair Chance Ordinance. Grammarly is an equal opportunity employer and participant in the U.S. Federal E-Verify program.",5.0,"Grammarly
5.0","San Francisco, CA","San Francisco, CA",201 to 500 employees,2009,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Machine Learning Engineer - Think Tank Team,"$101K-$175K
(Glassdoor est.)","Title: Machine Learning Engineer

Company: Samsung Research America (SRA)

Lab: Think Tank Team

Location: Mountain View, CA

Lab Summary:

The Think Tank Team is an interdisciplinary collective of researchers, designers, scientists and engineers located in Mountain View, CA. Our mandate is to explore what's next for Samsung by applying bleeding-edge advances in software, machine learning, computer-human interaction, sensor and display technologies to solve real-world challenges that will transform users' experiences in ways we can only just glimpse on the horizon today.

TTT began as a small team in 2012 and brought its first concept -- the Samsung Gear watch -- to market one year later. Since then we have released several projects such as the Beyond 3D/360/4k camera for AR/VR cinematography, the BotChef cooking robot, the Ballie personalized companion, and others. We work on a wide variety of time scales, advancing science and applying it to create new products and experiences that will impact the lives of millions.

Our team members represent a diverse skillset, including electrical engineering, computer engineering, signal processing, machine learning, computer vision, visual design, interaction design, industrial design, optics, physics, and more from institutions such as MIT, Caltech, Stanford, CMU, Oxford and others. We believe that the best way to show is to design and build prototypes, and that the best products come from teams collaborating to understand and solve a problem from multiple perspectives. We believe that design and creativity are core duties of every member of our team.

Qualifications & Skills

You must be passionate about creating new devices and technologies, and ready to learn on the fly, solve complex problems, work closely with others, and creatively approach design and engineering tasks at all scales. We believe a person's work speaks for itself, and welcome everyone with the right drive, attitude, and skills.
BS/MS/PhD degree in Computer Science or related technical field or equivalent practical experience.
2 years of work experience in Machine Learning or Artificial Intelligence in real-world settings.
Strong C++ and/or Python skills.
Ability to rapidly prototype with leading ML frameworks.
Experience with current state-of-the-art methods from machine learning & deep learning libraries such as TensorFlow, Caffe, Scikit-Learn, Scipy, Pandas, Torch and others.
Experience with a multitude of machine learning methods such as SVMs, logistic regression, boosting, decision trees, clustering, HMMs etc.
Experience with CV libraries such as OpenCV
Experience in multiple forms of machine leaning, from the very simple to the most complex.
Experience in creation of novel custom features and pre-processing approaches to improve baseline algorithms. Work should go beyond using standard libraries.
Solid understanding of proper evaluation including folds, cross-validation and metrics.
Experience with one or more of the following: Natural Language Processing, GANs, autoencoders, Reinforcement Learning, CNNs, and others.
Flexibility to deal with rapidly changing environment.
Prior experience with signal processing from sensor data is a plus.
Responsibilities
Participate in cutting edge research in machine intelligence and machine learning applications. Leverage expertise from ML research and develop novel predictive models/algorithms
Develop solutions and algorithms that can be applied in variety of real-world applications and devices.
Work closely with researchers and engineers from variety of disciplines to develop new algorithms, product concepts and core-technologies that will bring new business opportunities to Samsung.
If this is something you would love to do, let us know. Show us what you have built, and tell us what you would like to build next!

Samsung is an EEO/Veterans/Disabled/LGBT employer. We welcome and encourage diversity as we strive to create an inclusive workplace.",3.5,"Samsung Research America
3.5","Mountain View, CA","Mountain View, CA",1001 to 5000 employees,1988,Subsidiary or Business Segment,Computer Hardware & Software,Information Technology,$50 to $100 million (USD),"Sony, LG Electronics, Nokia"
Data Scientist- Machine Learning Software Engineer,"$76K-$124K
(Glassdoor est.)","We are looking for the right people — people who want to innovate, achieve, grow and lead. We attract and retain the best talent by investing in our employees and empowering them to develop themselves and their careers. Experience the challenges, rewards and opportunity of working for one of the world’s largest providers of products and services to the global energy industry.

Overview:

As a data scientist and machine learning software engineer on Halliburton Digital Solution team, you are responsible to deliver digital solutions which can achieve measurable business results through collaborating with subject matter experts in businesses, applying common open source libraries for building data analytics models, prototyping data driven digital tools to tackle business problems. We are looking for top talents who enjoy learning and contributing to our team through creative and innovative thinking.

Job Responsibilities:
Efficiently extract large scale complex business data (time series data, structured/unstructured) from various data sources and prepare them for data analytics.
Partner with product experts, leverage common open source Machine Learning/Deep Learning packages for identifying data patterns/trends or building predictive models.
Deploy solutions to business units using software technologies to generate measurable values for businesses.
Grasp the application of the latest machine learning & artificial intelligence open source packages, cloud and distributed computing technologies to ensure the best technologies are implemented to meet businesses’ data challenges.


Required Qualifications:
Undergraduate degree in Data Science, Computer Science, or Math, or Statistics.
For candidates who hold an engineering degree, we require candidates have taken data science classes already.
7 years of experiences with a minimum of 2 years experiences in extracting the data, using common classification or regression open source packages through R or Python.
Has basic knowledge with big data platforms like Hadoop, Hive, or Phoenix, as well as knowledge in parallel programming, and distributed computing frameworks like Spark.
Preferred Qualifications:
Advanced degree in in Data Science, Math, Statistics, Computer Science, or Engineering:
5 years of experiences with a Master’s degree.
2 years of experiences with a PhD degree.
Has experience with open source machine learning packages and deep learning packages provided by Microsoft Azure, Amazon AWS, or Google GCP (such as Scikit-learn, Azure ML, TensorFlow, Sagemaker).
Interview process:

Potential candidates are required to pass a data challenge test before on-site interview can be scheduled.

Halliburton is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, disability, genetic information, pregnancy, citizenship, marital status, sex/gender, sexual preference/ orientation, gender identity, age, veteran status, national origin, or any other status protected by law or regulation.

Location

3000 N. Sam Houston Parkway E., Houston, Texas, 77032, United States

Job Details

Requisition Number: 87825
Experience Level: Experienced Hire
Job Family: Engineering/Science/Technology
Product Service Line: Global R&D
Full Time / Part Time: Full Time

Additional Locations for this position:

Compensation Information
Compensation is competitive and commensurate with experience.",3.5,"Halliburton
3.5","Houston, TX","Houston, TX",10000+ employees,1919,Company - Public,Oil & Gas Services,"Oil, Gas, Energy & Utilities",$10+ billion (USD),"Weatherford, Schlumberger"
"Data Scientist, Two Sigma Private Investments","$116K-$152K
(Glassdoor est.)","Sightway Capital is a Two Sigma company focused on private equity investments. We employ a principal mindset and flexible capital approach to building successful business platforms with experienced operators and strategic partners. The team at Sightway Capital thinks long-term, targeting business opportunities that we believe afford both asymmetric risk rewards and enterprise value creation over time. Sightway’s unique platform building approach affords team members the opportunity to participate in each investment’s growth and success from an early stage. Data science is key to Sightway’s strategy, and we aim to leverage Two Sigma’s expertise, data sources and analytical models in order to make informed investment decisions, and create enterprise value and positive outcomes for our portfolio companies.

Sightway Capital is building a world class data science team in order to execute on this vision. The team has a multifaceted data driven private investment strategy that encompasses private equity deal sourcing, due diligence, and portfolio company value creation. This role includes working with business analysts to gather business needs and requirements from our portfolio companies; forming creative data driven hypotheses to solve these needs; using a range of statistical and machine learning methods using a range of different data sources in order to build models that prove or disprove these hypotheses; communicate findings to management and work with software engineers to craft solutions based on the models you build.

You will take on the following responsibilities:

Design and implement models that explore, predict, and optimize a range of key business drivers such as lead generation, customer risk, revenue, pricing
Work with business analysts to extract business needs from portfolio company management teams
Perform data exploration and visualization in order to uncover insights from data
Brainstorm hypotheses to solve business needs
Work with Data Strategy team to source and on-board new data sets and portfolio company technical teams to on-board company data
Build models using a range of analytical techniques in order to prove or disprove hypotheses
Prepare and present findings to TSPI management, portfolio executive team
Work with software engineers to engineer tools that use production models to deliver impact for the portfolio company
You should possess the following qualifications:
1-5+ years of experience in applied data analysis & prediction, preferably in an industry setting
Experience solving business problems using data science by directly interfacing with a client’s management team would be ideal
Degree in a technical or quantitative disciplines, like statistics, mathematics, physics, electrical engineering, or computer science
Demonstrably strong data science modeling intuition and feature engineering creativity
Intimate familiarity with the potential flaws & fallacies in the applications of specific statistical methods
Experience specifying & managing requirements for datasets leveraged in your analyses
Working knowledge of SQL and common data science toolkits : Python, R, Spark, Matlab
Strong written & verbal communication and presentation skills, with experience crafting a compelling narrative supported by data
A portfolio of open-data analyses or data-driven research publications would be ideal
You will enjoy the following benefits:
Core Benefits: Fully paid medical and dental insurance premiums for employees and dependents, competitive 401k match, employer-paid life & disability insurance
Perks: Onsite gyms with laundry service, wellness activities, casual dress, snacks, game rooms
Learning: Tuition reimbursement, conference and training sponsorship
Time Off: Generous vacation and unlimited sick days, competitive paid caregiver leaves
We are proud to be an equal opportunity workplace. We do not discriminate based upon race, religion, color, national origin, sex, sexual orientation, gender identity/expression, age, status as a protected veteran, status as an individual with a disability, or any other applicable legally protected characteristics.",4.4,"Two Sigma
4.4","New York, NY","New York, NY",1001 to 5000 employees,2001,Company - Private,Investment Banking & Asset Management,Finance,Unknown / Non-Applicable,-1
Principal Software Engineer,"$108K-$211K
(Glassdoor est.)","The Pindrop engineering team solves tough problems and invents new ways to battle fraud using big data and machine learning in the cloud. We are looking for a Principal Backend Software Engineer to join the Data Analytics team as we continue to develop new ways to fight fraud and improve security in voice channels.

The team is responsible for services that process billions of non-audio data events and contribute to our fraud detection and authentication capabilities. Key responsibilities include:
Designing, developing, testing, deploying, and monitoring high-performance, scalable APIs consumed by both cloud and on premise clients
Working with research scientists to design, develop, and deploy state-of-the-art machine learning models to detect fraudsters and positively identify genuine actors
Applying experience and knowledge of industry best practices to support and continuously improve the performance, efficiency, and maintainability of existing applications
what you'll do
Work with a growing team to design, develop, test, deploy, maintain and improve brand new software components and microservices
Refactor existing systems and architect new solutions
Develop applications in Golang and Python on top of a modern cloud focused platform
Maintain and manage services running in our Kubernetes platform
Develop and maintain AWS native services using products such as Kinesis, DynamoDB, and S3
Deliver production ready code from start to finish
Continuously improve service architecture
Create and maintain DataDog monitors
Review code to maintain quality with an eye towards performance, scale, and security
Work with multiple teams to implement company wide solutions
Assist in leading the full development life cycle of projects within the team
Identify and evaluate new technologies for implementation
Contribute to establishing and improving software engineering best practices
Help team members grow their technical expertise through mentoring and coaching
Be a role-model to engineers throughout the Engineering department
who you are
10+ Years of Software engineering experience
Strong expertise in multiple programming languages such Python, Go, Java or C++
Experience building Distributed and Scalable architectures
Expertise in Data Structures, Algorithms and Concurrency
Experience building microservices and RESTful APIs
Knowledge of different Data Storage technologies such as Redis, MySQL, etc.
Knowledge of Docker and container orchestration frameworks such as Kubernetes
Experience with AWS managed services such as S3, ElastiCache and DynamoDB
Experience with service monitoring solutions such as DataDog
Proven track record of providing stable and secure code in production environments
what we offer


As a part of Pindrop, you'll have a direct impact on our growing list of products and thus the future of security in the voice driven economy. We hire great people and take care of them. Here's a snapshot of benefits we offer:
Competitive salary
Paid Parental Leave
Company holidays
Paid time off
Pick your own Apple MacBook Pro
Retirement plan with 401k match
Health plans
Continued education budget (certifications, conferences, etc.)
Flex schedules
Best in class tools
Paid commuter options
Fun outings to celebrate our accomplishments as a team
All the good karma you can rack up for fighting bad guys (our conference rooms are named after the ones we've busted)
who we are


Pindrop is a company founded on research and continues to innovate new ideas to market. Our solutions are leading the way to the future of voice by establishing the standard for security, identity, and trust. Pindrop products secure the future of voice, making technology more human from the call center to IoT devices.

what we live by


Pindrop is driven by our DEPTH values. These are reflected in our goals and the base of our team's peer awards.

Act with Deliberate urgency.
Create Evangelical customers.
Passionate about the fight.
Playing for the Team.
Make Hard easy.

Pindrop is an Equal Opportunity Employer.

Here at Pindrop, it is our mission to create and maintain a diverse and inclusive work environment. As an equal opportunity employer all qualified applicants receive consideration for employment without regard to race, color, age, religion, sex, gender, gender identity or expression, sexual orientation, national origin, genetic information, disability, marital and/or veteran status.",4.0,"Pindrop
4.0","Atlanta, GA","Atlanta, GA",201 to 500 employees,2011,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Data Engineer – Full-Time,"$105K-$121K
(Glassdoor est.)","Job Description

Data Engineers are tasked with building and maintaining our bespoke enterprise data pipelines. They take ownership of our data pipelines, starting with how we ingest data from the outside world, to transforming that information into actionable insights, to ultimately designing the interfaces and APIs that our analysts and quants use to monetize that information. Throughout that process our data engineers work side-by-side with investment professionals and data scientists to design systems that are solving our must challenging problems and answering the most difficult questions in the hedge fund industry.

Key Responsibilities:


· Develop solutions that enable internal analysts to efficiently extract insights from data. This includes owning the ingestion (web scrapes, S3/FTP sync, bespoke processes), transformations (Python, Perl) and interface (API, schema design, events, etc.)

· Build tooling and automation around data pipelines that improve the efficiency, quality and resiliency of our data platform

· Partner with internal analysts, quants and data scientists to design, develop, test and deploy solutions that answer fundamental questions about financial markets.

· Take on an entrepreneurial mentality by building and selling your own ideas. We work in an evolving space and we expect you to help design our evolution by challenging the status quo and independently identifying opportunities to improve the entire data organization.

Required Skills

· A deep passion for working with data and developing software to address data processing challenges

· Bachelor’s, Master’s or PhD degree in Computer Science or equivalent experience

·Proficiency within one or more programming languages like Java, Python, Perl or JavaScript.

· Proficiency with RDBMS, or NoSQL

· Experience with some of the following areas: Distributed Computing, Natural Language Processing, Machine Learning or Software Architecture

· Experience with any of the following systems: Apache Airflow, AWS/GCP/Azure, Jupyter, Kafka, Docker, Nomad/Kubernetes

· Strong written and verbal communications skills

· Ability to manage multiple tasks and thrive in a fast-paced team environment

About Citadel


Citadel is a global investment firm built around world-class talent, sound risk management, and innovative leading-edge technology. For a quarter of a century, Citadel’s hedge funds have delivered meaningful and measurable results to top-tier investors around the world, including sovereign wealth funds, public institutions, corporate pensions, endowments and foundations.

With an unparalleled ability to identify and execute on great ideas, Citadel’s team of more than 675 investment professionals, operating from offices including Chicago, New York, San Francisco, London, Hong Kong and Shanghai, deploy capital across all major asset classes, in all major financial markets.

Apply Now",3.8,"Citadel
3.8","New York, NY","Chicago, IL",1001 to 5000 employees,1990,Company - Private,-1,-1,$50 to $100 million (USD),"Soros Fund Management, D. E. Shaw & Co. - Investment Firm, Fortress Investment Group"
"Senior Data Engineer, Ingestion","$121K-$218K
(Glassdoor est.)","Chime is the largest and fastest-growing player in the challenger-banking space, providing mobile and online banking technology in the U.S. on behalf of partner banks and facilitating over 10M accounts with no physical branches. We're a technology company relentlessly focused on helping our members achieve financial peace of mind. That's why we offer access to an award-winning bank account that doesn't charge a ton of traditional bank fees, can give members early access to their paychecks, and enables members to grow their savings automatically. And we're just getting started. We are proud of our mission, devoted to our members, and passionate about applying technology to the challenge of making financial health a reality for everyone.

We have one of the most experienced management teams in Fintech and have raised over $800M in funding from DST, General Atlantic, Iconiq, Coatue, Dragoneer, Menlo, Access, Forerunner, and others. If you're looking to join a fast-growing company with a beloved, daily-use product and an authentic mission that puts people first, we want to meet you.

About the Role

In this role, you'll be responsible overseeing the design, development and operations of large-scale, real-time data systems. The ideal candidate will be excited by the prospect of owning, optimizing or even re-designing our company's data architecture and building out a team to support our next generation of products and data initiatives. The data engineering team will support our software developers, database architects, data analysts, data scientists, and machine learning engineers on back-end data initiatives.

Responsibilities

We're looking for a leader who is self-directed and comfortable supporting the data needs of multiple teams, systems and products. Your responsibilities will include:
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS 'big data' technologies
Work with stakeholders including the Analytics, Risk, Machine Learning, and Technical Operations teams to assist with data-related technical issues and support their data infrastructure needs
Participate in key technical and design discussions with technical leads in the team as a hands-on manager
Act as a project manager for the projects that your team is responsible for
Provide technical leadership to your team by giving guidance on designs and coding when time allows
Help manage and consult in designing our data governance initiatives
Requirements
6+ years of experience in designing, implementing, optimizing and operationalizing real-time big data analytics systems including data-pipelines, data warehouses and enterprise wide data-flows
You've earned a bachelor's degree in Computer Science or other technical field
Understanding of the tradeoffs between different big data solutions
Strong analytic skills related to working with unstructured datasets
Experience with a variety of traditional, streaming, and big data tools such as:
Hadoop ecosystem: Hadoop, Hive, Spark
Kafka, Sqoop, Flume
Airflow or other workflow scheduler
Data Warehouses: Redshift, Snowflake (preferred)
SQL databases, including MySQL, Postgres
AWS cloud services: EC2, EMR, RDS
Stream-processing systems: Storm or Spark-Streaming or equivalent.
Advanced SQL, Python, Java and/or Scala
What we offer
Competitive salary based on experience, with medical and dental benefits.
Free snacks and drinks, plus weekly catered lunches.
Flexible vacation policy.
Monthly happy hours and company events.
A challenging and fulfilling opportunity to join one of the most experienced teams in FinTech and help create a completely new kind of banking service.
We know great work isn't done alone. We're building a team of individuals to Chime in with their different strengths to benefit our employees and members. We strongly believe that different backgrounds and ideas are a competitive advantage; we hire candidates of any race, color, ancestry, religion, sex, national origin, sexual orientation, gender identity, age, marital or family status, disability, Veteran status, and any other status. Chime is proud to be an Equal Opportunity Employer and will consider qualified applicants with criminal histories in a manner consistent with the San Francisco Fair Chance Ordinance. If you have a disability or special need that requires accommodation, please let us know. To learn more about how Chime collects and uses your personal information during the application process, please see the Chime Applicant Privacy Notice.",4.8,"Chime
4.8","San Francisco, CA","San Francisco, CA",201 to 500 employees,2013,Company - Private,Banks & Credit Unions,Finance,Unknown / Non-Applicable,-1
Computer Vision Software Engineer,"$99K-$174K
(Glassdoor est.)","Introduction

iRobot is looking to hire a Computer Vision Software Engineer on our Perception team who will play a vital role in developing the next generation of Robots that will live in millions of homes across the world. If you are a consumer centric pioneer eager to build innovative robot products, please apply now or reach out to one of our recruiters on LinkedIn.
What you will do
Develop algorithms for computer vision, SLAM, and related disciplines in challenging and dynamic environments
Design, implement, test, and document software and algorithms for desktop and embedded platforms, in C/C++ and other languages
Collaborate closely with team members on developing systems from prototypes to production level. Take solutions “over the wall” through manufacturing and customer deployment

To Be Successful You Will Have
Experience in state-of-the-art geometric computer vision and SLAM technologies
Hands-on experience developing computer vision systems
Solid understanding of computer vision fundamentals
Experience studying and implementing research papers from conferences such as CVPR, ICCV, ECCV, NIPS, ICPR, ICML
Excellence at writing embedded C/C++ and familiarity with a Linux Environment
Understanding and experience in design patterns, data structures and advanced programming techniques
BS in Computer Science, Electrical Engineering, or related field
Beneficial: M.S in Computer Science, Robotics, Computer Vision, or related field
In Return You Can Expect
To work on exciting problems in computer vision and SLAM deployed on the largest installed base of consumer robots
Be an integral part of a team dedicated to building the next generation of robots
Opportunities to continuously learn and collaborate with our innovative and knowledgeable technical staff including leading scientists in Computer vision, machine learning, and SLAM.
An attractive salary package with good benefits
Excellent career growth opportunities",3.5,"iRobot
3.5","Pasadena, CA","Bedford, MA",1001 to 5000 employees,1990,Company - Public,Consumer Electronics & Appliances Stores,Retail,$1 to $2 billion (USD),-1
Data Science All Star Program - Data Engineer Track,"$64K-$81K
(Glassdoor est.)","Data Science All Star Program - Data Engineer Track

Job Title

Data Science All Star Program - Data Engineer Track

Job
ID

27260177

Duration

Location

Columbia,

MD

Other Location

Description

Dynamic, Fast-growing, Entrepreneurial Data Science Solutions Company seeking data Engineers! If you’ve got entrepreneurial spirit and passion, are driven by results, and want to be a part of significant growth, we’re looking for you!

BLEND360 is a multi-award winning Marketing Company who is privileged to provide our services to some of the most respected and recognized brands in the world. At BLEND360 it is all about advancing our clients marketing capabilities and performance.

If you are ready to ignite the fire for digital marketing and join our team, please keep reading!

*************************************************************************************

Our Data Science All Stars Program is a 6-month consultant training program for master’s graduates in Analytics, Statistics, Computer Science and other quantitative programs. Participants will have the opportunity to learn from top Data Scientists, work on real-world analytics projects, and gain experience with Fortune 500 clients across a variety of verticals. They will work alongside our Data Scientists to get data into proper shape, perform statistical analyses and develop predictive models to solve our clients’ business problems.

The primary objective of this program is to develop participants into productive, client engaged BLEND360 employees and set the foundation to build a fast track career in one of 4 areas:

Data Science

Data Engineering

Marketing- Adobe Cloud

Marketing Analytics .

The All-Star focused on Data Engineering will:
Work with business leaders to solve clients’ business challenges and improve clients’ business results using advanced analytics techniques. We contribute our Advanced Data Science subject matter expertise to the recommendations and solutions delivered to our clients.
Spend most of their time on getting data into proper shape, performing statistical analyses, developing predictive models and machine learning algorithms to solve clients’ business problems. We evaluate different sources of data, discover patterns hidden within raw data, create insightful variables, and develop competing models with different machine learning algorithms. We validate and cross validate our recommendations to make sure our recommendations will perform well over time.
Partner with client technical resources as well as BLEND360 team members, providing guidance and solutions for data architectures, data conversions, ETL and implementation of models in a production environment. The ideal candidate has retail experience and can provide technical expertise working with cloud based platforms as well as traditional data warehouse environments.
Main Responsibilities
Work with practice leaders and clients to understand how to make data accessible and usable throughout the organization.
Defines data environment design for the reporting and modeling/machine learning use cases that is consistent, maintainable and flexible.
Works with client and BLEND360 teams to identify use cases and functional requirements that drive the reporting and modeling data solutions.
Designs the database structure including tables, views, synonyms, sequences, triggers, procedures, functions, indexes and materialized views as relevant.
Provides the framework for integrating source systems with the reporting and modeling data environments – develops the ERD and data dictionaries
Implements business rules via stored procedures, middleware, or other technologies.
Develops strategies for flexibility and scalability, and defines the future technical architecture direction for the business intelligence reporting and analytical environments.
Problem solve with practice leaders to understand how to build the data pipelines that can support the business, formulate different approaches, outline pros and cons for each approach.
Work with practice leaders to get client feedback, get alignment on approaches, deliverables, and overall timeline
Document data flow, infrastructure and processes.
Turn models and machine learning algorithms into implementable production code
The Details:
Location: Columbia, MD
Duration:Full-time
Travel Requirements:Up to 25% (could be as much as (30% - 40% depending on projects)
Benefits:Health, Vision, Dental, 401K plan, Life Insurance, Pretax Commuter Benefits, and an incredibly supportive team cheering you on!
Qualifications:

o MS or PhD degree in Operation Research, Advanced Analytics, Computer Sciences, Engineering

o 1+ years’ professional experience in Data Engineering practices, such as:
data warehousing, optimization, and productionalization with examples of increased responsibility and evolving technologies.
developing code and/or applications using software such as Pyspark, Python, SQL, Scala, Java, etc.
deploying machine learning and data science pipelines into production using model management solutions and leveraging CICD solutions (e.g., Jenkins) for automation
configuring cloud platforms and configuring elastic compute environments in a cloud platform
Familiarity with and understanding of modern machine learning approaches, algorithms, libraries, and processes for feature selection / engineering
Experience building containerized applications and deploying those applications using solutions like Kubernetes
Experience with structured or un-structured data processing tools (SQL, Hadoop, Spark, NoSQL, MySQL, MariaDB, Hive, Pig, etc)
Comfortable with cloud-based platforms (AWS, Azure, Databricks, Google)",4.6,"Blend360
4.6","Columbia, MD","Columbia, MD",51 to 200 employees,2002,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,-1
Machine Learning Engineer - Data Plus Math,"$121K-$204K
(Glassdoor est.)","Machine Learning Engineer - Data Plus Math

LiveRamp is the trusted platform that makes data accessible and meaningful. Our services power people-based customer experiences that improve the relevance of marketing and allow consumers to better connect with the brands and products they love. We thrive on solving the toughest technical and customer challenges, and we're always looking for smart, compassionate people to help us blaze a trail.

Mission: LiveRamp makes it safe and easy for businesses to use data effectively.

We are looking for an experienced Machine Learning Engineer to join our team and help us revolutionize the way TV advertising is measured. The ideal candidate is someone with experience working closely with data scientists and turning their models into scalable production code and systems. You will support and interface with our scientists, data engineers, architects and analysts to ensure optimal data delivery architecture is consistent throughout ongoing projects. You must be self-directed and comfortable supporting the data needs of multiple teams, systems and products.

You will:
Work hand-in-hand with our data science team to help them iterate over new models and new data sets rapidly and make those models operational for production.
Design self-running software to automate predictive models.
Design, develop and maintain the machine learning infrastructure that will power the next generation of our research and production.
Build infrastructure required for optimal ingestion, transformation, and loading of data from a wide variety of data sources using SQL and cloud agnostic technologies.
Your team will:

Consist of a cross-functional mix of Software Engineers and Data Scientists working closely to develop the next generation models that will power our TV Measurement platform.

About you:
5+ years of experience in an engineering capacity
Master's degree or higher, preferably, with a concentration in a computational field such as Computer Science, Mathematics, Statistics, Physics or other Engineering discipline
Advanced math skills (linear algebra, Bayesian statistics, group theory)
Experience implementing machine learning models, data pipelines and testing frameworks for research and production use.
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases
Experience with object-oriented/object-functional scripting languages: Python, Java, Scala, etc.
Experience processing large datasets using parallel, elastic, streaming and/or batch techniques (e.g. experience with Spark and or Presto a big plus).
Experience working on multiple clouds a plus (AWS, GCP, Azure)
Strong analytic skills related to working with unstructured data sets.
Bonus Points:
Experience with machine learning frameworks such as TensorFlow, Scikit-Learn, PyTorch or Keras
Good understanding of database internals, query processing and query optimization
Experience using object-relational mapping (ORM) frameworks
A desire to solve business problems with technology.
Great communication skills and the ability to influence stakeholders.
Strong interpersonal skills and exceptional character
Interest, willingness and demonstrated ability to quickly pick up new technology quickly
A self-starter who brings energy, passion, and creativity to work every day
Benefits:
People: work with talented, collaborative, and friendly people who love what they do.
Food: enjoy catered meals, boundless snacks, and the occasional food truck.
Fun: we host in-person and virtual events such as game nights, happy hours, camping trips, and sports leagues.
Work/Life Harmony: flexible paid time off, remote work opportunities, and paid parental leave.
Stock: every employee is a stakeholder in our future.
Whole Health Package: medical, dental, vision, and disability insurance. Plus mental health support (via Talkspace) and fitness reimbursement up to $100 per month.
Savings: our 401K matching plan helps you plan ahead.
Commuter Subsidy: $75 per month to be used toward commuter cards, monthly parking, rideshare pools, or metro/bus passes.
Location: work in the heart of Boston
More about us:

LiveRamp's mission is to connect data in ways that matter, and doing so starts with our people. We know that inspired teams enlist people from a blend of backgrounds and experiences. And we know that individuals do their best when they not only bring their full selves to work but feel like they truly belong. Connecting LiveRampers to new ideas and one another is one of our guiding principles—one that that informs how we hire, train, and grow our global team across eight countries and four continents.

LiveRamp is an affirmative action and equal opportunity employer (AA/EOE/W/M/Vet/Disabled) and does not discriminate in recruiting, hiring, training, promotion or other employment of associates or the awarding of subcontracts because of a person's race, color, sex, age, religion, national origin, protected veteran, disability, sexual orientation, gender identity, genetics or other protected status. Qualified applicants with arrest and conviction records will be considered for the position in accordance with the San Francisco Fair Chance Ordinance.

California residents: Please see our California Personnel Privacy Policy for more information regarding how we collect, use, and disclose the personal information you provide during the job application process.


To all recruitment agencies: LiveRamp does not accept agency resumes. Please do not forward resumes to our jobs alias, LiveRamp employees or any other company location. LiveRamp is not responsible for any fees related to unsolicited resumes.",4.6,"LiveRamp
4.6","Boston, MA","San Francisco, CA",1001 to 5000 employees,2005,Company - Public,Computer Hardware & Software,Information Technology,$100 to $500 million (USD),-1
"Senior Software Engineer, Data","$96K-$187K
(Glassdoor est.)","The Opportunity


Simply stated, Livongo exists to empower people with chronic conditions to live better and healthier lives. Livongo is seeking an engineer with an emphasis on data processing, transformation, fidelity and scalability. The applicant should have a strong interest in the interface between real-time and reporting systems, pulling data from multiple sources into central data storage, and collaborating with internal Livongo teams to help provide for their data needs.

What makes a Senior Data Engineer at Livongo different?
It is engineering! Members are why we come to work every day and our engineers design and developing the product, product features, and tools for members to have a best in class health consumer experience throughout their journey with Livongo
Strong communication skills especially around collaboration with internal Livongo teams
After our Members, data is pretty significant at Livongo and our engineers design and develop data pipelines to manage how data flows between our disparate systems
Develop real time member registration with our CRM, integrating data systems across businesses like MyStrength, Retrofit, Livongo, etc.
Work with Scala, Python, Tensorflow, Keras, SKL (or Scala/DL4J) to build production-grade machine learning (ML) pipelines and tools
Create tools and data sets to assist data science
Perform continuous integration to ensure that every step of an ML pipeline is testable and automated
Assist in maintaining data integrity in production systems
Use trained models to enable rapid experimentation
Participate in Agile planning around data feature requests and advocate for the best data engineering projects in priority planning.
Collaborating closely with Livongo's ML experts, Data Scientists, Product Managers and clinical researchers to build products that help people live better lives
Candidate Profile
Experience with big data technologies such as Hadoop and Spark, and a strong depth of expertise with at least one of these
Unshakeable (nearly innate) grasp of software engineering fundamentals
Specific experience creating and maintaining production pipelines
Keen attention to detail and a knack for prioritizing competing objectives
The ability to solve real-life business problems with data
A passion for using your work to improve lives
BS degree in Engineering, Computer Science or a related field. In lieu of degree, relevant work experience and/or trade school is acceptable
7+ years' experience in software development
3+ years in a data engineering role
Strong SQL development experience (Postgres / AWS Redshift/MySQL)
Expertise in Scala, Java, or Python
People and culture are Livongo's greatest and most valued assets! We've built a culture we are proud of that reflects our values of diversity and inclusion where everyone's voice is equally important.

Our Benefits Include
Competitive compensation packages
Comprehensive medical, dental, vision and 401K
Generous PTO policy
10 paid holidays each year
Lunch provided Monday through Thursday (in office)
An endless variety of healthy snacks and beverages to fuel your creativity
Employee Stock Purchase Plan
Employee Referral Bonus Program
Team events and social gatherings
Pet-friendly environment in Mountain View, CA and Denver
Diabetes Care Prescription Reimbursement
Discount/Subsidy program for gym membership
Provide the full line of Livongo programs and services to all employees and their families
The Opportunity


The Transformative Name in Healthcare: The transformative industry forces in Community, Content and Commerce are now household names. As Amazon is to Commerce, Livongo is to Healthcare. With our Applied Health Signals engine, AI+AI, we've transformed how care is delivered.

Our Work Truly Matters: Livongo's proprietary, consumer-first technology is revolutionizing the experience of living with a chronic health condition. Our data-driven digital health engine enables our Members to seamlessly manage multiple health conditions on one empowering platform. We use smart, connected devices, personalized digital guidance, and 24x7x365 access to health professionals to make it easier for people to stay healthier.

Make an Impact: Do you want to accomplish something meaningful? To create results that matter? Livongo's innovative solution produces industry-leading member satisfaction, measurable clinical outcomes and proven healthcare costs savings. Here you can truly improve lives.

The Largest Digital Health IPO in History: We are at a milestone period in our history. On July 25, 2019 we took our company public, in order to elevate and expand the way the industry views us, thus ushering us into a whole new set of mission-critical conversations that will help us accomplish the work still to be done. As we reach new levels of achievement, we accelerate our ability to deliver life-changing services.

Focus on PEOPLE: Livongo has been voted one of the Best Places to Work in healthcare, by Fortune Magazine and Best Place to Work! Talented, passionate individuals make the difference, in this fast-moving, collaborative and inspiring environment.

Diversity and Inclusion: At Livongo we believe that personal and professional diversity is the key to innovation. We hire based solely on your strengths and qualifications, and the way in which those strengths can directly contribute to your success in your new position.

Growth and Innovation: We've already made healthcare history, yet we remain on the threshold of very big things. Leading the industry with our Applied Health Signals category, we have cracked the code to transforming healthcare. Come grow with us and support our mission to make a tangible difference in the lives of our Members.

See photos, watch videos and learn more about Livongo: follow us on Glassdoor.

#LivongoIPO #appliedhealthsignals

As an Equal Opportunity Employer, we never have and never will discriminate against any job candidate or employee due to age, race, religion, color, ethnicity, national origin, gender, gender identity/expression, sexual orientation, membership in an employee organization, medical condition, family history, genetic information, veteran status, marital status, parental status or pregnancy (including breastfeeding we have a mother's room in both our offices). In our innovative and inclusive workplace, we prohibit discrimination and harassment of any kind.",4.6,"Livongo
4.6","Denver, CO","Mountain View, CA",501 to 1000 employees,2014,Company - Public,Health Care Services & Hospitals,Health Care,Unknown / Non-Applicable,-1
Data Analyst/Data Scientist,-1,"Sr. Software Engineer – (Discovery Module)
About Privacera
Founded in 2016 by the creators of Apache Ranger™ and Apache Atlas™, Privacera’s mission is to empower enterprises building data platforms in the cloud to balance data governance and security with data access, discovery, and analytics. Often described as “Apache Ranger in the Cloud”, Privacera provides centralized access control that extends Ranger’s capabilities beyond traditional Big Data environments to cloud-native services and leading analytics platforms such as AWS, Azure, GCP and Databricks. Privacera enables IT and data platform teams to make as much data as possible available to the business for analytics while ensuring it is used ethically and in compliance with privacy regulations. Privacera offices are located in Fremont, California and Mumbai. To learn more, visit www.privacera.com
If you are a Data Scientist with a passion for solving major problems with Machine Learning and Big Data Analytics, this is a great opportunity to work with one of the industry’s leading security architects.
Principal Responsibilities:
· Development and implementation of Machine Learning algorithms in Big Data environment
· Work with Data Analysis Engineers, R&D and Product Management to solve complex customer problems and highlight opportunities
· Develop and communicate descriptive, diagnostic, predictive and prescriptive insights/algorithms
· Use machine learning and statistical modeling techniques
Minimum Requirements:
· Master or equivalent degree in a computational science
· 4+ years experience with Machine Learning
· Experience with traditional as well as modern statistical techniques, including Regression, Support Vector Machines, Regularization, Boosting, Random Forests and other ensemble methods
· Strong Analytical skills
· Proficiency in SQL and one or more of JAVA, Python and Scale
· In depth knowledge of statistical methods, data analysis and data mining
· Tuning PID loops for controllers a plus.",5.0,"Privacera
5.0","Fremont, CA","Fremont, CA",1 to 50 employees,-1,Unknown,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Machine Learning Engineer,-1,"Machine Learning Engineer
Are you a Data Scientist with a strong Machine Learning background and want to join a profitable start-up? If so, please read on!

Based in the Palo Alto area, we are a leading AI SaaS Company! Our cutting edge software suite empowers businesses of all sizes to optimize their data on a secure platform! We are using the latest Machine Learning and Data Science technologies to help our clients see anywhere from 30-40% performance improvement over traditional methods! With these off-the-chart metrics, the demand for our innovative software solutions and services has gone through the roof! We now have an urgent need for talented Machine Learning Engineers to join our team!
Top Reasons to Work with Us
1. We are dedicated to building meaningful products that are changing lives!
2. Talented Technical Team utilizing the the latest technologies
3. Tons of room for career growth and Industry stability!
What You Will Be Doing
Join our collaborative team of talented Engineers as we continue to build and enhance new features for our dynamic applications!
- Work closely with cross-functional teams on generating ideas that you will then turn into efficient and functional code (python)
- Build and implement ML and statistical models based on pricing and behavioral analytics
-Develop design experiments, optimization systems and A/B testing
- Serve as the go-to resource for all data science related questions
What You Need for this Position
- 3+ years of professional experience in Data Science or Machine Learning
- Proficiency with Python and/or R
- Preferred experience with A/B Testing and Experiment Design
- Experience building practical Machine Learning solutions (ie. Neural Networks, xgboost, Gradient Boosted Decision Trees, Regression, etc.)
- Strong background in Pricing, Behavioral Economics and/or Demand Models
- Advanced Degree in Computer Science or related field
What's In It for You
EXCELLENT benefits including:
- Competitive salaries (DOE)
- Vacation/PTO
- Medical, Dental, Vision
- 401(k) and matching
- Catered meals and much more!
So, if you're a Machine Learning Engineer with strong experience, please apply today!

OR send your resume AND salary requirements to me directly at: brenna.boies@cybercoders.com
-
Applicants must be authorized to work in the U.S.


CyberCoders, Inc is proud to be an Equal Opportunity Employer

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, protected veteran status, or any other characteristic protected by law.

Your Right to Work In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification document form upon hire.",4.2,"CyberCoders
4.2","San Jose, CA","Irvine, CA",201 to 500 employees,1999,Subsidiary or Business Segment,Staffing & Outsourcing,Business Services,$100 to $500 million (USD),-1
Principal Machine Learning Engineer,"$150K-$253K
(Glassdoor est.)","Principal Machine Learning Engineer

Cloud Solutions | US Austin Office

About the company:

In today's highly connected digital world, understanding, managing and securing the identity of individuals and things is essential to safety and success of both businesses and their customers. Billions of people connect from anywhere, use a wide variety of devices and expect a seamless yet secure experience.

The ForgeRock mission is to provide the most simple and comprehensive Identity and Access Management Platform to help our customers deepen their relationships with their consumers and improve the productivity and connectivity of their employees and partners. Our identity solution enables great digital experiences and is embedded with a rich set of security, privacy and consent features. We deliver our platform through both cloud services and on-premises software.

Our customers are some of the biggest companies, organizations, and even countries in the world. On any given day, it's likely that the ForgeRock Identity Platform helped keep your data safe, gave you access to stuff, and supported trusted relationships between you, companies and the devices you were using.

ForgeRock is headquartered in San Francisco, but we are a global company with offices in the following cities: Vancouver, WA; Austin, TX; Munich, Germany; London & Bristol, UK; Grenoble & Paris, FR; Oslo, NO; Singapore and Sydney, Australia. Please read more about us at forgerock.com or follow ForgeRock on Twitter at http://www.twitter.com/forgerock.

The Role:

We are looking for a highly motivated,Principal Machine Learning Engineer to build out the next generation Identity platform. This role requires someone to develop the technology and platform for data processing, feature engineering and analysis to propel company transformation into a data insight driven organization. Work with peers in cloud engineering, SRE to drive data driven insight through the enterprise. Work on complex, high scale machine learning models in production and develop cutting edge algorithms that are deployed directly to customers in real-time. If you are self-driven, passionate about learning, work well in a collaborative environment and have effective communication skills, then we'd love to hear from you!

Responsibilities:
Provide architectural leadership; conduct regular reviews of project work and peer review.
Help in development and scaling of data pipelines, feature pipelines and data lakes to support large scale processing of millions of data events.
Develop an industry view of analytics and design-driven problem solving. Use academic and competitor research to understand recent advances and best practices and inform our approach to developing solutions.
Required Skills and Qualifications:
Masters or PhD degree in computer science, mathematics, statistics, physics, or related quantitative field
Ten years of progressive experience in a data engineering or quantitative role.
Business acumen to work with business partners and understand their domains, processes, and issues to identify strategies to optimize and innovate
Ability to leverage data visualizations to highlight insights to business partners and make a business case for a recommended action or innovation opportunity
Proficient in the language of statistics with an advanced understanding of mathematical statistics, including combinatorics, probability, common discrete and continuous distributions, univariate and multivariate distributions, conditional probability, random variables, expectation, variance, convergence, estimation (bias, MSE, consistency, sufficiency, maximum likelihood, moments, etc.), hypothesis testing, and confidence intervals.
Ability to collaborate effectively with Data Scientists, product management, engineering, UI/UX
Theoretical and practical understanding of a range of machine learning techniques including unsupervised learning (e.g. clustering, outlier detection, PCA, ICA, NNMF, SVD, etc.), supervised learning (e.g., regression techniques, naive bayes, support vector machines, LDA, decision trees, neural networks, etc.), reinforcement learning (e.g., Q-learning, neural networks, etc.), and meta-methods (e.g., boosting, bagging)
Written communication skills to engage partners, document methodology and results, and publish research
Organizational and project management skills for overall project planning and task management
Solid understanding of (1) data structures, (2) sequential algorithms, (3) distributed algorithms, (4) runtime and space complexity
Knowledge of information technology integration and deployment patterns to design and implement solutions
Advanced proficiency in one of the programming languages like Java, Scala or Python.
Advanced proficiency in data processing frameworks like Pandas.
Advanced proficiency in TensorFlow, Keras, Cloud based ML frameworks, external ML libraries and NLP libraries.
Nice to haves:
Project and/or program management experience.
Experience in representing company in International ML conferences.
Proficiency in cloud and ML deployment strategies.
Docker, Kubernetes and VM experience
Life at ForgeRock:

We believe in and facilitate a flexible, collaborative work environment. We've grown enormously, but remain true to the innovative, can-do startup values that got us here. Most important of all, we keep hiring talented, smart, fun, and genuinely nice people because that's who we want to succeed with every day. Below are just a few of the great things we have to offer at ForgeRock:
A great team of smart, fun and genuinely nice individuals.
Awesome company culture focused around providing a flexible and collaborative work environment
Regular office bonding events, from lunches and happy hours to group offsites and hack-days
Well-stocked fridges, whether you're hungry or thirsty
Competitive benefits and perks
We're Mac-friendly!
Generous employee referral bonus program
Amazing offices across the globe San Francisco HQ; Vancouver, WA; Austin, TX; Munich, Germany; London & Bristol, UK; Grenoble & Paris, FR; Oslo, NO; Singapore, Australia & counting!
ForgeRock is the collective sum of all our individual experiences, backgrounds and influences and we pride ourselves in growing and learning together. We are committed to building an inclusive and diverse environment where everyone's individuality is respected and everyone has an Identity. In recruiting for new colleagues, we welcome the unique contributions you can bring and encourage you to be your best self.

ForgeRock is an Equal Opportunity/Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex including sexual orientation and gender identity, national origin, disability, protected Veteran Status, or any other characteristic protected by applicable federal, state, or local law.",3.9,"ForgeRock
3.9","Austin, TX","San Francisco, CA",501 to 1000 employees,2010,Company - Private,Enterprise Software & Network Solutions,Information Technology,$50 to $100 million (USD),"Okta, Ping Identity, Oracle"
eCom Data Engineer,"$61K-$115K
(Glassdoor est.)","Auto req ID: 212077BR
Job Description


As other sectors have shifted to eCommerce-first business models in recent years, food & beverage has continued to rely predominantly on traditional brick & mortar models, but this is changing rapidly and a period of extraordinary disruption is now underway. New technologies are transforming every aspect of reaching consumers, from the rise of digital marketing and online grocery platforms to the creation of supply chain tools that enable speedy at-home delivery.

To seize this opportunity and lead the food & beverage industry into its remarkable next chapter, PepsiCo – the international food & beverage powerhouse with annual net revenue exceeding $64 billion and beloved brands including Frito-Lay, Gatorade, Pepsi-Cola, Quaker, and Tropicana – is expanding its Global eCommerce Team. As it needs the greatest minds in data & analytics, software development, machine learning optimization, and next-generation supply chain. Although PepsiCo is a large multinational, the PepsiCo Global eCommerce Team prides itself on having the entrepreneurial, action-oriented culture of an exciting startup business. As part of our group, alongside Silicon Valley veterans, founders of successful startup companies, and food & beverage experts to address a wide variety of the fascinating technical challenges facing our industry.

Given PepsiCo’s incredible global reach – our foods and beverages are enjoyed more than one billion times a day in more than 200 countries and territories, and our value chain involves diverse partners ranging from farmers and food scientists to retailers and logistics specialists – the challenges we’re addressing are complex and the solutions will be deeply impactful. The goal of the PepsiCo Global eCommerce Team is to build the technological products and capabilities that will reinvent our industry and make us the #1 food & beverage business in eCommerce for decades to come.

Accountabilities:
Lead problems assessment of eCommerce challenges to lead the development and design of technology solutions across functions involving computer hardware and software
Lead technology project evaluations as well as proposal feasibility with the different eCommerce businesses
Apply theoretical expertise and innovation to create or apply new technologies to apply to the entire digital landscape
Act as a consultant to the broader business users, management, vendors, and technicians to determine technology needs and system requirements
Build new technologies and algorithms to optimize any business process
Develop data set processes and projects requirements
Use large data sets to resolve major business and functional issues whisle improving data reliability, efficiency and quality
Optimize processes implementing new technology and automation across eCommerce businesses and eCommerce functions
Qualifications/Requirements
BS or MS degree in Computer Science or a related technical field
6+ years of Python or Java development experience, Experience with multiple data technologies and concepts such as Airflow, Kafka, Hadoop, Hive, Spark, MapReduce, SQL, NoSQL, and Columnar databases
6+ years of experience with schema design and dimensional data modeling
Ability in managing and communicating data warehouse plans to internal clients
Experience designing, building and maintaining data processing systems
Experience working with either a Map Reduce or an MPP system on any size/scale
Experience with specific AWS technologies (such as Glue, S3, Redshift, EMR, and Kinesis) a plus
Experience writing production code for Python or JVM-based systems, but you know a few other languages and like the right tool for the job
Knowledge of machine-learning tools and techniques
Experience optimizing larger applications to increase speed, scalability, and extensibility
Proven self-starter who can move projects forward by filling in the gaps on Agile teams, from leading a design session to doing some test automation, to mentoring a teammate struggling with a new technology
Relocation Eligible: Not Applicable
Job Type: Regular

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, or disability status.

PepsiCo is an Equal Opportunity Employer: Female / Minority / Disability / Protected Veteran / Sexual Orientation / Gender Identity

Our Company will consider for employment qualified applicants with criminal histories in a manner consistent with the requirements of the Fair Credit Reporting Act, and all other applicable laws, including but not limited to, San Francisco Police Code Sections 4901 - 4919, commonly referred to as the San Francisco Fair Chance Ordinance; and Chapter XVII, Article 9 of the Los Angeles Municipal Code, commonly referred to as the Fair Chance Initiative for Hiring Ordinance.

If you'd like more information about your EEO rights as an applicant under the law, please download the available EEO is the Law & EEO is the Law Supplement documents. View PepsiCo EEO Policy

Please view our Pay Transparency Statement",3.7,"PepsiCo
3.7","New York, NY","Purchase, NY",10000+ employees,1965,Company - Public,Food & Beverage Manufacturing,Manufacturing,$10+ billion (USD),"Unilever, Mondelēz International, Amazon"
Machine Learning/Data Engineer,"$69K-$120K
(Glassdoor est.)","WHO WE ARE:

We're passionate about food and driven by data.

Do you want to impact our future through data, analytics and innovative technology? Do you thrive on leading big things and making it happen? Bring your passion, expertise and problem-solving skills to the table and make an impact.

General Mills is reshaping the future, and technology & data play an important role for us. Your technology experience will help us get the right data and solutions at the right time, every time. As one of the world's leading food companies,

General Mills operates across the globe with more than 100 recognizable consumer brands, including: Cheerios, LÄRABAR, Pillsbury, Yoplait, Annie's Homegrown, Totino's, Epic Provisions and Blue Buffalo.

WHAT YOU'LL DO

As a Machine Learning / Data Engineer, you will work closely with a multidisciplinary agile team to build high quality data pipelines driving analytic solutions. These solutions will generate insights from our connected data, enabling General Mills to advance the data-driven decision-making capabilities of our enterprise. This role requires deep understanding of data architecture, data engineering, data analysis, reporting, and a basic understanding of data science techniques and workflows. This team is amid transitioning data engineers into machine learning engineers. In addition, we are moving from Hadoop to Google Cloud. In this role you will:
Increase the Team's ability to understand, train, and develop ML models and supporting data pipelines
Utilize machine learning models as APIs or software libraries to be integrated into a cloud application
Establish scalable, efficient, automated processes for large scale data analyses, model development, validation, and implementation.
Design, develop, optimize, and maintain data architecture and pipelines that adhere to ETL principles and business goals.
Solve complex data problems to deliver insights that helps our business to achieve their goals
Create data products for analytics and data scientist team members to improve their productivity
Advise, consult, mentor and coach other data and analytic professionals on data standards and practices
Foster a culture of sharing, re-use, design for scale stability, and operational efficiency of data and analytical solutions
Lead evaluation, implementation and deployment of emerging tools & process for analytic data engineering to improve our productivity as a team
Develop and deliver communication & education plans on analytic data engineering capabilities, standards, and processes
Partner with business analysts and solutions architects to develop technical architectures for strategic enterprise projects and initiatives.
Learn about machine learning, data science, computer vision, artificial intelligence, statistics, and/or applied mathematics
WHO YOU ARE
Bachelor's Degree
Two (2+) or more years of professional experience in data engineering, software development/engineering, or data science
Two (2+) or more years of hands on development with frameworks such as Python, Java, Scala
Experience of developing, deploying, maintaining and debugging ML / Data Science models in a production environment
Expertise in SQL and data analysis and experience
Experience developing and maintaining data warehouses in big data solutions
Exposure to machine learning, data science, computer vision, artificial intelligence, statistics, and/or applied mathematics
Big Data development experience using Hadoop, Hive, BigQuery, Impala, Spark and familiarity with Kafka
Experience working with BI tools such as Tableau, Power BI, Looker, Shiny
Conceptual knowledge of data and analytics, such as dimensional modeling, ETL, reporting tools, data governance, data warehousing, structured and unstructured data.
Exposure to machine learning, data science, computer vision, artificial intelligence, statistics, and/or applied mathematics
Passion for agile software processes, data-driven development, reliability, and experimentation
Experience working on a collaborative agile product team
Excellent communication, listening, and influencing skills
WHAT'S NICE TO HAVE
Bachelor's degree in Computer Science, MIS, or Engineering
5+ years applicable work experience
Experience with developing solutions on cloud computing services and infrastructure in the data and analytics space
Familiarity with the Linux operating system
Experience with OLAP such as AtScale, SSAS, SAP BW, Essbase
Knowledge of Data Preparation, Data Wrangling, and Feature Engineering
Experience work with Google's cloud data ecosystem",3.8,"General Mills, Inc.
3.8","Minneapolis, MN","Minneapolis, MN",10000+ employees,1866,Company - Public,Food & Beverage Manufacturing,Manufacturing,$10+ billion (USD),-1
Artificial Intelligence/Machine Learning Engineer,"$67K-$100K
(Glassdoor est.)","Requisition ID: 51543

All Locations: El Segundo, CA (California)

A trusted partner. A national resource. A leader in national security space. We are THE Aerospace Corporation. A team that takes pride in our readiness to solve some of the most complex technical challenges in existence. With challenges spanning government to commercial, you’ll have the unique opportunity to work on projects that are literally evolving our nation's space and launch capabilities. We all share a common passion and aspiration – to serve a mission much bigger than ourselves. When you join our team, you’ll be part of a rare collection of thought leaders and game-changing innovators. Are you ready to launch your career?
Responsibilities
The Aerospace Corporation is seeking an Artificial Intelligence/Machine Learning (AI/ML) Engineer with a keen knowledge and interest in leveraging cutting edge technologies for space-domain specific applications and solutions focused on developing effective enterprise-level AI/ML technologies and frameworks. The qualified candidate will become part of Aerospace’s Data Science and AI Department, where they will develop tools, prototypes and production systems and analytic applications for mission-critical space systems.

Key Functions
Assessment of the maturity and prevalence of Artificial Intelligence and Machine Learning technologies in industry for use in scalable and resilient mission-critical applications in a production environment
Evaluation of selected technologies for specific system development tasks
Presentation of evaluation results to senior members of the team with a recommendation for the best path forward for projects
Development of prototypes and proof-of-concept software/systems for distributed, mission-critical systems
Application of engineering techniques, procedures, and criteria in software and Artificial Intelligence/Machine Learning system development and design
Development of proof-of-concept infrastructure configuration and software prototypes for/with team leads
Development and execution of experiments with other advanced information technologies (e.g. virtualization/cloud platforms, software technologies, etc.) to prove technology viability for Artificial Intelligence/Machine Learning solutions for specific applications/systems
Ability to work in small teams, as well as independently drive projects
Learning and understanding of new and cutting-edge technologies for utilization within product development and lifecycles
Creating an environment of learning and progress with team members and others
This position is available as AI/ML Engineer or Sr. AI/ML
Qualifications
Required for AI/ML Engineer
Bachelor's degree in Machine Learning, Data Science, Computer Science, Computer Information Systems, Engineering, Physics, Mathematics or a related field from a recognized institution
Two or more years of software development in at least two different languages (e.g. Java, Python, C/C++)
One or more years of experience developing Artificial Intelligence/Machine Learning solutions in TensorFlow, Keras, PyTorch, Caffe, SciKit Learn, or any other machine learning frameworks
Understanding of full-stack software engineering process
Experience with machine learning methods like random forests, logistic regression, neural networks, k-nearest neighbors, etc.
Experience with Artificial Intelligence techniques like Probabilistic Programming, Genetic Algorithms, Reinforcement Learning and adaptive systems
Working knowledge of Unix/Linux operating systems
Leadership or technical responsibility in one or more software development or computer engineering projects
This position requires the ability to obtain and maintain a Secret security clearance, which is issued by the U.S. government. U.S. citizenship is required to obtain a security clearance.
Required for Sr. AI/ML Engineer
All requirements necessary for AI/ML Engineer
Familiarity/Experience with full ML/AI development life-cycle (e.g. data management, data curation, data pipelines, model development, model deployment, model auditing)
Five or more years of progressively responsible experience in relevant Artificial Intelligence/ Machine learning or Data Science roles
Expertise in Python, CUDA, and/or C++ programming languages
Strong experience working with Unix/Linux operating systems
This position requires the ability to obtain and maintain a Secret security clearance, which is issued by the U.S. government. U.S. citizenship is required to obtain a security clearance.
Preferred
Advanced degree in a technically related field
Active security clearance
Participation in extracurricular activities related to data science (e.g. Kaggle competitions)
Experience with data visualization and user interfaces
Experience with statistical modeling tools (R, Python, Octave/Matlab, etc.)
Experience in implementing real-time machine learning and data mining algorithms in large scale environments
Experience with big data frameworks (e.g. Hadoop, Spark, etc.)
Experience in image/signal processing, statistics, data mining, and predictive modeling
Experience in SQL, NoSQL, and other big data querying languages
Familiarity with statistical tests, distributions, maximum likelihood estimators, etc.
Proficiency in at least one visualization tool and/or library (D3, Matplotlib, MS Excel, etc.)
Experience utilizing Scikit-learn, OpenCV, Caffe/TensorFlow/PyTorch libraries
Experience in collecting data from/exposing data to various data sources and services (API, XML, JSON, etc.)
Demonstrated ability to effectively define goals and track progress on tasks
Demonstrated ability to apply initiative and creativity to solve problems
Demonstrated ability to cooperate as a member of a team
Demonstrated ability to operate independently and proactively seek guidance as needed
Transcript Requirement
Transcripts are required for this position.

Additional Requisition Details

System Job Title:MEMBER-TECH STF

Clearance Requirement: None

Access: None

Polygraph: None

Employment Type: Regular

Work Schedule: Full Time

Company Statement

The Aerospace Corporation has provided independent technical and scientific research, development, and advisory services to national security space programs since 1960. We operate a federally funded research and development center (FFRDC) for the United States Air Force and the National Reconnaissance Office, and support all national security space programs. We also apply more than 50 years of experience with space systems to provide critical solutions to technologically complex systems in such areas as communications, shipping, law enforcement, and cyber, among others.

From our inception, our highly skilled technical staff has focused on ensuring the success of every mission and developing the most effective and economic space-related hardware and software in the world. Our greatest asset is the technical expertise of our people. Our state-of-the-art laboratory facilities are staffed by some of the leading scientists in the world.

Equal Opportunity Commitment

The Aerospace Corporation is an Equal Opportunity/Affirmative Action employer. We believe that a diverse workforce creates an environment in which unique ideas are developed and differing perspectives are valued, producing superior customer solutions. All qualified applicants will receive consideration for employment and will not be discriminated against on the basis of race, gender, gender identity or expression, color, religion, national origin, sexual orientation, protected veteran status, or disability status.

You can also review The Equal Employment Opportunity is the Law poster and the supplement, as well as the Pay Transparency Policy Statement",3.9,"The Aerospace Corporation
3.9","El Segundo, CA","El Segundo, CA",1001 to 5000 employees,1960,Nonprofit Organization,Aerospace & Defense,Aerospace & Defense,$1 to $2 billion (USD),-1
"Machine Learning Engineer, Conversations","$127K-$208K
(Glassdoor est.)","Square builds common business tools in unconventional ways so more people can start, run, and grow their businesses. When Square started, it was difficult and expensive (or just plain impossible) for some businesses to take credit cards. Square made credit card payments possible for all by turning a mobile phone into a credit card reader. Since then Square has been building an entire business toolkit of both hardware and software products including Square Capital, Square Terminal, Square Payroll, and more. We're working to find new and better ways to help businesses succeed on their own terms-and we're looking for people like you to help shape tomorrow at Square.The Conversations team at Square is building Square Assistant -- a virtual assistant to help merchants serve their customers. Today, Square Assistant responds to customers asking for help with their appointments, including cancellations, confirmations, and conversational rescheduling of appointments; as well as, of course, answering common questions. Looking into 2021 we're excited to expand Square Assistant with new skills to save merchants as much time as we can, and we're excited to bring Square Assistant to the phone: adding voice capabilities to the bot. The team itself was created in mid-2019 with the acquisition of Eloquent Labs.We're looking for NLP engineers and research scientists, particularly those with an interest in dialog systems, speech, and/or textual entailmentYou will...* Help design and develop novel dialog systems within Square* Build AI systems to handle millions of conversations* Work with Backend, iOS, and web engineers to ship features.* Work cross collaboratively with product managers and designers to improve and define product scope and design.* Ship cutting-edge AI to businesses that traditionally haven't had access to itYou have* Experience with machine learning, with a specialization in natural language processing* Experience with Python and PyTorch is recommended* Experience in Java is a plus* Interest to help shape the mission and roadmap of a team, and rallying others to join you* Eagerness to share your ideas, and openness to those of othersLanguages and technologies we use (and teach)...* Python and Java for development* PyTorch for training ML models* SQL for storing and processing analytics data from the bot* AWS for training and serving ML modelsAt Square, we value diversity and always treat all employees and job applicants based on merit, qualifications, competence, and talent. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. We will consider for employment qualified applicants with criminal histories in a manner consistent with the requirements of the San Francisco Fair Chance Ordinance. Applicants in need of special assistance or accommodation during the interview process or in accessing our website may contact us by sending an email to assistance(at)squareup.com. We will treat your request as confidentially as possible. In your email, please include your name and preferred method of contact, and we will respond as soon as possible.PerksAt Square, we want you to be well and thrive. Our global benefits package includes:* Healthcare coverage* Retirement Plans* Employee Stock Purchase Program* Wellness perks* Paid parental leave* Flexible time off* Learning and Development resources",4.0,"Square
4.0","Redwood City, CA","San Francisco, CA",1001 to 5000 employees,2009,Company - Public,Computer Hardware & Software,Information Technology,$1 to $2 billion (USD),-1
Machine Learning / Data Scientist,-1,"Job Description
Our client is a digital invention agency focused on machine learning methodologies, enterprise mobile and web applications, eCommerce, augmented reality and IoT. They look to innovatively make this world a better place with each and every product, system, idea and app they release.

Job Summary

Our client is looking for a machine learning engineer to join our existing ML team in developing and refining a predictive application.

The ideal candidate is adept at using large data sets to find opportunities for product and process optimization and using models to test the effectiveness of different courses of action.

You must have strong experience using a variety of data mining/data analysis methods, using a variety of data tools, building and implementing models, using/creating algorithms and creating/running simulations. You must have a proven ability to drive business results with their data-based insights. You must be comfortable working with a wide range of stakeholders and functional teams. The right candidate will have a passion for discovering solutions hidden in large data sets and working with stakeholders to improve business outcomes.

As a ML Engineer, you will:
Work with stakeholders throughout the organization to identify opportunities for leveraging data to drive business solutions
Mine and analyze data from databases to drive optimization and improvement of product development, marketing techniques and business strategies
Assess the effectiveness and accuracy of new data sources and data gathering techniques
Develop custom data models and algorithms to apply to data sets
Use predictive modeling to increase and optimize customer experiences, revenue generation, ad targeting and other business outcomes
Coordinate with different functional teams to implement models and monitor outcomes
Develop processes and tools to monitor and analyze model performance and data accuracy
For this role you will need:
Strong with Statistics and can code in either R, Python, Java and Scala
Experience with designing and building using micro-services architectural pattern, web APIs using dotnet core & C#
Experience and passion for simulations, optimization, neural networks, artificial intelligence (deep learning and machine learning)
Experience with distributed data/computing tools: Map/Reduce, Hadoop, Hive, Spark, GIT, SQL, etc.
Able to understand statistical solutions and execute similar activities
Experience in data wrangling and advanced analytic modeling
Strong communication and organizational skills and has the ability to deal with ambiguity while juggling multiple priorities and projects at the same time
Experience visualizing/presenting data for stakeholders using: Seaborn, Business Objects, D3, ggplot, etc.
Ability to investigate the feasibility and data requirements necessary to develop an ML solution for a given problem
Ability to design, build and test production ready ML-based products while interpreting and explaining the basis for predictions generated by ML models
The perfect candidate will have:
Knowledge and experience using one or more of the following, or similar, machine learning software frameworks: CAFFE, Torch 7, Keras and Tensorflow
Experience building production-ready NLP or information retrieval systems
Hands-on experience with NLP tools, libraries and corpora (e.g. NLTK, Stanford CoreNLP, Wikipedia corpus, etc.)
PROPRIUS is an AI Industry recruiting firm. We’re lucky enough to recruit the best candidates into the most exciting companies all over the United States. We deliver performance.
LI-Y",5.0,"PROPRIUS
5.0","San Francisco, CA","London, United Kingdom",1 to 50 employees,-1,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
"Machine Learning Engineer, Data Science","$122K-$209K
(Glassdoor est.)","Atlassian is continuing to hire with all interviewing and on-boarding done virtually due to COVID-19. Everyone new to the team, along with our current staff, will temporarily work from home until it is safe to return to our offices.

Do you have a passion for crafting products and insights with data? Do you love the idea of rapidly iterating on new features and finding the ones which move the needle and hit customer engagement out of the ballpark? Would you like to drive real change at the world’s hottest SaaS company?
Atlassian is looking for a Machine Learning Engineer to join our Data Science team based in Mountain View CA. We are looking for someone passionate about data science and its applications to create business value. You enjoy working with cutting edge technology, and you relish the opportunity to make an impact to the way millions of users use our products in their day-to-day work. You are able to work effectively with a variety of other disciplines across the company.

In a data-hungry place like Atlassian experiencing rapid growth, business opportunities from the application of data science abound. Join us for the opportunity to do groundbreaking applied machine learning work that will help shape the Atlassian user experience!
In this role, you'll get to
Construct and refine AI algorithms to optimize our marketing and on-boarding funnels
Craft machine learning and predictive models to drive intelligent product features
Work with our seriously large volume of analytics data
Define and build out scalable distributed infrastructure to support our vision of optimized real-time personalization across the portfolio of Atlassian products
Extend existing ML libraries and frameworks
Research and implement appropriate ML algorithms and tools
Provide technical leadership and influence data-driven optimization efforts.
Challenge and enrich yourself in an environment of like-minded engineers and data scientists, and most importantly have fun!
On the first day, we'll expect you to have
MS or PhD in Computer Science or a related quantitive field
5+ years of related industry experience in a data science or engineering domain
Development experience in a Python/ Java/ Scala
Experience working in an Agile environment
Extensive data modeling and data architecture skills
Knowledge of Spark or other distributed cloud computing systems
Experience developing, building and scaling machine learning models in business applications using large amounts of data
Strong written and verbal communication skills

It's great, but not required, if you have
Experience working in an enterprise or B2B space, as well as the consumer or B2C space
Working knowledge of DataBricks environment
Experience with ML platforms such as MLflow, MLeap, MichelAngelo
Knowledge of A/B experimentation
This team is being built within the broader Analytics group and tasked to pursue business opportunities that can generate revenue or MAU improvements. The team works multi-functionally across the organization, using insights generated by marketing and product analytics that can be scaled or automated to generate business value. The team will be highly nimble, with a focus on velocity between ideation and initial output, and laser-focused on business impact.

More about our benefits

Whether you work in an office or a distributed team, Atlassian is highly collaborative and yes, fun! To support you at work (and play) we offer some fantastic perks: ample time off to relax and recharge, flexible working options, five paid volunteer days a year for your favourite cause, an annual allowance to support your learning & growth, unique ShipIt days, a company paid trip after five years and lots more.

More about Atlassian

Creating software that empowers everyone from small startups to the who’s who of tech is why we’re here. We build tools like Jira, Confluence, Bitbucket, and Trello to help teams across the world become more nimble, creative, and aligned—collaboration is the heart of every product we dream of at Atlassian. From Amsterdam and Austin, to Sydney and San Francisco, we’re looking for people who want to write the future and who believe that we can accomplish so much more together than apart. At Atlassian, we’re committed to an environment where everyone has the autonomy and freedom to thrive, as well as the support of like-minded colleagues who are motivated by a common goal to: Unleash the potential of every team.

Additional Information

We believe that the unique contributions of all Atlassians is the driver of our success. To make sure that our products and culture continue to incorporate everyone's perspectives and experience we never discriminate on the basis of race, religion, national origin, gender identity or expression, sexual orientation, age, or marital, veteran, or disability status.

All your information will be kept confidential according to EEO guidelines.",4.4,"Atlassian
4.4","Mountain View, CA","Sydney, Australia",1001 to 5000 employees,2002,Company - Public,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,GitHub
eCom Full Stack Senior Engineer,"$89K-$153K
(Glassdoor est.)","Auto req ID: 213130BR
Job Description


The next great shift in consumer behavior driven by technological disruption is underway, and it’s happening in the food & beverage industry.

As other sectors have shifted to eCommerce-first business models in recent years, food & beverage has continued to rely predominantly on traditional brick & mortar models, but this is changing rapidly. New technologies are transforming every aspect of reaching consumers, from the rise of digital marketing and online grocery platforms to the creation of supply chain tools that enable speedy at-home delivery. According to the Food Marketing Institute, 70% of U.S. consumers will shop online for groceries by 2024, with an estimated annual spend of $100 billion.

To deepen our efforts to seize this opportunity and lead the food & beverage industry into its remarkable next chapter, PepsiCo – a global company with powerhouse brands including Frito-Lay, Gatorade, Pepsi-Cola, Quaker, and Tropicana – is expanding its Global eCommerce Team. We’re looking for the greatest minds in software engineering, data & analytics, machine learning and next-generation supply chain. Given PepsiCo’s incredible reach (our foods and beverages are enjoyed more than one billion times a day in more than 200 countries and territories, leveraging a value chain involving diverse partners ranging from farmers and food scientists to retailers and logistics specialists), the challenges we’re addressing are complex and the solutions will be deeply impactful.

Although PepsiCo is a large multinational, the PepsiCo Global eCommerce Team prides itself on having the entrepreneurial, action-oriented culture of an exciting startup business. Our group includes startup founders, Silicon Valley veterans, food & beverage experts, and seasoned executives from digital transformation leaders such as Amazon and Walmart. Our goal is to build the technological products and capabilities that will reinvent our industry and make us the #1 food & beverage business in eCommerce for decades to come.

We're looking for a Full Stack Engineer to join our growing engineering team and assist us in driving product initiatives forward while upholding our high engineering standards.

In this role you will have several distinct responsibilities and priorities:
You will own application development end-to-end, spanning data models, testing, scalability, operability, and ongoing metrics.
We work in Elixir: however, languages can be learned. We put more emphasis on your general engineering skill and willingness to learn than knowledge of a particular language or framework.
We need you to be versatile, display leadership qualities, and be enthusiastic to take on new problems across the full-stack as we continue to push technology forward.
You will work directly with designers to implement and build fully-featured modern web applications.
Some technologies that we use - we don't expect you to know all of these but some familiarity would be great:
Functional programming e.g. Elixir, Clojure or Haskell
Ruby on Rails
Python
PostgreSQL
Qualifications/Requirements
Bachelor’s Degree in Computer Science or related field
Preferred Qualifications:
Experience defining system architectures and exploring technical feasibility tradeoffs
6+ years of professional experience in software development
3+ years of professional experience with HTML/CSS (Sass) and javascript
Knowledge of professional software engineering practices & best practices for the full software development life cycle, including coding standards, code reviews, source control management, continuous integrations, testing, and operations
Hands-on experience with cloud-based platform capabilities
Ability to transform a design into a working product
Bonus Qualifications:
Experience with Elixir and the Phoenix web framework
Extra bonus points if you’ve used Phoenix LiveView
Experience deploying applications to Kubernetes
Relocation Eligible: Not Applicable
Job Type: Regular

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, or disability status.

PepsiCo is an Equal Opportunity Employer: Female / Minority / Disability / Protected Veteran / Sexual Orientation / Gender Identity

Our Company will consider for employment qualified applicants with criminal histories in a manner consistent with the requirements of the Fair Credit Reporting Act, and all other applicable laws, including but not limited to, San Francisco Police Code Sections 4901 - 4919, commonly referred to as the San Francisco Fair Chance Ordinance; and Chapter XVII, Article 9 of the Los Angeles Municipal Code, commonly referred to as the Fair Chance Initiative for Hiring Ordinance.

If you'd like more information about your EEO rights as an applicant under the law, please download the available EEO is the Law & EEO is the Law Supplement documents. View PepsiCo EEO Policy

Please view our Pay Transparency Statement",3.7,"PepsiCo
3.7","San Francisco, CA","Purchase, NY",10000+ employees,1965,Company - Public,Food & Beverage Manufacturing,Manufacturing,$10+ billion (USD),"Unilever, Mondelēz International, Amazon"
Machine Learning,"$55K-$101K
(Glassdoor est.)","Position Title Software Engineer ConsultantExpert Duration Long Term Location Dearborn,MI,48124 Position Description Position Overview GDIA is looking for a Machine Learning Platform Engineer focused on building an Data Science and AI,ML platform. The team you will be working on is focused on building Mach1ML platform. an AIML enablement platform to democratize Machine Learning across Ford enterprise (similar to Uber.s Michelangelo, Facebook.s FBLearner, etc). Position Responsibilities . Lead software engineers to understand platform vision, break out tasks and help them solve challenging issues. . Grow technical capabilities, expertise and provide guidance to other software engineers on the team. . Work with architects to make technical decision on tools, integration and other issues. . Mentor and train other Software Engineers to help them learn agile methods and build technical skills. . Help innovate and iterate on agile processes and share our learnings. . Work hand to hand with Data Scientists to shape the future vision of our Data Science platform. Basic Qualifications . A Bachelor.s degree in Computer Science , Computer Engineering or similar technical discipline . MUST 2 or more years of professional experience (not including education) with Machine Learning Platforms, MLOps, Kubernetes, Feature Stores etc. . 2or more years of experience leading developers . Experience and good understanding of Machine Learning , Deep Learning Models , Python , ML Model Deployment and ML Model Management for production environments . Understanding or desire to learn end to end Machine Learning technology stack (Tools such as , Kubernetes, SeldonCore, Data Robot, Domino Data Labs etc) Skills Required Machine Learning Platforms Software Engineering Kubernetes MLOps Experience Required PLEASE DO NOT SUBMIT CANDIDATES WHO DO NOT HAVE AT LEAST 2 YEARS OF EXPERIENCE WITH MACHINE LEARNING PLATFORMS, KUBERNETES , AND SOFTWARE ENGINEERING. Education Required Minimum Bachelor Thanks Regards Srikala E P +1 732 898 6780 E srikala.elpulaxoriant.com",3.6,"Xoriant Corporation
3.6","Dearborn, MI","Sunnyvale, CA",1001 to 5000 employees,1990,Company - Private,IT Services,Information Technology,$100 to $500 million (USD),"Persistent Systems (India), GlobalLogic, Synechron"
Principal Machine Learning Software Engineer,"$219K-$371K
(Glassdoor est.)","Are you interested in being part of a team with close to $10B in revenue and rapid growth? Are you looking for joining a fun and fast paced environment, where people are empowered to innovate? Are you excited about cutting-edge machine learning technologies? Are you passionate about solving real customer problems with AI?Online Advertising is still one of the fastest growing businesses on the Internet today, and Bing Ads is considered one of the most important players in the world of Advertising business. In Campaign Intelligence team, we use truly state-of-the-art machine learning and AI technologies, to transform the user experience with AI infusion, and to unlock the magic of advertising data. We train large BERT/GTP2 models to automatically generate ad creatives and offer online suggestions. We work on Federated Learning to preserving user privacy while improving algo performance. We use GNN to deepen the advertiser understanding so we could provide best recommendations and optimizations. The technologies are amazing and the team is fast growing, it is the perfect time to join!* BS in Computer Science, Statistics, Applied Mathematics or Physics. MS/PhD is strongly preferred.* Excellent communication and collaborative skills* 8+ years of professional experience in applications of machine learning, data science and/or analysis* 3+ years of experience in at least one of the DL frameworks like PyTorch, TensorFlow or etc.* 5+ years of experience in at least one of programming languages like Python/R/C#/Java/C++* Experience with NLP, CV or Recommender System is a big plusMicrosoft is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable laws, regulations and ordinances. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. If you need assistance and/or a reasonable accommodation due to a disability during the application or the recruiting process, please send a request via the Accommodation request form.Benefits/perks listed below may vary depending on the nature of your employment with Microsoft and the country where you work.#BingAds#As a Principal Software Engineer, you will formulate approaches to solve problems using AI and ML in the context of customer, engineering and business needs. You will dive deep into data to find key insights that impact the business. You will design algorithm, train model and deploy to production. You will lead other data scientists to work with engineers and product managers to deliver end-to-end experience. You will collaborate across the company including research teams to adopt the latest technologies in AI and ML. You will come up with innovative solutions to address customer challenges.",4.3,"Microsoft Corporation
4.3","Bellevue, WA","Redmond, WA",10000+ employees,1975,Company - Public,Computer Hardware & Software,Information Technology,$10+ billion (USD),"Google, Amazon, Apple"
Machine Learning Engineer/Scientist,"$143K-$166K
(Glassdoor est.)","About the Position


Jane Street is seeking exceptional candidates for the role of Senior Machine Learning Engineer/Scientist.

Responsibilities:
Help lead the effort to expand and improve Jane Street's ML infrastructure and data pipeline.
Collaborate with teams of researchers and traders in our offices around the world to design and train ML models.
Invent new techniques when necessary to deal with the specific problems Jane Street works on.
About You
At least three years experience building ML infrastructure and production models in an industrial setting.
Very strong coding skills, including experience developing and deploying large software projects.
Deep experience with applying one or more major ML packages (e.g. TensorFlow, PyTorch) to very large data sets.
A desire to push the boundaries of ML to better deal with the problems specific to financial data including low signal-to-noise ratios and non-stationarity.
No finance background is necessary.",4.8,"Jane Street
4.8","New York, NY","New York, NY",501 to 1000 employees,2000,Company - Private,Investment Banking & Asset Management,Finance,Unknown / Non-Applicable,-1
"Master Software Engineer (Java, Angular, AWS)","$101K-$122K
(Glassdoor est.)","1 Broadway (21026), United States of America, Cambridge, Massachusetts

At Capital One, were building a leading information-based technology company. Still founder-led by Chairman and Chief Executive Officer Richard Fairbank, Capital One is on a mission to help our customers succeed by bringing ingenuity, simplicity, and humanity to banking. We measure our efforts by the success our customers enjoy and the advocacy they exhibit. We are succeeding because they are succeeding.

Guided by our shared values, we thrive in an environment where collaboration and openness are valued. We believe that innovation is powered by perspective and that teamwork and respect for each other lead to superior results. We elevate each other and obsess about doing the right thing. Our associates serve with humility and a deep respect for their responsibility in helping our customers achieve their goals and realize their dreams. Together, we are on a quest to change banking for good.

Master Software Engineer (Java, Angular, AWS)
Do you want to re-imagine how we manage risk and build great products that users love? This may be the place for you, if:
Youre passionate about engineering and obsess about code quality, performance, and CI/CD
You like to work with modern architecture and latest open source technologies: Microservices, Docker, AngularJS, Node.js, Java, Python, Kafka, Spark, and many many more
You take an interest in infrastructure resiliency and how your code actually works at runtime: OS, network, and AWS cloud
You thrive in a continuously learning and collaborative environment by reviewing others code and asking them to do the same for you
You participate in forums, hackathons, meetups, and conferences
You own your work by building systems to succeed in production, and you fix them when they dont
By joining our Risk and Governance team, you will:
Build microservices to fully automate and integrate the full lifecycle of issues & events management into our real-time, event-based data ecosystem in the public cloud
Build platforms and machine learning-driven capabilities to support investigations of AML and other financial crimes
Develop governance capabilities for the companys advanced analytic environments where data scientists rapidly build and deploy models & algorithms
Basic Qualifications:
Bachelors Degree or military experience
At least 8 years experience in Java and Spring
At least 3 years of experience with JavaScript Frameworks (Angular or React or Ember or Type Script)
At least 3 years RESTful web services experience
At least 1 year of experience working with microservices architecture
At least 1 year of experience working in AWS
Preferred Qualifications:
Masters Degree
10+ years experience in software development
3+ years experience in microservices architecture
3+ years experience with AWS
Experience mentoring junior team members
At this time, Capital One will not sponsor a new applicant for employment authorization for this position.",3.9,"Capital One
3.9","Cambridge, MA","Mc Lean, VA",10000+ employees,1994,Company - Public,Banks & Credit Unions,Finance,$10+ billion (USD),"J.P. Morgan, Wells Fargo, McKinsey & Company"
Data Scientist - Analytics Competency Center,"$63K-$113K
(Glassdoor est.)","Job Profile

Position Overview
At PNC, our people are our greatest differentiator and competitive advantage in the markets we serve. We are all united in delivering the best experience for our customers. As a Data Scientist within PNC's Analytics Competency Center (ACC) Data Science group, you will be based in Cleveland, Ohio or Pittsburgh, Pennsylvania.

In this role you will

• Recommend design and develop state-of-the-art data-driven analysis using statistical & advanced analytics methodologies to solve business problems. Expertise in Data Science, Data Mining, Machine Learning, Predictive Modeling best practices is vital.
• Develop models & recommend insights. Form hypothesis and run experiments to gain empirical insights and validate the hypothesis. Identify and eliminate possible obstacles and identify an alternative creative solution.
• Partner with a cross-functional team of data engineers, data scientists, software engineers, and product managers to deliver a solutions
• Leverage a broad stack of technologies R, Python, Conda, Spark, SAS and more to reveal the insights hidden within huge volumes of numeric and textual data
• Build machine learning models through all phases of development, from design through training, evaluation, validation, and implementation. Machine Learning for Data Science includes algorithms that are central to ML: K-nearest neighbors, Random Forests, Naive Bayes, and Regression Models. PyTorch, TensorFlow, Keras also find its usability in Machine Learning for Data Science
• Independently research, experiment, prototype ML solutions to solve problems within a large enterprise domain (say, Ad Targeting, Video Processing, NLP, Computer Vision, etc.)
• Collaborate with software engineers, data engineer and DevOps to integrate and scale ML solutions into large, complex software products in the enterprise ecosystem
• Flex your interpersonal skills to translate the complexity of your work into tangible business goals.

Requirements:

•BS in a STEM related area. Masters/PhD in STEM is a plus.

•3+ years of experience in open source programming languages for large scale data analysis, machine learning, and experience with relational databases.

•Strong communication and writing skills.

• Strong working knowledge of Python, R, SQL OR Scala

Please note, PNC will not sponsor work visas for this position.

Job Description
Performs analytical tasks on vast amounts of structured and unstructured data to extract actionable business insights.
Participates in the data gathering, data processing and data mining of large and complex datasets.
Develops algorithms using advanced mathematical and statistical techniques like machine learning to predict business outcomes and recommend optimal actions to management.
Runs analytical experiments in a methodical manner to find opportunities for product and process optimization. Assists in the presentation of business insights to management using visualization technologies and data storytelling.
May partner with Data Architects, Data Analysts, Data Engineers and Visualization Experts to develop data-driven solutions for the business.
PNC Employees take pride in our reputation and to continue building upon that we expect our employees to be:
Customer Focused - Knowledgeable of the values and practices that align customer needs and satisfaction as primary considerations in all business decisions and able to leverage that information in creating customized customer solutions.
Managing Risk - Assessing and effectively managing all of the risks associated with their business objectives and activities to ensure they adhere to and support PNC's Enterprise Risk Management Framework.
Competencies
Data Architecture Knowledge and ability to create models and standards to govern which data is collected, and how it is stored, arranged, integrated, and put to use in data systems and in organizations.Data Mining Knowledge of tools, techniques and practices in data mining technologies used to acquire essential business information.Disruptive Innovation Knowledge of concepts, principles, and approaches of disruptive innovation; ability to adopt the knowledge into related processes and practices.Information Capture Knowledge of the processes and the ability to identify, capture and document relevant business information in an auditable, organized, understandable and easily retrievable manner.Machine Learning Knowledge of principles, technologies and algorithms of machine learning; ability to develop, implement and deliver related systems, products and services.Modeling: Data, Process, Events, Objects Knowledge of and the ability to use tools and techniques for analyzing and documenting logical relationships among data, processes or events.Prototyping Knowledge of and ability to implement prototyping disciplines, tools and techniques in evolutionary models within the target environment.Query and Database Access Tools Knowledge of and the ability to use, support and access facilities for extracting and formatting a database management system.
Work Experience
Roles at this level typically require a university / college degree, with 3+ years of relevant / direct industry experience. Certifications are often desired. In lieu of a degree, a comparable combination of education and experience (including military service) may be considered.
Education
Masters

Disability Accommodations Statement:

The PNC workplace is inclusive and supportive of individual needs. If you have a physical or other impairment that might require an accommodation, including technical assistance with the PNC Careers website or submission process, please call 877-968-7762 and select Option 4: Recruiting or contact us via email at pathfinder@pnc.com.

The Human Resources Service Center hours of operation are Monday - Friday 9:00 AM to 5:00 PM ET.

Equal Employment Opportunity (EEO):

PNC provides equal employment opportunity to qualified persons regardless of race, color, sex, religion, national origin, age, sexual orientation, gender identity, disability, veteran status, or other categories protected by law.

California Residents

Refer to the California Consumer Privacy Act Privacy Notice to gain understanding of how PNC may use or disclose your personal information in our hiring practices.",3.4,"PNC Financial Services Group
3.4","Pittsburgh, PA","Pittsburgh, PA",10000+ employees,1845,Company - Public,Banks & Credit Unions,Finance,$10+ billion (USD),"J.P. Morgan, Bank of America"
Machine Learning Platform Engineer,"$55K-$101K
(Glassdoor est.)","Software Engineer ConsultantExpert Dearborn Michigan Remote (Until Covid-19 ends) Long Term Position Description looking for a Machine Learning Platform Engineer focused on building an Data Science and AI,ML platform. The team you will be working on is focused on building Mach1ML platform. an AIML enablement platform to democratize Machine Learning across client enterprise (similar to Uber.s Michelangelo, Facebook.s FBLearner, etc). Position Responsibilities . Lead software engineers to understand platform vision, break out tasks and help them solve challenging issues. . Grow technical capabilities, expertise and provide guidance to other software engineers on the team. . Work with architects to make technical decision on tools, integration and other issues. . Mentor and train other Software Engineers to help them learn agile methods and build technical skills. . Help innovate and iterate on agile processes and share our learnings. . Work hand to hand with Data Scientists to shape the future vision of our Data Science platform. Basic Qualifications . A Bachelor.s degree in Computer Science , Computer Engineering or similar technical discipline . MUST 2 or more years of professional experience (not including education) with Machine Learning Platforms, MLOps, Kubernetes, Feature Stores etc. . 2or more years of experience leading developers . Experience and good understanding of Machine Learning , Deep Learning Models , Python , ML Model Deployment and ML Model Management for production environments . Understanding or desire to learn end to end Machine Learning technology stack (Tools such as , Kubernetes, SeldonCore, Data Robot, Domino Data Labs etc). Skills Required Machine Learning Platforms Software Engineering Kubernetes MLOps. Education Required Minimum Bachelor Thanks, Sandeep Pedhi 732-898-6796",3.6,"Xoriant Corporation
3.6","Dearborn, MI","Sunnyvale, CA",1001 to 5000 employees,1990,Company - Private,IT Services,Information Technology,$100 to $500 million (USD),"Persistent Systems (India), GlobalLogic, Synechron"
"Senior Software Engineer, Machine Learning","$96K-$112K
(Glassdoor est.)","Do you want to be a part of something innovative and cutting edge? If your answer is yes, then join our team of more than a hundred software specialists, data scientists and analysts, technical project managers, system engineers, security engineers and web designers that are smart, creative and excited by what they do!
Cambium Assessment’s technology team is an innovation driver in the assessment industry. We regularly deal with technology challenges such as algorithmic computing, dynamic scalability, and artificial intelligence. Some of our ground-breaking work includes: advanced computer-adaptive algorithms (only one that’s peer-approved in the country); mobile support for the user interfaces; learning management systems with social media features; user interfaces that are universally accessible to people with or without disabilities; innovative, machine-scorable items and that’s just to name a few.
We design and build things that are inspiring and make a real impact in the online testing industry and we are currently seeking a Senior Software Engineer, Machine Learning for their office in Washington, D.C.
Position Summary
The machine learning engineer work will be an integral part of the machine learning / scoring development team within Cambium Assessment. This diverse group of professionals that include mathematicians, computer scientists, psychometricians, statisticians and software engineers, provide custom machine learning solutions for our clients as well as internal support systems. The right candidate will have the skills needed to perform full life-cycle software development to take research ideas and initiatives from concept/prototype to production quality software. This includes participation in research discussions, requirements gathering, application and database design, system documentation, writing and unit-testing efficient code, and deployment.

• Implement high performance, scalable and reliable software solutions in Python on Linux or Windows platforms
• Develop and deploy synchronous and asynchronous REST API web services using Python frameworks
• Develop effective methods of ML model testing during all stages: development, deployment, and recalibration
• Train machine learning models, analyze performance metrics, and communicate results with visual and statistical aids
• Analyze, visualize, and summarize large multidimensional datasets
• Utilize best practices for software development of high performance systems around design, coding, automated unit and regression testing and deployment

• Bachelors degree in Computer Science or related field and 5+ years professional software development experience
• Extensive experience with Python and python frameworks (e.g. CherryPy, Bottle, Flask, Django)
• Solid experience with multithreading and multiprocessing in Python on Linux and Windows platforms
• Solid SQL and querying databases through Python (e.g. pyodbc)
• Experience using AWS instances and S3 buckets
• Tools and frameworks for testing (unittest, pytest) and software versioning (Bitbucket)
• Ability to train machine learning models, analyze performance metrics, and communicate results
• Solid understanding of ML algorithms
• Self-starter, independent thinker and worker
• Excellent analytical skills
• Highly detail-oriented
• Good communication skills
• Ability to work well on a team as well as independently
• Ability to communicate results effectively
Preferred Qualifications
• Masters degree in Computer Science
• Experience with Python-based machine learning frameworks (e.g., Keras, PyTorch, gensim)
*LI-DG1
Cambium Assessment is one of America’s leading K -12 educational assessment entities, currently holding prime contracts for educational testing and scoring in many states. We offer superior technology and next-generation questions making our tests valid, innovative, and informative. Our tests are able to collect more information on what each student knows and can do in the same amount of time as a traditional test – thus freeing up teachers to teach and students to learn.
Cambium Assessment joined Cambium Learning Group, Inc. as it’s sixth business unit in their existing portfolio on January 1, 2020. Cambium Learning Group, Inc. is a leading educational solutions and services company committed to helping all students reach their full potential. The company’s award-winning brands provide breakthrough technology solutions for students and teachers—including best-in-class intervention and supplemental instructional programs; gold-standard professional development; valid and reliable assessments; and products that enable access to learning for all students.With this new relationship, Cambium Assessment has been positioned to grow and expand into new markets unlocking even greater opportunities for success. Click here for more information.
All qualified applicants will receive consideration for employment without discrimination on the basis of race, color, religion, sex, gender, gender identity/expression, sexual orientation, national origin, protected veteran status, or disability.",3.1,"American Institutes for Research
3.1","Washington, DC","Washington, DC",1001 to 5000 employees,1946,Nonprofit Organization,Social Assistance,Non-Profit,$100 to $500 million (USD),"Mathematica, Abt Associates, Impaq International"
General Engineer Application,"$80K-$139K
(Glassdoor est.)","Interested in working at Tapad but don't see the job title you identify with on our careers page? We're always open to adding strong engineers to our team. This is a general application that is not specific to any particular role at Tapad. Apply here if you are interested in future openings in the following areas:
Software Engineer
Data Engineer
Machine Learning Engineer
Data Scientist
Javascript Engineer
Cloud Engineer
Cloud Security Engineer
At Tapad, we look for individuals who are motivated by complex and challenging work. We want to work with people who share compelling solutions to those challenges, solutions informed by their unique experiences, passions, and expertise.

No matter what job title you're seeking, we always need people who can solve complex problems to help build advanced software systems. We face daily unique and engaging challenges while processing petabytes in any 60-day time frame—that is over one trillion data points, and all privacy safe. The size and scale of our challenges demand our use of cutting edge open-source technologies like Apache Spark, Apache Beam, Kubernetes, and we're proud to have been built on Scala from day one. Tapad operates on a culture of collaboration, so our Engineers regularly work with the Business and Engineering teams to guarantee we are delivering the best products. A successful Tapad employee understands that their ideas hold weight, and they contribute freely and regularly. We want someone motivated to find large scale solutions with us. Tapad employees work with big data in a small team, where every contribution matters.

When you work with us, you matter. We ask our employees to make an impact and feel it is only right to give a lot in return. We believe if you're sick, feel like you're getting sick, or just need a personal day, take that time to get better. We love to develop a sense of community so we host meetups, share knowledge, and have regular team outings. At Tapad, we make sure our office is full of individuals who can teach and learn from one another.

At Tapad, you will be using (don't worry, we'll teach you):
Google Cloud Platform (GCP), Google Dataflow/Beam, SQL, BigQuery
Scala, sbt, cats, http4s, fs2
Spark ML, Python
Airflow, Prometheus, Kubernetes
TypeScript, Angular, Node.js, Hapi.js, Postgres, MySql
Tapad Perks:
Generous PTO - no accruing necessary
401k matching
On-site medical and dental practitioners (we bring the doctors in-house so you can make appointments at your convenience)
Scala School (we'll teach you!), Coursera, LinkedIn learning, peer-lead professional development, and an abundance of resources to help you stay sharp
Unlimited snacks and beverages, collaboration catered lunches
Discounts on gym memberships
Foosball, ping pong, diversity and inclusion group, book club, Tough Mudder, push-up challenges, and tons of other extra-curricular activities that will make you feel like part of the Tapad family
Check out our #TapadLife page to see what our employees have to say
Find more about our engineering culture HERE
About Tapad:


Founded in 2010, Tapad cracked the code on cross-device marketing technology. Our groundbreaking, proprietary technology assimilates trillions of data points to find the relationship between smartphones, desktops, laptops, tablets, and connected TVs. Ten years later, we are processing data at petabyte scale, with an engineering team that comprises roughly half of our entire organization. When you work with us, you matter, and your work matters.

We use Scala, in combination with large-scale data processing and open-source technologies, to build our device graph. Across our engineering teams, we also use GCP, Spark, Kubernetes, Python, TypeScript, Angular, and anything else that helps us get the job done. We're open-minded about new technologies, we're passionate about what we do, and we make time for everyone to learn and grow as the industry changes. Engineers at Tapad are approachable and ambitious people who think outside the box and solve big problems collaboratively. Are you up for the challenge?

Find more on our engineering blog HERE

Tapad is proud to be an equal opportunity employer and will consider all qualified applicants regardless of age, sex, race, religion, national origin, sexual orientation, gender identity, marital or family status, disability, or any other legally protected status. Tapad does not accept resumes from unsolicited search firms nor recruiters. In no event shall fees be paid to any unsolicited search firms nor recruiters, regardless of whether the candidate is made an offer or accepts a placement at Tapad. All resumes received through any channels will be considered the sole property of Tapad.",4.2,"Tapad
4.2","New York, NY","New York, NY",51 to 200 employees,2010,Company - Private,Internet,Information Technology,$50 to $100 million (USD),-1
Software Engineer - Worldwide Learning,-1,"We seek to empower learners around the world to acquire the skills enabling them to get a job, advance in their career and achieve more. Here is an opportunity for you to influence our learning programs and experiences designed to build world class capability for customers, partners, employees, and future generations.

Within Worldwide Learning, we reach millions of learners where they are, anytime, anywhere, and deliver experiences that support exploring, learning, practicing, and proving their skills. We use Dynamics 365, Power platform and Microsoft’s cloud assets to augment and enhance our ability to support learners throughout their learning journey across the diversity of our program offerings.

As a Software Engineer, you will be empowered to contribute to the solution design, participate in technical decisions, provide the implementation, and ensure the quality of services supporting our learning programs. You can help the team with better ways to utilize Microsoft technologies, machine learning, AI, analytics, and open source technologies to better provide scale and simplicity in delivering successful learner outcomes and program business success. In this role, you’ll collaborate with peer software engineers, designers, data scientists, operation specialists, program managers, and marketing stakeholders to creatively solve complex business challenges while following an agile engineering practice.

Responsibilities
Full life cycle of product development for scalable solutions: Design, Develop, Test, Deploy & Monitor
Deliver required solution capabilities per team standards, aligning with portfolio roadmap
Collaboration with partners to deliver compelling learning experiences and address customer needs
Ownership of quality standards, process, schedule, costing, resources and deliverables
Analyze risks and compromises with various design choices
Sharing of expertise throughout all stages of product design and development
Contribution to a team culture that embraces diversity and inclusion
Qualifications
BS degree in CS or related engineering field or equivalent experience/education
3+ years of development, technical design, problem solving, and debugging experience
3+ years of development experience with C#, ASP.NET, REST, SQL, HTML5, and JavaScript/JQuery
3+ years of proven record of successful delivery of shipping software across multiple release cycles
Good communication and collaboration skills
Passion for quality with strong customer empathy and focus
Passion for improving engineering practices and producing high quality software
Strong intellectual curiosity and passion for learning new technologies
Experience building, integrating, or customizing Dynamics 365 applications or other CRM software packages (Salesforce, SAP, etc.)
Knowledge of Dynamics 365 (Customer Engagements), PowerApps, Power Automate, Common Data Service and Power BI
Expertise in Microsoft Azure technologies and SSIS is a plus
Experience with CSS and client-side frameworks such as Angular/React, etc
Experience and knowledge of relational databases, data modeling, and ETL tools
Microsoft is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable laws, regulations and ordinances. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. If you need assistance and/or a reasonable accommodation due to a disability during the application or the recruiting process, please send a request via the Accommodation request form.

Benefits/perks listed below may vary depending on the nature of your employment with Microsoft and the country where you work.",4.3,"Microsoft
4.3",United States,"Redmond, WA",10000+ employees,1975,Company - Public,Computer Hardware & Software,Information Technology,$10+ billion (USD),"Google, Amazon, Apple"
Data Scientist,-1,"Job Application for Data Scientist at PanjivaFirst Name *Last Name *Email *Phone *Location (City) *Resume/CV *Drop files hereAttach Dropbox Google Drive PasteCover LetterDrop files hereAttach Dropbox Google Drive PasteWhen autocomplete results are available use up and down arrows to review+ Add Another EducationLinkedIn ProfileWebsiteSecurity Clearance *Please selectNo Clearance Active Confidential Active Secret Active Top Secret Active Top Secret SCI Inactive Confidential Inactive Secret Inactive Top Secret Inactive Top Secret SCIWork AuthorizationPlease selectUnited States Citizen or Permanent Resident US Work Visa Holder No Visa: Seeking Work AuthorizationHow did you hear about this job?SchoolDegree High School Associate's Degree Bachelor's Degree Master's Degree Master of Business Administration (M.B.A.) Juris Doctor (J.D.) Doctor of Medicine (M.D.) Doctor of Philosophy (Ph.D.) Engineer's Degree OtherDiscipline Accounting African Studies Agriculture Anthropology Applied Health Services Architecture Art Asian Studies Biology Business Business Administration Chemistry Classical Languages Communications & Film Computer Science Dentistry Developing Nations Discipline Unknown Earth Sciences Economics Education Electronics Engineering English Studies Environmental Studies European Studies Fashion Finance Fine Arts General Studies Health Services History Human Resources Management Humanities Industrial Arts & Carpentry Information Systems International Relations Journalism Languages Latin American Studies Law Linguistics Manufacturing & Mechanics Mathematics Medicine Middle Eastern Studies Naval Science North American Studies Nuclear Technics Operations Research & Strategy Organizational Theory Philosophy Physical Education Physical Sciences Physics Political Science Psychology Public Policy Public Service Religious Studies Russian & Soviet Studies Scandinavian Studies Science Slavic Studies Social Science Social Sciences Sociology Speech Statistics & Decision Theory Urban Studies Veterinary Medicine OtherStart DateEnd DatePowered byRead our Privacy Policy{""@context"":""schema.org"",""@type"":""JobPosting"",""hiringOrganization"":{""@type"":""Organization"",""name"":""Panjiva""},""title"":""Data Scientist"",""datePosted"":""2017-05-22"",""jobLocation"":{""@type"":""Place"",""address"":{""@type"":""PostalAddress"",""addressLocality"":""Cambridge, Massachusetts, United States"",""addressRegion"":""Massachusetts"",""addressCountry"":""United States"",""postalCode"":""""}},""description"":""\u003ch2\u003e \u003c/h2\u003e\n\u003ch2\u003e\u003cstrong\u003eSolve important and challenging problems\u003c/strong\u003e\u003c/h2\u003e\n\u003cp\u003eWe're looking for someone that can help us to solve the data challenges that we know we have, as well as help to identify new opportunities to leverage our data. You'll be working with a variety of teams across the company: engineering, business development, sales, and design to explore exciting and meaningful problems.\u003c/p\u003e\n\u003cp\u003eStrong candidates can leverage a wide array of machine learning and statistical techniques at scale, to address challenges with semi-structured and multilingual international trade data. Responsibilities will include helping us develop the next generation of our product, as well as analysis of our internal metrics to assist the company in making a wide variety of data-driven decisions. Our team uses a range of tools including python, R, Ruby, and SQL to communicate and visualize results.\u003c/p\u003e\n\u003cp\u003e \u003c/p\u003e\n\u003cp\u003eAt Panjiva, you'll work on:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eFuzzy matching and clustering of data, at scale\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eNatural language processing, robust to messy text and multiple languages\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eImputation of missing data\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eNetwork analysis\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eInference of company structures\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eAnomaly detection\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eShipment trend prediction and modeling\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eOptimization of search weightings\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003ePredictive modeling of customer acquisition and retention\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e \u003c/p\u003e\n\u003ch2\u003e\u003cstrong\u003eRequirements\u003c/strong\u003e\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eB.S, M.S, or Ph.D. in a quantitative field, or equivalent experience\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eDeep statistical knowledge and a broad understanding of analytical and machine-learning techniques\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eTrack record of providing valuable insights into large, highly multidimensional datasets\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eExperience with a scripting language, such as Python with NumPy / SciPy or R, and the ability to use it to perform complex analyses of large data sets\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eBasic understanding of relational databases\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eStrong ability to communicate and visualize findings\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e \u003c/p\u003e\n\u003ch2\u003e\u003cstrong\u003eNice-to-Haves\u003c/strong\u003e\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eSolid understanding of relational databases, including advanced query techniques\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eBackground in text analysis / information retrieval algorithms\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eExperience building production software\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eFamiliarity with Ruby, Postgres\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eFamiliarity with libsvm\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eExperience with C++ or a similar highly performant language\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eFamiliarity with large-scale, distributed data processing techniques (Hadoop, Pig, Hive, etc.)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eStartup experience\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e \u003c/p\u003e\n\u003ch2\u003e\u003cstrong\u003ePerks and Benefits\u003c/strong\u003e\u003c/h2\u003e\n\u003cul\u003e\n\u003cli style=\""font-weight: 400;\""\u003e\u003cspan style=\""font-weight: 400;\""\u003eCompetitive salary\u003c/span\u003e\u003c/li\u003e\n\u003cli style=\""font-weight: 400;\""\u003e\u003cspan style=\""font-weight: 400;\""\u003eBuild or buy your dream computer\u003c/span\u003e\u003c/li\u003e\n\u003cli style=\""font-weight: 400;\""\u003e\u003cspan style=\""font-weight: 400;\""\u003eHarvard Square office 1 minute walk from the Red Line T stop\u003c/span\u003e\u003c/li\u003e\n\u003cli style=\""font-weight: 400;\""\u003e\u003cspan style=\""font-weight: 400;\""\u003e15 days vacation (rising to 25 days with longer tenure), 3 floating holidays / personal days, and 10-12 paid holidays annually, with unlimited sick leave\u003c/span\u003e\u003c/li\u003e\n\u003cli style=\""font-weight: 400;\""\u003e\u003cspan style=\""font-weight: 400;\""\u003eWeekly tech talks\u003c/span\u003e\u003c/li\u003e\n\u003cli style=\""font-weight: 400;\""\u003e\u003cspan style=\""font-weight: 400;\""\u003eHealth, dental, and vision insurance as well as many other benefits\u003c/span\u003e\u003c/li\u003e\n\u003cli style=\""font-weight: 400;\""\u003e\u003cspan style=\""font-weight: 400;\""\u003e401(k) plan, with company matching\u003c/span\u003e\u003c/li\u003e\n\u003cli style=\""font-weight: 400;\""\u003e\u003cspan style=\""font-weight: 400;\""\u003eHacker Continuing Education Wednesdays i.e., craft beer tasting, ping pong lessons\u003c/span\u003e\u003c/li\u003e\n\u003cli style=\""font-weight: 400;\""\u003e\u003cspan style=\""font-weight: 400;\""\u003eWork with a talented, focused, driven team in a growing company with opportunity for advancement and career development\u003c/span\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e\u003cstrong\u003eHow to apply\u003c/strong\u003e\u003c/h2\u003e\n\u003cp\u003eTo",4.2,"Panjiva
4.2","Cambridge, MA","New York, NY",1 to 50 employees,2006,Company - Private,Internet,Information Technology,$1 to $5 million (USD),-1
Software Engineer in Machine Learning / Deep Learning,"$101K-$174K
(Glassdoor est.)","Software Engineer in Machine Learning / Deep Learning

Baidu USA, located in Silicon Valley, is looking for Senior Software Engineer in machine learning / deep learning to work on the Baidu autonomous driving technology. You will be responsible for obstacle detection and prediction, as well as motion policy decision making.

Here's what you will do:
You will be working closely with a group of engineers and scientists to tackle challenges in autonomous driving technology by utilizing your knowledge in machine learning and deep learning
You will be working on traffic participant detection and behavior prediction, and motion policy decision making in medium to high volume traffic
You will have the opportunities to play with a large data set, design algorithms, build models and verify them through simulation
You will be responsible for integrating, deploying, testing and verifying your algorithms and models in real-time computing system on vehicles
Here's what we'd like to see in you:
Solid background and knowledge in machine learning and deep learning
Proficiency in various deep neural networks including CNN, RNN, Deep Reinforcement Learning and etc.
Solid familiarity with one of the deep learning frameworks: Pytorch, Tensorflow or Paddle
Strong programming in C++ and Python
Advanced degree in computer science, mathematics, optimization or other related disciplines
Prior experience in autonomous driving is preferred
Culture Fit:
Mission alignment: If you want to be part of a team to accomplish this great mission, we will provide you the best possible platform to do that.
Self­-directed: We work best with people that are driven, motivated, and aspire to greatness. Are you the sort of person that, if you had time on your hands, will independently find interesting and useful things to do?
Hungry to learn: We are eager to see you learn new skills and grow. But learning is hard work and this is something we hope you want to do.
Team orientation: We work in small, fast­-moving teams. We don't believe in lone wolves. We watch out for each other and go after big goals together as a team.",4.2,"Baidu USA
4.2","Sunnyvale, CA","Sunnyvale, CA",51 to 200 employees,2000,Company - Public,Internet,Information Technology,$50 to $100 million (USD),-1
Jr. Applied Machine Learning Engineer,-1,"Jr. Applied Machine Learning Engineer


Join our team's mission to create robots that help people reach their full potential!

COVID-19 Hiring Update: We’ve transitioned to a work-from-home model and we’re continuing to interview and hire during this time. This role is expected to begin as a remote position. We understand each person’s circumstances may be unique and will work with you to explore possible interim options.

Embodied, Inc.’s mission is to build socially and emotionally intelligent animate companions with believable personality and empathy to enhance our daily lives. We have developed a new platform, SocialX™, that provides a way to use natural human interaction to engage with technology. The first iteration of this technology is Moxie, an animate companion for children developed to help promote social, emotional and cognitive learning. Moxie has been called “the robot pal you dreamed of as a kid” (Wired Magazine), “the sophisticated robot for the curious child” (Wallpaper Magazine), and “a technically impressive childhood robot” (TechCrunch).

From the heart of Pasadena in sunny Los Angeles, California, our diverse team of engineers, therapists, and designers is led by experts in robotics, AI and machine learning, entertainment, and consumer electronics. We are financially backed by some of the most prominent corporate and institutional investors including Intel Capital, Toyota AI Ventures, Amazon Alexa Fund, Sony Innovation Fund, JAZZ Venture Partners, Calibrate Ventures, Osage University Partners, Grishin Robotics, and Vulcan Capital.

At Embodied, we support diversity and we are an equal opportunity workplace. We offer a competitive benefits package that includes compensation, health benefits, employee stock options, 401(k) match, flexible PTO, and flexible schedules. We are a dynamic and diverse team that likes to push the status quo. Our work environment is collaborative, flexible, and very supportive of work-life balance.

We are continuing to build an amazing, high-performance team that works hard to innovate, collaborate, and solve complex challenges in order to serve our company mission and goals. We are bold in our vision, relentless in its pursuit, and excited to be discovering new ways to provide positive impact to the families we serve. We are committed to our mission not because it's easy but out of a shared boundless optimism that together we will put a dent in the universe.

Position Summary

Contribute to human-robot interactions and conversational AI like you have never experienced before. Embodied is looking to add a talented and creative Junior Applied Machine Learning Engineer to our growing technical team.

Responsibilities include:
Implement and validate next generation conversational AI systems to enable organic, emotionally responsive conversations with a believable character
Leverage the latest advancements in machine learning and NLP to lead the research efforts in adopting/creating novel approaches to improve our conversational AI system
Work with and pre-process large quantities of real-time multimodal data (audio, video, and text)
Deploy and validate (in partnership with engineers) models that power specific applications and lead to tangible improvements
Develop evaluation metrics for NLP models and improvements
Work collaboratively with:
A team of top machine learning and AI experts to improve and personalize user perception and experience
Domain experts to implement interactive and conversational features and behaviors
Creative team of writers, UX designers, and animators to develop engaging multimodal content
Collaborate with other engineers and scientists on applied research
Have fun & learn while working at a startup with a great team and an incredible mission!

Minimum Qualifications
BS or MS Degree (or equivalent) in Computer Science, Computational Linguistics, or similar.
Internship experience in AI, natural language-processing (NLP), or computer vision (CV) at top industry institutions
Experience developing and building upon NLP frameworks (HuggingFace, spaCy, etc.) or machine learning (ML) architectures (BERT, GPT-2/3, ImageNet, ResNet, or similar)
Experience with deep learning frameworks such as Pytorch, Tensorflow, or Keras
Excellent programming skills in Python, C++, or Java
Excellent communication skills to effectively collaborate with an interdisciplinary team
Preferred Qualifications
Experience developing and launching conversational systems designed for voice driven interactivity (e.g., Alexa Prize)
Some research experience with NLP, CV, or other ML problems
Some scientific contributions in international conferences such as ACL, EMNLP, NeurIPS, CVPR, ICCV, or ECCV
Experience with multimodal/audiovisual data processing
Experience in leveraging software for text processing and representation (e.g., NLTK, gensim, OpenNLP, CoreNLP, etc.)
Embodied is creating robots to help make the world a better place. Come join us to make an impact!

Please email your resume to: hr@embodied.com",2.0,"Embodied
2.0","Pasadena, CA","Pasadena, CA",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Machine Learning Engineer - Recommendations Platform,-1,"By applying for this role, you could choose to work in the following locations:
US - Remote US
San Francisco

Who We Are:

Recos Platform team builds recommendations platforms such as candidate generation and feature generation engines for product teams. The unrivaled challenges that we face at Twitter are both the data scale and the real-time nature of the product. How do you find the most meaningful content among hundreds of millions of new tweets for hundreds of millions of users every day at Twitter? We build large scale personalized recommendation engines utilizing different kinds of signals such as social network, user activity, and geolocation. Most of our work is about recommendation systems, machine learning, graph algorithms, distributed systems, and social graph analysis.

What You'll Do:

Apply your engineering skills to either improve existing recommendation systems, unlock new directions or provide entirely new ML solutions in recommendation systems within Twitter. You will work closely with live production systems and product teams, and deliver ML solutions at scale within the Twitter tech stack.

Who you are:

A machine learning software engineer with a passion for working on exciting algorithmic and deep infrastructure issues in ML environments.
Thrive on working in concert with other smart people, including from distributed offices.
Communicate fluidly, at the level of your audience, and seek to understand and be understood.
Have the ability to take on complex problems, learn quickly, iterate, and persist towards a good solution.
Take pride in polishing and supporting our products.
Work hand-in-hand with modeling engineers and data scientists, and your passion is to enable them with better infrastructure.
Requirements:

BS, MS or PhD in Computer Science with 3-5 years experience or equivalent experience.
Fluent in one or more languages like Java, Scala, C++, Python
Experience with Hadoop, Pig or other MapReduce-based architectures
Knowledgeable of core CS concepts such as common data structures and algorithms
Comfortable conducting design and code reviews
We are committed to an inclusive and diverse Twitter. Twitter is an equal opportunity employer. We do not discriminate based on race, color, ethnicity, ancestry, national origin, religion, sex, gender, gender identity, gender expression, sexual orientation, age, disability, veteran status, genetic information, marital status or any legally protected status.

San Francisco applicants: Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.",4.0,"Twitter
4.0",Remote,"San Francisco, CA",1001 to 5000 employees,2006,Company - Public,Internet,Information Technology,$2 to $5 billion (USD),"Facebook, Google, Pinterest"
Machine Learning / AI Engineer,-1,"**Machine Learning / AI Engineer**

**Cambridge, MA**

**Job Type:** Direct Hire

**Recruiter:** Denise Reha at https://digitalprospectors.com/our-team/denise-reha

**Phone:** 6173374251

**Find your job at** **www.LoveYourJob.com**

**Job Title:** Machine Learning and AI Engineer

**Location** : Cambridge, MA

**Duration:** Direct Hire

Candidates need to be a US Citizen as the Laboratory is a cleared facility.

**A Secret Clearance without Incident or the ability to acquire a security clearance is required for this role.**

POST-OFFER BACKGROUND CHECK IS REQUIRED. An essential function of this job is physical attendance. Digital Prospectors is an Equal Opportunity Employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or veteran status.

**JOB DESCRIPTION:**

As an ML/AI Engineer at our client, you will work with our multidisciplinary team of scientists, engineers, and software developers to design and implement machine learning and AI algorithms for various autonomous system applications. You will push the boundaries of what is possible in our current autonomy applications. Applications vary from vehicle path planning, vision-based navigation, image classification, and big data assimilation.

Skills & Requirements

The candidate must be eager to learn new technologies and stay on top of the latest trends. The candidate will work on a team developing new code bases that are heavily object-oriented, extensible, and maintainable. Therefore, the candidate must have a tacit understanding of design patterns and anti-patterns; polymorphism and encapsulation; high cohesion and low coupling; and the different strengths and weakness of various programming languages.

US CITIZENSHIP REQUIRED or the ability to obtain a U.S. Security Clearance

• Expertise in C++, Python, C

• Excellent Coding Skills

• Experience with version control systems Git and Subversion

• Experience with Agile development (Scrum or Kanban)

• BS, MS or PhD in computer science or equivalent degree, or significant professional experience

**Make this your next career move as one of our many long term contractors or employees!**

Work as our full time employee with full benefits (Medical, Dental, Vision, STD, LTD, PTO, Retirement, etc.) - OR - work as a W2 hourly contractor at a higher pay rate if you don't need the benefit package.

**ABOUT DIGITAL PROSPECTORS:**

Founded in 1999, Digital Prospectors is an award-winning recruiting and consulting firm that specializes in placing contract, contract-to-hire and direct hire engineers into rewarding opportunities with our impressive and ever-growing client base. We believe that all people should love their jobs.

Come see why Digital Prospectors has been voted "" **Best Staffing Firm to Temp For** "" by Staffing Industry Analysts, "" **Best of Staffing** "" for candidate satisfaction by Inavero / CareerBuilder.com, "" **Top Temporary Placement Firm** "" by Boston Business Journal, "" **Best Company To Work For** "" by Business NH magazine, "" **Excellence in IT and Engineering Staffing** "" by TechServe Alliance, "" **Top IT Services Company** "" by Inc. Magazine, "" **Most Reliable Staffing Agency** "" in Forbes Magazine and "" **Top Ranked Staffing Firm** "" by Staffing Industry Analysts.

**www.LoveYourJob.com** at http://www.loveyourjob.com/

**Phone: 603-772-2700**",5.0,"Digital Prospectors
5.0","Cambridge, MA","Exeter, NH",51 to 200 employees,1999,Company - Private,IT Services,Information Technology,$50 to $100 million (USD),-1
"Machine Learning Engineer, Mid.",-1,"Qntfy is looking for a talented and highly motivated ML Engineer to join our team. ML Engineers are responsible for building systems at the crossroads of data science and distributed computing. You will do a little bit of everything: from tuning machine learning models, to profiling distributed applications, to writing highly scalable software. We use technologies like Kubernetes, Docker, Kafka, gRPC, and Spark. You aren’t a DevOps, but an understanding of how the nuts and bolts of these systems fit together is helpful and you aren't a data scientist, but understanding how models work and are applied is just as important.

Responsibilities
Collaborate with data scientists to get their models deployed into production systems.
Develop and maintain systems for distributed model training and evaluation.
Design and implement APIs for model training, inference, and introspection.
Build tools for testing, benchmarking, and deploying analytics at scale.
Interface with the technical operations team to understand analytic performance and operational behavior.
Write and test code for highly available and high volume workloads.
Qualifications
BS or Master’s degree in Computer Science, related degree, or equivalent experience.
5+ years experience with software engineering, infrastructure design, and/or machine learning.
Familiarity with Python and machine learning frameworks, paricularly Scikit-learn, Tensorflow, and Pytorch.
Experience with distributed machine learning using tools like Dask, Tensorflow, Kubeflow, etc.
Write well-structured, maintainable, idiomatic code with good documentation.
Strong work-ethic and passion for problem solving.
Preferred Qualifications
Machine learning API development competencies.
Golang development experience.
Container orchestration and optimization knowledge.
Proficiency designing, implementing, and operating large-scale distributed systems.
Prior experience working in a distributed (fully remote) organization.
Qntfy is committed to fostering and supporting a creative and diverse environment. Qntfy is an equal opportunity employer, and as such will consider all qualified applicants for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status.

U.S. Citizenship Required",5.0,"Qntfy
5.0",Remote,"Arlington, VA",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Senior Software Engineer,-1,"About you:
Care deeply about democratizing access to data.
Passionate about big data and are excited by seemingly-impossible challenges.
At least 80% of people who have worked with you put you in the top 10% of the people they have worked with.
You think life is too short to work with B-players.
You are entrepreneurial and want to work in a super fast-paced environment where the solutions aren't already predefined.
Comfortable working with a remote team.
About SafeGraph:
SafeGraph is a B2B data company that sells to data scientists and machine learning engineers.
SafeGraph's goal is to be the place for all information about physical Places
SafeGraph currently has 30+ people and has raised a $20 million Series A. CEO previously was founder and CEO of LiveRamp (NYSE:RAMP).
Company is growing fast, over $10M ARR, and is currently profitable.
Company is based in San Francisco but more than 50% of the team is remote. We get the entire company together in the same place every month (when possible).
We have been moving very quickly in the current pandemic, building up new products and releasing up-to-date dashboards to the general public. We are providing our aggregated and anonymized location data at no cost for non-commercial use, to anyone with the shared goal of fighting to prevent the spread of COVID-19 and helping to get the economy moving in its aftermath. We now have a vibrant community of 2000+ organizations in this Consortium. You can see the publications here.

About the role:
Core software engineer.
Reporting to SafeGraph's VP Engineering.
Work as an individual contributor.
Opportunities for future leadership.

Requirements:
No Resume? No Problem! A LinkedIn is all you need to apply!
You have at least 6 years of relevant work experience.
Proficiency writing production-quality code, preferably in Scala, Java, or Python.
Strong familiarity with distributed system, or map/reduce data processing.
Deep understanding of all things ""data"" - schema design, modeling, optimization, scalability, etc.
You are authorized to work in the U.S.
Excellent communication skills.
You are amazingly entrepreneurial.
You want to help build a massive company.
Nice to haves:
Extra bonus points: Deep understanding of Apache Spark in solving production-scale problems.
Experience with AWS.
Experience with building ML models from the ground up.
Experience working with huge data sets.
Python, Database and Systems Design, Scala, Data Science, Apache Spark, Hadoop MapReduce.
Good reading on how we are thinking:
SafeGraph Vision and Values
Open Information to Power Innovation
Where Should Machines go to Learn
Data-As-A-Service Bible: Everything You Wanted to Know About Running DaaS Companies
Don't fit this description perfectly but still think this is the role for you? Apply and let us know why!",4.5,"SafeGraph
4.5",Remote,"San Francisco, CA",1 to 50 employees,2016,Company - Private,Internet,Information Technology,$10 to $25 million (USD),-1
"Software Engineer, Machine Learning, Planner/Behavior Prediction","$114K-$204K
(Glassdoor est.)","Who We Are


Nuro is a robotics start-up whose mission is to accelerate the benefits of robotics for everyday life. We have an elite team of entrepreneurs and engineers, designers, and scientists. We believe AI and robotics are at the cusp of transforming daily life and we are dedicated to building meaningful products with this technology. Join us and play a critical role in our mission.

About the Role


Our team is growing and we are looking for machine learning R&D experts to join us. We apply machine learning to solve the challenging behavior(prediction and planning) problems, e.g. predicting other road agents’ behaviors, understanding their intents, and plan our own self-driving vehicle in a safe and acceptable manner. In this role, you will work on developing full-stack machine learning solutions, from building robust and scalable data pipelines, state of the art models, to deploying the models on our self-driving cars.

About the Work
Develop scalable and robust data pipelines that are able to process petabytes of data for model training, and deploy models in production
Work alongside with machine learning domain experts to design advanced models based on state of the art machine learning techniques.
Collaborate closely with engineers across behavior, perception, research, mapping and localization, infrastructure, etc.
About You
Experience with scalable and robust production machine learning data pipeline
Experience with production machine learning model deployment
Strong C++ or python programming skills
Nuro is an equal opportunity employer and expressly prohibits any form of workplace harassment based on race, color, religion, gender, sexual orientation, gender identity or expression, national origin, age, genetic information, disability, or veteran status.",4.4,"Nuro
4.4","Mountain View, CA","Mountain View, CA",201 to 500 employees,2016,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Machine Learning Engineer,-1,"At Liftoff, we're solving one of the core problems faced by every mobile app: growth. To do so, we build Machine Learning models and infrastructure that can accurately predict which apps a user will like and how to connect them in a compelling way. Our systems operate at a scale unseen outside of the largest Internet companies -- processing over a million requests per second and interacting with over a billion users. Our technology is creative and we have strong product-market fit; as a result, we've already reached profitability and are seeing tremendous growth.

As a Machine Learning Engineer at Liftoff, you will:
Own both the ML models and the underlying software tooling and infrastructure. Our ML Engineer role combines the classic ""ML Scientist"" and ""Data Engineer"" role at other companies.
Have a closed feedback loop from hypothesis generation to live AB testing, with no cross-team friction and sub-day iteration cycles.
Take on unique modeling challenges not covered in the scientific literature, like extreme positive sample sparsity and labelling delay.
Work with modeling techniques at the state-of-the-art of probability prediction, as well as a multitude of other ML areas from NLP to CNNs.
Become an expert in Clojure, Go, and the many other cutting-edge open source technologies that maximize our development velocity.
Join a nimble, consistently excellent, and experienced engineering team (former Google/LI/Ooyala/etc).
Desired qualities and experiences:
Very strong coding ability (experience in Go and Clojure is a plus).
2+ years of industry experience applying Machine Learning to large scale problems.
Strong core CS fundamentals (data structures, algorithms, architecting systems).
A passion for quality and excellence, and the ability to temper it when necessary to ship.
Sets ego aside in pursuit of finding the best solution, no matter where it comes from.
Self-motivated and a great ability to hustle.
B.S. or higher in Computer Science. PhD a big plus.
We are an equal opportunity employer and value diversity at our company. Come join our team and help us shape the future of mobile growth!",4.7,"Liftoff
4.7","Redwood City, CA","Redwood City, CA",201 to 500 employees,2012,Company - Private,Advertising & Marketing,Business Services,Unknown / Non-Applicable,"AppLovin, Drawbridge"
Machine Learning Engineer,"$104K-$163K
(Glassdoor est.)","Posted: Jul 16, 2020
Weekly Hours: 40
Role Number:
200180706
Apple's Online Retail Analytics team is looking for a hardworking machine learning engineer who is passionate about crafting, implementing, and operating production machine learning solutions that have direct and measurable impact to Apple and its customers. You will design, build and deploy predictive modeling and statistical analysis techniques on production systems that drive increased sales, improved customer experience for our online customers.

Apple has a tremendous amount of data, and we have just scratched the surface in pattern detection, anomaly detection, predictive modeling, and optimization. There are many exciting problems to be discovered and solved and many business owners eager to use data mining. The Apple Analytic Insight team encourages scientists to stay ahead of data science research by attending conferences and working with academic faculty and students. We have a work environment that encourages collaboration, but also allows solution autonomy on projects.

Apple's dedication to the customer experience, the commitment to privacy, and the enormous scale of the business present exciting challenges to traditional machine learning and data science techniques. On this team, you will push the limits of existing data science methods while delivering tangible business value.
Key Qualifications
Strong solid understanding of data science algorithms including decision trees, probability networks, association rules, clustering, regression, and neural networks.
Familiarity with database modeling and data warehousing principles and SQL.
Familiarity with Big Data tools like Spark, Hive etc.
Strong programming skills in Java, Python, or similar language.
Ability to comprehend and debug sophisticated systems integrations.
Ability to extract relevant business insights and patterns from data.
Creativity to engineer novel solutions, and to push beyond current tools and approaches.
2+ years experience in hiring & leading team of data scientists.
Good interpersonal, written, and verbal communication skills.
Ability to work independently and make key decisions on projects.
Description
- Conceive and design end to end data science solutions to support Apple's business units and initiatives.
Work with business owners to map business requirements into technical solutions.
Develop and implement data science solutions to fit business problem, which may include applying algorithms from a standard tool or custom algorithm development.
Work closely with data warehouse architects and software developers to generate flawless business intelligence solutions for end users.
Support production analytic solutions.
Perform ad hoc statistical and data science analyses.
Present results of analyses to business units.
Education & Experience
Ph.D. in Data Science, Machine Learning, Statistics, Operations Research or related field

M.S. in related field with 5+ years experience applying data science techniques to real business problems.",4.1,"Apple
4.1","Austin, TX","Cupertino, CA",10000+ employees,1976,Company - Public,Computer Hardware & Software,Information Technology,$10+ billion (USD),"Google, Microsoft, Samsung Electronics"
Data Science Software Engineer,"$58K-$122K
(Glassdoor est.)","Software EngineerWhy YOU want this positionEnverus delivers business-critical insights to the global energy industry through a state-of-the-art SaaS platform built on industry-leading data and energy analytics. Our solutions deliver value across the entire energy value chain, empowering customers to be more agile, efficient and competitive. The range of energy industry participants we serve includes exploration and production (E&P) companies and related businesses such as oilfield services, midstream, capital markets, power generators and utilities, energy traders, and downstream commercial & industrial energy consumers.Enverus' Software Engineering culture emphasizes team building, mentorship, and accountability that fits well with individuals who are self-starters, team players, and have a strong desire for continuous learning and growth. We offer a competitive compensation package along with industry leading perks that include:* Casual dress code* Annual technical training budget* A well-stocked kitchen with snacks and beveragesWe are currently seeking a highly driven Software Engineer to join our Data Science team in Conshohocken, PA, Denver, CO, or Calgary, AB. This role offers the opportunity to join a rapidly growing company delivering industry-leading solutions to customers in the world's most dynamic and fastest growing sector. Enverus is the right company at the right time.Performance Objectives* Collaborate with Data Scientists to productize machine learning models* Design, develop, test, and maintain production ready code* Support and maintain current production platform* Evaluate different tools and algorithms for reliable functionality and scalability* Participate in performance and stress testing with the development team* Participate in scrum planning and daily team standupCompetitive Candidate Profile* 5+ years Python experience* Solid understanding of algorithms and data structures* Solid Linux and git expertisePreferred Qualifications* Pandas, NumPy, scikit-learn, TensorFlow, multiprocessing* Docker, Airflow, Kubernetes, Spark, Jenkins* SQL Server* GoLang* Azure cloud computing",3.6,"Drilling Info
3.6","Conshohocken, PA","Austin, TX",1001 to 5000 employees,1999,Company - Private,Energy,"Oil, Gas, Energy & Utilities",$100 to $500 million (USD),-1
Data Scientist,-1,"Position OverviewAt PNC, our people are our greatest differentiator and competitive advantage in the markets we serve. We are all united in delivering the best experience for our customers. As a Data Scientist within PNC's ACC Data Science group organization, you will be based in Cleveland, OH or Pittsburg PA.In this role you will* Recommend design and develop state-of-the-art data-driven analysis using statistical & advanced analytics methodologies to solve business problems. Expertise in Data Science, Data Mining, Machine Learning, Predictive Modeling best practices is vital.* Develop models & recommend insights. Form hypothesis and run experiments to gain empirical insights and validate the hypothesis. Identify and eliminate possible obstacles and identify an alternative creative solution.* Partner with a cross-functional team of data engineers, data scientists, software engineers, and product managers to deliver a solutions* Leverage a broad stack of technologies -R, Python, Conda, Spark, SAS and more - to reveal the insights hidden within huge volumes of numeric and textual data* Build machine learning models through all phases of development, from design through training, evaluation, validation, and implementation. Machine Learning for Data Science includes algorithms that are central to ML: K-nearest neighbors, Random Forests, Naive Bayes, and Regression Models. PyTorch, TensorFlow, Keras also find its usability in Machine Learning for Data Science* Independently research, experiment, prototype ML solutions to solve problems within a large enterprise domain (say, Ad Targeting, Video Processing, NLP, Computer Vision, etc.)* Collaborate with software engineers, data engineer and DevOps to integrate and scale ML solutions into large, complex software products in the enterprise ecosystem* Flex your interpersonal skills to translate the complexity of your work into tangible business goals* At least 2 year of experience in open source programming languages for large scale data analysis* At least 2 year of experience with machine learning* At least 2 year of experience with relational databases* Experience with Python, R, SQL OR ScalaPlease note, PNC will not sponsor work visas for this position.Job Description* Performs analytical tasks on vast amounts of structured and unstructured data to extract actionable business insights.* Participates in the data gathering, data processing and data mining of large and complex datasets.* Develops algorithms using advanced mathematical and statistical techniques like machine learning to predict business outcomes and recommend optimal actions to management.* Runs analytical experiments in a methodical manner to find opportunities for product and process optimization. Assists in the presentation of business insights to management using visualization technologies and data storytelling.* May partner with Data Architects, Data Analysts, Data Engineers and Visualization Experts to develop data-driven solutions for the business.PNC Employees take pride in our reputation and to continue building upon that we expect our employees to be:* Customer Focused - Knowledgeable of the values and practices that align customer needs and satisfaction as primary considerations in all business decisions and able to leverage that information in creating customized customer solutions.* Managing Risk - Assessing and effectively managing all of the risks associated with their business objectives and activities to ensure they adhere to and support PNC's Enterprise Risk Management Framework.CompetenciesData Architecture - Knowledge and ability to create models and standards to govern which data is collected, and how it is stored, arranged, integrated, and put to use in data systems and in organizations.Data Mining - Knowledge of tools, techniques and practices in data mining technologies used to acquire essential business information.Disruptive Innovation - Knowledge of concepts, principles, and approaches of disruptive innovation; ability to adopt the knowledge into related processes and practices.Information Capture - Knowledge of the processes and the ability to identify, capture and document relevant business information in an auditable, organized, understandable and easily retrievable manner.Machine Learning - Knowledge of principles, technologies and algorithms of machine learning; ability to develop, implement and deliver related systems, products and services.Modeling: Data, Process, Events, Objects - Knowledge of and the ability to use tools and techniques for analyzing and documenting logical relationships among data, processes or events.Prototyping - Knowledge of and ability to implement prototyping disciplines, tools and techniques in evolutionary models within the target environment.Query and Database Access Tools - Knowledge of and the ability to use, support and access facilities for extracting and formatting a database management system.Work ExperienceRoles at this level typically require a university / college degree, with 3+ years of relevant / direct industry experience. Certifications are often desired. In lieu of a degree, a comparable combination of education and experience (including military service) may be considered.EducationMastersDisability Accommodations Statement:The PNC workplace is inclusive and supportive of individual needs. If you have a physical or other impairment that might require an accommodation, including technical assistance with the PNC Careers website or submission process, please call 877-968-7762 and select Option 4: Recruiting or contact us via email at pathfinder@pnc.com.The Human Resources Service Center hours of operation are Monday - Friday 9:00 AM to 5:00 PM ET.Equal Employment Opportunity (EEO):PNC provides equal employment opportunity to qualified persons regardless of race, color, sex, religion, national origin, age, sexual orientation, gender identity, disability, veteran status, or other categories protected by law.California ResidentsRefer to the California Consumer Privacy Act Privacy Notice to gain understanding of how PNC may use or disclose your personal information in our hiring practices.",3.4,"PNC Bank
3.4","Pittsburgh, PA","Holmdel, NJ",201 to 500 employees,-1,Other Organization,Sports & Recreation,"Arts, Entertainment & Recreation",Unknown / Non-Applicable,-1
Software Engineer - Algorithms,-1,"LeapYear's secure machine learning platform is deployed by some of the largest enterprises in the world across finance, healthcare, and technology.

Our technology ensures differential privacy, a widely recognized standard of data privacy that enables all data - including sensitive information - to be utilized for analytics, while providing mathematically proven privacy protection.

The LeapYear system is composed of a core set of components that allow private machine learning on data sets that can scale to petabytes. The system includes private algorithms for relational operations, statistical methods and machine learning. A data scientist accesses private data using a Python API. Administration is provided via a web-based GUI or an API.

If you work at the intersection of machine learning and functional programming, we're looking for you. You will collaborate with developers, researchers, and data scientists to transform machine learning theory into enterprise applications, and the novel algorithms that you develop will be deployed on massive enterprise datasets.

For details on the specific responsibilities and requirements of this role, please see below.
Responsibilities
Design and implement novel machine learning techniques
Develop performance-critical code
Plan, implement, and optimize new features to carry out our product roadmap
Requirements
PhD, or equivalent experience, in a field involving the application of advanced mathematics (machine learning, computer science, statistics, physics, math, electrical/systems engineering)
Exposure to functional programming
Strong foundation in data structures, algorithms, software design, and the theoretical underpinnings of machine learning
Preferred
Familiarity with differential privacy theory and implementation
Excellent Haskell skills
Professional machine learning experience and functional programming
Experience in enterprise data science and data engineering
Background applying advanced machine learning techniques in enterprise data environments
A Few of the Perks
Culture of teaching and learning
Competitive compensation package of salary and equity
Catered lunch every day
Company outings
Build your ideal work station
Generous health insurance plan
Relocation support and visa sponsorship",4.2,"LeapYear
4.2","San Francisco, CA","San Francisco, CA",1 to 50 employees,2015,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Machine Learning Engineer,"$99K-$165K
(Glassdoor est.)","Upstart is a leading AI lending platform partnering with banks to expand access to affordable credit. Forbes recently ranked Upstart #12 on its list of ""most promising AI companies in America."" Inc. Magazine also recognized Upstart as one of the Best Workplaces for 2020.

By leveraging Upstart's AI platform, Upstart-powered banks can have higher approval rates and lower loss rates, while simultaneously delivering the exceptional digital-first lending experience their customers demand. Upstart's patent-pending platform is the first to receive a no-action letter from the Consumer Financial Protection Bureau related to fair lending. Upstart is based in San Mateo, California and Columbus, Ohio.

Most Upstarters join us because they connect with our mission of enabling access to effortless credit based on true risk. If you are energized by the impact you can make at Upstart, we'd love to hear from you!

The Team

Upstart's data science team has a direct impact on our company's success. Our data science team consists of full-stack generalists as well as specialists in statistical modeling or machine learning as well as machine learning engineers.

Because our challenges are so new, members of our data science team need strong creative problem-solving skills and the technical background to implement solutions. Our research environment affords team members the opportunity to utilize a variety of statistical and machine learning methods with the freedom and encouragement to pursue alternative approaches to solving problems. Whether developing new products or identifying novel approaches to core models, we are continuously seeking the next big ideas to move our business forward.

The Role

As a Machine Learning Engineer with Upstart, you'll enjoy a fast-paced environment with a focus on productionalizing, deploying and training machine learning models. You'll also have an opportunity to work alongside a talented team that values curiosity, humility, drive and teamwork.

What we're looking for:
2+ years of professional experience as a data scientist or software engineer
Experience productionalizing, deploying, and training machine learning models (we use Python and sklearn, but experience in any language is valuable)
Interest in helping other data scientists improve code quality in addition to conducting independent analyses
Experience optimizing models for memory and speed
Knowledge of machine learning and statistics or a strong desire to learn
BS in computer science, mathematics, statistics or related area of study with advanced degree(s) preferred
What you'll love:
Competitive compensation (base + bonus & equity)
Comprehensive medical, dental, and vision coverage
Personal development and technology & ergonomic budgets
Life insurance and disability benefits
Clubs and Activities (game nights, Fitstarters, Superwomen, book club, investing club, money discussions, photography club and basketball teams)
Generous vacation policy
401(k) retirement plan
Catered lunches + snacks & drinks
Upstart is a proud Equal Opportunity Employer. We are dedicated to ensuring that underrepresented classes receive better access to affordable credit, and are just as committed to embracing diversity and inclusion in our hiring practices. We celebrate all cultures, backgrounds, perspectives, and experiences, and know that we can only become better together.",4.2,"Upstart
4.2","San Mateo, CA","San Mateo, CA",201 to 500 employees,2012,Company - Private,Lending,Finance,Unknown / Non-Applicable,-1
Machine Learning Engineer,-1,"About Us:

BlackSky is a geospatial intelligence solutions provider that enables organizations to task, collect, and transform data from earth observation, global sensor networks, mobile devices, and social media to deliver on-demand insights about places, events, and assets that are critical to their operations. BlackSky provides satellite collection, data, and cloud-based processing and analytic solutions to organizations that are capitalizing on the exponential growth of a wide range of sensor and collection platforms for delivering the next generation of geo-intelligence and location intelligence solutions. BlackSky has extensive expertise and capabilities in commercial remote sensing, multi-source analytics, cloud computing, open source software development, Amazon Web Services, and big data geospatial analytics. BlackSky is operating and deploying a constellation of high-resolution imaging spacecraft to image the planet in near real time.

BlackSky is looking for a talented and creative Machine Learning Engineer to support the development, operation, and capability evolution of Spectra AI, BlackSky's cutting edge AI/ML Platform. As part of the machine learning team, you are instrumental in supporting the automated monitoring mission at BlackSky. You will help ensure that Spectra AI produces consistent, reliable, and relevant analytics to BlackSky's growing user base.

This position is a critical element of the BlackSky AI/ML Engineering team and is expected to work collaboratively with external satellite development teams to ensure success. The ideal candidate has AI model development, operations, and test experience; familiarity with national security use cases; and success working in an agile development environment. Additionally, the ideal candidate has demonstrated the ability to manage their own efforts over a broad scope of work as an independent contributor. Finally, the candidate should be an independent thinker with the demonstrated ability and willingness to lean in and solve new problems.

Responsibilities:
Design and implement solutions for internal and external customers that exploit traditional machine learning and novel deep learning for next-generation satellite imagery analytics
Plan and conduct research projects related to computer vision, content curation, probabilistic modeling, machine learning, predictive analytics, and geometric modeling
Collaborate with management and technical team on product strategy
Develop algorithms, models, and analytical tools for solving domain specific business problems
Collaborate with software developers to plan and construct the model deployment architecture.
Qualifications:
3+ years of hands-on experience as a machine learning engineer or data scientist.
Bachelor's Degree or higher in one of the following fields: computer science, mathematics, physics, statistics, or another computational field with a strong background of using machine learning/data mining for predictive modeling.
Hands on experience working with large data sets including data cleansing/transformation, statistical analyses, and visualization.
Working knowledge of a wide range of machine learning concepts including supervised and unsupervised deep learning methods for both classification and regression.
Extensive experience developing machine learning based software solutions. In particular, developing models in Python 3, NumPy, Scikit-Learn, Tensorflow or PyTorch, and Keras.
Experience performing research in both groups and as a solo effort with a history of implementing algorithms directly from research papers.
Strong ability to communicate concepts and analytical results with customers, management, and the technical team, highlighting actionable insights.
US Citizenship Required.
Desired Skills:
5+ years of hands-on experience as a machine learning engineer or data scientist.
Ph.D./Master's degree in the previously mentioned fields.
Experience working with remote sensing data, ideally satellite imagery.
Natural language processing techniques including entity extraction and dependency parsing.
Experience developing asynchronous processing algorithms and Cloud-based solutions (especially AWS services like EC2 & S3).
BlackSky is committed to hiring and retaining a diverse workforce. We are proud to be an Equal Opportunity/Affirmative Action Employer All Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, age, national origin, sexual orientation, gender identity, disability, protected veteran status or any other characteristic protected by law.

EEO/AAP/ Pay Transparency Statements: https://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf
https://www.dol.gov/ofccp/regs/compliance/posters/pdf/OFCCP_EEO_Supplement_Final_JRF_QA_508c.pdf",5.0,"BlackSky
5.0","Herndon, VA","Herndon, VA",51 to 200 employees,1999,Company - Private,Aerospace & Defense,Aerospace & Defense,$50 to $100 million (USD),-1
Data Scientist/Machine Learning (NLP),-1,"Senior NLP Engineer

There are many examples of disruption in the consumer space Uber disrupting the cab industry, Airbnb disrupting the hospitality industry and so on; but have you wondered who is disrupting support and operations?

AISERA helps make businesses and customers successful by offering consumer-like user experience for support and operations. We have built the world's first AISM solution for IT, HR, Customer Service, Facilities, and IT/Cloud Operations. With AISERA, organizations can provide a personalized and proactive experience for users by automating the resolution of tasks and actions.

What you'll be doing

As a NLP Engineer Manager, you will be responsible for pursuing excellence across these NLP tasks as a core contributor, while also serving as an NLP mentor and guide more broadly. You will lead a team of 8 (and growing) very skilled data scientists.

You will be understanding our users and their communication patterns is quintessential in helping our customers. Success in this role is making sense of the chaos, analyzing vast amounts of data and extracting patterns. Deep understanding of languages and passion towards helping machines understand context will ensure enjoyment and success in daily work.

Requirements

Experience in text classification a PLUS.

Experience as technical lead in designing and developing software and algorithms for natural language processing and conversational AI.

Development and implementation of novel methods for data extraction from free text data, including named entity recognition, relation extraction, part of speech tagging, etc.

Strong coding and software engineering skills in a mainstream programming language, such as Python, Java, C/C++.

Experience coding and debugging deep learning neural networks for text processing in PyTorch, Keras and/or TensorFlow.

Development and implementation of methods for topic modeling, document clustering and text summarization.

Development and implementation of methods for unsupervised identification of keywords and for detection of word similarity: latent semantic indexing, brown clustering, word2vec, etc.

Design and coding of algorithms that can enable researchers to identify, categorize, prioritize and process large volumes of unstructured textual datasets.

Experience in building large-scale NLP systems from researching a prototype to production

Experience with supervised, unsupervised and semi-supervised machine learning methods.

Experience with the key open-source software resources in these domains.

Strong communication and writing skills in English are essential.

The ideal candidate will have a proven track record of scientific publication in the fields of machine learning, deep learning, and/or natural language processing.

Must be eligible to work in the U.S.",4.3,"Coit Group
4.3","Palo Alto, CA","San Francisco, CA",1 to 50 employees,2001,Company - Private,Staffing & Outsourcing,Business Services,$5 to $10 million (USD),-1
Data Scientist(s)/Machine Learning Engineer,-1,"Company: AI/Data Science
Location: New York City, NY
Position: Data Scientist/Machine Learning Engineer

Sizzle: Without a doubt you will have the opportunity to collaborate with top engineers in the AI and Machine Learning space; work in ""google esq "" environment and get compensated with a strong base salary, bonus, stock options, UNLIMITED time off, ability to work remote and great benefits

The Company:

Our client is a highly recognized leader in the AI driven RPA software space, an emerging form of business process automation technology based on the notion of software robots or artificial intelligence (AI) workers. Unlike traditional workflow automation tools RPA systems develop the action list by watching the user perform that task in the applications graphical user interface (GUI), and then perform the automation by repeating those tasks directly in the GUI. This can lower the barrier to use of automation in products that might not otherwise feature APIs for this purpose.

RPA tools have strong technical similarities to graphical user interface testing tools. These tools also automate interactions with the GUI, and often do so by repeating a set of demonstration actions performed by a user. RPA tools differ from such systems including features that allow data to be handled in and between multiple applications, for instance, receiving email containing an invoice, extracting the data, and then typing that into a bookkeeping system

The Role:

The need is for multiple Data Scientists who also are versed in Machine Learning. You will interface extensively with Client, other software engineers, stakeholders and business sponsors while building and enhancing customized Client models put into production. The day to day can include the following as well:

Design, develop and create machine learning models to deliver use case requirements.
Use our Auto-Client framework and iteratively improve performance through new data representations, feature engineering and model optimization. Implement analytical models into production by collaborating with software developers and machine learning engineers.
Communicate the analytic solution to stakeholders and provide improvements to client's operational systems.

This position requires expertise in acquiring, processing, analyzing and modeling of information from massive amounts of structured and unstructured data. A track record of data-driven implementation and strong experimental design cannot be overemphasized.

What You'll Need for Success:

1-3 years of experience using machine learning in an applied setting.
Bachelor's or Master's in a related field such as CS, Machine Learning, Statistics, Physics
Excellent programming skills in Java and Python
The ability to think ""out of the box” to combine multiple possibly unrelated solutions to solve a single complex problem",5.0,"Blue Horizon Tek Solutions
5.0","New York, NY","Coconut Creek, FL",1 to 50 employees,1987,Company - Private,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
Software Engineer - Full Stack,"$138K-$159K
(Glassdoor est.)","At Databricks, we are obsessed with enabling data teams to solve the world's toughest problems, from security threat detection to cancer drug development. We do this by building and running the world's best data and AI infrastructure platform, so our customers can focus on the high value challenges that are central to their own missions.

Founded in 2013 by the original creators of Apache Spark, Databricks has grown from a tiny corner office in Berkeley, California to a global organization with over 1000 employees. Thousands of organizations, from small to Fortune 100, trust Databricks with their mission-critical workloads, making us one of the fastest growing SaaS companies in the world.

Our engineering teams build highly technical products that fulfill real, important needs in the world. We constantly push the boundaries of data and AI technology, while simultaneously operating with the resilience, security and scale that is critical to making customers successful on our platform.

We develop and operate one of the largest scale software platforms. The fleet consists of millions of virtual machines, generating terabytes of logs and processing exabytes of data per day. At our scale, we regularly observe cloud hardware, network, and operating system faults, and our software must gracefully shield our customers from any of the above.

Unlike traditional enterprise software, we design and build modern SaaS products that bring delight to all of the stakeholders: decision makers, admins, and end users. As a full stack software engineer, you will work closely with your team and product management to bring that delight through great user experience.

Below are some example teams you can join:

Clusters UI: Build the compute fabric powering all the workloads executed on the platform and the services necessary for managing Apache Spark workloads. The team also provides Databricks' customers with fast and easy ways to provision Spark clusters, and empower advanced use cases that enable cloud features, services, and data sources.

Delta Pipelines: The mission of this team is to enable customers to successfully deploy, test & upgrade pipelines and eliminate operational burdens for managing and building high quality data pipelines. The UI is critical to the success of this product. It sets the tone for the simplicity and intuitiveness of configuring and monitoring these pipelines.

Enterprise Platform: Offer a simple and powerful experience for onboarding and managing all of their data teams across 10ks of users on the Databricks platform. We do this by building reliable, scalable services and infrastructure with intuitive UIs and by delivering high-impact, cross-cutting projects that drive the ""land and expand"" strategy for enterprise customers.

Redash: Provide a great SQL-centric data exploration and dashboarding experience on Databricks, leveraging Redash, the most popular open source project in this area.

Workspace: Build and extend the Databricks workspace which is a rich single page Javascript application powered by react+redux and a GraphQL server interface. This is an interactive environment for machine learning and data scientists to load data, visualize results, and create statistical models. The workspace is a SaaS service that is used by hundreds of thousands of data scientists daily.

Competencies
2+ years of experience with HTML, CSS, and JavaScript.
Passion for user experience and design and a deep understanding of front-end architecture.
Comfortable working towards a multi-year vision with incremental deliverables.
Driven by delivering customer value and impact.
Experience with modern JavaScript frameworks (e.g., React, Angular, VueJs/Ember).
Strong familiarity with server-side web technologies (eg: Node.js, Java, Python, Scala, C#, C++,Go, JVM).
Good knowledge of SQL.
Experience with cloud technologies, e.g. AWS, Azure, GCP, Docker, Kubernetes.
Experience in architecting, developing, deploying, and operating large scale distributed systems.
Benefits
Comprehensive health coverage including medical, dental, and vision
401(k) Plan
Equity awards
Flexible time off
Paid parental leave
Family Planning
Gym reimbursement
Annual personal development fund
Employee Assistance Program (EAP)",4.8,"Databricks
4.8","San Francisco, CA","San Francisco, CA",1001 to 5000 employees,2013,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,"Google, IBM"
"Software Engineer, Machine Learning",-1,"Data Science is at the core of TRM's mission to build a safer financial system for billions of people. To achieve such goal, the Data Science team relies on a diverse set of structured and unstructured data to design, build, and support machine learning models to detect and prevent fraud and financial crime in cryptocurrencies and digital assets. As our platform grows, the Data Science team will be building a scalable foundation to propel our impact and product forward.

As a Machine Learning Engineer at TRM Labs, you will collaborate with an experienced team of engineers, data scientists, and product managers to build scalable systems to detect, prevent, and mitigate cryptocurrency fraud and financial crime. You will be deeply involved in the technical details of building highly available and real-time risk detection services to understand the ever evolving attack vectors in crypto and to build a safer financial system for billions of people.

Your Responsibilities
Build machine learning system to detect high-risk activities like money laundering, terrorist financing, human trafficking, account takeovers, and credit card fraud. This will consist of feature engineering / storage, deep learning training pipelines, offline evaluation systems, and online serving infrastructure.
Push the boundary of natural language processing (NLP) technologies and combine artificial and human intelligence to extract illicit activity on the DarkWeb, Social Media Platforms, and other forums.
Working cross-functionally with engineering and data science teams to define and expand labels for model training, productionize real-time machine learning models, and conduct independent research projects to drive our innovation forward
Developing your skills through exceptional training as well as frequent coaching and mentoring from colleagues
Some of the Traits we value
Advanced graduate degree in quantitative field
3+ years industry experience developing production machine learning systems at scale from inception to business impact. Proven ability to tailor your solutions to business problems in a cross-functional team.
Basic understanding of modern machine learning techniques and their mathematical underpinning, such as classification, clustering, optimization, deep neural network and natural language processing.
Engineering skills. This is a hybrid research/engineering role. You'll be responsible for productionizing your pipelines/models and integrating against our back-end services.
Experience in one or more of the following languages: Python (preferred), Scala (preferred), Java, C++, or other equivalent languages.
Experience with large scale data processing is a plus (Hive, Spark preferred)
Adaptable. Goals can change fast. You anticipate and react quickly.
Autonomous. You own what you work on. You move fast and get things done.
Excellent communication. You will need communicate complex ideas effectively to both technical and non-technical audiences, and both verbally and in writing
Collaborative. You must work collaboratively in a cross-functional team and with people at all levels in an organization
Relevant experience in crypto/blockchain is a plus
Benefits
Stock
$2,000 yearly coupon for books, conferences, and professional coaching
Competitive salary
Paid time off
Volunteer time off
Parental leave
Medical, dental, & vision insurance
Life & disability coverage
401K
Apple equipment
Daily lunch and dinner
Why us

We work with the best. TRM is YC-backed and funded by Blockchain Capital, the leading blockchain VC firm. Our customers include the world's top digital asset companies.

Strong engineering and product culture. Collectively, we've researched machine learning at Harvard and Stanford, led strategy teams at McKinsey, built data pipelines at Facebook and shipped distributed apps at Amazon and OpenDoor.

Our culture is creative, collaborative, and hypothesis-driven. We focus on creating the best products possible with low ego and high productivity.

TRM Labs is an equal opportunity employer.",5.0,"TRM Labs
5.0","San Francisco, CA","San Francisco, CA",1 to 50 employees,2018,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
"Senior Machine Learning Engineer, Infrastructure","$140K-$234K
(Glassdoor est.)","Company Description

As an Etsy employee, you can do the work you love, be yourself, and make an impact in the lives of millions. Our commitments to diversity and inclusion, team culture and the spaces where we work all reflect our mission to keep commerce human.

Job Description

Etsy is looking for a Senior Software Engineer to join our Machine Learning Platform team to build the next generation Machine Learning platform and help us connect buyers and sellers in meaningful ways.

The Machine Learning Platform team is part of Etsy's data organization. Our mission is to simplify the development and deployment of machine learning models at Etsy. For many sellers, Etsy is their primary source of income, and we work hard to support them. We continue to improve our portfolio to ship new relevance based AI products every year. In this role, you will have the opportunity to work with our Data Science and ML team, Data Platform team and many more product squads. We're a growing team with huge impact that builds tools and platform capabilities for data scientists and ML engineers to access feature data, build machine learning models, test hypotheses and productionize them on our ML platform hosted in Google Cloud. We value empathy, communication and technical skills equally.

Qualifications

About the Job:
Design, build and evolve the core ML Platform components and services
Work cross-functionally with various product engineering, data engineering and data science teams
Mentor and help grow other engineers on the team
About You:
You are a senior engineer with experience in machine learning, infrastructure engineering and/or distributed systems who takes pride in building large scale, high performance and fault tolerant systems
You are hyper-focused on (even obsessed with!) code quality and can lead a team in improving the quality of existing codebases
You have helped drive the development of a platform, with a strong focus on developer experience
You have worked with machine learning and understand the needs of data scientists and ML engineers
You can define and solve unconstrained problems and know when to seek help
You are comfortable collaborating closely with other engineers, engineering leaders, data scientists and product managers
You have a ""leave it better than you found it"" mentality and are willing to work with and improve on code you did not originally write
You love to experiment and use data to drive decision-making
You are generous with your time and experience and can mentor other engineers
You are mindful and transparent in your communication with others
Additional Information

At Etsy, we believe that a diverse, equitable and inclusive workplace makes us a more relevant, more competitive, and more resilient company. We welcome people from all backgrounds, ethnicities, cultures, and experiences. Etsy is an equal opportunity employer. We do not discriminate on the basis of race, color, ancestry, religion, national origin, sexual orientation, age, citizenship, marital or family status, disability, gender identity or expression, veteran status, or any other legally protected status. We will ensure that individuals with disabilities are provided a reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. While Etsy supports visa sponsorship, sponsorship opportunities may be limited to certain roles and skillsets.",3.6,"Etsy
3.6","Brooklyn, NY","Brooklyn, NY",501 to 1000 employees,2005,Company - Public,Other Retail Stores,Retail,$100 to $500 million (USD),"Airbnb, Warby Parker, Kickstarter"
Computer Scientist - Software Engineer/Cyber Developer - Entry to Experienced Level,"$54K-$114K
(Glassdoor est.)","Job Description

notificationsA personal message from the NSA Hiring Team re COVID-19
Computer Scientist - Software Engineer/Cyber Developer - Entry to Experienced Level
Fort Meade, MD
Pay Plan: GG
,
Grade: 07/1 to 14/10
Open: 2020-06-16, Close: 2020-08-31
Job Posting: 1145866

link

Responsibilities


Responsibilities

The mission demands that NSA ""see"" the world through a different lens than any other organization. Our Computer Scientists face technical challenges well beyond the wildest imaginations of most people. NSA's mission requires persistent engagement to anticipate and understand complex threats in real-time, on a global scale. From Counter-Terrorism to Combat Support to Cybersecurity, NSA's Computer Science community creates novel, cutting-edge solutions that advance science and underpin every aspect of our foreign intelligence and cybersecurity missions. Solving these extraordinary problems allows NSA to share solutions with the world by contributing to open source, licensing patents, and publishing technical papers.

A world-class Computer Science cadre at NSA is vital to the security of the nation. The standards of reliability, repeatability, scale, speed, and compliance that NSA hardware and software products must meet are daunting. Industry and academia change the question to one that can be answered; NSA must answer the question as is. The mission problems, questions, and threats fuel our constant drive for more robust solutions and the use of revolutionary technologies like artificial intelligence, machine learning algorithms, high performance computing, big data analysis, anticipatory algorithms predictive analytics, complex data modeling, advanced computing and network architectures, distributed systems and sensor networks, advanced systems and IT networks, and those we create along the way.

Computer Science jobs at NSA run the entire spectrum of the field. Opportunities are available in systems software, mission applications software development, business applications and systems, advanced data management systems and analysis, development of advanced analytic environments, computing research, cybersecurity and encryption.

Applicants may also be considered for one of NSA's Development Programs. Designed for entry to mid-level employees, development program participants are afforded the opportunity to receive tailored training, often with a cohort, and multiple assignments across Agency Directorates to develop skills and experience to ground their career at the NSA.

As an NSA Computer Scientist your responsibilities may include:
creating analytic applications that scale across multiple, very large, data sets from disparate sources
leveraging and integrating open source, commercial off-the-shelf, and government developed software
leading new advances in computer science, such as:
microprocessor-based advances
beyond the horizon supercomputers
signals processing (including analog control)
user interfaces
deep learning
cybersecurity
design and implementation of encryption
advanced algorithms
As an NSA Cyber Developer, your responsibilities may include:
detecting, identifying, and evaluating vulnerabilities in cyberspace systems
developing software and/or hardware exploitation capabilities that enable collection of foreign intelligence from target networks and systems
designing solutions to defend against adversarial threats directed towards the US, to include cutting-edge technologies such as mobile, SCADA, and Internet of Things
analyzing sophisticated malware to thwart cyber attacks and identify new threats
Job Summary


Does solving unique problems energize you? Do you like to create distinctive solutions? The difference between NSA Computer Scientists and others are the problems we MUST solve. Our culture believes in solving ""unsolvable"" problems, which we do by creating new science and new technologies not yet discovered, that will protect and advance our Nation in the 4th Industrial Revolution. Are you ready for the challenge? Are you fearless? ...then click to read more!

Qualifications


Salary Range: $72,351 - $90,157 (Entry/Developmental)
The qualifications listed are the minimum acceptable to be considered for the position. Salary offers are based on candidates' education level and years of experience relevant to the position and also take into account information provided by the hiring manager/organization regarding the work level for the position.
Entry is with a Bachelor's degree and no experience. An Associate's degree plus 2 years of relevant experience may be considered for individuals with in-depth experience that is clearly related to the position.

Degree must be in Computer Science (CS). Related fields (e.g., Engineering, Mathematics) may be considered relevant if the programs contain, at minimum, a concentration of courses in the following foundational CS areas: algorithms; computer architecture (not network architecture); programming methodologies and languages; data structures; logic and computation; and advanced mathematics (for example, calculus, discrete mathematics). Information Technology (IT) or Information Systems (IS) degrees may be considered relevant if the programs contain the amount and type of coursework equivalent to a CS major.

Relevant experience must be in the software development process (i.e., requirements analysis, software design, implementation, testing, integration, deployment/installation, and maintenance) and programming.

Salary Range: $83,692 - $112,240 (Full Performance)
The qualifications listed are the minimum acceptable to be considered for the position. Salary offers are based on candidates' education level and years of experience relevant to the position and also take into account information provided by the hiring manager/organization regarding the work level for the position.
Entry is with a Bachelor's degree plus 3 years of relevant experience or a Master's degree plus 1 year of relevant experience or a Doctoral degree and no experience. An Associate's degree plus 5 years of relevant experience may be considered for individuals with in-depth experience that is clearly related to the position.

Degree must be in Computer Science (CS). Related fields (e.g., Engineering, Mathematics) may be considered relevant if the programs contain, at minimum, a concentration of courses in the following foundational CS areas: algorithms; computer architecture (not network architecture); programming methodologies and languages; data structures; logic and computation; and advanced mathematics (for example, calculus, discrete mathematics). Information Technology (IT) or Information Systems (IS) degrees may be considered relevant if the programs contain the amount and type of coursework equivalent to a CS major.

Relevant experience must be in the software development process (i.e., requirements analysis, software design, implementation, testing, integration, deployment/installation, and maintenance) and programming.

Salary Range: $102,663 - $157,709 (Senior)
The qualifications listed are the minimum acceptable to be considered for the position. Salary offers are based on candidates' education level and years of experience relevant to the position and also take into account information provided by the hiring manager/organization regarding the work level for the position.
Entry is with a Bachelor's degree plus 6 years of relevant experience or a Master's degree plus 4 years of relevant experience or a Doctoral degree plus 2 years of relevant experience. An Associate's degree plus 8 years of relevant experience may be considered for individuals with in-depth experience that is clearly related to the position.

Degree must be in Computer Science (CS). Related fields (e.g., Engineering, Mathematics) may be considered relevant if the programs contain, at minimum, a concentration of courses in the following foundational CS areas: algorithms; computer architecture (not network architecture); programming methodologies and languages; data structures; logic and computation; and advanced mathematics (for example, calculus, discrete mathematics). Information Technology (IT) or Information Systems (IS) degrees may be considered relevant if the programs contain the amount and type of coursework equivalent to a CS major.

Relevant experience must be in the software development process (i.e., requirements analysis, software design, implementation, testing, integration, deployment/installation, and maintenance) and programming. Formal or informal leadership experience is preferred.

Competencies


The ideal candidate is someone who thrives on solving hard problems, has excellent communication and interpersonal skills, and is able to:
work independently as well as in a team environment to build solutions
handle multiple assignments
synthesize information to solve complex problems
apply knowledge of data structures and algorithms to software engineering problems
develop, diagnose, and operate complex computer systems
identify customer needs and validate product design
Additionally, the ideal candidate is someone with knowledge and experience in one or more of the following:
programming and scripting experience (e.g., C, C++, Java, Assembly, Python, Perl, Ruby, Bash, Node.js, Spark, Puppet, SALT, KAFKA, HADOOP, VHDL, Verilog)
building user facing services, middleware, and backend systems
full-stack development
computer networking (e.g., communication protocols, distributed systems, Internet of Things, real-time systems, routing and switching)
protocol analysis (e.g. Wireshark, tcpdump)
data spaces, data modeling, data analysis, storage design, and administration
simulation/model development & prototyping
information retrieval, machine learning, artificial intelligence, statistics and analytics
hardware and software vulnerability analysis
software reverse engineering/interactive debugging tools (e.g., IDA Pro, Ollydbg, gdb)
hardware reverse engineering tools (e.g., JTAG, Oscilloscopes)
software development life-cycle (design, develop, implementation, debug, testing)
kernel and device driver development
network/socket programming
embedded systems development
Pay, Benefits, & Work Schedule


On-the job training, Internal NSA courses, and external training will be made available based on the need and experience of the selectee.

Monday - Friday, with basic 8hr/day work requirements between 0600 and 1800 (flexible).

How to apply


To apply for this position, please click the 'Apply' button located at the top right of this posting. After completing the application for the first time, or reviewing previously entered information, and clicking the 'Submit' button, you will receive a confirmation email. Please ensure your spam filters are configured to accept emails from noreply@intelligencecareers.gov.

Please attach an unofficial copy of your transcripts when applying for this position. Providing a copy of your transcripts is especially critical since the minimum qualifications for this position require a CS/CE degree OR a degree that demonstrates a concentration of CS coursework. For example, degrees in Computer Networking, Information Science, Information Systems, Information Technology, Information Security, Information Assurance, Cyber Security, and Digital Forensics MAY be considered for this position IF your coursework/transcripts demonstrate a concentration of CS coursework. Foundational CS coursework includes the following courses: Computer Architecture, Programming Languages, Data Structures, and Algorithms.
**PLEASE NOTE: U.S. Citizenship is required for all applicants. Reasonable accommodations provided to applicants with disabilities during the application and hiring process where appropriate. NSA is an equal opportunity employer and abides by applicable employment laws and regulations. All applicants and employees are subject to random drug testing in accordance with Executive Order 12564. Employment is contingent upon successful completion of a security background investigation and polygraph.
This position is a Defense Civilian Intelligence Personnel System (DCIPS) position in the Excepted Service under 10 U.S.C. 1601. DoD Components with DCIPS positions apply Veterans' Preference to eligible candidates as defined by Section 2108 of Title 5 USC, in accordance with the procedures provided in DoD Instruction 1400.25, Volume 2005, DCIPS Employment and Placement. If you are a veteran claiming veterans' preference, as defined by Section 2108 of Title 5 U.S.C., you may be asked to submit documents verifying your eligibility.

Please note that you may be asked a series of questions depending on the position you apply for. Your responses will be used as part of the screening process of your application and will assist in determining your eligibility for the position. Be sure to elaborate on experiences in your resume. Failure to provide the required information or providing inaccurate information will result in your application not being considered for this position. Only those applicants who meet the qualifications for the position will be contacted to begin employment processing.

Please Note: Job Posting could close earlier than the closing date due to sufficient number of applicants or position no longer available. We encourage you to apply as soon as possible.

DCIPS Disclaimer


The National Security Agency (NSA) is part of the DoD Intelligence Community Defense Civilian Intelligence Personnel System (DCIPS). All positions in the NSA are in the Excepted Services under 10 United States Codes (USC) 1601 appointment authority.
arrow_upwardBack to Top",3.8,"National Security Agency
3.8","Fort Meade, MD","Fort George G Meade, MD",Unknown,-1,Government,Federal Agencies,Government,Unknown / Non-Applicable,-1
"Software Engineer, Product and Machine Learning - Search and Recommendations","$81K-$162K
(Glassdoor est.)","Company Description

As an Etsy employee, you can do the work you love, be yourself, and make an impact in the lives of millions. Our commitments to diversity and inclusion, team culture and the spaces where we work all reflect our mission to keep commerce human.
Job Description

About the Team

Our teams are responsible for search ranking and recommendations. Our aim is to present the best of Etsy’s inventory. As an engineer on our team, you will play a major role in improving the shopping experience for millions of Etsy buyers. We’re a cross-functional group of engineers, data scientists, product managers, designers, and researchers.

With your help, we are giving our buyers better tools to find what they are looking for and to help them form a connection with our sellers. In this role, you will put your skills to use by helping us improve the ranking and suggestions of localized results through machine learning algorithms. You will also create workflows and pipelines to effectively transform data into appropriate results for our buyers. You will join a talented team of engineers to collaborate on all of these projects.

In this role, you will have the opportunity to work with our Data Science and ML team, Data Platform team and many more product squads. We’re a growing team with a huge impact that builds tools and platform capabilities for data scientists and ML engineers to access feature data, build machine learning models, test hypotheses and productionize them on our ML platform hosted in Google Cloud. We value empathy, communication and technical skills equally. Here’s a taste of the problems we’re solving:
How can we help someone find that perfect item, even when they don’t know what they’re looking for?
How do we rank millions of search results in a matter of milliseconds, so that we’re always surfacing the best of Etsy?
How can we maximize the relevance of search results over an enormous range of queries and buyers?
How can the search experience make Etsy come to life and feel as vibrant as the community of makers that’s behind it?
How can we understand buyer’s motives and interests to personalize their experience?
How can we help buyers to explore the breadth of Etsy's inventory?
Our production systems rely on PHP, JavaScript, Java, Python and Scala; we are proud to have an engineering culture that encourages career growth and learning. You can learn more about our philosophies, tools, and some of the challenges we’ve been solving on our Engineering blog: http://codeascraft.com/

We are language-agnostic in our approach to interviewing.

This role is located in our Brooklyn HQ.

Qualifications
Experience with objective-oriented programming languages: Python, Java, Scala, etc.
Familiarity with machine learning and deep learning solutions across the entire machine learning stack, from data collection to evaluation
Experience with machine learning frameworks (like PySpark, Scalding, etc.)
Strong verbal and written communication skills.
About the Role

In this role you will:
Contribute at all levels of Etsy’s search and recommendations stacks, ranging from application back-end technologies (PHP, Java, Python, MySQL, Scala, Vertica) as well as machine learning stack (PySpark, Scalding, Airflow).
Work cross-functionally with various engineering teams (e.g. machine learning infrastructure, data science, search experience), participating in design, prioritization and implementation.
Develop and train machine learning data sources and models, both to iterate on existing features and develop new features.
Use feature engineering tools and principles to clean and transform data into signals driving listing quality
Deploy models to production, sometimes including application development for your feature.
Provide detailed and constructive design and code reviews.
Empathy, communication, and technical skill are valued equally.
About You

You will do well in this role if you:
Enjoy thinking about the implications of your work on end users.
You are comfortable collaborating with Product Managers, Data Analysts, and Designers to ensure that you’re delivering impactful product features.
Have experience operating within a large codebase and working to create simplicity from complex systems, including using experiments and data to drive decision making.
Are an analytical thinker and understand how to wield data to make informed decisions about your work.
Write understandable, testable code with an eye towards maintainability.
You turn ideas into deeply reliable and well tested code that other people – or you, six months into the future – will find easy to comprehend and modify.
You have worked with machine learning and understand the needs of data scientists and ML engineers.
You have solid engineering and coding skills, data structure knowledge and ability to write high performance production quality code.
Additional Information

At Etsy, we believe that a diverse, equitable and inclusive workplace makes us a more relevant, more competitive, and more resilient company. We welcome people from all backgrounds, ethnicities, cultures, and experiences. Etsy is an equal opportunity employer. We do not discriminate on the basis of race, color, ancestry, religion, national origin, sexual orientation, age, citizenship, marital or family status, disability, gender identity or expression, veteran status, or any other legally protected status.

We will ensure that individuals with disabilities are provided a reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment.

While Etsy supports visa sponsorship, sponsorship opportunities may be limited to certain roles and skillsets.",3.6,"Etsy
3.6","Brooklyn, NY","Brooklyn, NY",501 to 1000 employees,2005,Company - Public,Other Retail Stores,Retail,$100 to $500 million (USD),"Airbnb, Warby Parker, Kickstarter"
"Lead Data Engineer, Modeling & Machine Learning",-1,"At Rockstar Games, we create the games we would want to play ourselves.A career at Rockstar is about being part of a team working on some of the most creatively rewarding, large-scale projects to be found in any entertainment medium. You would be welcomed to a friendly, inclusive environment where you can learn, and collaborate with some of the most talented people in the industry.Rockstar San Diego is seeking a Lead Data Engineer to join a team focused on building a cutting-edge game analytics platform and tools to better understand our players and enhance their experience in our games. This is a full-time permanent position based out of Rockstar's unique game development studio in Carlsbad, CA.The ideal candidate will be skilled in developing complex ingestion and transformation processes with an emphasis on reliability and performance. In collaboration with other data engineers, database administrators, and developers, the candidate will empower the team of analysts and data scientists to deliver data driven insights and applications to company stakeholders.WHAT WE DO* The Rockstar Analytics team provides insights and actionable results to a wide variety of stakeholders across the organization in support of their decision making.* We partner with multiple departments across the company to design and implement data and pipelines.* We collaborate as a global team to develop cutting-edge data pipelines, data products, data models, reports, analyses, and machine learning applications.RESPONSIBILITIES* Lead the development of data models/aggregations, machine learning pipelines, machine learning feature stores and data products for the Analytics team and partner groups.* Assure Rockstar's ongoing competitive advantage through best-in-class data model designs, machine learning pipelines and data products that have a high business value.* Identify and lead projects aligned with long-term, strategic initiatives.· Lead the development, maintenance, and improvement of new and existing algorithms and their underlying systems.* Establish scalable, efficient, automated processes for data analyses, model development, validation and implementation.* Lead the implementation of end-to-end solutions for batch and real-time algorithms along with requisite tooling around monitoring, logging, automated testing, performance testing and A/B testing with a team of analysts and data scientists who create insights and analytics applications for our stakeholders.* Contribute to and promote good software engineering practices across the team.* Lead, manage and inspire a team of world class data engineers, providing leadership through coaching and mentorship on a regular basis.* Influence the analytics and technology roadmap.* Participates in the recruitment of the best in class data engineers.QUALIFICATIONS* 3+ years of experience managing and supervising a team.* 5+ years of work experience with ETL, data modeling, and business intelligence big data architectures.* 5+ years of experience with the Hadoop ecosystem (Map Reduce, Spark, Spark-Streaming, Oozie, Impala, etc.) and big data ecosystems (Kafka, Cassandra, etc.).* Expert in at least one SQL language such as T-SQL or PL/SQL.* Experience developing and managing data warehouses on a terabyte or petabyte scale.* Strong experience in massively parallel processing & columnar databases.* Experience working with Real-Time, Near-Real-Time streaming pipelines.* Experience with Python and shell scripting.* Experience working in a Linux environment.SKILLS* Strong problem-solving skills.* Proven ability to reconcile technical and business perspectives.* Proven ability to develop and maintain good relations and communicate with people at all hierarchical levels.* Autonomy and entrepreneurship.* Strong mentoring abilities.* Strong team spirit.* Passion for Rockstar Games and our titles.PLUSESPlease note that these are desirable skills and are not required to apply for the position.* Experience with event processing frameworks.* Experience with Java or Scala programming languages.* Familiar with Restful APIs.* Experience with Artifact Repositories.* Game industry experience.HOW TO APPLYPlease apply with a resume and cover-letter demonstrating how you meet the skills above. If we would like to move forward with your application, a Rockstar recruiter will reach out to you to explain next steps and guide you through the process.Rockstar is proud to be an equal opportunity employer, and we are committed to hiring, promoting, and compensating employees based on their qualifications and demonstrated ability to perform job responsibilities.If you've got the right skills for the job, we want to hear from you. We encourage applications from all suitable candidates regardless of age, disability, gender identity, sexual orientation, religion, belief, or race.",4.0,"Rockstar Games
4.0","Carlsbad, CA","New York, NY",1001 to 5000 employees,1998,Subsidiary or Business Segment,Video Games,Media,$10 to $25 million (USD),-1
"Research Scientist, Core Machine Learning (PhD)","$83K-$159K
(Glassdoor est.)","Facebook's mission is to give people the power to build community and bring the world closer together. Through our family of apps and services, we're building a different kind of company that connects billions of people around the world, gives them ways to share what matters most to them, and helps bring people closer together. Whether we're creating new products or helping a small business expand its reach, people at Facebook are builders at heart. Our global teams are constantly iterating, solving problems, and working together to empower people around the world to build community and connect in meaningful ways. Together, we can help people build stronger communities - we're just getting started.At Facebook, we use machine learning across a diverse set of applications to help people discover better content more quickly, and to connect with the things that matter most to them.In order to meet the demands of our scale, we approach machine learning challenges from a system engineering standpoint, pushing the boundaries of scalable computing and tying together numerous complex platforms to build models that leverage trillions of actions. Our research and production implementations leverage many of the innovations being generated from Facebook's research in Distributed Computing, Artificial Intelligence and Databases, and run on the same hardware and network specifications that are being open sourced through the Open Compute project. As a Software Engineer or Research Scientist at Facebook, you will help build the next generation of machine learning systems behind Facebook's products, create web applications that reach millions of people, build high volume servers and be a part of a team thats working to help connect people around the globe.

Responsibilities:

Develop highly scalable classifiers and tools leveraging machine learning, regression, and rules-based models.
Suggest, collect and synthesize requirements and create effective feature roadmap.
Code deliverables in tandem with the engineering team.
Adapt standard machine learning methods to best exploit modern parallel environments (e.g. distributed clusters, multicore SMP, and GPU).
Mininum Qualifications:

Currently has, or is in the process of obtaining, a PhD degree or postdoctoral assignment in Machine Learning, or a related field.
Research and/or work experience in machine learning, NLP, recommendation systems, pattern recognition, signal processing, data mining, artificial intelligence, information retrieval or computer vision.
Knowledge in Java or C++, Perl, PHP or Python.
Proven track record of achieving results as demonstrated by grants, fellowships, patents, as well as first-authored publications at workshops or conferences such as ICML, NIPS, KDD or similar.
Must obtain work authorization in country of employment at the time of hire, and maintain ongoing work authorization during employment.
Preferred Qualifications:
Facebook is proud to be an Equal Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law.

Facebook is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.",4.5,"Facebook
4.5","Menlo Park, CA","Menlo Park, CA",10000+ employees,2004,Company - Public,Internet,Information Technology,$5 to $10 billion (USD),"Google, Microsoft, Apple"
"Software Engineer, Machine Learning","$160K-$178K
(Glassdoor est.)","About Netskope
Today, there's more data and users outside the enterprise than inside, causing the network perimeter as we know it to dissolve. We realized a new perimeter was needed, one that is built in the cloud and follows and protects data wherever it goes, so we started Netskope to redefine Cloud, Network and Data Security.

Since 2012, we have built the market-leading cloud security company and an award-winning culture powered by hundreds of employees spread across offices in Santa Clara, San Francisco, Seattle, Bangalore, London, Melbourne, and Tokyo. Our core values are openness, honesty, and transparency, and we purposely developed our open desk layouts and large meeting spaces to support and promote partnerships, collaboration, and teamwork. From catered lunches and office celebrations to employee recognition events and social professional groups such as the Awesome Women of Netskope (AWON), we strive to keep work fun, supportive and interactive.Visit us at netskope.com/company/careers and follow us on Twitter @Netskope and Facebook.

Software Engineer, Machine Learning

Within Netskope Engineering, Security Services organization is responsible for building core security products and features, such as Advanced Threat Protection, Data Loss Prevention, User and Entity Behavior Analytics and Secure Web Gateway. We apply Artificial Intelligence and Machine Learning technologies across Netskope cloud security platform. We are looking for talented software engineers to join a newly created data science team. A successful candidate has deep technical expertise in productizing AI/ML technologies in security applications and/or adjacent domains, ideally has been through the entire lifecycle of an award winning AI/ML-driven product, and must be passionate about cloud security. You will have the opportunity to work with a team of talented engineers, researchers and data scientists to solve the most challenging cloud security problems.

Responsibilities:
Design, train, test, productize and deploy machine learning models, writing production-level code and assuming end-to-end ownership of successful ML use case implementation with excellent scalability and performance;
Work closely with data scientists, fellow ML engineers, and product management team to ensure our solutions deliver continuous values to end customers;
Document use case, data acquisition, feature engineering, training, validation, deployment, future improvement opportunity and other important aspects;
Be an evangelist of AI/ML within Netskope. Promote AI/ML wherever applicable, beyond security use cases;
Collaborate with data analytics team to define new platform requirements and continuously improve our horizontally scalable data lake.
Qualifications/Requirements:
First of all, must have true startup spirit. Be willing to wear multiple hats and deliver end-to-end;
Ability to think out-of-box and evaluating results based on customer value;
5+ years of industry experience in applying AI/ML, preferably on well-known security products or services, such as malware detection, anomaly detection, security analytics and data security. Note we are open to all experience levels;
Experience implementing highly efficient AI/ML applications, making best use of modern parallel computing environment such as distributed clusters and GPU;
Experience applying AI/ML in more than one domains highly desirable;
Hands-on experience with relevant technology stacks such as CUDA, Python, R, Spark, Flink, Tensorflow;
Energetic self-starter, with the desire to work in a dynamic fast-paced environment;
Excellent verbal and written communication skills;
Ability to influence without authority;
MS or PhD in Computer Science or equivalent technical degree.
#LI-SD1",4.1,"Netskope
4.1","Santa Clara, CA","Santa Clara, CA",501 to 1000 employees,2012,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,"Skyhigh Networks, Zscaler, NortonLifeLock"
Machine Learning Scientist,-1,"Axiom Group has partnered with an elite group of venture backed technology firms, helping them to rapidly scale and achieve their goals.

One of our clients is seeking Machine Learning Scientists to join their founding Data Science team. As an applied researcher and engineer you will focus on machine learning algorithm development and distributed computation. The team of Data Scientists work with state-of-the-art research and commercial machine learning algorithms and apply them to their core technology.

Representative work:
Demonstrated capabilities to explain and distill state-of-the-art research in machine learning
Develop and implement software for novel machine learning techniques
Decompose machine learning algorithms/models into their computational characteristics
Conduct and report on detailed analysis of machine learning models
Algorithm implementation in the areas of graph transforms, linear algebra kernels, and combinatorial optimization

Skills and Qualifications
Experience with at least two machine learning frameworks, such as TensorFlow, Caffe/2, Torch, Theano
Fluency in at least two programming languages, such as Python, C, bash
Proficiency with linear algebra and dynamical systems
Experience with software development engineering
Experience with both asymptotic performance analysis and performance tuning specific case studies
Candidates with Ph.D. and candidates with B.Sc. are encouraged to apply",4.7,"Axiom Group
4.7","Mountain View, CA","Aurora, Canada",51 to 200 employees,1987,Company - Private,Transportation Equipment Manufacturing,Manufacturing,$25 to $50 million (USD),-1
Data Management Engineer II,"$60K-$133K
(Glassdoor est.)","The Position


As an organization, Pharma Technical Development (PTD) works to design processes to manufacture large molecule therapeutics. We develop drugs that can be manufactured at sites worldwide in an efficient manner while keeping in mind that patient safety is our primary goal. Within PTD, the Department of Protein Analytical Chemistry (PAC) is responsible for developing and deploying analytical methods providing detailed structural characterization of recombinant proteins to support the clinical and commercial biotechnology product portfolio. By thoroughly characterizing product quality, we ensure that every patient in need is dosed with safe and effective medicines.

With a thriving pipeline and limited resources, we anticipate that automation, data management, and business process improvement are critical to our success. We are seeking a Software Engineer to initiate, lead, and deliver Digital Transformation projects within PAC. The individual will help deliver crucial applications that increase the insights of scientists, magnify the productivity of technical development teams, and accelerate the rate of drug development. We welcome your deployment of techniques in computer science and mathematics, entrepreneurial spirit, and expertise in delivering complex software development projects to help us drive change as well as resolve complex scientific issues and ambiguous needs.

We are hopeful to find someone with a background in software engineering, data science, and biotechnology/analytical chemistry. You should be comfortable working in a large and complex company, but be flexible to switch hats as project and business situations evolve. As a Software Engineer within PTD, you will leverage technical expertise, leadership and influencing skills to bring applications through the entire software development lifecycle.

Core Responsibilities:
Collaborate with researchers, managers, and engineers to understand how physicochemical characterization data is produced, results are generated, and ultimately how these results are consumed in support of bringing safe and effective drugs to the patient.
Collaborate with scientific, IT, development team, vendors, and business partners to drive projects to completion in different roles as a product owner, project manager, subject matter expert, or software developer.
As a member of the PAC Digital Transformation Team, collaborate with team members to prioritize and manage resources. Provide technical or strategic guidance to team members, as needed.
Act as either a team leader or individual contributor for different projects and applications. Evaluate business and scientific processes to benefit from new technologies.
Ideate, evaluate, and adopt technologies appropriate for the department to drive scientific or business efficiency.
Evaluating and ideating proposals for projects that drive scientific or business efficiency.
Engineer and deploy backend and frontend software components, and tools that meaningfully impact drug development activities.
Ensure all software applications meet internal data integrity standards. Work closely with data integrity teams to build-in compliance.
Communicate and present clearly and effectively to stakeholders across organizations.
Manage project timelines and stakeholder inputs to ensure impactful software solutions are delivered in reasonable time.
Dive into data to unlock insight from experiments.
Code using primarily Python, Javascript, React.
Core Requirements:
Bachelors degree in computer science, software engineering, bioinformatics, or equivalent. Graduate degree preferred.
3-7 years of full-stack industry software engineering experience. This should include experience developing web front-end, back-end, and database solutions.
2+ years of experience building on or managing data platforms, data infrastructure, metrics or pipeline management.
Experience establishing and managing applications in hybrid cloud computing environments with GCP, AWS, or Azure.
Experience with standard software engineering practices including code reviews, TDD, version control, containerization, configuration management, and CI/CD
Exceptional candidates will broadly cover one or more elements in this background:
Javascript expertise with React, Angular, Node
Python expertise with Django, Pandas, sci-kit learn
R expertise with tidyverse, shiny, caret
REST and GraphQL APIs
Google Cloud Platform development
Data management with noSQL technologies and PostgreSQL
Networking and security administration
Software engineering/development experience in a biomedical, biotech, or drug development organization
Complex data visualization and plotting libraries like echarts, ggplot2, matplotlib
Working knowledge of statistical methods.
DevOps toolchain expertise: git, docker, kubernetes, ansible, jenkins
Background in analytical chemistry and/or drug development
Data science background in text mining, image analysis, stochastic models, or machine learning
Bioinformatics background in mass spectrometry, proteomics
Chemometrics background in spectroscopy and liquid chromatography
#LI-DW1

Who We Are


A member of the Roche Group, Genentech has been at the forefront of the biotechnology industry for more than 40 years, using human genetic information to develop novel medicines for serious and life-threatening diseases. Genentech has multiple therapies on the market for cancer & other serious illnesses. Please take this opportunity to learn about Genentech where we believe that our employees are our most important asset & are dedicated to remaining a great place to work.

The next step is yours. To apply today, click on the ""Apply online"" button.

Genentech is an equal opportunity employer & prohibits unlawful discrimination based on race, color, religion, gender, sexual orientation, gender identity/expression, national origin/ancestry, age, disability, marital & veteran status. For more information about equal employment opportunity, visit our Genentech Careers page.

Job Facts
JOB FUNCTION
Devices, Systems and Solutions COMPANY/DIVISION
Pharmaceuticals SCHEDULE
Full time JOB TYPE
Regular",4.0,"Genentech
4.0","South San Francisco, CA","South San Francisco, CA",10000+ employees,1976,Subsidiary or Business Segment,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,$10+ billion (USD),-1
"Software Engineer - AMAZON ALEXA MACHINE LEARNING TEAM - Cambridge, Massachusetts","$68K-$108K
(Glassdoor est.)","Software Engineer - Amazon Alexa Machine Learning Team - Kendall Square..

All-New Amazon Echo

Interested in delivering Natural Language Understanding (NLU) engineering solutions for Alexa working closely with a team of scientists in the Machine Learning (ML) space? The Amazon Alexa NLU team is a group of scientists and software engineers working on natural language solutions that push the envelope in the NLU space, in order to revolutionize how customers interact with Amazons products and services. Products such as Amazon Echo, Echo Show, and Fire TV are illustrative of the user-delighting spoken language solutions Amazon is building.


As a Software Development Engineer, you will be responsible for designing, developing, testing, and deploying distributed machine learning systems and large-scale data mining solutions for natural language understanding (NLU). You will collaborate closely with a team of speech and machine learning scientists to influence our overall strategy, and define the teams road map. You will also drive the system architecture, spearhead best practices that enable a quality product, and help coach and develop junior engineers.

A successful candidate will have an established background in engineering large scale software systems, a strong technical ability, great communication skills, and a motivation to achieve results in a fast paced environment.

Responsibilities:
· Lead the development and maintenance of key Machine Learning systems and infrastructure for NLU in Alexa; deliver high quality software against aggressive schedules
· Actively participate in defining strategy, roadmaps and architecture for the teams products
· Work with other team members to investigate best design approaches, prototype new technology and evaluate technical feasibility
· Mentor and help develop junior engineers, and demonstrate best development practices




Basic Qualifications

· 2+ years of non-internship professional software development experience
· Programming experience with at least one modern language such as Java, C++, or C# including object-oriented design
· 1+ years of experience contributing to the architecture and design (architecture, design patterns, reliability and scaling) of new and current systems.
· BS in Computer Science or equivalent
· 3+ years of industry experience
· Programming experience in at least one language (e.g., Java, Python, C/C++)
· Experience with the tools of the trade, including experience with a variety of modern programming languages (e.g., Java, JavaScript, C/C++, Objective C, Python, Ruby) and open-source technologies (e.g., Linux, SQLite, OpenGL, Spring, Hadoop, Spark, Mesos, Rails)
· Experience with machine learning, big data or large scale distributed systems for commercial online services

Preferred Qualifications

· Advanced degree (MS, PhD)
· Strong sense of ownership, customer obsession, and drive
· Experience developing machine learning software and an understanding of design for scalability, performance and reliability
· Sharp analytical abilities and proven design skills
· Experience in data modeling and analysis, especially with distinctive data sources
· Demonstrated leadership abilities in an engineering environment in driving operational excellence and best practices
· Excellence in technical communication with peers and non-technical cohorts
· Demonstrated ability to achieve stretch goals in a highly innovative and fast paced environment

Amazon is an Equal Opportunity Employer Minority / Women / Disability / Veteran / Gender Identity / Sexual Orientation / Age.

Tags: Amazon, Amazon Alexa Echo, IoT, Internet of Things, Java, Java, Java, C++, C++, C, cloud, cloud, machine learning, machine learning, speech recognition, speech recognition, distributed systems, big data, big data, computer vision, CV, NLU, natural language understanding, automatic speech recognition, ASR, AWS, Amazon Web Services, large scale distributed file systems, Boston jobs at Amazon, Boston Massachusetts, Cambridge, Massachusetts, 02142, senior software development engineer, senior software engineer, principal software engineer, MTS",3.9,"Amazon
3.9","Cambridge, MA","Seattle, WA",10000+ employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),"Google, Microsoft, Walmart"
Machine Learning Engineer,"$53K-$97K
(Glassdoor est.)","Tiger Analytics is an advanced analytics consulting firm. We are the trusted analytics partner for several Fortune 100 companies, enabling them to generate business value from data. Our consultants bring deep expertise in Data Science, Machine Learning and AI. Our business value and leadership has been recognized by various market research firms, including Forrester and Gartner.We are looking for a Machine Learning Engineers for our team. As part of this job, you will be responsible for:* Providing solutions for the deployment, execution, validation, monitoring, and improvement of data science solutions.* Creating high performance and scalable Machine Learning systems* Building reusable production data pipelines for machine learning models* Writing production quality code and libraries that can be packaged as containers, installed and deployed* Demonstrate up-to-date knowledge in software engineering practices and provides solutions for the development, implementation and scaling, execution, validation, monitoring, and improvement of data science solutions* Collaborate with Data Engineers and Data Scientist to build data and model pipelines and help in running machine learning tests and experiments* Manage the infrastructure and data pipelines needed to bring ML solution to production* Demonstrate end-to-end understanding of applications (including, but not limited to, the machine learning algorithms) being created and maintain scalable machine learning solutions in production* Abstracts complexity of production for machine learning through the use of containers* Troubleshoots production machine learning model issues, including recommendations for retrain, re-validate, and improvements* 3-5 years of experience with Big Data Projects using multiple types of structured and unstructured data* Ability to work with a global team, playing a key role in communicating problem context to the remote teams* Excellent communication and team work skills* Bachelor's degree or higher in computer science or relatedAdditional Skills Required:* Technologies used would include Python (multiple versions), Spark, Hadoop, Docker, with an emphasis on good coding practices in a continuous integration context, model evaluation, and experimental design* Test driven development (prefer py.test / nose), experience with Cloud environments* Proficiency in statistical tools, relational databases & expertise in programming languages like Python/SQL is desiredSignificant career development opportunities exist as the company grows. The position offers a unique opportunity to be part of a small, challenging, and entrepreneurial environment, with a high degree of individual responsibility.",4.6,"Tiger Analytics
4.6","Dallas, TX","Santa Clara, CA",201 to 500 employees,2011,Company - Private,Consulting,Business Services,$10 to $25 million (USD),"Mu Sigma, LatentView Analytics, Fractal"
Data Engineer,-1,"Design, build and maintain high-performance, fault-tolerant, and scalable data pipelines for business reporting using Microsoft Azure Cloud Services and Microsoft DevOps using Agile software. Build a system that builds and evaluates machine learning models at scale. Work with technologies such as SQL, Azure and/or Kubernetes to build a data platform for projects. Work with data scientists to design and implement advanced statistical models and machine learning pipelines. Build automated tools to help answer questions about impact and design and manage queries from stakeholders. Translate end user requirements into Power BI reports and dashboards and analyze impact of product offerings using Power BI. Collect data from sources such as API, internal data source, and third party data source. Investigate data interactions and dependencies across complex data pipelines and transformation to validate assumptions and find sources of problems.Your profileRequires: Bachelor's degree in Computer Science or Electrical or Electronic Engineering and 5 years' experience as above or as an EDI Administrator or Programmer Analyst using similar skills as above.Not available to persons needing sponsorship for employment.About usMunich Re America Services, Inc. is a services provider to affiliated group companies primarily related to general services, procurement and IT services.",3.7,"Munich Re
3.7","New York, NY","Munich, Germany",5001 to 10000 employees,1880,Company - Public,Insurance Carriers,Insurance,$10+ billion (USD),-1
Machine Learning Engineer,-1,"Description Robert Half is currently sourcing for an urgent Sr. Machine Learning Engineer need for our client in Richmond, VA. The hiring manager is currently conducting interviews now please apply quickly if you are interested. Please apply directly on our website or contact me via email at travis.robertsroberthalf.com Job Title Sr. Machine Learning Engineer Duration 12+ Month Contract Location Remote or after working Remotely transitioning to onsite in Richmond, VA 23219 Keys to the position 5+ years of software development experience using Python 2 years' experience developing REST API's and deploying microservices in Azure Essential Responsibilities bullWork collaboratively and creatively with other developers to production and operationalize models using the latest Microsoft Azure technologies and leading industry practices bullDevelop scalable model-as-a-service patterns and enterprise capabilities bullBuild scalable onlineoffline feature stores and streaming capabilities bullPartner with Data Scientists, Product Managers, and Data Engineers to deliver creative, cutting-edge, high-quality engineering solutions, enhancing the iconic Client's experience for their customers Requirements Qualifications bull5+ years of software development experience using Python and C including a strong understanding of software engineering principles bull2 years' experience developing REST API's and deploying microservices in Azure bull2 years' experience with Databricks bull1-year experience deploying and managing containerized applications, preferably using Azure Kubernetes Services bull1-year experience developing streaming capabilities bull1-year experience with Azure Machine Learning Services and MLflow bullExposure to machine-learning libraries and tools, such as PyTorch, Tensorflow, or scikit-learn. bull2 years' experience working on Agile teams implementing DevOpsDataOpsMLOps practices bullExcellent communication skills, adapting to various audience types bullPassionate about innovation and loves solving complex problems in a highly- collaborative, fast-paced team environment Robert Half Technology matches IT professionals with some of the best companies on a temporary, project or full-time basis. From roles in software and applications to IT infrastructure and operations, we provide you unparalleled access to exciting career opportunities. Our personalized approach, innovative matching technology and global network with local market expertise help you find the technology jobs that match your skills and priorities - fast. By working with us, you have access to challenging opportunities, competitive compensation and benefits, and training to enhance your skill sets. From philanthropy to environmental stewardship to employee programs, Robert Half is proud to have an active role in the communities in which we live and work. Our company has appeared on FORTUNE's ""Most Admired Companies"" list every year since 1998. Download our mobile app to take your job search on the go! Contact your local Robert Half Technology office at 888.490.4429 or visit www.roberthalf.comjobstechnology to apply for this job now or find out more about other job opportunities. All applicants applying for U.S. job openings must be authorized to work in the United States. All applicants applying for Canadian job openings must be authorized to work in Canada. 2020 Robert Half Technology. An Equal Opportunity Employer MFDisabilityVeterans. By clicking 'Apply Now' you are agreeing to Robert Half Terms of Use httpswww.roberthalf.comterms-of-use .",3.5,"Robert Half
3.5","Richmond, VA","Menlo Park, CA",10000+ employees,1948,Company - Public,Staffing & Outsourcing,Business Services,$2 to $5 billion (USD),"Adecco, Manpower"
"Software Engineer, Perception (Machine Learning/Computer Vision)","$114K-$204K
(Glassdoor est.)","Who We Are


Nuro is a robotics start-up whose mission is to accelerate the benefits of robotics for everyday life. We have an elite team of entrepreneurs and engineers, designers, and scientists. We believe AI and robotics are at the cusp of transforming daily life and we are dedicated to building meaningful products with this technology. Join us and play a critical role in our mission.

About the Role


Our team is growing and we are looking for machine learning R&D experts to join us. We apply machine learning to solve challenging perception problems, e.g. object detection, semantic segmentation, instance segmentation, dense depth, optical flow, tracking. In this role, you will work on developing novel machine learning models, robust and scalable data pipelines, and deploy the models on our self driving vehicles.

About the Work
You will develop novel machine learning methods and algorithms that solve complex problems, including but not limited to, object detection, semantic segmentation, instance segmentation, depth estimation, optical flow, etc.
Develop scalable and robust data pipelines that are able to process petabytes of data for model training, and deploy models in production
Work fast and smart, and collaborate well with other awesome team members to deliver high-quality perception solutions that power the next generation of mobile robots
About You
Recent experience in state-of-the-art deep learning models for computer vision tasks on camera, lidar, radar
Strong ML fundamentals and has demonstrated experience building and expanding model architectures
Strong SWE fundamentals and has demonstrated SWE experience in both high and low-level languages (python and C++)
Strong research capabilities, track record of publishing papers at top conferences on relevant topics
Bonus: Experience in deploying models in real time environments. Optimizing architectures to explore the accuracy vs. compute tradeoff
Bonus: Experience working with productizing ML models and the infrastructure supporting model development (data, large scale training, eval, etc)
Nuro is an equal opportunity employer and expressly prohibits any form of workplace harassment based on race, color, religion, gender, sexual orientation, gender identity or expression, national origin, age, genetic information, disability, or veteran status.",4.4,"Nuro
4.4","Mountain View, CA","Mountain View, CA",201 to 500 employees,2016,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Machine Learning Engineer,"$70K-$126K
(Glassdoor est.)","About Frontier CommunicationsFrontier® Communications provides communications services to urban, suburban, and rural communities in 25 states. Frontier offers a variety of services to residential customers over its FiOS® and Vantage fiber-optic and copper networks, including video, high-speed internet, advanced voice, and Frontier Secure® digital protection solutions. Frontier Business offers communications solutions to small, medium, and enterprise businesses.Machine Learning Engineer - Job DescriptionAs a machine learning engineer, you will be responsible developing machine learning models to support development of product and services to improve the state of the Frontier communications network and elevate the customer experience. You will be working on developing applications to train machine learning models using big datasets. You will have the opportunity to work with a small high impact team and bring AI into an industry that has not fully captured the potential of AI.What will you do?* Design and train machine learning models. You will be working on building AI models using communications datasets. You will apply fundamental machine learning concepts to quickly iterate and debug model related issues and develop new techniques.* Collect, process and analysis data. A big part of our machine learning projects is to understand and analyzing data. You will be working very closely with senior data scientists to execute well defined experiments and feature engineering tasks.* Debug and analyze models. You must be able to investigate and debug models and identify issues quickly. You will be responsible for proposing/implementing solutions for identified issues.* Be part of building a world-class AI team in the communications industry. You will have the opportunity to work with cutting edge technologies in AI and apply skills to a unique dataset that has not been used for predictive modeling before. This will give you the freedom to explore the latest ideas from academia and publicly available industry research in AI and apply them to communications data.* You must be able to read and understand the latest machine learning research publications. You will have the opportunity to discuss these articles with internal data science teams, generate new ideas, and experiment with then using large datasets.Qualifications* Minimum:* Master's Degree in a quantitative field or relevant experience.* 5+ years of industry experience in predictive modeling and data analysis* 5+ years of industry experience in enterprise level software development* Experience working with Big data* Strong background in python language (and R, C/C++)* Deep understanding of a modern machine learning framework (TensorFlow, PyTorch, scikit learn)* Experience in Linux* Preferred:* PhD in Computer Science (Data Science, Machine Learning, AI)* Exposure to industry or academic research (peer review publications)* Experience in cloud computing technologies (GCP, AWS)* Experience in deploying ML models to production environments* Working knowledge of computer networking* Experience in analyzing ISP IoT data",2.4,"Frontier Communications
2.4","Allen, TX","Norwalk, CT",10000+ employees,1935,Company - Public,"Cable, Internet & Telephone Providers",Telecommunications,$5 to $10 billion (USD),"Comcast, Spectrum Comm, Windstream"
Machine Learning- Engineer,-1,"Description

The Data Engineer - Machine Learning is a key member of our Data Engineering team that contributes to the success of our organization by enabling our Data Scientists to create and deploy models efficiently and effectively. As a Data Engineer - Machine Learning, you will design, build, and test machine learning piplines and platforms to streamline the development of models as well as tools for model versioning, testing and validation. The Data Engineer -ML would be expected to be knowledgeable in Kubernetes and containerization technologies as well as have hands on experience within Google Cloud Platform.

The Role You'll Play:
Machine Learning Development
Build new machine learning platform/pipelines
Support the ML pipelines to facilitate model training, evaluation, deployment and monitoring
Understand the business requirement and suggest/ evaluate the right features and technique best suited to train and test the model.
Support and Maintenance
Collaborate with stakeholders to assist with data science related issues and support their data infrastructure needs.
Maintain any Data Engineering cloud infrastructure via Infrastructure as Code

Process Improvement & Optimization
Refine and improve our continuous integration/continuous delivery (CI/CD) pipelines to streamline deployment and product release cycles.
Identify, design and implement internal process improvements (automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc).
Create data tools for analytics and data scientist team members that assist them in building and optimizing our data systems.
Qualifications
Bachelor's Degree in Computer Science, Software Engineering, Information Systems or Information Technology or related field required, or equivalent experience
Three to five years of experience in Cloud technologies, Kubernetes, Machine Learning Platforms
Google Cloud Platform - Professional Cloud Architect (not required, not preferred)
Google Cloud Platform - Professional Data Engineer (not required, but preferred)
Experience with Kubernetes and Docker
Experience building data pipelines utilizing Google Cloud Platform.
Experience building large-scale machine learning pipelines using Kubeflow or other machine learning platforms
Linux/Unix environments
Google Cloud Platform networking and Cloud Identity and Access Management
Experience with continuous integration/continuous delivery (CI/CD) pipelines
Familiarity with ML Frameworks such as Tensorflow or Pytorch is a plus
NoSQL database technologies (MongoDB, Big Table, Cassandra, etc)
Infrastructure as Code and deployment management tools (Terraform, Ansible, GCP Deployment Manager, etc..)
Experience with message queuing, stream processing, and highly scalable 'big data' data stores (Kafka, Pub/Sub)
Experience with object-oriented and scripting languages (Python, Java, etc..)
Agile Development and Agile Deployment tools and versioning using Git or similar tools",3.4,"DICK'S Sporting Goods
3.4","Coraopolis, PA","Coraopolis, PA",10000+ employees,1948,Company - Public,Sporting Goods Stores,Retail,$5 to $10 billion (USD),"REI, Academy Sports + Outdoors, Cabela's"
Machine Learning Engineer – Maps Search,"$134K-$210K
(Glassdoor est.)","Posted: Jun 15, 2020
Role Number:
200175198
Apple Maps are being used by millions of users every single day and powers thousands of applications. As a fundamental tool for human activity, Maps technology is evolving and new techniques are emerging. As a part of Apple Maps search team, you will play a big part in the next revolution in maps to enable users to find things in maps by working in a high-performing and collaborative environment. You will have plenty of opportunities to create groundbreaking technologies using machine learning at scale to improve the search quality for Apple Maps. This is an ideal role for someone who is passionate about search, cares about innovation, software craftsmanship, building high performance software products, always thinking about optimizing software for best utilization of resources and provide a high quality of customer experience by providing the best search results.
Key Qualifications
Experience in applying machine learning in information retrieval domain such as search engines, natural language processing, or similar areas.
Strong programming experience in one or more of the following: Java, C++, Python or equivalent
Excellent interpersonal and communication skills
Outstanding problem solving and analytical skills
Description
The goal of Maps Search team is to take Apple’s Maps to the next level of intelligence and accuracy using advanced machine learning and artificial intelligence techniques. Engineers and scientists on this team work on a wide spectrum of approaches in improving search experience on Apple Maps. You will be working closely with data, and analytics teams to develop applied machine learning algorithms and models that help improve search relevance and experience. You would also work on developing scalable tools and platform foundations that enable other engineers and scientists to develop, evaluate and release algorithms, models and features quickly. You will participate in design and code reviews and work with engineers and QA to deliver high quality search experience to our customers.

This position involves a wide variety of skills and innovation, and is a unique opportunity that sits at the cutting-edge of machine learning and information retrieval techniques. Ultimately, your work would have a huge impact on millions of users across the globe.
Education & Experience
BS/MS in Computer Science or equivalent. PhD preferred.

- Experience/knowledge of large scale machine learning applied to very large and diverse datasets
(preferred)
- Experience/knowledge of search, natural language processing, and related fields (preferred)
- Experience with Lucene/Solr/Elastic Search or any other Search Engine Experience with
Hadoop/Map-Reduce/Spark (preferred)",4.1,"Apple
4.1","Santa Clara, CA","Cupertino, CA",10000+ employees,1976,Company - Public,Computer Hardware & Software,Information Technology,$10+ billion (USD),"Google, Microsoft, Samsung Electronics"
Machine Learning Engineer,-1,"Job Description
Machine Learning Engineer – Simply Biotech

Are you looking for a new career opportunity with an exciting biotech company?! Then we have got the right team for you! In this role, you are responsible for the duties listed below.

Immediate opening for a Machine Learning Engineer in Palo Alto, CA who possess:
PhD, MS, or BS in computer science, engineering, statistics, or similar
2+ years of technical industry experience (biotech and software engineering preferred)
Must have experience with development and deployment in a production environment
Significant experience with Python
Significant experience with a deep learning framework (high preference for PyTorch & TensorFlow)
Email your resumes to mdaniels@simplybiotech.com or call 858.239.2849

FULL DESCRIPTION: As a (Senior) Machine Learning Engineer, you will lead the development and deployment of advanced machine learning models that will give greater resolution into the health and molecular state of patients. You will work closely with an inter-disciplinary team of laboratory scientists, data scientists, and engineers to ensure the company meets its key milestones and objectives as well as identify additional opportunities where machine learning can bring real business value. You will also have the advantageous opportunity to collaborate on the data generation process itself.

The selected candidate will further possess:
Experience with developing and deploying in a cloud platform e.g. AWS, GCP, Azure
Fundamental knowledge of probability and statistics in their application to developing and deploying machine learning models
Ability to communicate and collaborate with an inter-disciplinary team
Ability to translate business-level and scientific-level objectives to engineering objectives
Experience with clinical or biological data e.g. genomics, proteomics, imaging, EMR
Experience in NLP or image recognition applications
Experience with knowledge graphs
For immediate and confidential consideration, please email your resume to mdaniels@simplybiotech.com or call 858.239.2849

More information can be found at www.SimplyBiotech.com
Company Description
We are Kinetic Personnel Group! As our name implies, we are dedicated to keeping your career in motion by connecting exceptional candidates with great companies. We work with companies across a variety of industries both, locally and nationwide to keep their businesses moving forward. Our customers are established Organizations; large and small; in the private, public, and municipalities sectors. We partner with them to staff for a broad range of positions and across various functionalities, such as:

Accounting/Finance

Information Technology

Sales/ Customer Service

Engineering Disciplines

Manufacturing

Administration

Logistics

Benefits offered by Kinetic Personnel Group: Medical, Dental, Vision, Sick Pay, Longevity Pay, and Holiday Pay",4.8,"Simply Biotech
4.8","Palo Alto, CA","San Diego, CA",51 to 200 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Operations - Machine Learning Engineer,-1,"At Eisai, satisfying unmet medical needs and increasing the benefits healthcare provides to patients, their families, and caregivers is Eisai s human health care (hhc) mission. We re a growing pharmaceutical company that is breaking through in neurology and oncology, with a strong emphasis on research and development. Our history includes the development of many innovative medicines, notably the discovery of the world's most widely-used treatment for Alzheimer s disease. As we continue to expand, we are seeking highly-motivated individuals who want to work in a fast-paced environment and make a difference. If this is your profile, we want to hear from you. Job Summary The Data Operations Group within the Neurology Biometrics division at Eisai, Inc. is seeking a Machine Learning Engineer to drive drug development through predictive modeling of disease and drug response. The role will focus on enabling analysis of high-dimensional data. The Engineer will collaborate closely with Data Scientists in the Statistical Methodology Machine Learning group, as well Software Engineers in the IT group, to support projects in various stages of development. In particular, the Engineer will help build the image processing pipeline at Eisai. Essential Functions Technical Skills Experience with two or more of the following languages MATLAB, Python, R, SAS Strong software engineering skills Machine Learning (including deep learning methods, e.g., Neural Networks using PyTorchTensorFlow) Actual experience working on cloud servers and HPC clusters- setting up analysis pipelines (genomics, image, etc.) Neuroimaging or other image processing experience desirable Scripting skills on Linux Data storytelling Visual Analytics and apps deployed on the Web (Tableau, R-Shiny, other tools) Requirements Master's Degree or higher required Minimum of 4 years relevant experience (level determined by experience) Proven track record of developing, deploying, and supporting data science pipelines Experience developing front-end interface (Webservers) to statistical models Experience coordinating with ITSoftware engineering personnel to maintain secure and compliant tools and applications Experience with developing and deploying cloud-based workflow or on distributed computing environment (HPC clusters) Excellent communication and presentation skills required Experience in managing different workstreams and coordinating tasks with internal teams and outside consultants Eisai is an equal opportunity employer and as such, is committed in policy and in practice to recruit, hire, train, and promote in all job qualifications without regard to race, color, religion, gender, age, national origin, citizenship status, marital status, sexual orientation, gender identity, disability or veteran status. Similarly, considering the need for reasonable accommodations, Eisai prohibits discrimination against persons because of disability, including disabled veterans. Eisai Inc. participates in E-Verify. E-Verify is an Internet based system operated by the Department of Homeland Security in partnership with the Social Security Administration that allows participating employers to electronically verify the employment eligibility of all new hires in the United States. Please click on the following link for more information Right To Work httpsus.eisai.com-mediaFilesEisaiRightToWorkPoster.pdf?laen E-Verify Participation httpsus.eisai.com-mediaFilesEisaiEVerifyParticipationPoster.pdf?laen",3.0,"Eisai
3.0","Woodcliff Lake, NJ","Hatfield, United Kingdom",201 to 500 employees,-1,Company - Private,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,Unknown / Non-Applicable,-1
Machine Learning Engineer – Platform R&D,"$61K-$109K
(Glassdoor est.)","Job Description:

Machine Learning Engineer

Collaborate with Innovative 3Mers Around the World

Choosing where to start and grow your career has a major impact on your professional and personal life, so it’s equally important you know that the company that you choose to work at, and its leaders, will support and guide you. With a diversity of people, global locations, technologies and products, 3M is a place where you can collaborate with 93,000 other curious, creative 3Mers.

This position provides an opportunity to transition from other private, public, government or military environments to a 3M career.

“3M is a place where diversity is welcomed and curiosity nurtured. We’re investing in digital talent who have the opportunity to shape the foundation and next generation of 3M. Come collaborate, invent and solve the ‘what's next’ set of problems that are meaningful to our customers and communities.” – Hung Brown Ton, chief architect of the Corporate Research Systems Labs at 3M

The Impact You’ll Make in this Role

As a Machine Learning Software Engineer you will have the opportunity to tap into your curiosity and collaborate with some of the most innovative and diverse people around the world. Here, you will make an impact by:
Being part of a core team researching and applying latest cloud based ML tools and technologies from end-to-end (ML training, ML model development, deployment and ML model lifecycle management).
Utilizing machine learning models as APIs or software libraries to be integrated into a full-stack AI cloud application
Establishing scalable, efficient, automated processes for large scale data analyses, model development, validation and implementation.
Developing and establishing model management technology and processes for helping enable MLOps such as: measure on-going accuracy, tooling for data / model drift, etc.
Advising, consulting, mentoring and supporting 3M businesses, data scientists and data consumers / users on model standards, scalability and deployment.
Your Skills and Expertise

To set you up for success in this role from day one, 3M is looking for candidates who must have the following qualifications:
Bachelor’s degree or higher (completed and verified prior to start) from an accredited university
One (1) year professional experience in data engineering, software development/engineering, or data science in a private, public, government or military environment
One (1) year of hands on development with frameworks such as Python, C++, C#, Java, Javascript, Scala in a private, public, government or military environment
Additional qualifications that could help you succeed even further in this role include:
Possess or in the final year of pursuing a M.S. or Ph.D. degree or post-doctoral fellowship in Computer Science, Machine Learning, Electrical Engineering, Data Science, Cognitive Science, Computational Linguistics, Software Engineering, Applied Physics, Applied Mathematics, or related discipline from an accredited university
Proficiency in machine learning algorithms such as multi-class classifications, decision trees, support vector machines, deep learning and familiarity with NLP/ML tools and packages like pyTorch, TensorFlow, Weka, scikit-learn, XGBoost, Onnx, TensorFlow serving, et al
Software development experience developing API’s, DevOps Pipelines and/or front-end applications and experience with core software and experience with data engineering tools: Spark/PySpark, SparkML, Auto-ML, Containers, GitHub
Experience with training, integrating and working with cloud AI and big data systems like: Amazon Kinesis, Azure Stream Analytics, Spark, Storm, Kafka, S3 / Azure Data Lake (Data Lake), Azure ML Studio, Sagemaker, etc.
Individuals should display leadership, excellent communication skills (oral, written and presentation) networking skills, self-motivated and self-directed
Travel: May include up to 10% Domestic/international travel

Relocation Assistance: May be authorized

Must be legally authorized to work in country of employment without sponsorship for employment visa status (e.g., H1B status).

Supporting Your Well-being

3M offers many programs to help you live your best life – both physically and financially. To ensure competitive pay and benefits, 3M regularly benchmarks with other companies that are comparable in size and scope.

Resources for You

For more details on what happens before, during and after the interview process, check out the Insights for Candidates page at 3M.com/careers.

Learn more about 3M’s creative solutions to the world’s problems at www.3M.com or on Twitter @3M.Responsibilities of this position include that corporate policies, procedures and security standards are complied with while performing assigned duties.3M is an equal opportunity employer. 3M will not discriminate against any applicant for employment on the basis of race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, or veteran status.

Please note: your application may not be considered if you do not provide your education and work history, either by: 1) uploading a resume, or 2) entering the information into the application fields directly.

3M Global Terms of Use and Privacy Statement

Carefully read these Terms of Use before using this website. Your access to and use of this website and application for a job at 3M are conditioned on your acceptance and compliance with these terms.

Please access the linked document by clicking here, select the country where you are applying for employment, and review. Before submitting your application you will be asked to confirm your agreement with the terms.",3.9,"3M
3.9","Maplewood, MN","Saint Paul, MN",10000+ employees,1902,Company - Public,Miscellaneous Manufacturing,Manufacturing,$10+ billion (USD),-1
Machine Learning QA Engineer,"$109K-$127K
(Glassdoor est.)","Posted: Oct 31, 2019
Role Number:
200119677
Imagine what you could do here. At Apple, new ideas have a way of becoming extraordinary products, services, and customer experiences very quickly. Bring your passion and dedication to the team and there's no telling what you could accomplish.

Apple services are an essential part of the Apple experience. Our users rely on services such as ApplePay, iTunes, the App Store and much much more to communicate, to access powerful applications, and to build, store and protect their memories seamlessly across all their devices. We strive to improve user experience by avoiding unnecessary friction. You will perform continuous analysis and designs and provide internal tools to help ensure that our users remain in control of their accounts, even when their credentials leave their control. The group comprises teams of Software Developers, Data Engineers, Data Analysts and Data Scientists that focus on crafting and implementing fraud prevention mechanisms, systems and tools to guarantee that new devices, software and features in our services, provide the safest experience to our customers.
Key Qualifications
- Design and implement software for quality assurance of ML datasets and models
- Collaborate with Data Scientists to understand data and models.
- Applying statistical concepts to validate and QA data and models.
- Familiarity with database modeling and data warehousing principles and SQL/noSQL
- Possess an intuitive understanding of machine learning algorithms, supervised and unsupervised modeling techniques
- Detail oriented, analytical, and creative thinker with passion for quality.
- Exceptional analytical and problem solving skills
- Experience executing and contributing to automation infrastructure.
- Prototyping and tools development is a plus
- Programming skills in Scala, Python, Java or similar language is a plus
- Experience in crafting and developing testing infrastructure for Distributed Systems, Big Data Platforms is a plus
- Familiarity with Cassandra, Kafka, Spark, Hive and other big data tools is a plus
- Hands-on testing on devices is a plus
Description
As part of this team, you will establish, implement and evolve the formal QA processes to ensure that the group is using industry accepted standard methodologies. Design and develop the testing infrastructure i.e. testing tools, test frameworks , test reporting mechanisms to test the software, services, Alternative data platforms of the team as well as the existing and new machine learning models build on the platform. Integrate the testing infrastructure with the continuous integration and continuous deployment systems to ensure all of the tools, services developed are properly tested and meet the quality goals. Write different types of tests i.e. Unit, Integration , Acceptance for existing and new projects so as to ensure bug free software is delivered which is as per the requirements. Stay knowledgeable of new testing tools and strategies and evaluate the technologies to incorporate into the projects.
Education & Experience",4.1,"Apple
4.1","Santa Clara, CA","Cupertino, CA",10000+ employees,1976,Company - Public,Computer Hardware & Software,Information Technology,$10+ billion (USD),"Google, Microsoft, Samsung Electronics"
"Engineering Manager, Machine Learning - Ads Ranking","$117K-$190K
(Glassdoor est.)","By applying for this role, you could choose to work in the following locations:
Seattle
US - Remote US
New York City
San Francisco

Who We Are:

We are a team of ML software engineers that are responsible for placing each and every ad that Twitter serves. The mission of our team is to make ads as relevant at the moment as organic content through the state-of-the-art ranking of ads. Our team is responsible for building the machine learning models that predict the engagement for an ad given the signals from the advertiser and the user and owns the end to end service for serving the predictions as well. The ads ranking is the most critical component in delivering personalized experience for the user and is driving top line business metrics for the company. Our team is responsible for the majority of the revenue that Twitter business generates and we routinely deliver revenue improvements that contribute to the success for the company. We work in a close sync with our executive staff (including our GM, CFO, and VP of Sales).

Who You Are:

You are an engineering manager with a strong background in engineering. You are principled and are looking to play a critical role at a very public company operating a multi-billion dollar business. You have a track record of establishing long-term visions for teams and then making them successful against those visions. You lead, manage and mentor contributors on your team. You’re skilled at communicating the results of technical work to executives, as well as proactively changing priorities and tactics for your team in response to strategic changes at the executive level.

What You’ll Do:

You’ll join the ads ranking team and lead a world-class team of Machine Learning engineers. We’re looking for a hands-on, technical manager with a real passion for working on user-facing products. The ideal candidate would be equally comfortable guiding the development of models to rank ads and predict engagement, white boarding new product ideas with designers and product managers, or brainstorming ways to efficiently index and serve ads with systems engineers.
Establish the vision and mission of where the ads marketplace team will be one year from now.
Be an engineering and machine learning talent magnet to make the team successful in your established mission
Mentor the professional development of each direct report through personal and performance management.
Give engineers the tools, confidence, and motivation to make decisions independently that lead to the recognition of your engineers and the team.
Facilitate the use of data and evangelize data-driven practices across that ads organization.
Be responsible for the team’s technical strategy and roadmap – creating success metrics in close collaboration with other Engineering and Product Managers.
Qualification:
Previously managed a team of 5+ contributors and has 2+ years of management experience. Experience with building products, taking them to the market and iterating and improving them over time.
Previous experience as a machine learning engineer individual contributor or manager of data scientists/machine learning engineers.
Previous experience as a software engineer individual contributor or manager of software engineers.
Familiarity with basic fundamentals of probability theory and statistics.
BS computer science, machine learning, statistics, mathematics or natural science.
Bonus Points:
Past experience in ad tech
PhD in computer science, mathematics, machine learning, or related quantitative field.
Equal Employment Opportunity

We are committed to an inclusive and diverse Twitter. Twitter is an equal opportunity employer. We do not discriminate based on race, ethnicity, color, ancestry, national origin, religion, sex, sexual orientation, gender identity, age, disability, veteran, genetic information, marital status or any other legally protected status.

San Francisco applicants: Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.",4.0,"Twitter
4.0","Seattle, WA","San Francisco, CA",1001 to 5000 employees,2006,Company - Public,Internet,Information Technology,$2 to $5 billion (USD),"Facebook, Google, Pinterest"
"Data Engineer, Machine Learning",-1,"BICP is partnered with an iconic retail client to hire a Machine Learning Data Engineer to join the global Data, Analytics & AI team. Our clients singular focus is to revolutionize and redefine the apparel business. The global Data, Analytics & AI is best framed up as having the vibe of a startup but with considerable technology assets at your fingertips, where you will have a chance to work with the latest and greatest technologies to deliver cutting edge solutions that will significantly impact how we do business. As a ML Data Engineer, you will build a solid data foundation that powers the entire spectrum from Business Intelligence to Artificial Intelligence. You’ll be critical to helping us in our transition from batch to real-time, one-to-one to many-to-many connections, centrally-managed infrastructure to self-service tools that allow easy experimentation, and from manual to automated processes.

This role will work closely with the Data Science and AI team and will focus on enablement and acceleration of new and existing workflows. We need someone who will bring thoughtful perspective, empathy, creativity, and a positive attitude to solve problems at scale. This role is ideal for someone looking to extend software engineering skills into the field of Machine Learning and Artificial Intelligence.

Job Responsibilities
Establish scalable, efficient, automated processes for data analyses, model development, validation and implementation
Work closely with data scientists and analysts to create and deploy new features
Write efficient and well-organized software to ship products in an iterative, continual-release environment
Monitor and plan out core infrastructure enhancements
Contribute to and promote good software engineering practices across the team
Mentor and educate team members to adopt best practices in writing and maintaining production code
Communicate clearly and effectively to technical and non-technical audiences
Actively contribute to and re-use community best practices
Embody the values and passions that characterize company’s values with empathy to engage with colleagues from a wide range of backgrounds
Required Skills
University or advanced degree in engineering, computer science, mathematics, or a related field
Strong experience working with a variety of relational SQL and NoSQL databases
Strong experience working with big data tools: Hadoop, Spark, Kafka, etc.
Experience with at least one cloud provider solution (AWS, GCP, Azure)
Strong experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.
Ability to work in Linux environment
Experience working with APIs
Strong knowledge of data pipeline and workflow management tools
Expertise in standard software engineering methodology, e.g. unit testing, code reviews, design documentation
Experience creating ETL processes that prepare data for consumption appropriately
Experience in setting up, maintaining and optimizing databases for production usage in reporting, analysis and ML applications
Working in a collaborative environment and interacting effectively with technical and non-technical team members equally well
Relevant working experience with Docker and Kubernetes preferred
Ability to work with ML frameworks preferred
Additional Key Metrics
Preference will be given to candidates either based in, or willing to relocate to, Dallas/Ft. Worth or San Francisco area.
US Citizens, Green Card & H1B Visa holders are eligible for consideration and welcome to apply. Client has ability to transfer H1B’s and sponsor.
Start date is ASAP and compensation is negotiable contingent on experience and qualifications.
Job Type: Full-time

Pay: $150,000.00 - $160,000.00 per year

Benefits:
401(k)
Dental Insurance
Employee Discount
Health Insurance
Paid Time Off
Vision Insurance
Supplemental Pay:
Signing Bonus
Experience:
AWS, Azure or GCP: 1 year (Preferred)
Scala: 1 year (Preferred)
Kafka: 1 year (Preferred)
Java: 1 year (Preferred)
SQL: 3 years (Required)
Python: 1 year (Required)
Kubernetes: 1 year (Preferred)
Docker: 1 year (Preferred)
NoSQL: 1 year (Preferred)
Spark: 1 year (Preferred)
Education:
Bachelor's (Required)
Work authorization:
United States (Required)
Additional Compensation:
Bonuses
Store Discounts
Work Location:
Fully Remote
This Company Describes Its Culture as:
Innovative -- innovative and risk-taking
Stable -- traditional, stable, strong processes
People-oriented -- supportive and fairness-focused
Schedule:
Monday to Friday
Day shift",5.0,"BICP
5.0","Dallas, TX","Carlsbad, CA",1 to 50 employees,2009,Company - Private,IT Services,Information Technology,$10 to $25 million (USD),-1
Machine Learning Engineer,-1,"Machine Learning Engineer

Job Details
Level
Experienced
Job Location
Undisclosed
Position Type
Full Time
Education Level
Undisclosed
Salary Range
Undisclosed
Travel Percentage
Undisclosed
Job Shift
Undisclosed
Job Category
Engineering
Description
Interested in driving machine learning innovation?

This position is approved to be remote or report to any of the three E Source locations in Buffalo, NY, Boulder, CO or Baton Rouge, LA.

In this position you will be collaborating on developing cutting edge software products within a team of like-minded software engineers, data scientists, and disciplined utility experts. If you join the TROVE team, expect to work with what you love best the latest Python and R scientific programming packages, distributed computing frameworks, machine learning packages, relational and non-relational database management systems, cloud infrastructure, and all within a well established Continuous Delivery and Agile Development process.

The ideal candidate will have experience programming in Python and R, developing reusable Python and R packages, knowledgeable of software design patterns and scalable data structures, able to evaluate database design and author performance queries for data processing needs, able to breakdown complex software tasks into manageable user and technical stories, ensure quality test coverage, review peer code and provide recommendations, and keep up to speed on the latest scientific programming and machine learning open source trends such as MLOps.

You will be a full-time employee of the TROVE Software Engineering team. TROVE Software Engineering positions appeal to self-starters who welcome and excel in team-based, collaborative projects from conception to release, providing an excellent End User Experience throughout. The ability to simplify complex software requirements to understandable and well communicated designs and development tasks is highly desired.

The ideal candidate has a BS or MS in a Software Engineering, Computer Science, or related field of study. Work experience should consist of a proven track record of efficiently designing, developing, and releasing machine learning software product both independently and collaboratively over a 5+ year period. Exceptional educational or industry experience can offset any particular requirement. A broad background in the utility/power/energy sector is a plus!

Key Experience
B.S. or M.S. in a software related field of study
5+ years of software development in Python and R
Demonstrated experience developing and maintaining reusable Python and R packages
Proficiency with Scientific Programming Packages in Python (NumPy, Pandas, scikit-learn, PySpark) and R (dplyr, ggplot2, tidyr, rpart, caret, randomForest, gbm, glmnet, sparklyr, xgboost, among many others)
Experience with SQL and relational/non-relational DBMS
Working with GIT, AWS, Jenkins
Product-oriented mindset and experience
You have a creative mind, keen ability, and the initiative to think beyond


About TROVE Predictive Data Science:


TROVE is the data science software company obsessed with making data useful. We deliver high-quality, commercial-grade, and state-of-the-art predictive data science software solutions and services for the electric utility industry. Smart grid, distributed energy renewables like storage and solar, grid electrification through electric vehicles, and many other modern technology trends are up-heaving traditional business operations for utilities. TROVE's solutions help utilities make sense of the massive amounts of data they are collecting to maintain grid resiliency and operations efficiency in the grid of the future.

TROVE, and E Source Company is an Equal Employment Opportunity Employer and does not discriminate against applicants or employees on the basis of race, color, religion, creed, national origin, ancestry, disability that can be reasonably accommodated without undue hardship, sex, sexual orientation, gender identity, age, citizenship, marital or veteran status, or any other legally protected status.
Qualifications",3.3,"E Source
3.3","Baton Rouge, LA","Boulder, CO",51 to 200 employees,1987,Company - Private,Energy,"Oil, Gas, Energy & Utilities",$100 to $500 million (USD),-1
Software Data Engineer - Machine Learning - Data Cloud,-1,"Software Data Engineer - Machine Learning - Data Cloud-20000JMX No Visa Sponsorship is available for this position. Applicants are required to read, write, and speak the following languages: English
Preferred Qualifications


Introducing the Oracle Data Cloud

We are looking for a Senior Software and Data Engineer- Machine Learning for the Identity Graph Data Science team at Oracle Data Cloud (ODC), where we are leveraging the power of big data, cloud technologies, and data science to perform entity resolution across thousands of disparate data sources to create comprehensive and accurate anonymized profiles. Creating anonymized profiles at scale that link email, mobile, browser, tv, and postal address in a privacy safe and accurate manner is the foundation to any successful marketing campaign and the backbone of ODC’s offerings.

The Identity Graph is made possible because of massive data sets, high engineering standards, and advanced data science. As a Senior Data Scientist within the Identity Data Science (iDS) Research & Development team, you’ll be involved in developing a best-in-class ID Graph that fuels the ODC. In this role, you will be doing a blend of traditional data science work and big data/software engineering. You will be building scalable, cost-conscious, stable, repeatable, and accurate machine learning and graph-based ETL pipelines in the cloud. This work may span all aspects of the data science and software development lifecycle. To be successful in this role, you must be equally an expert in machine learning and big data/software engineering.

Role
Develop and maintain production-scale ML systems, including ETL and modeling runtimes.
Collaborate with other data scientists and engineers to design, research, and implement new data science products.
Maintain and improve existing analytics solutions.
Build tools to help team members and stakeholders interact with and understand our data science products.
Bring an open mind and understanding of established engineering best-practices with regards to software lifecycle, code reviews, GIT branching, and structuring complex ETL container-based build pipelines.
Prerequisites
A successful candidate must have experience with Spark programming.
BS / MS in Computer Science or equivalent industry experience that provided exposure to big data / ML and software engineering.
1+ years experience working on large-scale data processing systems in production including data ingestion, normalization, and storage.
Ability to apply core software engineering principles to practical business and machine learning problems.
Fluency in Scala.
Experience developing Spark applications at scale, including tuning and debugging.
Experience with build pipelines (Jenkins) and software build tools (python packaging, sbt, gradle).
Experience with monitoring production data workflows with all aspects of CI/CD.
Experience with container-based architecture (Docker or comparable).
Ability to automate the setup and management of data infrastructure in any cloud environment
Nice-To-Haves
Experience with ElasticSearch and Kibana.
Fluency in Python
Expert at writing complex SQL queries.
Understanding of machine learning model evaluation techniques; ability to assess, diagnose, and reason about a model's performance.
Understanding of the spatial interpretations of modeling features.
Understanding of common machine learning models and when to apply them.

Detailed Description and Job Requirements
Designs, develops and programs methods, processes, and systems to consolidate and analyze unstructured, diverse “big data” sources to generate actionable insights and solutions for client services and product enhancement.

Interacts with product and service teams to identify questions and issues for data analysis and experiments. Develops and codes software programs, algorithms and automated processes to cleanse, integrate and evaluate large datasets from multiple disparate sources. Identifies meaningful insights from large data and metadata sources; interprets and communicates insights and findings from analysis and experiments to product, service, and business managers.

Job duties are varied and complex utilizing independent judgment. May have project lead role. 5 years relevant work experience. BS/BA preferred.

Oracle is an Affirmative Action-Equal Employment Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability, protected veterans status, age, or any other characteristic protected by law.

Job
: Business Operations
Travel
: No
Location
: US-CO,Colorado-Broomfield
Other Locations
: United States
Job Type
: Regular Employee Hire
Organization
: Oracle",3.6,"Oracle
3.6",United States,"Redwood City, CA",10000+ employees,1977,Company - Public,Enterprise Software & Network Solutions,Information Technology,$10+ billion (USD),"SAP, Salesforce, Microsoft"
Data Engineer,"$116K-$213K
(Glassdoor est.)","As a data engineer, you will build a solid data foundation that powers the entire spectrum from Business Intelligence to Artificial Intelligence. Youll be critical to helping us in our transition from batch to real-time, one-to-one to many-to-many connections, centrally managed infrastructure to self-service tools that allow easy experimentation, and from manual to automated processes.

This role will work closely with the Data Science and AI team and will focus on the enablement and acceleration of new and existing workflows. We need someone who will bring a thoughtful perspective, empathy, creativity, and a positive attitude to solve problems at scale. This role is ideal for someone looking to extend software engineering skills into the field of Machine Learning and Artificial Intelligence.

Responsibilities:

• Establish scalable, efficient, automated processes for data analyses, model development, validation and implementation

• Work closely with data scientists and analysts to create and deploy new features

• Write efficient and well-organized software to ship products in an iterative, continual-release environment

• Monitor and plan out core infrastructure enhancements

• Contribute to and promote good software engineering practices across the team

• Mentor and educate team members to adopt best practices in writing and maintaining production code

• Communicate clearly and effectively to technical and non-technical audiences

• Actively contribute to and re-use community best practices

Requirements:

• University or advanced degree in engineering, computer science, mathematics, or a related field

• Strong experience working with a variety of relational SQL and NoSQL databases

• Strong experience working with big data tools: Hadoop, Spark, Kafka, etc.

• Experience with at least one cloud provider solution (AWS, GCP, Azure)

• Strong experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.

• Ability to work in Linux environment

• Experience working with APIs

• Strong knowledge of data pipeline and workflow management tools

• Expertise in standard software engineering methodology, e.g. unit testing, code reviews, design documentation

• Experience creating ETL processes that prepare data for consumption appropriately

• Experience in setting up, maintaining and optimizing databases for production usage in reporting, analysis and ML applications

• Working in a collaborative environment and interacting effectively with technical and non-technical team members equally well

• Relevant working experience with Docker and Kubernetes preferred

• Ability to work with ML frameworks preferred

Will be a plus:
Knowledge of CI/CI processes and components
Experience with OKTA and Optimizely

NB:

Placement and Staffing Agencies need not apply. We do not work with C2C at this time. At this moment, we are not able to process H1B transfers. Applicants with CPT and OPT visas are welcome to apply.

About us:
Grid Dynamics is the engineering services company known for transformative, mission-critical cloud solutions for retail, finance and technology sectors. We architected some of the busiest e-commerce services on the Internet and have never had an outage during the peak season. Founded in 2006 and headquartered in San Ramon, California with offices throughout the US and Eastern Europe, we focus on big data analytics, omnichannel services, DevOps, and cloud enablement.",3.9,"Grid Dynamics
3.9","Mountain View, CA","San Ramon, CA",1001 to 5000 employees,2006,Company - Private,Enterprise Software & Network Solutions,Information Technology,$50 to $100 million (USD),"Luxoft, EPAM, Capgemini Invent"
Machine Learning Engineer,"$106K-$184K
(Glassdoor est.)","The Opportunity


The machine learning effort is part of the Data Science team at Livongo and works closely with product managers, engineering and operations to identify, build, ship and maintain machine learning models and pipelines to personalize how our members manage chronic conditions.

This is an opportunity to use technical rigor to apply machine learning to real-world business problems, and engineer, deploy, measure and iterate ML in production, for every Livongo member.

Responsibilities:
Design, develop, deploy and maintain production grade data processing, machine learning and deep learning code, pipelines and systems.
Study and transform data science prototypes. Use Python, Tensorflow, PyTorch, and Keras to run exploratory analyses using both traditional and deep-learning techniques. This includes feature engineering, unsupervised learning, supervised learning, reinforcement learning.
Run machine learning tests and experiments; measure the performance of deployed models; work with data scientists to propose improvements and iterate to improve performance.
Manage machine learning model lifecycle: develop, deploy, monitor, maintain and update models in production.
Research and implement appropriate ML algorithms and tools.
Develop machine learning applications and services according to requirements.
Select appropriate datasets and data representation methods
Perform statistical analysis and fine-tuning using test results
Train and retrain systems when necessary
Extend existing ML libraries and frameworks
Keep abreast of developments in the field.
Collaborate closely with product management and engineering teams to drive requirements and define new product features and architecture.
Candidate Profile
Advanced degree in computer science, math, statistics or a related discipline
Proven experience as a Machine Learning Engineer or similar role
Deep knowledge of math, probability, statistics and algorithms
Ability to write robust code in Python, Spark, SQL, R or Java.
Familiarity with machine learning frameworks (like Keras or PyTorch) and libraries (like scikit-learn)
Knowledge of Hadoop or other distributed systems.
Experience with ML systems, recommendation engines, NLP, etc.
Extensive understanding of data structure, data modeling and software architecture
Experience in end-to-end machine learning model development, deployment and production.
Experience with agile sprint processes to deliver ML work.
Experience in ML CI/CD process; and familiar with Jenkins, dockers, Databricks, git code management, etc.
Experience designing and building useful, maintainable code for model training, evaluation and interpretation.
Familiarity with the entire ML algorithm life-cycle (modeling approach ideation, POC, data exploration, data processing, feature extraction, feature construction, model development, evaluation, iteration).
Willingness to learn new ML platforms and tools, as well as propose and help teams adopt new tools.
Experience in close collaboration with backend software engineer, data engineering team; as well as business owners to establish ML A/B testing platform.
Great active listening skills to infer product needs and underlying context.
Ability to collaborate effectively with peers, and respect for member privacy
Why Join Livongo?


The Transformative Name in Healthcare: The transformative industry forces in Community, Content and Commerce are now household names. As Amazon is to Commerce, Livongo is to Healthcare. With our Applied Health Signals engine, AI+AI, we've transformed how care is delivered.

Our Work Truly Matters: Livongo's proprietary, consumer-first technology is revolutionizing the experience of living with a chronic health condition. Our data-driven digital health engine enables our Members to seamlessly manage multiple health conditions on one empowering platform. We use smart, connected devices, personalized digital guidance, and 24x7x365 access to health professionals to make it easier for people to stay healthier.

Make an Impact: Do you want to accomplish something meaningful? To create results that matter? Livongo's innovative solution produces industry-leading member satisfaction, measurable clinical outcomes and proven healthcare costs savings. Here you can truly improve lives.

The Largest Digital Health IPO in History: We are at a milestone period in our history. On July 25, 2019 we took our company public, in order to elevate and expand the way the industry views us, thus ushering us into a whole new set of mission-critical conversations that will help us accomplish the work still to be done. As we reach new levels of achievement, we accelerate our ability to deliver life-changing services.

Focus on PEOPLE: Livongo has been voted one of the Best Places to Work in healthcare, by Fortune Magazine and Best Place to Work! Talented, passionate individuals make the difference, in this fast-moving, collaborative and inspiring environment.

Diversity and Inclusion: At Livongo we believe that personal and professional diversity is the key to innovation. We hire based solely on your strengths and qualifications, and the way in which those strengths can directly contribute to your success in your new position.

Growth and Innovation: We've already made healthcare history, yet we remain on the threshold of very big things. Leading the industry with our Applied Health Signals category, we have cracked the code to transforming healthcare. Come grow with us and support our mission to make a tangible difference in the lives of our Members.

See photos, watch videos and learn more about Livongo: follow us on Glassdoor.

As an Equal Opportunity Employer, we never have and never will discriminate against any job candidate or employee due to age, race, religion, color, ethnicity, national origin, gender, gender identity/expression, sexual orientation, membership in an employee organization, medical condition, family history, genetic information, veteran status, marital status, parental status or pregnancy (including breastfeeding we have a mother's room in both our offices). In our innovative and inclusive workplace, we prohibit discrimination and harassment of any kind.

#LI-Remote",4.6,"Livongo
4.6","Mountain View, CA","Mountain View, CA",501 to 1000 employees,2014,Company - Public,Health Care Services & Hospitals,Health Care,Unknown / Non-Applicable,-1
"Engineer / Scientist, Software Development",-1,"Areté Associates, an employee-owned company, is a growing research and development firm recognized for contributing to national security objectives by supplying innovative solutions to challenging technical problems faced by the United States. Our Chantilly, VA office has an immediate opening for a Engineer / Scientist, Software Development professional. This is an exempt non-supervisory full-time position. We have opportunities in Arlington, VA; Chantilly, VA; and Northridge, CA.SUMMARY:Designs, develops and analyzes software applications for the extraction of information from sensors, including implementation of signal and image processing with advanced computer architectures. Researches, designs, defines and develops computer algorithms for processing and dissemination. Develops requirements analysis, system architecture, and integrates new signal and image capture and processing technology systems.Primary responsibilities:* Design and implement advanced signal and image processing algorithms to extract actionable information from remote sensing data* Design, develop, analyze, and test software applications from prototype to operational using modern software development languages and practices* Assess algorithm performance on real-world data* Document results via written reports and/or well-commented code* Additional duties as assignedRequired Qualifications & Experience:* Bachelor's, Master's, or PhD in computer science, physical sciences, engineering, or mathematics* Proficiency in C/C++ and/or Python* Proven capability in software architecture and design with emphasis upon modular, maintainable, and extensible software designs and frameworks* Excellent written and verbal communication skills* Capacity to work in a team with minimal supervision and agility to work multiple potentially disparate projects simultaneously* Proven capability to develop creative solutions to complex technical problems* Appetite to attack and solve interesting problems of critical importance to national security* U.S. CitizenshipPreferred Qualifications & Experience:* GPU acceleration of image processing algorithms using CUDA* Cloud computing and/or developing cloud applications* Experience in any of the following areas: sensor applications including EO/IR and radar, data analysis, signal processing, machine learning, algorithm development* Ability to present technical results to customers and at technical review meetings* Proficiency in High Performance Computing techniques such as: multithreaded programming, inter-process communication, GPU programming, and coprocessor programming* Active security clearanceAreté Associates offers an excellent compensation and a full benefits package. U.S. citizenship, background screen and drug test are required to meet position eligibility. Please submit your resume on-line at: http://www.arete.comAreté Associates is an Equal Opportunity/Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex including sexual orientation and gender identity, national origin, disability, protected Veteran Status, or any other characteristic protected by applicable federal, state, or local law.If you are a qualified individual with a disability or a disabled veteran, you have the right to request an accommodation if you are unable or limited in your ability to use or access our career center as a result of your disability. To request an accommodation, contact a Arete Associates Human Resources Representative.Areté will consider for employment-qualified applicants with criminal histories in a manner consistent with the requirements of the Los Angeles Fair Chance Initiative for Hiring.",4.4,"Arete Associates Inc
4.4","Chantilly, VA","Rolling Meadows, IL",51 to 200 employees,2008,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Machine Learning Engineer,"$89K-$105K
(Glassdoor est.)","Responsibilities


As an engineer and technologist in image processing, machine learning, and/or computer vision with out team, you will be working with our clients to design, create, evaluate, and maintain solutions using your experience and expertise in image processing, machine learning, computer vision and data science. In your role you will work with various teams to research, develop, and deploy solutions for various national security missions spanning identity management, multimedia, and cyber end-to-end systems that are transforming the way law enforcement and intelligence communities handle and analyze information and translate it into actionable intelligence.

You would join Noblis’ identity intelligence group as we continue to grow our software and digital capabilities. Today our team consists of developers, scientists, engineers, researchers, and analysts that have served federal, state, and local government clients on high-consequence problems in analytics, biometrics, AI/machine learning, and forensic science for over 20 years. Our team is engaged across the identity intelligence community and has been instrumental in making our customers’ programs successful in analytics, automation, and digital solutions spanning identity science, AI/machine learning, computer vision, biometrics, forensics, media analytics, systems engineering, software development/integration, DevOps, and cloud technologies.

Client Engagement
· Learn about the Noblis business development life-cycle, processes, tools, and account structure · Contribute specialized domain or technical content to proposal sections or client white papers · Build a productive relationship with your client and understand their structure and goals.
Qualifications


Required Qualifications:

• You have BA/BS in a technology, engineering, computer science or related discipline

• You have hands-on experience in one or more of the fields of image processing, machine learning, computer vision, and data science

• You have hands-on experience of a broad ranges of technology systems and are able to work with:

- any of the following image processing and computer vision frameworks and libraries: OpenCV

- any of the following AI/machine learning frameworks, statistical packages, and libraries: Tensorflow, Caffe, Amazon Machine Learning, Apache Singa, Torch, Scikit-learn, Microsoft CNTK, Apache Mahout, SQL, d3.js, map-reduce, R, Weka, Orange, as well as open source and other emerging technologies/frameworks

- programming languages and scripting methods including: Python, C, C++, Java, .NET, Bash, AWK

- operating systems: Linux, Windows

- prefer a Linux terminal over a GUI

• You have hands-on experience:

- engineering solutions to optimize, monitor, and measure performance of operational biometric systems

- conducting (and/or leading) research and development of biometric, identity management, and fraud prevention solutions

- developing alternate concepts of operation to improve biometric sample and image quality, including automated image quality assessment, image enhancement, device calibration

- developing software algorithms to assess and improve image quality

- conducting research and assessment to develop technical contributions/guidance for national and international biometrics standards, proposed standards, laws and policies

• You desire to work in an agile and cross functional team environment, understand team goals and generate appropriate, innovative analytical insights to drive process and experience improvement

• You challenge the status quo, are hungry to explore, evaluate, and understand new technologies, and wish to share insights and mentor your peers

• You possess the ability to qualify for a Secret clearance

Desired Qualifications:

Beyond the requirements above, our ideal colleague:

• has advanced their formal education with a MS/PhD specializing in data science, computer vision, machine learning, and artificial intelligence

• has strong written and verbal communication skills (e.g., technical writing)

• has experience working with USG clients, operational components, and stakeholders

• has or are eligible for special access programs

• has hands-on experience with optics, sensors, color management, measuring image quality characteristics

• has hands-on experience with document security features, public key infrastructure (PKI), document imaging, and optical character recognition (OCR)

• complements our existing team, likes solving problems, and is comfortable with ambiguity

• can self manage, has strong self-organization skills, and is eager to contribute

• strives to be an excellent engineer, is eager to explore new technologies, and develop new skills

• is comfortable working with teams across geographic bounds

Overview


Noblis and our wholly owned subsidiary, Noblis ESI, are solving difficult problems that help our government and our country. We bring the best of scientific thought, management, and engineering expertise with a reputation for independence and objectivity. We support a wide range of government and industry clients in the areas of national security, intelligence, transportation, healthcare, environmental sustainability, and enterprise engineering. Learn more at Noblis -About Us

Why work at a Noblis company?

Our employees find greater meaning in their work and balance the other things in life that matter to them. Our people are our greatest asset. They are exceptionally skilled, knowledgeable, team-oriented, and mission-driven individuals who want to do work that matters and benefits the public.

Noblis has won numerous workplace awards. Noblis maintains a drug-free workplace and is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, veteran status or other characteristics protected by law.",4.0,"Noblis
4.0","Reston, VA","Reston, VA",1001 to 5000 employees,1996,Nonprofit Organization,Consulting,Business Services,$100 to $500 million (USD),"Booz Allen Hamilton, SAIC, LMI"
Machine Learning Engineering,-1,"Description:

Gravyty uses AI to streamline fundraising for nonprofits. As a machine learning engineer, you'll be responsible for developing natural language processing systems and ML pipelines to help fundraisers reach the right donors with the right messages. We seek candidates with in-depth knowledge of statistics, machine learning models, and deep learning frameworks. You will work closely with our Data Engineers and Data Scientists to build and deploy models.

Responsibilities:

Research and implement machine learning models for NLP and AI applications

Assess performance of models using appropriate metrics

Integrate models into existing infrastructure

Deploy models in a microservice architecture

Required:

Strong coding skills

Proficient in at least one programming language

Understanding of data structures, data modeling, and software architecture

In-depth knowledge of machine learning techniques, statistics, and NLP

Experience with machine learning libraries and frameworks such as Scikit-learn and TensorFlow

Proficient in SQL

BS degree in Computer Science or Engineering

Plus

Familiar with natural language processing techniques

Experience with NLP frameworks such as spaCy

Commercial/Enterprise application of data science or machine learning

Knowledge of Big Data solutions (e.g. Spark, Hadoop, MapReduce)

About Gravyty

Gravyty is the social good sector's first and leading provider of fundraiser enablement tools powered by artificial intelligence (AI). Fundraisers love Gravyty because AI and machine learning automate the most time-consuming processes that get in the way of doing the work they love – developing and cultivating relationships with donors. By empowering frontline fundraisers to personalize outreach more efficiently than ever before, build new relationships faster, and deepen existing relationships with donors through automated stewardship Gravyty and AI transform what's possible for entire organizations through fundraising. Visit www.gravyty.com to explore how Gravyty and AI expand the fundraising workforce without making new hires, build donor pipeline, inspire giving, and raise revenue for organizations on a mission to change our world.

Gravyty's culture is what sets it apart. Our office is casual and collaborative and thrives on forging connections—both within and across departments. We offer a 401K and subsidized medical, dental and vision benefits.",4.8,"Gravyty
4.8","Newton, MA","Boston, MA",1 to 50 employees,2016,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Senior Machine Learning Engineer (R,"$148K-$245K
(Glassdoor est.)","Description

SiriusXM and Pandora have joined together to create the leading audio entertainment company in the U.S. Together, we are uniquely positioned to lead a new era of audio entertainment by delivering the most compelling subscription and ad-supported audio experiences to millions of listeners -- in the car, at home and on the go. Our talent, content, technology and innovation continue to be at the forefront, and we want you to be a part of it! Check out our current openings below and at

Position Summary:
As part of the Shared Science Foundation team, you will design and build systems that solve prevalent science problems across SiriusXM and Pandora's digital products. These extensible, shared systems power personalization, content understanding, and advertising and marketing science. You will collaborate with scientists, engineers, and product managers to develop tools, platforms, and infrastructure that accelerates innovation of the entire organization. Your hybrid skill set of machine learning, software engineering, and empathetic communication uniquely positions you to architect systems with multiple stakeholders.
Duties and Responsibilities:
Design and build the next-generation representation of SiriusXM and Pandora listeners' tastes and interests, incorporating music and non-music listening, favorites, contextual variation, and behavioral, advertising, and marketing signals.
Architect and build large-scale machine learning infrastructure for data exploration, prototyping, and production.
Write production code and data pipelines and conduct code reviews.
Promote and role-model best practices of data science, engineering, and communication throughout the organization.
Supervisory Responsibilities:
None
Minimum Qualifications:
2+ years of industry experience as an applied data scientist or ML engineer.
Requirements and General Skills:
Excellent written and verbal communication skills, with the ability to effectively advocate technical solutions to scientists, engineers, and product audiences.
Demonstrated ability to collaborate with and coordinate teams.
Self-motivated, growth-oriented, and driven to pursue solutions to challenging problems.
Must have legal right to work in the U.S.
Technical Skills:
Production experience implementing machine learning pipelines and models at scale in Python, Java, Scala, or similar languages.
Proficiency with distributed processing and warehousing frameworks (e.g., Spark, Hadoop, Hive, Tez, etc.).
Experience with the research and development workflow/life-cycle for large-scale batch and streaming machine learning systems.
Experience architecting distributed systems and familiarity with software design patterns.
Ability to gather stakeholder requirements and evaluate technical trade-offs.
Bonus Skills:
M.S. or Ph.D. in a quantitative field (CS, EE, Statistics, Physics, Math, etc.).
Passion for data-driven development, reliability, and disciplined experimentation.
Experience designing or building feature stores to integrate and version heterogeneous data types from heterogeneous data sources.
Experience with any of the following:
Cloud computing: Google Cloud Platform, Amazon Web Services, Azure
Technologies: Kafka, Airflow, Composer
ML-frameworks: TensorFlow, PyTorch, Vowpal Wabbit, scikit-learn
Knowledge of professional software engineering practices including coding standards, code reviews, source control management, build processes, testing, and operations.
Our goal at SiriusXM+Pandora is to provide and maintain a work environment that fosters mutual respect, professionalism and cooperation. SiriusXM+Pandora is an equal opportunity employer that does not discriminate on the basis of actual or perceived race, creed, color, religion, national origin, ancestry, alienage or citizenship status, age, disability or handicap, sex, gender identity, marital status, familial status, veteran status, sexual orientation or any other characteristic protected by applicable federal, state or local laws.
The requirements and duties described above may be modified or waived by the Company in its sole discretion without notice.",3.5,"Pandora Media, Inc.
3.5","Oakland, CA","Oakland, CA",1001 to 5000 employees,2000,Company - Public,Radio,Media,$500 million to $1 billion (USD),-1
Principal Machine Learning Engineer,"$200K-$330K
(Glassdoor est.)","Join us as we pursue our disruptive new vision to make machine data accessible, usable and valuable to everyone. We are a company filled with people who are passionate about our product and seek to deliver the best experience for our customers. At Splunk, we're committed to our work, customers, having fun and most importantly to each other's success. Learn more about Splunk careers and how you can become a part of our journey!Role:Splunk's Machine Learning team is looking for a Principal Machine Learning Engineer who can design, build, test, and support our batch and streaming machine learning services at scale. These services will be used in solutions for both on-premise and cloud deployments, and they form a core part of our current and next-generation product offerings.Responsibilities:Splunk engineers are passionate about continuously improving both what we deliver, and how we deliver our product to customers. As a Principal Machine Learning Engineer, you will:* Drive the system architecture and design decisions for Splunk's machine learning infrastructure, for both cloud and on premise environments, and for both batch and stream based processing.* Design, develop, determine test strategy, test, and maintain key software improvements related to machine learning capabilities at Splunk.* Work in a team with product managers and data scientists, as the software engineering technical leader, to develop novel solutions for our most difficult data based challenges.* Be a team player who enjoys collaborating with, learning from, mentoring, and teaching other team members to create a positive work environment.Requirements:* 8+ years of commercial or open source product development experience, preferably in large scale cloud computing and/or distributed systems environments.* 4+ years of professional experience developing solutions using data pipelines, popular machine learning frameworks (scikit-learn, SparkML, or Tensorflow), and notebook based experimentation tools (Jupyter, Zepellin).* 8+ years of programming in large scale production systems, in languages such as Python, Java, Scala or C++.* A strong interest and preferably a strong background in mathematics, such that you are able to collaborate effectively in design discussions with machine learning researchers and data scientists.* Bachelors in Computer Science or related fields.Nice to have:* Expertise in developing software with containers and container orchestration technologies, such as Docker and Kubernetes.* Expertise in developing software on a public cloud platform (e.g. AWS, GCP, MS Azure etc.)* Expertise in developing software with stream processing technology (e.g. Flink, Kafka, etc.)We value diversity at our company. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, or any other applicable legally protected characteristics in the location in which the candidate is applying.For job positions in San Francisco, CA, and other locations where required, we will consider for employment qualified applicants with arrest and conviction records",4.1,"Splunk
4.1","San Francisco, CA","San Francisco, CA",1001 to 5000 employees,2003,Company - Public,Enterprise Software & Network Solutions,Information Technology,$1 to $2 billion (USD),-1
Machine Learning Platform Engineer,"$59K-$107K
(Glassdoor est.)","Make a difference

Ciber Global wants you. Come build new things with us and advance your career. At Ciber Global you'll collaborate with experts. You'll join successful teams contributing to our clients' success. You'll work side by side with our clients and have long-term opportunities to advance your career with the latest emerging technologies.
Exciting opportunity for a Machine Learning Platform Engineer focused on building a Data Science and AI, ML platform
Lead software engineers to understand platform vision, break out tasks and help them solve challenging issues
Grow technical capabilities, expertise and provide guidance to other software engineers on the team
Work with architects to make technical decision on tools, integration and other issues
Mentor and train other Software Engineers to help them learn agile methods and build technical skills
Help innovate and iterate on agile processes and share our learnings
Work hand to hand with Data Scientists to shape the future vision of our Data Science platform
Basic Qualifications:
A Bachelor’s degree in Computer Science, Computer Engineering or similar technical discipline
Must Haves:
Two or more years of professional experience (not including education) with Machine Learning Platforms, MLOps, Kubernetes, Feature Stores, etc.
Two or more years of experience leading developers
Experience and good understanding of Machine Learning, Deep Learning Models, Python, ML Model Deployment, and ML Model Management for production environments
Understanding or desire to learn end to end Machine Learning technology stack (Tools such as , Kubernetes, SeldonCore, Data Robot, Domino Data Labs etc.)
Skills Required:
Machine Learning Platforms
Software Engineering
Kubernetes
MLOps
*MSJA
At Ciber Global our consultants have access to a comprehensive benefits package. Benefits can include Paid-Time-Off, Paid Holidays, 401K matching, Life and Accidental Death Insurance, Short & Long Term Disability Insurance, and a variety of other perks.

Ciber Global is an Equal Opportunity Employer Minorities/Females/Gender Identity/Sexual Orientation/Protected Veterans/Individuals with Disabilities.

Find a purpose

Embrace emerging technologies, create inventive solutions and meet intriguing client challenges. Be a part of something bigger working on teams that make a difference and transform business.

Move ahead

No matter where you are in your career, you can work to move to the next level. You'll work hand in hand with top-tier talent and be part of a team focused on the technologies that lead the way to exciting technological changes.",3.1,"Ciber
3.1","Dearborn, MI","Troy, MI",1001 to 5000 employees,1974,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,"Capgemini, Wipro, Cognizant Technology Solutions"
"Machine Learning Engineer, AMP Analytics & Data Products","$137K-$214K
(Glassdoor est.)","Posted: Jun 22, 2020
Role Number:
200176813
At Apple, great ideas have a way of becoming phenomenal products, services, and customer experiences very quickly. If you are a self-motivated, high-energy individual who is not afraid of challenges, we’re looking for you. Apple is seeking a junior level Data Scientist to join a team passionate about Machine Learning applications for Apple Media Products (AMP), covering the App Store, Apple Music/iTunes, Video and other services. This role will involve working with Internet-scale data across numerous product and customer touch points, undertaking in-depth analysis as well as modeling, and building end-to-end Machine Learning applications to tackle the problem. The team’s culture is centered around rapid iteration with open feedback and debate along the way, plus strong collaboration with product, engineering, business, and marketing partners.
Key Qualifications
4+ years of experience in machine learning or software engineering.
Solid programming skills in at least one of the general programming languages such as Python, Java, Scala.
We look for hands-on experience with data processing and management with both RDBMS such as Postgres, MySQL and big data stack such as Apache Spark.
Experience with machine learning frameworks such as Scikit-Learn,, Tensorflow!
Experience in design, implementation and delivery of scalable build/test/release agile software development cycle.
Full-stack development experience for end to end machine learning solution preferred.
We seek experience with cloud platform such as AWS, Heroku, GCP a plus.
Familiarity with front end development such as React JS, D3.js, a plus.
Experience with Time Series data, Information Retrieval, Recommendation Systems a plus.
Excellent communication, interpersonal and presentation skills with meticulous attention to detail.
Description
You will dive deep into AMP’s data to uncover trends, identify key insights and build machine learning applications that will improve the entire analytics efforts. You will participate in designing and implementation of end-to-end Machine Learning system and bring state-of-art machine learning methods into real application. You will be collaborating with product, business, marketing, finance to tackle real business problems and deliver solutions. You will be partnering with other Apple organizations on data gathering, data governance, evangelizing key performance indicators and democratizing data.
Education & Experience
BS degree in Computer Science, or other relevant engineering/quantitative fields with 4+ years of experience applying machine learning to solve real business problems.",4.1,"Apple
4.1","Santa Clara, CA","Cupertino, CA",10000+ employees,1976,Company - Public,Computer Hardware & Software,Information Technology,$10+ billion (USD),"Google, Microsoft, Samsung Electronics"
Machine Learning Engineer,-1,"Examity, the world leader in online test integrity and the fastest-growing Edtech company in the United States, is looking for a dedicated Machine Learning Engineer to join the growing team in our Newton, MA location.

Position Overview

We are looking for an experienced machine learning engineer or data scientist with strong developer skills. The Machine Learning Engineer will apply a broad knowledge of AI and ML techniques to design and implement authentication, proctoring and automation solutions across the Examity product line. As part of a fast-growing and innovative team, you will apply creativity to solve technical challenges.

We authenticate and proctor millions of exams each year. As a result, you will have a vast pool of video data to analyze and leverage. You will use your software engineering skills to help build scalable machine learning models that create value across multiple areas of our products. You will work with product management, engineering and our services teams to propose and test models or applications of technologies that can improve proctoring results and create differentiated products and capabilities. You must be hands-on, creative and able to communicate your approach to technical and non-technical stakeholders across the company.

Familiarity and experience (preferable) using multimedia processing:
Cognitive Learning.
Facial Detection, Validation, Recognition, Sentiment Analysis frameworks in ML.
Video/audio processing frameworks.
System behavior detection frameworks.
Essential Duties
Work with the AI team in building world-class software, functioning as an AI/ML subject matter expert, and successfully deliver ML applications that impact our business.
Partner with product management to identify opportunities to leverage data science to advance Examity’s learning validation platform.
Collaborate with cross-functional agile teams to define, create and operate AI systems at scale.
Research and implement appropriate ML algorithms and tools in video/audio system tasks/programs processing.
Develop machine learning applications according to requirements in cognitive analysis.
Select appropriate datasets and data representation methods in user behaviors.
Run machine learning tests and experiments in user behaviors.
Perform statistical analysis and fine-tune using test results.
Train and retrain systems using video data.
Extend existing ML libraries and frameworks in cognitive frameworks.
Requirements
A Bachelors or Masters in Computer Science, Data Science, Machine Learning, Artificial Intelligence, Statistics, Operations Research or a similar field.
3+ years of work experience.
A passion for solving real-world problems with machine learning.
Excellent communications skills.
Experience solving problems in some of the following areas: natural language, machine vision, transfer learning, data labeling and classification, regression, information retrieval, and statistical modeling.
Experience with ML tools such as Tensorflow js.
Knowledge and experience with SQL and relational databases.
Knowledge of Hadoop, Hive, Redshift, Spark or other big data tools is a plus.
Proficiency in a low-level programming language such as Java or C++.
Strong computer science fundamentals, including data structures and complexity.
Legal authorization to work in the United States. We will not sponsor individuals for employment visas.
Benefits

Examity offers a competitive salary and a comprehensive benefits package including health, dental and 401k. As one of the fastest growing Massachusetts companies, you will be challenged to build your skills and take on increasing responsibility. Our office environment is open, collaborative, fast paced and high energy. Examity’s new urban office location in Newton, MA provides access to local shopping and restaurants. Employees enjoy Examity’s free snacks and drinks, a flexible work schedule, and frequent group outings to skyboxes for Celtics, Red Sox and summer concerts.

Examity is an equal opportunity employer. All qualified applicants will receive equal consideration for employment without regard to race, color, religion, age, disability, sexual orientation, gender identity, sex, national origin, protected veteran status, or any other basis protected by federal, state, or local laws.",4.0,"Examity
4.0","Newton, MA","Newton, MA",201 to 500 employees,2013,Company - Private,Enterprise Software & Network Solutions,Information Technology,$25 to $50 million (USD),-1
Strategic Machine Learning Engineer (Anywhere USA),-1,"Job Description
You are passionate about Machine Learning and Cloud Computing. You excel at building infrastructure and platform solutions with hypervisors, containers and orchestrators, as well as microservices and workflow pipelines, and you can make Python sing. Things like Docker, Kubernetes, Kubeflow, Kustomize, Airflow, TFX and MLOps are in your DNA and you enjoy the challenge of working on a variety of leading-edge projects to solve real world problems and help organizations succeed.

Key responsibilities:
Design and build pipelines to ingest, transform and preprocess data
Automate data collection and manage workflows, quality, integrity and monitoring
Manipulate and evaluate large and complex datasets
Write and review technical documentation, design architectures, project scopes and deliverables
Collaborate with a variety of technical and non-technical stakeholders to understand and interpret their objectives, distill real requirements, propose and deliver solutions, and communicate findings.
Work with scalable networking technologies and web standards (e.g. REST and gRPC APIs, web security (LDAP, OAuth, etc)).
Build and orchestrate containers with relevant technologies (e.g. Kubernetes, Docker), microservices, and cloud orchestration/management APIs.
Orchestrate ML workloads through Kubeflow and TensorFlow Extended (TFX) components.
Ability to build relationships and manage project delivery with partner teams and external R&D groups
Be a trusted technical advisor to customers and solve complex technical challenges
Minimum qualifications:
Bachelor's degree in Computer Science, Mathematics, related field, or equivalent practical experience.
Google Cloud Architect, Google Data Engineer or equivalent certifications.
Experience with distributed compute environments, big data analytics, microservices and cloud computing.
Experience scripting in Linux Bash, Python and supporting libraries.
Preferred qualifications:
Experience in big data, information retrieval, data mining and machine learning, as well as in building multi-tier highly available applications with modern data platforms and frameworks such as Spark and Tensorflow.
Experience with cloud storage solutions, SQL/NoSQL datastores, normalized / document databases, and federated technologies.

Company Description
Who We are:

Manceps is dedicated to helping organizations transform their businesses and automate their operations by building next-generation solutions using Machine Learning, Artificial Intelligence, and Data Science technologies. Our services are tailored to meet the demands of sophisticated IT shops with varying needs, spanning the full stack from infrastructure to applications.

You will be joining a fast-growing team of elite data scientists and software engineers working on a variety of exciting projects across industries. Trust us — there will be numerous opportunities to find creative, state-of-the-art solutions to complex problems. Whether wrangling large datasets, building models, or launching applications, our goal is to arm our clients with actionable insights and powerful solutions to help them achieve their most pressing business objectives.

We are driven by seeing the benefits of our solutions come to fruition!

Who We Are Seeking:

In short, we are seeking brilliant individuals with excellent interpersonal abilities.

We want you to be able to roll up your sleeves and work closely with team members and customer stakeholders alike. Good communication skills are essential as it will be up to you to capture detailed technical requirements and explain dependencies, findings, and results to project managers and practice leads.

If you have the aptitude to work within a fast-paced environment to deliver services that have a vast business impact, let’s talk.",5.0,"Manceps Inc
5.0","Portland, OR","Portland, OR",1 to 50 employees,-1,Company - Public,-1,-1,Unknown / Non-Applicable,-1
Sr. Data Scientist/Machine Learning Engineer - Manage and Analyze at Seal Software - a DocuSign Comp,"$156K-$257K
(Glassdoor est.)","Sr. Data Scientist/Machine Learning Engineer - Manage and Analyze at Seal Software - a DocuSign CompanyEngineering & Tech Operations | Walnut Creek, CAOur agreement with employeesDocuSign is committed to building trust and making the world more-agreeable for our employees, customers and the communities in which we live and work. You can count on us to listen, be honest, and try our best to do what's right, every day. At DocuSign, everything is equal. We each have a responsibility to ensure every team member has an equal opportunity to succeed, to be heard, to exchange ideas openly, to build lasting relationships, and to do the work of their life. Best of all, you will be able to feel deep pride in the work you do, because your contribution helps us make the world better than we found it. And for that, you'll be loved by us, our customers, and the world in which we live.The teamThe Analyze and Manage team builds and operates industry-leading analytics products that utilize AI, machine learning and cutting-edge NLP to provide deep insights from procurement, derivative and other contracts to financial institutions, manufacturers and others. We are the worldwide leader in AI-driven contract analytics. The Machine Learning (ML) team's primary goal is to maintain and enhance the core analysis engine. In order to keep up with the rapidly evolving field of Natural Language Processing (NLP) and ML, certain time is allotted for research. This allows us to lead the trend of automating the contract analysis processes by testing and evaluating the latest ML technology and methods in an inhouse designed lab. As such, we hire people who are excited about working on a groundbreaking and technically challenging AI vision that will be one of DocuSign's key investments over the next 5 years.This positionDocuSign is looking for a passionate, talented, and inventive machine learning engineer to help build industry-leading state of the art machine learning solutions. You will be leveraging data mining, deep learning, content understanding, image processing and more. You will integrate and deploy machine learning models that deliver more personalized and automated customer experiences.This position is an Individual Contributor role and reports to an Engineering Lead.ResponsibilitiesFeature extraction and data preparationAlgorithm development and evaluation of existing and emerging NLP/ML methods and technologies that could be effectively applied to contractual/legal dataApply NLP techniques to maintain and extend the current rule-based, supervised and unsupervised modelsApply ML algorithms and technologies to NLP tasks such as Named Entity Recognition, POS tagging, Parsing, Sentiment Analysis, Clustering, etc.Understanding of the entire software development end-to-end process as well as the product code and release management processUnderstand, assist and improved the existing training data maintenance and enrichment processIs ""hands-on"" and takes the initiativeBasic Qualifications6+ years of experience in designing, developing, deploying and monitoring models, specifically in the context of text processing/NLPExperience with Python programming, especially in the context of established deep learning frameworks.Bachelor's degree in computer science, data science, applied mathematics, or an equally computational fieldPreferred Qualifications:Experience with containerization and orchestration of machine learning models in production.Masters or PhD in computer science, data science, machine learning, applied mathematics, or an equally computational field.Demonstrated experience with text-based deep learning (NLP, NLU).Demonstrated experience in extracting, cleansing, and manipulating large, diverse unstructured datasets.Strong desire to stay ahead of industry trends & technologies with a commitment to continuous research and learning.About usDocuSign® helps organizations connect and automate how they prepare, sign, act on, and manage agreements. As part of the DocuSign Agreement Cloud, DocuSign offers eSignature: the world's #1 way to sign electronically on practically any device, from almost anywhere, at any time. Today, hundreds of thousands of customers and hundreds of millions of users in over 180 countries use DocuSign to accelerate the process of doing business and simplify people's lives. Plus, we save more trees together! And that's a good thing.DocuSign is an Equal Opportunity Employer. DocuSign is committed to building a diverse team of talented individuals who bring different perspectives to the discussion and who feel a sense of inclusion and belonging when they join our team. Individuals seeking employment at DocuSign are considered without regards to race, ethnicity, color, age, sex, religion, national origin, ancestry, pregnancy, sexual orientation, gender identity, gender expression, genetic information, physical or mental disability, registered domestic partner status, caregiver status, marital status, veteran or military status, citizenship status, or any other legally protected category.#LI-DS1",4.6,"Docusign, Inc.
4.6","Walnut Creek, CA","San Francisco, CA",5001 to 10000 employees,2003,Company - Public,Computer Hardware & Software,Information Technology,$1 to $2 billion (USD),"EchoSign, Inc"
Software Development Engineer- Machine Learning,"$107K-$168K
(Glassdoor est.)","The Items and Offers platform (IOP) manages the global catalog at at the heart of the systems that support the world's largest e-Commerce platform. We serve as the gateway for the millions of merchants that offer the earth's largest selection of products to Amazon customers, at a rate of hundreds of billions of updates on billions of catalog items every single day.

The relationships between catalog items are a first class architectural concern at Amazon, which the Items and Offers Platform Relationships team in NYC have ownership of.

The Catalog Relationship team is working to innovate in the space of inferring, managing, and presenting relationships between items in the catalog to drive better product discovery and customer experience while navigating Amazon's large and ever-growing catalog. Work in this space ranges from building high performance large scale distributed real-time systems, data modeling to capture new relationship structures, machine-learning based inference systems, and experiment frameworks that enable continuous measurement, feedback and improvement.

As a Software Development Engineer- Machine Learning of this team, you will
· Build and own systems, services and tools for inference, automation and maintenance of catalog relationships.
· Translate high-level, ambiguous business goals into technical specifications and break down the technical specifications into concrete tasks.
· Partner with Applied Scientists and Machine Learning community to built highly scalable machine learning solutions for inferring and maintaining catalog relationships.
· Automate the ML model development life-cycle and accelerate the development, testing and deployment of ML models to production.
· Write a high quality distributed system software that harnesses the power of Machine Learning to make inference decisions.
· Be a technical partner for the leadership and guide their business and technical decisions.

Technologies used:
· AWS (i.e. SageMaker, Glue, SQS, Kinesis, EMR, Lambda etc.)
· Spark/Hadoop (big data)
· RDS and DynamoDB
· Machine Learning(SparkML, TensorFlow, Keras, Deep Learning)
· Jupyter and Zeppelin (ML notebooks)
· Java, Scala, Python, React.JS
· Distributed Real-Time Streaming Systems
· Elastic Computing
· Massively Distributed Systems
Every day we are working hard, having fun and making history - and we would love you to work with us. If you have what we are looking for, come join a strong team in a highly visible organization. Your impact on our software will be felt around the world.



Basic Qualifications

Basic Qualifications:
· Have experience in building highly concurrent distributed systems for online services at scale
· 6+ years of work experience in software development
· Have project Lead experience
· Have knowledge of Object-Oriented Design, data structures, algorithm design, and complexity analysis
· Have strong proficiency in, at least, one modern programming language such as C, C++, C#, Java, Python, Scala or Perl
· Bachelors Degree or higher in Computer Science or related field
· Experience mentoring junior engineers

Preferred Qualifications

· Experience building complex software systems that have been successfully delivered to customers
· Experience developing service oriented architectures and an understanding of design for scalability, performance and reliability.
· Experience working in ML and Big Data technologies.
· Experience defining system architectures and exploring technical feasibility tradeoffs.
· Knowledge of professional software engineering practices & best practices for the full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations
· Ability to take a project from scoping requirements through actual launch of the project
· Experience in communicating with users, other technical teams, and management to collect requirements, describe software product features, and technical designs.
· Have a strong sense of ownership, urgency and drive
· Be a strong leader with a desire to mentor and lead people

· BA/BS in computer science or equivalent experience
· 3+ years of work experience or relevant experience with a PhD in CS or related field
· 2+ years of work experience building large-scale production ML systems
· Experience with ML libraries/frameworks such as Keras, Tensorflow, AWS Sagemaker
· Experience of Software development in one or more of the general purpose programming languages: C/C++, Go, Python, Java
· Desire and ability to write production quality code



Amazon is an Equal Opportunity Employer.",3.9,"Amazon
3.9","New York, NY","Seattle, WA",10000+ employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),"Google, Microsoft, Walmart"
Data Scientist,-1,"Job Description
Title: Data Scientist
Location: Washington, DC
Salary: $100,000 - 140,000
Contact: Paul Chatlos, pchatlos@smithhanley.com

Data Scientist The Position

We are seeking a data scientist to participate as a key team member in envisioning, designing, coding, testing and improving the algorithms that are central to our mission as a company.

Some key challenges will include:

-Identifying external datasets and developing API or other methods for accessing them
-Fluidly self-educating on existing methods for modeling end-user behavior in a variety of contexts, or developing new methods for doing this when necessary
-Designing experiments to answer targeted questions
-Teaming with developers to embed algorithms in applications
-Understanding business economics, user motivation and other contextual information in order to guide analytical trade-offs, with a focus on ""minimum viable algorithm"" followed by intensive, iterative improvement

Data Scientist The Successful Candidate

A successful candidate will be comfortable in a fluid, entrepreneurial environment, but one that is focused on developing reusable software applications, not bespoke analytical solutions.
He or she will likely have many of the following characteristics:
-2+ years professional experience using statistical software (R, S-Plus, SAS, or similar), relational and NoSQL databases and scripting languages (such as Python). Ideally, R and Python
-Familiar with general-purpose machine learning methods, such as neural networks, Bayesian networks, regression, decision trees and so on. Capable of self-teaching new algorithmic methods easily
-Passionate about using data to drive strategy and business recommendations.
-Well-rounded top performer who is able to ""crunch the numbers"" one minute, and critically think through strategic issues the next
-Self-starter with a high degree of rigor, organization, and discipline to get things done
-Able to communicate as effectively in delivering complex data-driven findings with businesspeople, as in discussing machine-learning specifications with engineer

Data Scientist Academic Qualifications

-Very strong math, physics, CS or similar degree from a leading program
-Extremely high SAT or similar standardized test scores",4.5,"Smith Hanley Associates
4.5","Washington, DC","New York, 061",1 to 50 employees,1980,Company - Private,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,"Kforce, PageGroup, Robert Half"
Data Scientist / Statistician,"$84K-$133K
(Glassdoor est.)","Job title: Data Scientist / Statistician
Job type: Permanent
Emp type: Full-time
Salary:
Negotiable
Location: New York, United States
Job published: 2019-08-05
Job ID: 41456

Job Description


Our client is looking for a Data Scientist/ Statistician to join their New York office.

Responsibilities:
Serve as expert statistician/data scientist on discretionary investment team
Test research hypotheses and assumptions of portfolio manager and investment analysts by designing methodology and writing necessary code to perform backtesting, cross-validation, event studies, Bayesian data analysis, etc.
Test and identify the most predictive and robust statistical, machine learning, and deep learning methods to forecast factors, features, metrics, drivers, etc. relevant to portfolio manager and investment analysts in making investment decisions
With guidance from and in collaboration with portfolio manager and investment analysts help select relevant data sets
Work closely with team’s data engineer/systems developer to help specify best sources, format, and delivery mechanism of data
Write efficient, modular, and dependable code, packages, libraries, and scripts
Ensure code is written so it is easily understood by teammates when reviewing
Document all work extensively and train teammates on use of work products (e.g., custom Python libraries or R packages)
Work closely with team’s data engineer/systems developer and portfolio manager to design research (e.g., backtesting software) and production (e.g., trade file creation) processes
Collaborate regularly with firm’s Big Data group (Aperio) and other firm resources
Stay abreast of new research in statistics, machine learning, and deep learning


Requirements:
3+ years of working experience in a role that requires advanced statistical analysis
Be an expert in statistics (e.g., doctoral level) including time-series analysis
Have strong programming skills in SQL/NoSQL and at least one of the following Python, R, or C++
Good communication skills
Education:
Advanced degree in quantitative discipline (or 6+ years of full-time work experience using advanced statistical analysis)
If you would like to be considered for the position of Data Scientist / Statistician or wish to discuss the role further then please leave your details below. Your resume will be held in confidence until you connect with a member of our team",4.2,"NJF Global Holdings
4.2","New York, NY","London, United Kingdom",51 to 200 employees,2003,Company - Private,Staffing & Outsourcing,Business Services,$10 to $25 million (USD),-1
Machine Learning Engineer (Imaging),"$70K-$124K
(Glassdoor est.)","Position SummarySamsung Austin Semiconductor is one of the most advanced semiconductor manufacturing facilities in the world with more than 3,000 employees and 2.45 million square feet of floor space. Samsung Austin Semiconductor has broad semiconductor process technology offerings serving customers in various application areas including mobile, consumer, networking/high performance computing, Internet of Things, RF and automotive. Since 1996, SAS has invested approximately $17 billion in its Austin, TX campus, making it one of the largest direct foreign investments in United States history. Samsung Austin Semiconductor is a US-based subsidiary of Samsung Electronics Co., Ltd. The Austin facility is one of the few semiconductor plants the company has outside South Korea. Visit www.samsung.com/us/sas.SAS is focused on being the World's Best Foundry product supplier.Role and Responsibilities* Our company creates some of the world's most high-tech semiconductor manufacturing line for CPUs, GPUs, and IoT sensors.* We are currently in search of a Machine Learning developer to find and optimize signals from data from various resources, transform data, implement new features, and design machine learning models for business value.* Looking for a Machine Learning engineer with a passion for data, and enjoys being a part of a small high performing team developing and maintaining in-house models.* Be a member of the Defect Engineering Systems group which provides data summarization across many key dashboards.* Helps by directing the focus of the factory and continuously improving time to detection, accuracy, and throughput.* Working with key members of the organization to obtain stronger predictive data.* Feature Engineering to improve model performance.* Attend team meetings and offer solutions to challenging problems.* Collaborate with peer data scientists across the organization on best methods for data modeling.* Other duties as needed.* Experience building and extending machine learning models.* Experience with open source frameworks (Tensorflow, PyTorch).* Comfortable working with command line interfaces (Ubuntu experience a plus).* Ability to summarize results to a broad range of audiences.* Ability to learn quickly and keep deadlines while applying good design principals.* Experience with CNNs, Auto-Encoders, Manifold Learning, and Recommendation Systems.* Ability to use VM container software (Docker / Kubernetes).* Familiar with Atlassian software (BitBucket, Confluence, Jira).* Semiconductor process knowledge (specifically defect domain knowledge: detection, classification, determining impact) is a plus.* Enjoy solving challenging problems and eager to learn new technologies.* Working with a small highly motivated team to develop and implement new ideas.* Work days and hours: M-F, 8am to 5pm/1st shiftSkills and Qualifications* B.S or M.S Engineering Degree.* 3- 7 years of Data Science/Machine Learning experience is a must* Proficient with Python, SQL, and data manipulation is required.* Prefer experience with Tensorflow image processing and modeling* Excellent communication, interpersonal, initiation, & troubleshooting skills.* Fundamental understanding of analytic techniques is a plus.* Fast learner with the ability to develop and maintain.* Please visit Samsung membership to see Privacy Policy, which defaults according to your location. You can change Country/Language at the bottom of the page. If you are European Economic Resident, please click here.* Samsung Electronics America, Inc. and its subsidiaries are committed to employing a diverse workforce, and provide Equal Employment Opportunity for all individuals regardless of race, color, religion, gender, age, national origin, marital status, sexual orientation, gender identity, status as a protected veteran, genetic information, status as a qualified individual with a disability, or any other characteristic protected by law.",2.9,"Samsung Electronics America Inc
2.9","Austin, TX","Ridgefield Park, NJ",1001 to 5000 employees,1938,Subsidiary or Business Segment,Computer Hardware & Software,Information Technology,$10+ billion (USD),-1
"Software Engineer, Machine Learning",-1,"About CharterUP

CharterUP aims to be the leading charter bus platform in the world and is looking for people that want to be along for the ride! We are disrupting the highly fragmented bus industry by connecting supply-side bus companies to demand-side clients (corporations, non-profits, and governmental entities). We strive towards having as many enthusiastic customers as possible, which leads to increased group travel and a greener earth.
About This Role

We are looking to add a Machine Learning Software Engineer to the team. While traditional approaches to optimization and problem decomposition are sufficient to disrupt transportation, building next-generation platform for low-cost, ultra-immersive transportation to improve people’s lives warrants modern ML utilizing peta-byte scale data. Our highly motivated Machine Learning Software Engineers work on these challenging problems and define solutions to directly impact various aspects of our core business.
What You'll Do
Design, build, train and test Machine Learning models
Write production-level code to convert your ML models into working pipelines
Work closely with Product Managers, Data Scientists, and fellow ML Engineers to frame Machine Learning problems within the business context
Analyze experimental and observational data, communicate findings, and facilitate launch decisions
Participate in code reviews to ensure code quality and distribute knowledge

What You'll Need
B.S., M.S. or Ph.D. in Computer Science or related technical field
5+ years (or Ph.D. with 2+ years) of industry or research experience developing ML models
Deep knowledge of ML libraries like scikit-learn, Tensorflow, PyTorch, Keras, MXNet, etc
Proven ability to quickly and effectively turn research ML papers into working code
Practical knowledge of how to build efficient end-to-end ML workflows
Strong oral and written interpersonal skills
Application Process

The selection process for this role differs from our traditional tech team application process. A member of our team will reach out to you if you qualify for the next step.

CharterUP Principles

At CharterUP, we don’t compromise on quality. We hire smart, high-energy, trustworthy people and keep them as motivated and happy as possible. Do that by adhering to our principles, which are:

Customer First
We always think about how our decisions will impact our clients; earning and keeping customer trust is our top priority
We are not afraid of short-term pain for long-term customer benefit
Create an Environment for Exceptional People
We foster intellectual curiosity
We identify top performers, mentor them, and empower them to achieve
Every hire and promotion will have a higher standard
Everyone is an Entrepreneur / Owner
No team member is defined by their function or job title; no job is beneath anyone
We do more with less; we are scrappy and inventive
We think long-term
Relentlessly High Standards
We don’t accept “that’s how it’s always been done”; we constantly innovate and question established routines to improve processes
We actively push to be proved wrong and welcome different ideas; the best idea wins
We don’t compromise on quality
Clarity & Speed
When in doubt, we act; we can always change course
We focus on the key drivers of a process that will deliver the most results
Mandate to Dissent & Commit
We are confident in expressing our opinions; it is our obligation to express our disagreement
Once we decide, we enthusiastically move together in the agreed upon direction",4.7,"CharterUP
4.7","Atlanta, GA","Atlanta, GA",51 to 200 employees,2017,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Machine Learning Researcher,"$125K-$162K
(Glassdoor est.)","Vicarious aims to transform robotics by creating robots with human level performance on real-world manipulation tasks. We are passionate about changing the world with science and software, and we are looking for exceptional people to join us in that mission.

Here you will join a small, tightly knit collective of engineers and scientists committed to solving long-term problems. Our focus is the systematic integration of perception, concept learning, reasoning, and motor control, used to build robotic manipulation systems. As a member of the research group at Vicarious, you will play a critical role in developing the technology to push the state of the art on robotic manipulation.
Your responsibilities
Understanding our current body of research and improving upon it.
Further the research on the different pieces of AGI, as well as how to assemble them. These include, but are not limited to: vision, dynamics learning, planning, sensorimotor control, causality, reasoning, concept learning, language.
Publish papers in world-class conferences and journals.
Produce efficient code for your algorithms and demonstrate its applicability in real use cases, with a focus on robotics.
Background/Experience
Masters or PhD in a computer vision-related discipline (or equivalent professional experience), preferably in one of the following areas: probabilistic graphical models, approximate inference, combinatorial optimization, neural networks, object class and instance detection, pose estimation, 3D scene understanding and recognition from RGB-D imagery, 3D reconstruction, structure-from-motion, multi-view stereo, etc.
Strong publication record and/or industry experience in the above mentioned areas, in top-tier conferences such as NeurIPS, ICML, ICLR, AAAI, AISTATS.
Interest/background in algorithms with human-like abilities such as learning from small amounts of data and tight sensorimotor feedback.
Strong C++ and/or Python skills. Experience developing with OpenCV, TensorFlow, and PCL.
Desired personal qualities
Integrity
Ability to admit when wrong
Altruism
Fearlessness working outside your comfort zone
Patience with others
Described by others as the best researcher / engineer / thinker they know
Intellectual breadth
Sense of humor
Vicarious is proud to be an equal opportunity employer. We’re committed to fair hiring practices and a welcoming working environment. All candidates are considered for employment without regard to race, religion, ethnicity, age, gender, sexual identity or expression, medical condition, or socioeconomic status. We value our differences and we’re excited to learn what you can add to our team.",4.9,"Vicarious
4.9","Union City, CA","Union City, CA",51 to 200 employees,-1,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Software Engineer - Platform,-1,"LeapYear's secure machine learning platform is deployed by some of the largest enterprises in the world across finance, healthcare, and technology.

Our technology ensures differential privacy, a widely recognized standard of data privacy that enables all data - including sensitive information - to be utilized for analytics, while providing mathematically proven privacy protection.

The LeapYear system is composed of a core set of components that allow private machine learning on data sets that can scale to petabytes. The system includes private algorithms for relational operations, statistical methods and machine learning. A data scientist accesses private data using a Python API. Administration is provided via a web-based GUI or an API.

LeapYear's platform team builds the services that allow our product to integrate with complex enterprise environments and operate effectively on our customers’ most sensitive data.
The platform includes services for authentication, access control, logging, auditing and support for integration of data from a variety of data sources including SQL/NoSQL Databases, HDFS and S3. Queries are processed using Spark to support to enable fast, distributed processing of massive data sets. The services are primarily written in Haskell, with Python, Scala, and Java used as additional supporting languages.

We are looking for platform engineers that have a track record of developing enterprise-ready features for technical end users, including enterprise integrations, rigorous security, flexible deployment, and support for diverse data sources.

Recent technical challenges we've been working on
Developing a Spark-based query engine with strong typechecking.
Achieving terabyte and petabyte scale on Spark.
Refactoring our persistence layer.
Using Haskell to implement enterprise-ready subsystems for authentication, permissioning, job management, and logging.
Extending the platform to support automated daily data updates.

For details on the specific responsibilities and requirements of this role, please see below.
Responsibilities
Develop greenfield systems and scale existing services to support internet-scale deployments.
Own the full software development lifecycle - problem definition, design, development, testing, demoing, and supporting production use of the features you own.
Partner with product management to define problems and identify iterative solutions
Balance immediate business objectives against long-term architectural vision
Contribute to an engineering-wide culture of code quality and shared responsibility for testing
Requirements
2+ years of professional experience writing production code
Acquainted with and interested in functional programming (Haskell, OCaml, Clojure, Erlang, Scala)
Track record of delivering high-quality product features on schedule
Preferred
Experience developing for on-premise enterprise deployments
Professional experience with functional programming
Prior experience developing production-level Spark applications or machine learning platforms
Experience with ODBC/JDBC databases, AWS, CircleCI
Lifelong learners and mentors
A Few of the Perks
Culture of teaching and learning
Competitive compensation package of salary and equity
Catered lunch every day
Company outings
Build your ideal work station
Generous health insurance plan
Relocation support and visa sponsorship",4.2,"LeapYear
4.2","San Francisco, CA","San Francisco, CA",1 to 50 employees,2015,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
AI Engineering: Data Scientist/Machine Learning Engineer,"$71K-$131K
(Glassdoor est.)","JPMorgan Chase (JPMC) is a leading global financial services firm with assets of $2 trillion and operations in more than 60 countries. It is on the transformation journey to be a client-centric technology driven company over the last few years. With an annual tech budget of $10B+, it has started significantly investing and building in the next generation core infrastructure, data and AI technology.

Responsibilities
• Collaborate with all of JPMorgan's lines of business and functions to delivery software solutions.
• Experiment, develop and productionize high quality machine learning models, services and platforms to make huge technology and business impact.
• Lead a team of engineers to build products and deliver solutions, depending on previous architecture and technical leadership experience.
• Design and implement highly scalable and reliable data processing pipelines and perform analyses and insights to drive and optimize business result.

Minimum Qualifications
• BS, MS or PhD degree in Computer Science or related quantitative field.
• Solid programming skills with C/C++, Java, Python or other equivalent languages.
• Deep knowledge in Machine Learning, Data Mining, Information Retrieval, Statistics.
• Expert in at least one of the following areas: Natural Language Processing, Computer Vision, Speech Recognition, Reinforcement Learning, Ranking and Recommendation, or Time Series Analysis.
• Major machine learning frameworks: Tensorflow, Caffe/Caffe2, Pytorch, Keras, MXNet, Scikit-Learn.
• Experience in ETL pipelines, both batch and real-time data processing.
• Strong analytical and critical thinking skills.
• Self-motivation, great communication skills and team player.

Preferred Qualifications
• Cloud computing: Google Cloud, Amazon Web Service, Azure, Docker, Kubernetes.
• Experience in big data technologies: Hadoop, Hive, Spark, Kafka.
• Experience in distributed system design and developmentJPMorgan Chase & Co., one of the oldest financial institutions, offers innovative financial solutions to millions of consumers, small businesses and many of the world's most prominent corporate, institutional and government clients under the J.P. Morgan and Chase brands. Our history spans over 200 years and today we are a leader in investment banking, consumer and small business banking, commercial banking, financial transaction processing and asset management.

We recognize that our people are our strength and the diverse talents they bring to our global workforce are directly linked to our success. We are an equal opportunity employer and place a high value on diversity and inclusion at our company. We do not discriminate on the basis of any protected attribute, including race, religion, color, national origin, gender, sexual orientation, gender identity, gender expression, age, marital or veteran status, pregnancy or disability, or any other basis protected under applicable law. In accordance with applicable law, we make reasonable accommodations for applicants' and employees' religious practices and beliefs, as well as any mental health or physical disability needs.

Equal Opportunity Employer/Disability/Veterans",3.9,"JPMorgan Chase Bank, N.A.
3.9","Jersey City, NJ","New York, NY",10000+ employees,1799,Company - Public,Investment Banking & Asset Management,Finance,$10+ billion (USD),-1
"Senior Machine Learning Engineer, Infrastructure","$145K-$237K
(Glassdoor est.)","Company Description

Cash App is the fastest growing financial brand in the world. Initially built to take the pain out of peer-to-peer payments, Cash App has gone from a simple product with a single purpose to a dynamic app with over 24 million monthly active users. We are bringing a better way to send, spend, invest, and save to anyone who has ever sought an alternative to the traditional banking system.

Loved by customers and pop culture, we’ve consistently held the top spot for finance in the App Store for many years, seeing more engagement with millions of followers across social media in a day than most brands see in a year. We are building an ecosystem to redefine the world’s relationship with money by making it universally accessible.

We want to hire the best talent regardless of location. Our employment model is distributed, offering the opportunity to collaborate with teams across the world in San Francisco, New York, St. Louis, Portland, Toronto, Kitchener-Waterloo, Sydney, and Melbourne.

Interested in learning more?

Job Description

At Cash App we believe Machine Learning, especially Deep Learning powered Artificial Intelligence, is the future. Our mission is to make them available in the present. To achieve this we’re organized into three teams: ML Platform, Data Infrastructure & Risk.

We believe each Machine Learning Engineer has a diverse set of skills, regardless of what your strength is, we would love to talk to you.

Problems you’d be solving:
Prototype new approaches and productionize solutions at scale for our 24+ millions of active users
Help execute our long-term Machine Learning strategy across Cash App
Create a world class platform for training, hosting and maintaining ML models '
Identify opportunities for platformization by communicating with our applied ML team
Balance the needs of Product, Data Scientists, User Research, and other engineers in a small team to develop machine learning approaches that advance our mission to detect fraud
Qualifications

You have:
Demonstrated technical initiative and leadership on previous projects
The ability to work in a fast paced, autonomous and unpredictable environment
Desire to mentor & grow other machine learning engineers across the org to further these efforts
A deep understanding of software that allows you make the right trade offs
Natural curiosity & eagerness to learn (we have one day a week dedicated to Passion Projects)
Technologies we use:

We’re agnostic to what you know walking in the door. You’ll need to be happy working with:
Kotlin, Java, Go & Python
AWS
Kafka, Beam and Flink
Additional Information

Cash App treats all employees and job applicants equally. Every decision is based on merit, qualifications, and talent. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

We will consider for employment qualified applicants with criminal histories in a manner consistent with each office’s corresponding local guidelines.",4.0,"Square
4.0","San Francisco, CA","San Francisco, CA",1001 to 5000 employees,2009,Company - Public,Computer Hardware & Software,Information Technology,$1 to $2 billion (USD),-1
Machine Learning Engineer (TX),"$55K-$100K
(Glassdoor est.)","Tiger Analytics is an advanced analytics consulting firm. We are the trusted analytics partner for several Fortune 100 companies, enabling them to generate business value from data. Our consultants bring deep expertise in Data Science, Machine Learning and AI. Our business value and leadership has been recognized by various market research firms, including Forrester and Gartner.

We are looking for a Machine Learning Engineers for our team. As part of this job, you will be responsible for:
Providing solutions for the deployment, execution, validation, monitoring, and improvement of data science solutions.
Creating high performance and scalable Machine Learning systems
Building reusable production data pipelines for machine learning models
Writing production quality code and libraries that can be packaged as containers, installed and deployed
Requirements
Demonstrate up-to-date knowledge in software engineering practices and provides solutions for the development, implementation and scaling, execution, validation, monitoring, and improvement of data science solutions
Collaborate with Data Engineers and Data Scientist to build data and model pipelines and help in running machine learning tests and experiments
Manage the infrastructure and data pipelines needed to bring ML solution to production
Demonstrate end-to-end understanding of applications (including, but not limited to, the machine learning algorithms) being created and maintain scalable machine learning solutions in production
Abstracts complexity of production for machine learning through the use of containers
Troubleshoots production machine learning model issues, including recommendations for retrain, re-validate, and improvements
3-5 years of experience with Big Data Projects using multiple types of structured and unstructured data
Ability to work with a global team, playing a key role in communicating problem context to the remote teams
Excellent communication and team work skills
Bachelor's degree or higher in computer science or related
Additional Skills Required:
Technologies used would include Python (multiple versions), Spark, Hadoop, Docker, with an emphasis on good coding practices in a continuous integration context, model evaluation, and experimental design
Test driven development (prefer py.test / nose), experience with Cloud environments
Proficiency in statistical tools, relational databases & expertise in programming languages like Python/SQL is desired
Benefits

Significant career development opportunities exist as the company grows. The position offers a unique opportunity to be part of a small, challenging, and entrepreneurial environment, with a high degree of individual responsibility.",4.6,"Tiger Analytics
4.6","Dallas, TX","Santa Clara, CA",201 to 500 employees,2011,Company - Private,Consulting,Business Services,$10 to $25 million (USD),"Mu Sigma, LatentView Analytics, Fractal"
Machine Learning Platform Engineer,-1,"V2Soft (www.v2soft.com) is a global company, headquartered out of Bloomfield Hills, Michigan, with locations in Mexico, Italy, India, China and Germany. At V2Soft, our mission is to provide high performance technology solutions to solve real business problems. We become our customer’s true partner, enabling both parties to enjoy success. We are committed to promoting diversity in the workplace, and believe it has a positive effect on our company and the customers we serve.

Description:

GDIA is looking for a Machine Learning Platform Engineer focused on building an Data Science and AI, ML platform. The team you will be working on is focused on building Mach1ML platform. an AIML enablement platform to democratize Machine Learning across client enterprise (similar to Uber.s Michelangelo, Facebook.s FBLearner, etc).

Position Responsibilities:
Lead software engineers to understand platform vision, break out tasks and help them solve challenging issues.
Grow technical capabilities, expertise and provide guidance to other software engineers on the team.
Work with architects to make technical decision on tools, integration and other issues.
Mentor and train other Software Engineers to help them learn agile methods and build technical skills.
Help innovate and iterate on agile processes and share our learnings.
Work hand to hand with Data Scientists to shape the future vision of our Data Science platform.
Basic Qualifications:
A Bachelor.s degree in Computer Science , Computer Engineering or similar technical discipline .
Must: 2 or more years of professional experience (not including education) with Machine Learning Platforms, MLOps, Kubernetes, Feature Stores etc.
2 or more years of experience leading developers.
Experience and good understanding of Machine Learning, Deep Learning Models , Python , ML Model Deployment and ML Model Management for production environments.
Understanding or desire to learn end to end Machine Learning technology stack (Tools such as , Kubernetes, SeldonCore, Data Robot, Domino Data Labs etc)
Skills Required:
Machine Learning Platforms Software Engineering Kubernetes MLOps
Experience Required:
Please Do Not Submit Candidates Who Do Not Have At Least 2 Years of Experience with Machine Learning Platforms, Kubernetes, and Software Engineering.
Experience Preferred:
All Software Engineers are required to take HackerRank Coding Assessment:
Education Required:
Minimum Bachelor
V2Soft is an Equal Opportunity Employer ( EOE).
https://www.v2soft.com/careers - to view all of our open opportunities and to learn more about our benefits.",3.9,"V2Soft
3.9","Dearborn, MI","Bloomfield Hills, MI",501 to 1000 employees,1998,Company - Private,IT Services,Information Technology,$25 to $50 million (USD),-1
Software Engineer - Machine Learning,-1,"Lightmatter builds chips for artificial intelligence computing. Our architecture leverages unique properties of light to enable fast and efficient inference and training engines. If you're a collaborative engineer or scientist who has a passion for innovation, solving challenging technical problems and doing impactful work...work like building the world's first optical computers, consider joining the team at Lightmatter!
Job Description
Work closely with a Machine Learning Scientist to build state-of-the-art and novel machine learning algorithms that learn semantics of data (images, video, text, audio, and other modalities).
Understand and analyze the interplay between machine learning accelerator software and hardware.
Develop and maintain code repositories for training and visualizing neural network models.
Key Qualifications
Masters or PhD in computer science, physics, mathematics, or any related field.
>3 years experience in software engineering or a machine learning related field (preferred).
Highly proficient in scientific object-oriented programming languages, e.g. Python, Julia, C++, with good code hygiene.
Solid understanding of artificial intelligence, machine learning, and neural networks.
Experience in machine learning and deep learning programming languages and framework, e.g. Tensorflow, PyTorch, Caffe, Keras.",4.7,"Lightmatter
4.7","Boston, MA","Boston, MA",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Principal Machine Learning Engineer,"$157K-$271K
(Glassdoor est.)","Our MissionAt Palo Alto Networks® everything starts and ends with our mission:Being the cybersecurity partner of choice, protecting our digital way of life.We have the vision of a world where each day is safer and more secure than the one before. These aren't easy goals to accomplish - but we're not here for easy. We're here for better. We are a company built on the foundation of challenging and disrupting the way things are done, and we're looking for innovators who are as committed to shaping the future of cybersecurity as we are.Your CareerYou will have the opportunity to build a career solving network security challenges leveraging on advanced data analytics and data driven technologies. You will help create and deliver the most advanced AI and Machine Learning enabled solution to discover threats, provide intelligence and protect IoT devices.Your Impact:You will work in a fast paced team to create and deliver new product and mission mission features to the IoT security platform that many customers use on a daily basis. You will actively engage and contribute to the security community through collaborations. You will be part of the team that is leading and driving industry technology evolution in security and creating positive impact on business.Your Experience:* MS or above in mathematics, science or technology, strong programing PhD is preferred* 8+ years industry experience in software development, minimum 3 years as a machine learning engineer or data scientist* Domain expert knowledge and solid skills in computer science, applied math, statistics, and machine learning* Exposure in networking and security is a major plus* Proficient in at least two general programming language such as Python, Java, C++ or Scala* Excellent communication skills with the ability to influence at all levels of the organization* A self driven individual contributor and an excellent team playerThe TeamWe're not your ordinary Information Security team. We're a diverse group of security professionals that accepts challenging the status quo in order to protect Palo Alto Networks and our customers.Driving innovation on the Information Security team of the fastest-growing high-tech cybersecurity company is a once in a lifetime opportunity. You'll be joined by the brightest minds in technology, and our global teams are on the front line of defense against cyberattacks.Our CommitmentWe're trailblazers that dream big, take risks, and challenge cybersecurity's status quo. It's simple: we can't accomplish our mission without diverse teams innovating, together.We are committed to providing reasonable accommodations for all qualified individuals with a disability. If you require assistance or accommodation due to a disability or special need, please contact us at accommodations@paloaltonetworks.com.Palo Alto Networks is an equal opportunity employer. We celebrate diversity in our workplace, and all qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or other legally protected characteristics.#LI-SM2",3.3,"Palo Alto Networks Inc.
3.3","Santa Clara, CA","Santa Clara, CA",5001 to 10000 employees,2005,Company - Public,Enterprise Software & Network Solutions,Information Technology,$2 to $5 billion (USD),"Check Point Software Technologies, Fortinet, Cisco Systems"
Machine Learning Research Engineer,"$64K-$112K
(Glassdoor est.)","Schrödinger, a leader in the field of computational biochemistry, is seeking a research engineer to tackle problems from a data based perspective. This position will tackle problems dealing with DNA, RNA, small molecule design, materials design and/or quantum physics. Previous experience in these domains is not required, but an interest in learning is.

The ideal candidate will have a strong grasp of software development fundamentals, along with an interest in learning more about both new cutting-edge technologies and the Chemistry, Biology, and Physics problems that our software helps to solve.

Come join our team in our mission to improve human health and quality of life!

Responsibilities:
Collaborate closely within an interdisciplinary team composed of scientists, developers, and drug hunters to deliver new research that meet business and product goals
Given a clean slate, figure out whether an idea has merit and help the team decide whether to develop it into a full feature
Exercise your own judgment along with support from teammates to architect and implement proof of concept solutions
Participate in a code reviewing environment that encourages learning and high code quality

Requirements:
Knowledge of basic statistics
Ability to work with multi-dimensional data and solve data munging problems with Python
B.S., M.S. or Ph.D. in Computer Science, Software Engineering, Machine Learning, Mathematics, Physics or Chemistry

Experience with most of these...
Running independent projects end to end
Self-directed research
Wading through Technical Domains to get to the “Real Problem”
Proficient interpersonal skills (oral/verbal communication), complemented by an ability to collaborate in a team environment
Enthusiasm for solving interesting problems and a willingness to learn new technologies
Tensorflow, Pytorch, pandas and sklearn

Pluses:
Source control (GIT, SVN, etc)
Continuous Integration
Experience with large scale distributed computing (pbs, slurm, Distributed Computing)
Experience building a system that operated on greater than 10 machines
Familiar with log processing and data analysis
Science minor or independent interest (chemistry, physics, biology, or related)

Pay and perks:
Schrödinger understands it’s people that make a company great. Because of this, we’re prepared to offer a competitive salary, stock options, and a wide range of benefits that include healthcare (with dental and vision), a 401k, pre-tax commuter benefits, a flexible work schedule, and a parental leave program. We have catered meals in the office every day, a company culture that is relaxed but engaged, and over a month of paid vacation time. Our Administrative and Human Resources departments also plan a myriad of fun company-wide events. New York is home to our largest office, but we have teams all over the world. Schrödinger is honored to have been selected as one of Crain's New York Best Places to Work in 2018 and 2019.


As an equal opportunity employer, Schrödinger hires outstanding individuals into every position in the company. People who work with us have a high degree of engagement, a commitment to working effectively in teams, and a passion for the company's mission. We place the highest value on creating a safe environment where our employees can grow and contribute, and refuse to discriminate on the basis of race, color, religious belief, sex, age, national origin, citizenship status, marital status, union status, sexual orientation, or gender identity. To us, ""diversity"" isn't just a buzzword, but an important element of our core principles and key business practices. We believe that diverse companies innovate better and think more creatively than homogenous ones because they take into account a wide range of viewpoints. For us, greater diversity doesn't mean better headlines or public images - it means increased adaptability and profitability.",4.4,"Schrödinger
4.4","New York, NY","Portland, OR",201 to 500 employees,1990,Company - Public,Internet,Information Technology,$50 to $100 million (USD),-1
Machine Learning Engineer (Imaging),"$62K-$108K
(Glassdoor est.)","Position Summary

Samsung Austin Semiconductor is one of the most advanced semiconductor manufacturing facilities in the world with more than 3,000 employees and 2.45 million square feet of floor space. Samsung Austin Semiconductor has broad semiconductor process technology offerings serving customers in various application areas including mobile, consumer, networking/high performance computing, Internet of Things, RF and automotive. Since 1996, SAS has invested approximately $17 billion in its Austin, TX campus, making it one of the largest direct foreign investments in United States history. Samsung Austin Semiconductor is a US-based subsidiary of Samsung Electronics Co., Ltd. The Austin facility is one of the few semiconductor plants the company has outside South Korea. Visit www.samsung.com/us/sas.

SAS is focused on being the World’s Best Foundry product supplier.

Role and Responsibilities
Our company creates some of the world’s most high-tech semiconductor manufacturing line for CPUs, GPUs, and IoT sensors.
We are currently in search of a Machine Learning developer to find and optimize signals from data from various resources, transform data, implement new features, and design machine learning models for business value.
Looking for a Machine Learning engineer with a passion for data, and enjoys being a part of a small high performing team developing and maintaining in-house models.
Be a member of the Defect Engineering Systems group which provides data summarization across many key dashboards.
Helps by directing the focus of the factory and continuously improving time to detection, accuracy, and throughput.
Working with key members of the organization to obtain stronger predictive data.
Feature Engineering to improve model performance.
Attend team meetings and offer solutions to challenging problems.
Collaborate with peer data scientists across the organization on best methods for data modeling.
Other duties as needed.
Experience building and extending machine learning models.
Experience with open source frameworks (Tensorflow, PyTorch).
Comfortable working with command line interfaces (Ubuntu experience a plus).
Ability to summarize results to a broad range of audiences.
Ability to learn quickly and keep deadlines while applying good design principals.
Experience with CNNs, Auto-Encoders, Manifold Learning, and Recommendation Systems.
Ability to use VM container software (Docker / Kubernetes).
Familiar with Atlassian software (BitBucket, Confluence, Jira).
Semiconductor process knowledge (specifically defect domain knowledge: detection, classification, determining impact) is a plus.
Enjoy solving challenging problems and eager to learn new technologies.
Working with a small highly motivated team to develop and implement new ideas.
Work days and hours: M-F, 8am to 5pm/1st shift
Skills and Qualifications
B.S or M.S Engineering Degree.
3- 7 years of Data Science/Machine Learning experience is a must
Proficient with Python, SQL, and data manipulation is required.
Prefer experience with Tensorflow image processing and modeling
Excellent communication, interpersonal, initiation, & troubleshooting skills.
Fundamental understanding of analytic techniques is a plus.
Fast learner with the ability to develop and maintain.
* Please visit Samsung membership to see Privacy Policy, which defaults according to your location. You can change Country/Language at the bottom of the page. If you are European Economic Resident, please click here.

* Samsung Electronics America, Inc. and its subsidiaries are committed to employing a diverse workforce, and provide Equal Employment Opportunity for all individuals regardless of race, color, religion, gender, age, national origin, marital status, sexual orientation, gender identity, status as a protected veteran, genetic information, status as a qualified individual with a disability, or any other characteristic protected by law.",3.6,"Samsung Electronics
3.6","Austin, TX","Suwon, South Korea",10000+ employees,1969,Company - Public,Computer Hardware & Software,Information Technology,$10+ billion (USD),-1
"Big Data Machine Learning Engineer in Chicago, IL at Key Bank","$69K-$127K
(Glassdoor est.)","Job Description

ABOUT THE JOB

The Decision Sciences team is part of the Enterprise Payments and Analytics organization. Its mission is to lead KeyBank’s journey to become an innovative, data driven enterprise by building advanced analytics solutions for solving business problems. Our experienced team of AI/ML and Data Science practitioners focuses on engaging, enabling, and empowering decision-makers across the enterprise by developing, managing and supporting advanced analytics products and scalable digital solutions, such as real time and on demand predictive models and prescriptive analytics, and continuously researching, specifying, and deploying next-generation analytics capabilities. We are an internal consulting and services organization that works directly with users across the firm, including Lines of Businesses and partners in Enterprise Strategy, Marketing, Data Analytics, and Enterprise Architecture, to facilitate the development of innovative solutions that help KeyBank compete and win with analytics.

The Big Data ML Engineer fills a critical data, analytics, technology support, and innovation role for the business analytics and advanced analytics functions within the organization. The Engineer is primarily responsible for end-user product development, deployment in production framework, data analytics technical support as well as leveraging best tools and techniques, and end-user training of new emerging analytics open source technologies. S/he is also the primary conduit for identifying, researching, and evaluating new and innovative technologies that enhance the organization’s enterprise analytics and advanced analytics capabilities.
ESSENTIAL JOB FUNCTIONS

The ML Engineer works both independently and in collaboration with a cross-functional team of Data scientists and solution system architects to effectively develop, deploy, monitor, manage, and support AI/ML models and advanced analytics technology, data infrastructures, and underlying analytics use cases—primarily focused around open source technologies including cloud infrastructures. This individual evaluates short/long-term business needs required to support key business goals and priorities and works to ensure Advanced analytics solutions are built and deployed in an effective and efficient manner on Key Enterprise systems. Under the guidance of the Group’s Director and in cooperation with partners in decision science, technology, and data the Engineer will coordinate the development of on-premise and cloud-based analytical non-production and production infrastructure and tools providing computational and statistical capabilities to enhance business results and monetize on key data assets for business decision management solutions. The Engineer will be working closely with data scientists, data mining experts, and business partner supporting the design of experiments and analytics, data sampling and mining, verification of data quality and information integrity, and best practices around the development and deployment of predictive/prescriptive models, DevOps operational systems and practices, and data visualization solutions. The Engineer has responsibility for advising data scientists, Agile project teams, and solution architects in the integration of analytical models/methods into decision management solutions. The Engineer will assist peers in best practices and in the selection and integration of appropriate tools to support required analytic products in close coordination with the organization’s AI/AutoML analytics, digital intelligence engineers, solution/data architects, data integration developers, and data science community ensuring tight integration of functionality and toolsets.
REQUIRED QUALIFICATIONS
Bachelor's degree in computer science, electrical/electronic engineering or other engineering or technical discipline is required.
Minimum of 8 years of experience in IT and Big data software development is required
Minimum 3+ Predictive Analytics model implementation experience in production environments using ML/DL libraries like TensorFlow, H20, Pytorch, Sci-kit Learn.
Experience in using NLP, Bi/Visual analytics, Graph Databases like Neo4j/Tiger Graph is preferred,
Experiences in designing, developing, optimizing and troubleshooting complex data analytic pipelines and ML model applications using Spark, HDFS and other big data related technologies
Programming in Python, R or Scala using distributed frameworks like PySpark, Spark, SparkR
Working Knowledge in IDE environment/Tools like Jupyter, R Studio, GitHub, Docker, Jenkins
Solid knowledge of data warehousing such as Hadoop, MapReduce, HIVE, Apache Spark, as well as cloud base data storage: Google Cloud Storage with various formats (Parquet, JSON, ORC, Avro, delimited)
Solid understanding of databases such as DB2, Oracle, Teradata, MySQL, PostgreSQL
Extensive Experience with R and Python including language-specific and data science-oriented packages required.
Experience with Hadoop and Spark cluster, SparkSQL, Spark ML, and other third-party machine learning algorithms using Scala, PySpark and/or SparkR
Experience with Linux/Unix required
Exposure to Google Cloud services- GCP or any cloud environment.
Working experience on Apache Airflow
Experience in enterprise scale analytic solutions development and deployment with high performance, scalability, availability & reliability.
Certified Professional Google Data Engineer preferred
Candidate must be a self-starter and creative problem-solver with an innovative and curious mindset.
Must have a working knowledge of advanced technology uses cases in financial services including machine learning, interactive data visualization, cloud computing, and streaming analytics.
Strong communication skills and the ability to interact and collaborate with all levels of the organization.
A broad, enterprise-wide view of the business and varying degrees of appreciation for strategy, processes and capabilities, enabling technologies, and governance
The ability to recognize pain points within the organization, functional interdependencies and cross-silo redundancies. Those issues may exist in role alignment, process gaps and overlaps, and business capability maturity gaps
The ability to apply architectural principles, methods, and tools to business challenges
The ability to create capability portfolios and technical roadmaps addressing gaps
The ability to understand and recognize the economics of technology and the business goals
The ability to perform industry analysis and identify business and technology trends specific to the portfolio
The ability to visualize and create high-level models that can be used in future analysis to extend and mature the business architecture
The ability to assist business case creation and realization by aligning business goals to organizational capabilities
Strong situational analysis and decision-making abilities
Financial and/or Banking background preferred.
FLSA STATUS:Exempt

KeyCorp is an Equal Opportunity and Affirmative Action Employer committed to engaging a diverse workforce and sustaining an inclusive culture. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or veteran status.

42178BR",3.4,"KeyBank
3.4","Chicago, IL","Cleveland, OH",10000+ employees,1849,Company - Public,Banks & Credit Unions,Finance,$5 to $10 billion (USD),-1
Software engineer / Data scientist,-1,"CarbonPlan is a non-profit working on the data and science of carbon removal and climate solutions.

We aim to ensure the quality, scientific integrity, and transparency of climate solutions, and we work across a range of approaches — forests, soil, air capture, mineralization, energy, and more. We analyze solutions based on the best available science and data and build open source tools and data products. We work directly with decision makers across the public and private sector to help them achieve ambitious climate goals. You can read more about our work on our website.

As the first Software engineer / Data scientist on our Technology team, you will contribute to CarbonPlan’s core technical and scientific activities, filling a hybrid role that includes data engineering, data analysis, machine learning, data visualization, and web development. Our core software tools are open source, and we build visualizations for broad audiences. If you’re excited about being part of a small and scrappy team tackling big problems, please apply!

You will
Design and build data analysis tools and rich interactive data visualizations on carbon removal and other climate solutions
Interact closely with CarbonPlan’s entire team, including the strategy and policy side of our work
Produce open source tools and public datasets
Learn about climate science and carbon removal technology
Contribute to existing open source software libraries
You should have:
Passion about our mission
3-5+ years experience with scientific Python
1-3+ experience with statistical modeling and machine learning in an applied setting
A portfolio of your work (e.g. open source code, websites, papers, etc.)
You’ll be an especially good fit if you have:
Web development experience in Javascript using React, Vega/D3, and/or WebGL
Data analytics experience in Python with Pandas, Xarray, and/or Dask
Machine Learning experience using frameworks such as Scikit-Learn, Pytorch, and/or TensorFlow
Geospatial data analysis and visualization experience
Background in one or more relevant domains (ecology, material science, biogeochemistry, energy technologies or systems, climate science, climate policy, social justice)
Software development experience using version control, continuous integration, etc.
You should include in your application:
A link to your portfolio (GitHub, website, etc.).
Your CV or a link to your LinkedIn profile
A paragraph on why you are excited about CarbonPlan
CarbonPlan is an equal opportunity employer, and we are committed to building an inclusive and diverse workplace. Addressing climate change requires confronting systems that create inequity and injustice, and doing so will require a team with culturally diverse perspectives. All qualified applications — regardless of race, color, gender, religion, age, sexual orientation, sexual identity, national or ethnic origin, disability, marital status, veteran status, and any other occupationally irrelevant criteria — will receive full consideration. We especially encourage applications from individuals from underrepresented groups in science, technology, and environmental organizations.

We are committed to providing competitive compensation and comprehensive benefits to our employees. We offer fixed salary levels based on experience and role to minimize biases in compensation and to ensure team members are paid the same for doing the same work. We expect this position to be at an annual salary of $90,000 USD based on the experience required for the role. As we are still developing our team, we may also consider a more senior position in a related role, so please still consider applying if this description is not an exact fit.

We are not currently able to sponsor a visa for this position, and therefore can only consider applications from people who are already authorized to work in the United States. We are based primarily in San Francisco, but currently work remotely. The hiring manager for this role is in Seattle. Remote work from any location on Pacific or Mountain Time works for us!",3.0,"CarbonPlan
3.0",United States,"London, United Kingdom",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Software Engineer,"$39K-$85K
(Glassdoor est.)","Job Description:What makes Gartner a GREAT fit for you? When you join Gartner, you'll be part of a fast-growing team that helps the world become smarter and more connected. We're the world's leading research and advisory company, achieving consistent double-digit growth by steering clients toward the right decisions with business and technology insights they can't find anywhere else. Our associates enjoy a collaborative work environment, exceptional training and career development - as well as unlimited growth opportunities. If you like working with a curious, supportive, high-performing team, Gartner is the place for you.Software EngineerGartner is looking for a software engineer to focus on the data engineering. This person will be a part of team supporting Gartner's client facing experience. This includes supporting both the gartner.com website as well as other engagement applications like email. The ideal candidate will have experience capturing, storing and processing both structured and unstructured data using different tools and technologies. In this position candidate will be working closely with Data Analysts and Data Scientists to gain insight on our client experience as well as build machine learning applications that improve those experiences.Qualifications and Technical Skills* University degree in Bachelor of Engineering with 2+ years' experience or a Master's degree in CS with 1-2 years of experience in software development* Experience in developing application with Python or Java* Strong desire to improve upon their skills in software development, frameworks and technologies* Experience with version control tools (Git, Subversion)Preferred Skills:* Experience with Big Data tools like AWS EMR* Experience with cloud-based platforms (AWS)Operational Skills:* Should be able to interact well with both internal associates and external clients in resolving operational issues.* Must be able to provide accurate estimates of technology work and deliver high quality work on schedule* Identify systemic operational issues and resolve themJob Requisition ID:46648By submitting your information and application, you confirm that you have read and agree to the country or regional recruitment notice linked below applicable to your place of residence.Gartner Applicant Privacy Link: https://jobs.gartner.com/applicant-privacy-policyFor efficient navigation through the application, please only use the back button within the application, not the back arrow within your browser.",3.6,"Gartner
3.6","Arlington, VA","Stamford, CT",10000+ employees,1979,Company - Public,Consulting,Business Services,$2 to $5 billion (USD),"Salesforce, Boston Consulting Group, ZS Associates"
"Senior Software Engineer, Bioinformatics",-1,"Do you have a passion for analyzing scientific data and broad experience crafting bioinformatics pipelines? Do you think that cancer treatment should be personalized and want to accelerate that reality? Are you looking for a mission driven company where your work will directly impact human lives?Notable Labs seeks a lead bioinformatics engineer to found our data science team. As a technical leader in a quickly growing startup, you will build machine learning tools and data pipelines, advise on software architecture and experimental design, analyze proteomic and cell imaging data, and drive the data strategy foundational to our mission: all cancer is treatable. We're building a translational drug discovery platform to identify treatment options for relapsed and refractory cancer patients -- starting with Acute Myeloid Leukemia -- to address the long tail of cancer treatment. We have a highly automated lab in San Francisco running on our custom software (Python/Django, JavaScript/React, PostgreSQL), and are currently testing relapsed/refractory cancer patients as well as samples from a variety of biopharma partnerships.What You'll Do:* Build and design machine learning pipelines for the automated analysis of flow cytometry and cell imaging data* Develop a statistical process control framework for flow cytometry validation and laboratory quality control* Analyze production and research flow cytometry, cell imaging, and drug response data to report to clinicians and biopharma partners* Design algorithms to optimize our combinatorial drug search and inform drug development hypotheses* Collaborate with the science team on the design and analysis of research experiments* Work in a dynamic interdisciplinary environment on multi-functional project teams of: software engineers, automation engineers, data scientists, bioengineers, computational biologists, process engineers, clinical and R&D scientists, etc.* Regularly present your results and analysis at group and individual meetings as well as externally through conferences and publications* Use a modern data stack to analyze data and develop methods: Jupyter, Pandas, SciPy, NumPy, SciKits, Python, Docker, R, etc.Who You Are:* Love wrangling complex biological datasets to derive innovative insights and are passionate about personalizing the treatment of cancer* Deep knowledge of statistics, machine learning, and data analysis as well as a broad working knowledge of common bioinformatics tools/methods* PhD in bioinformatics, computational biology, {bio}statistics, or equivalent experience and training* 3+ years of postgraduate experience working in a production environment with large data sets using Python/Jupyter or R* Have contributed significant publication quality work that is demonstrated through your publication record, personal web page, GitHub account, or prior experience* Solid programming skills and proficiency with Unix, Git, and other command line tools* Familiar with machine vision and image analysis algorithms and researchNice to Haves:* Flow cytometry or cell imaging data analysis experience is a plusWhat we can offer you:* The opportunity to directly fight cancer, one patient at a time* Exposure to experts from diverse backgrounds ranging from engineering, data science, operations, clinical medicine, patient advocacy, and beyond* Work in a collaborative environment with a team dedicated to both personal and scientific growth and development* Highly competitive, early stage company compensation package, with incredible growth opportunities* Outstanding healthcare benefits* Flexible vacation policy* did we mention daily catered lunch?More About Us:Notable Labs is a precision medicine company that has a translational drug discovery platform focused on identifying therapeutic options for relapsed and refractory cancer patients.Our clinical research lab helps oncologists identify personalized combinations of existing FDA-approved treatments for patients. We've developed a high throughput robotic flow cytometry lab platform that screens thousands of FDA-approved drug combinations against the patient's own cancer cells to help predict safer and more effective cancer treatments. Our lab has completed initial feasibility studies with clinicians in relapsed Acute Myeloid Leukemia & Myelodysplastic Syndrome, with an 84% predictive rate. Focusing on individual patients and existing treatments, we're working to discover novel uses of drugs and defining mechanisms underlying cancer progression and drug resistance.Our research and development platform extends our clinical research to drug discovery, testing novel compounds with primary patient samples for pharmaceutical and biotechnology companies. Using our automated, high-throughput, multi-parametric drug screening research platform, industry partners can assay the biological impact of novel compounds on primary cells in a physiologically relevant environment. This helps our partners stratify patients by their predicted responsiveness, increasing the probability of successful clinical development. We are actively partnering with pharmaceutical companies that have preclinical and clinical stage drug pipelines in Acute Myeloid Leukemia, Myelodysplastic Syndrome, or related hematological malignancies to profile experimental drug activity in patient samples.Our investors include Builders Venture Capital, Founders Fund, First Round Capital, Y Combinator, several prominent angels and seed-stage funds, and Accelerate Brain Cancer Cure, a venture philanthropy firm founded by Steve Case. We have offices and a laboratory in San Francisco's SoMa district.At Notable Labs we value diversity and are an equal opportunity employer. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.",5.0,"Notable Labs
5.0","San Mateo, CA","San Francisco, CA",1 to 50 employees,-1,Company - Private,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,Less than $1 million (USD),-1
Machine Learning SW Engineer,-1,"The Artificial Intelligence, Machine Learning (AI ML) Software Engineer will be responsible for supporting Artificial Intelligence, Machine Learning, and Data Science solutions for our client. We""re looking for engineers with a passion for Artificial Intelligence to help drive a new generation of data and machine learning enabled services and products to impact healthcare. You will enjoy working with a highly talented and diverse team of data scientists and engineers specializing in deep learning, active learning, and classical machine learning on one of the richest data sets in US healthcare. You'll be equipped with nearly limitless cloud compute resources and be expected to deliver business impact through implementation of a large pipeline of AI models.The ideal candidate will have a background in Python, have experience working with large data sets, and have experience in building and deploying data-driven solutions. You are focused on results, a self-starter, able to put the team-first, and have demonstrated success in using data science to develop and deploy solutions with a focus on impact. Responsibilities Provide technical leadership and implementation for Software Engineering projects supporting our AI and machine learning goals Modifies, implements, tests, and supports all product related technology and functionality, including software infrastructure in an AWS hosted environment Demonstrates strong drive to learn and advocate for development best practices (TDD, code reviews, continuous integration, etc.) Communicates proactively and effectively with team members and other product stakeholders in a highly Agile environment Self-starter that will take tasks and accomplish them with little oversight according to timelines and budgets agreed upon with business and technology stakeholders Required Skills 2+ years"" experience working on applications of machine learning with strong to expert ability in Python as a primary language Experience building automated processes that are supportable, monitored, and enterprise-scale Experience working with and integrating services from popular ML packages such as Keras, TensorFlow, XGBoost, SciKit Learn Above average capabilities with cloud computing techniques or tools such as S3, EC2, EMR, SageMaker, ECS, Lambda, IAM SQL design and development skills Additional KnowledgeSkills Spark or Pyspark experience preferred Experience buildingconsuming REST web services Demonstrated initiative with learning new technologies Exceptional interpersonal and communication skills",4.4,"Armada Group, Inc.
4.4","Emeryville, CA","Santa Cruz, CA",51 to 200 employees,1995,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,"TEKsystems, Akraya, Intelliswift"
AI/Machine Learning Data Security Engineer (Louisville or,"$49K-$80K
(Glassdoor est.)","Description

The Data Governance Office (DGO) at Humana is seeking an AI and Machine Learning Data Security engineer to support the appropriate and secure use of information assets. DGO coordinates the synthetic data capability for the enterprise that creates widely usable and anonymized data sets by mathematically modeling production data and generating replicas of that data that retain the rich relationships between the data components without compromising individuals’ privacy. The synthetic data capability requires application of generative neural network methodologies supported by considerable amounts of compute, memory, and storage resources within a cloud platform to meet the dynamic demand of the multivariate regression processes. Humana is seeking a Data Science Engineer with AI and Machine Learning experience (particularly in Azure) to operate these processes and to do so with data security disciplines to protect the highly sensitive data required for modeling while in that process.

Responsibilities

Responsibilities

The successful candidate will work within the Machine Learning environment at Humana and with that team to perform activities in support of and related to the build out, maintenance, and enhancement of the Synthetic Data resources. This is a challenging environment that must innovate while respecting the rigors, policies, and constraints of a corporate analytical facility. The Machine Learning team operates in an open environment that encourages sharing of ideas, code, feedback, and documentation of their work.
Tooling includes:
Python, SQL, Bash, PowerScript, Scala
SQL Server, Hadoop, PySpark, Kafka, Databricks
RedHat Enterprise Linux, Windows, Docker, Azure Kubernetes Services
Git, Azure DevOps, Gira, Confluent
Job Description
Design, build out, maintain, monitor, and enhance the Synthetic Data environment in Azure
Interface with Data Scientists, Business Users, and Developers to support their synthetic data requests
Interface with the synthetic data engine vendor(s) to maintain and enhance the operation of their engine in the Azure platform
Research and develop enhancements to the pre-processing of data sets for introduction to the synthetic data engine
Periodically research and present emerging synthetic data innovations from the field to the Data Science community
Mentor and train Data Scientists and Engineers within Humana’s analytics community to operate synthetic data capabilities
Role Essentials
BS in Computer Science, Data Science or related field
5 or more years of experience designing, developing, and testing software applications and infrastructure
3 or more years of machine learning experience
Experience writing maintainable, testable, production-ready, and documented Python code
Experience in big data platforms (Hadoop, Spark, Hive, etc. . .) and big data formats (Parquet, Avro, etc. . .)
Experience with secure development and security features required by cloud infrastructures
Preferred Qualifications
Terraform deployment of Azure infrastructure configurations
Experience with deep learning libraries and frameworks (TensorFlow, PyTorch, Keras, etc. . .)
Master’s Degree in Computer Science, Data Science or related field
Scheduled Weekly Hours

40",3.6,"Humana
3.6","Boston, MA","Louisville, KY",10000+ employees,1961,Company - Public,Insurance Carriers,Insurance,$10+ billion (USD),"Cigna, Aetna, UnitedHealth Group"
Data Engineer,"$68K-$128K
(Glassdoor est.)","Job DescriptionDesign, build and maintain high-performance, fault-tolerant, and scalable data pipelines for business reporting using Microsoft Azure Cloud Services and Microsoft DevOps using Agile software. Build a system that builds and evaluates machine learning models at scale. Work with technologies such as SQL, Azure and/or Kubernetes to build a data platform for projects. Work with data scientists to design and implement advanced statistical models and machine learning pipelines. Build automated tools to help answer questions about impact and design and manage queries from stakeholders. Translate end user requirements into Power BI reports and dashboards and analyze impact of product offerings using Power BI. Collect data from sources such as API, internal data source, and third party data source. Investigate data interactions and dependencies across complex data pipelines and transformation to validate assumptions and find sources of problems.QualificationsRequires: Bachelor's degree in Computer Science or Electrical or Electronic Engineering and 5 years' experience as above or as an EDI Administrator or Programmer Analyst using similar skills as above.Not available to persons needing sponsorship for employment.Employment TypeFull Time",3.5,"American Modern Insurance Group
3.5","New York, NY","Amelia, OH",Unknown,1994,Subsidiary or Business Segment,Insurance Carriers,Insurance,$25 to $50 million (USD),-1
Software Development Engineer (Machine Learning and Big Data) - FinTech,-1,"Do you want to be part of a team dedicated to building machine learning applications that process billions of dollars a day using the latest technology? Do you want to measure the impact of your work in terms of millions of dollars?

In Finance Technology, we build machine learning systems that look through billions of dollars in transactions from across Amazon. Our goal is to increase the adoption of machine learning across Finance. To do this, we build machine learning applications which use the latest techniques for forecasting, classification, and anomaly detection purposes. Our current applications range from finding anomalies in data all the way to predicting how much cash to keep in an account.

In a typical day, you will work with machine learning scientists, other software engineers, and business groups across Amazon Finance. You will work with terabytes of data and develop machine learning pipelines which process billions of dollars. We partner with our customers, so you will meet with them directly to gain direct feedback on your work. Our team and customer are comfortable trying new ideas, so you will test your ideas in the real world.

As a senior member of the team you will design, develop, and launch core product features. You will have significant influence on our overall strategy by helping define product features, drive the system architecture, and spearhead the best practices that enable a quality product. Creating reliable, scalable, and high performance machine learning pipelines is second nature for you. You will hire and mentor junior engineers and enjoy advocating and advising other teams to adopt the machine learning technology you developed.
Basic Qualifications
3+ years of programming experience with at least one modern language such as Java, C++, or C# including object-oriented design
2+ years of experience contributing to the architecture and design (architecture, design patterns, reliability and scaling) of new and current systems
4+ years of professional software development experience
Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.",-1,Amazon Corporate LLC,"Seattle, WA",-1,-1,-1,-1,-1,-1,-1,-1
100% REMOTE Data Engineer,-1,"100% REMOTE Data Engineer
We are one of the fastest-growing medical device companies in the world! We are publicly traded, have a global presence, but still operate like a startup. We have an agile, fast-paced team and are looking for Data Engineers that thrive in that kind of environment.

Our Data Engineering team is growing and we have urgent openings for Mid-to-Senior level Data Engineers to join our team!

100% Remote.

If this sounds like a good fit, please apply today!
What You Will Be Doing
- Build enterprise-level ETL pipelines
- Develop real-time streaming pipelines and queue-based event processing systems
- Work closely with machine learning and data scientists to scale model training and explore new data sources and model features
What You Need for this Position
Must have:
- 3+ years of experience as a Data Engineer or in a similar role
- Experience with data modeling, data warehousing, and building ETL pipelines
- Software Engineering background
- Python
- Spark
- AWS

Nice to haves:
- Kafka
- Pandas
- Airflow
- Snowflake
What's In It for You
Base Salary: $140,000 - $185,000
- Stock options
- Bonus
- Quarterly flights to our headquarters
- Health, Dental, and Vision
- 401K
- Unlimited PTO
- Remote
So, if you are a Data Engineer with experience, please apply today!
-
Applicants must be authorized to work in the U.S.


CyberCoders, Inc is proud to be an Equal Opportunity Employer

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, protected veteran status, or any other characteristic protected by law.

Your Right to Work In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification document form upon hire.",4.2,"CyberCoders
4.2","Oakland, CA","Irvine, CA",201 to 500 employees,1999,Subsidiary or Business Segment,Staffing & Outsourcing,Business Services,$100 to $500 million (USD),-1
Data Engineer,-1,"MidSenior Level Data Engineer 6 month contract to hire Lincolnshire, IL (Remote until Covid restrictions are lifted) Our client is looking for a Data Engineer to join their AI services is a central group innovating new AI centric products, supporting Business Units on program acceleration and building an ecosystem that will allow client to scale its AI components across the business and partners. As a Data Engineer in computer vision you will have a unique opportunity to design and manage all of our data infrastructure used by our research team to solve real-world applications. You will face a variety of challenges from automating data acquisition and annotation to evaluating our latest cutting-edge algorithms, and you will have access to the best hardware to do the job. We are focusing on leveraging AI to help solve real-world problems on real-world data. This means embracing noise and complexity, both at the data level and at the methodological level. You will collaborate closely both with both software developers and research scientists to commercialize our products and manage data collection and management requirements. You will have experience in machine learning and management, either through your studies or industrial RD projects and will be equally adept at developing production-quality code. Must haversquos in a Candidate bull Computer vision and applications of machine learning. bull Collecting, QCing, and analyzing huge datasets. bull Using the best tools to streamline data acquisition and processing. bull Assisting research scientists achieve their goals bull A getting-it-done attitude with a desire to both push the boundary of fundamental knowledge and turn it into great products. bull A degree in computer science or a quantitative field and at least one year of industrial experience working with data. bull Strong math skills, a problem-solving aptitude and desire to automate bull Experience of scientific programming and libraries relevant to image and video processing and management, for example OpenCV. bull Experience with at least one programming language such as Python, C++, etc. bull Experience working in a diverse and international team.",4.5,"On-Demand Group
4.5","Lincolnshire, IL","Minneapolis, MN",51 to 200 employees,-1,Company - Private,IT Services,Information Technology,$10 to $25 million (USD),-1
Big Data - Software Engineer,-1,"Job TITLE: Big Data - Software Engineer

Location: Mountain View, CA

Term: Contract

Skill: Description:

We are seeking for an accomplished, enthusiastic Big Data Engineer to join the Client's eCommerce team. This exciting position involves many key engineering challenges as we deal with huge data sets (Billions of Transactions and Petabytes of data) to impact real-time customer activities.

Responsibilities and scope of this role include:
Build scalable, high- performance, and efficient pipelines and workflows that are capable of processing billions of transactions and real-time customer activities.
Work with big data and provide to our data scientists the right tools, data marts and rollups to build their machine learning models.
Fluent in Pig and/or Hive with experience in building UDFs, Pig and Hadoop streaming.
Build automated reports that can help the team to proactively identify quality and/or coverage problems in releases or new versions of our models.
Apply knowledge of Azkaban, Oozie or Hamake for workflow management and job scheduling.
Work on Data Warehousing architecture and data modeling best practices.
Qualifications
A Master of Science degree or equivalent in Computer Science, Computer Engineering, Electrical Engineering or related field plus 1+ years of software engineering experience; OR a Bachelor of Science degree with 5 years of software engineering experience.
Must have demonstrable, programming proficiency in at least one of the following: Java, C/C++, or Python.
Deep understanding of Map Reduce framework & Hadoop.
Fluent in Pig and/or Hive with experience in building UDFs, strong scripting ability.
Expert understanding of ETL techniques.
Knowledge of Azkaban, Oozie or Hamake for workflow management and job scheduling.
Must be team oriented and collaborative to interact with both managers and cross functional teams.
Ability to thrive in a fast paced environment on multiple projects in various phases and under tight deadlines

Experience: -

Education: -",4.0,"Flexton
4.0","Mountain View, CA","San Jose, CA",51 to 200 employees,2007,Company - Private,IT Services,Information Technology,$10 to $25 million (USD),-1
Senior Machine Learning Engineer,-1,"ZEFR is hiring! We are hiring a Data Scientist to be involved in building and optimizing large-scale systems to acquire, process, store, and understand multiple terabytes of YouTube and other social media data. This role is an important part of the rapidly growing demands of being the leader in VideoID technology for content owners and brands. In this role you will use advanced natural language and computer vision techniques to extract and understand tens of millions of rows of data. We are really looking for someone who is passionate about cutting edge research in the machine learning field. We want an individual who is able to digest research papers and implement interesting ones. This is a role where we both expect to learn from you and have you learn from us!Here's what you'll get to do:* Participate as a member of the Data Science team, work closely with other data scientists, engineers, and product managers* Design, implement, test, and productionalize both supervised and unsupervised machine learning models* Make use of NLP and image processing algorithms to help better understand our data* Prototype creative solutions quickly, test theories, evaluate feature concepts, and iterate rapidly* Get your models into a large scale engineering system including automatic retraining and model deployment.Here's what we're looking for:* A degree in a science discipline. While Computer Science and related fields are common we are actively looking for individuals who have demonstrated their saavy in data in other fields as well. A strength in Machine Learning, Information Retrieval, Natural Language Processing, and Image Processing is a plus.* Ability to think critically about an ill posed problem and come up with creative solutions* Desired experience in developing end-to-end machine learning pipeline from data exploration, feature engineering, model building, performance evaluation, and online testing with large data sets* Desired experience with large-scale data analysis frameworks: Hadoop, Spark, SQL* 3+ years of experience with at least one dynamically typed language, and one statically typed language. Here at ZEFR we make use of primarily Scala and Python.* Cloud computing infrastructure on Amazon is a plus* Foundation in data structures, algorithms and software design* Openness to new technologies and creative solutions",3.3,"Zefr
3.3","Venice, FL","Venice, CA",201 to 500 employees,-1,Company - Private,Motion Picture Production & Distribution,Media,$10 to $25 million (USD),-1
Data Scientist / Engineer (TRADOC),"$100K-$134K
(Glassdoor est.)","Secure our Nation, Ignite your Future

The Data Scientist/Engineer duties include:
Work with large data sets to better understand the changing worldwide geopolitical and tactical level military landscape. Use a variety of data mining/data analysis methods and data tools to build and implement models, using/creating algorithms and creating/running simulations.
Work with stakeholders to identify opportunities for leveraging data to drive data driven decision making
Mine and analyze data from existing databases to drive decision making
Assess the effectiveness and accuracy of new data sources and data gathering techniques.
Develop custom data models and algorithms to apply to data sets.
Use predictive modeling
Coordinate with different functional teams to implement models and monitor outcomes.
Develop processes and tools to monitor and analyze model performance and data accuracy.
Minimum qualifications:
Must be a U.S. citizen
Bachelors Degree
5 years of experience manipulating data sets and building statistical models
Familiar with the following software/tools:
Coding knowledge and experience with several languages: C, C++, Java,
JavaScript, etc.
Knowledge and experience in statistical and data mining techniques: GLM/Regression, Random Forest, Boosting, Trees, text mining, social network analysis, etc.
Experience querying databases and using statistical computer languages: R, Python, etc.
Experience creating and using advanced machine learning algorithms and statistics: regression, simulation, scenario analysis, modeling, clustering, decision trees, neural networks, etc.
Experience with distributed data/computing tools
Experience visualizing/presenting data for stakeholders
Strong problem-solving skills
Experience using statistical computer languages (R, Python, etc.) to manipulate data and draw insights from large data sets.
Experience working with and creating data architectures.
Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks.
Knowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) and experience with applications.
Excellent written and verbal communication skills for coordinating across teams.
A drive to learn and master new technologies and techniques
Excellent organizational skills
Sedentary work.
The person in this position needs to occasionally move about inside the office to access file cabinets, office machinery, etc.
Constantly operates a computer and other office productivity machinery, such as a calculator, copy machine and computer printer.
The person in this position frequently communicates with co-workers, management and customers, which may involve delivering presentations. Must be able to exchange accurate information in these situations

ManTech International Corporation, as well as its subsidiaries proactively fulfills its role as an equal opportunity employer. We do not discriminate against any employee or applicant for employment because of race, color, sex, religion, age, sexual orientation, gender identity and expression, national origin, marital status, physical or mental disability, status as a Disabled Veteran, Recently Separated Veteran, Active Duty Wartime or Campaign Badge Veteran, Armed Forces Services Medal, or any other characteristic protected by law.

If you require a reasonable accommodation to apply for a position with ManTech through its online applicant system, please contact ManTech's Corporate EEO Department at (703) 218-6000. ManTech is an affirmative action/equal opportunity employer - minorities, females, disabled and protected veterans are urged to apply. ManTech's utilization of any external recruitment or job placement agency is predicated upon its full compliance with our equal opportunity/affirmative action policies. ManTech does not accept resumes from unsolicited recruiting firms. We pay no fees for unsolicited services.

If you are a qualified individual with a disability or a disabled veteran, you have the right to request an accommodation if you are unable or limited in your ability to use or access http://www.mantech.com/careers/Pages/careers.aspx as a result of your disability. To request an accommodation please click careers@mantech.com and provide your name and contact information.",4.2,"ManTech
4.2","Fort Eustis, VA","Herndon, VA",5001 to 10000 employees,1968,Company - Public,Research & Development,Business Services,$1 to $2 billion (USD),-1
Machine Learning Engineer,-1,"tl;dr
Spring is accelerating the discovery of therapies for aging and its related diseases. Machine learning is at our core, and we're building a rare computational team that works closely with our biologists, together fighting disease.

Impact
Aging is the single greatest risk factor for the most detrimental diseases on Earth — cardiovascular disease, neurodegenerative disease, pulmonary disease, cancer, muscle wasting, and more — and drugs that slow the biological damage accumulated while aging have the potential to reduce the incidences of these diseases, possibly simultaneously. We believe that in the not-too-distant future, the discovery of therapies for aging will provide some of the most effective tools in history for reducing our burden of disease and extending our healthy lifespan.

Our mission is to dramatically accelerate the realization of that future. And we’re bringing a new set of machine learning tools to bear on this challenge.

Yes, you belong
We are building a cross-functional team. We don't expect you to have a background in biology, just as we don't expect our biologists to be experts in ML. We do expect our teams to work respectfully and closely, learning together every day.

We value building a diverse, inclusive environment and welcome all applicants regardless of gender, sexual orientation, ethnicity, race, education, age, or other personal characteristics.

About you
Experience. You have 3+ years of real-world experience in software development, machine learning, or data science.
Statistical intuition. You're comfortable dealing with data and forming and testing hypotheses. You have a developed sense of whether analysis lacks rigor and how to improve it.
Tends towards ownership. You do anything necessary to solve the problem at hand.
Maturity in face of ambiguity. You help define questions instead of just answering them. You work to resolve ambiguity — and you're comfortable making decisions when it remains.
Crisp communicator. You excel at crisp, concise written or spoken communication. You love learning and teaching others in a cross-functional team (we're biologists, computational folks, and more).
Driven by impact. You're most motivated when working on a problem of important consequence, no matter what's necessary to do so.

Nice to have
Deep learning intuition. You bring intuition about datasets and experiment structures for deep learning from personal experience.
Biological data experience. You bring familiarity with the pitfalls and analytical techniques typically encountered with large biological datasets.
Scientific background. You have cultural familiarity with scientists and labs from personal experience. You know the language of scientists as well as that of the technical world.

Benefits
Competitive salary and equity in a growing, well-funded startup
Excellent medical, dental, and vision coverage
Generous vacation policy
Healthy feedback-focused environment — leadership will have high expectations, regularly share constructive feedback, expect you to grow, and welcome receiving feedback from you

A unique moment
We have deep support from some of the best investors in the world: General Catalyst, First Round, Felicis, Laura Deming's Longevity Fund, pharma/biotech angels, and many more. Our advisors are world leaders in aging research, senior execs at pharma, and top tech entrepreneurs.

And at the same time, we're just getting started. You're joining a team that has the funding needed to be ambitious while still early enough to help define our culture, choices, and success. Our expectations of you — and of ourselves — are high.

To fighting disease, together!",4.0,"Spring Discovery
4.0","San Carlos, CA","Murfreesboro, TN",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Software Engineer - Infrastructure,-1,"LeapYear's secure machine learning platform is deployed by some of the largest enterprises in the world across finance, healthcare, and technology.

Our technology ensures differential privacy, a widely recognized standard of data privacy that enables all data - including sensitive information - to be utilized for analytics, while providing mathematically proven privacy protection.

The LeapYear system is composed of a core set of components that allow private machine learning on data sets that can scale to petabytes. The system includes private algorithms for relational operations, statistical methods and machine learning. A data scientist accesses private data using a Python API. Administration is provided via a web-based GUI or an API.

LeapYear's Infrastructure team builds the tools that build our software and scales our test infrastructure such that all developers can contribute to automated test suites. For deployments of LeapYear, Infrastructure engineers write sophisticated, parameterized installers for enterprise environments, and automate deployment into cloud environments.

We are looking for versatile problem solvers that are interested in developer productivity, automation, and cloud infrastructure.
Responsibilities
Develop greenfield systems and scale existing build system, deployment methods, and cloud infrastructure
Own the full software development lifecycle - problem definition, design, development, testing, demoing, and supporting production use of the features you own.
Conduct and automate deployment testing, concurrency testing, scale testing, and testing of differentially private machine learning algorithms
Partner with product management to define problems and identify iterative solutions
Balance immediate business objectives against long-term architectural vision
Contribute to an engineering-wide culture of code quality and shared responsibility for testing
Requirements
2+ years of general software programming experience, including regular use of major scripting languages (Python, Shell, Ruby)
Advanced knowledge of at least one infrastructure automation tool such as Terraform, Ansible, and Packer
Good understanding of Linux systems administration, command line tools, and various distributions of Linux (Centos, Red Hat).
Experience with Continuous Integration/Continuous Deployment tools (CircleCI preferred)
Experience with services provided by AWS, Azure, or GCP (AWS preferred)
Preferred
System admin experience, preferable enterprise experience
Experience with administering and running Hadoop and Spark clusters
Experience with Kubernetes and Docker
Experience with Maven, Bazel, Gradle, or other modern build systems
Acquainted with and interested in functional programming (Haskell, OCaml, Clojure, Erlang, Scala)
Experience testing the results of statistical analysis, preferably machine learning.
A Few of the Perks
Culture of teaching and learning
Competitive compensation package of salary and equity
Catered lunch every day
Company outings
Build your ideal work station
Generous health insurance plan
Relocation support and visa sponsorship",4.2,"LeapYear
4.2","San Francisco, CA","San Francisco, CA",1 to 50 employees,2015,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Machine Learning Engineer,-1,"Machine Learning Engineer Job Description

At Sippd, our mission is to revolutionize the consumer wine-dining and
eCommerce experience by offering highly-personalized wine
recommendations and scores based on the user’s taste and budget
preferences, both at restaurants and shopping online, across 100,000’s of
wines. We believe in empowering consumers by helping them know which
wines they will like, before having tried them focused on strong and delightful user-experiences and social networks.

Sippd is looking for an experienced Machine Learning Engineer to join our
start-up to continue development of our recommendation models, Computer Vision/Optical Character Recognition (OCR) solution for our Android and Apple/IOS applications and Chrome Browser Extension.

Please see our mobile app product demo here: https://www.youtube.com/watch?v=Re2OBoSMTac
and our Chrome extension product demo here: https://www.youtube.com/watch?v=Wr2K_DlPLT4&feature=youtu.be .

We need our engineers to be able to quickly test hypotheses, train, build test rigs and test models against predefined KPI’s and suggest new measurements approaches. You’ll be a member of a small start up dedicated to creating the world’s first Artificial Intelligence Personal Sommelier.

Essential Duties & Responsibilities include, but are not limited to the
following:

Design, develop, and deploy ML systems to power Sippd’s mobile
application and online shopping solutions at scale.
Extract and transform customer data feeds to be consumed by our ML
models.
Implement rigorous model testing, validation, and optimization
strategies within automated ETL and training pipelines.
Guide A/B testing practices to improve solution performance across all
customer implementations.
About Your Experience:
You have previous experience working as an engineer or data scientist.
You are proficient in at least one programming language. We use
Python.
You have experience crafting and deploying machine learning software
in a cloud environment. We use Amazon Web Services.
You are proficient with both supervised machine learning algorithms.
You have experience with recommendation systems and/or search
engine algorithms and their use-cases.
You understand data structures, data modeling, and the basics of
software architecture.
You enjoy building end-to-end data products leveraging both structured
and unstructured datasets, including images, text, and columnar data.
You are crafty and resourceful in the face of challenging problems.
You are unafraid to ask questions and continue learning.

What You Get
Competitive salary, stock options, paid-vacation
Computer and “get stuff done” office supplies
Remote-work and a flexible schedule
The opportunity to work for the coolest wine technology startup on the
planet!

Job-Type: Full-time

Benefits:

Equity
Flexible Schedule
Paid Time Off
Referral Program

Experience:

Software Development: 2 years (Preferred)
Machine Learning: 2 years (Preferred)

U.S. Citizenship or Green Card is required

Sippd Describes Our Culture as:

Innovative -- innovative and risk-taking
Outcome-oriented -- results-focused with strong performance culture
People-oriented -- supportive and fairness-focused

Company's website:

https://sippd.com/",3.4,"MORI Associates, Inc.
3.4",United States,"Bethesda, MD",51 to 200 employees,1997,Company - Private,Accounting,Accounting & Legal,Less than $1 million (USD),-1
Principal Software Engineer - Machine Learning,"$105K-$179K
(Glassdoor est.)","Manhattan designs, builds and delivers market-leading supply chain technology solutions for leading companies around the world. We help drive the commerce revolution with unmatched insight and unrivaled technology, connecting front-end revenue and relationships with back-end execution and efficiency-optimized on a common technology platform. This platform-based approach is enabling leading companies across the globe to Push Possible® by getting closer to customers and achieving real-world results.

What Drives Us.

We have 3 core philosophies that make up what we call the Manhattan Spirit. These philosophies call on each of us to Focus on the Customer, Seize Every Opportunity, and Never Settle. With these concepts as guides, we have become the most sought-after commerce supply chain solution for companies all over the globe. Our teams are diverse, intelligent, collaborative, and fun! At Manhattan Associates, your role would be unique and importantas all our employees are essential to building success with our clients and our reputation as a gold-standard in Supply Chain solutions. Named consistently as a Leader in the Gartner Magic Quadrant, Manhattan Associates is further expanding its leadership capabilities by investing in easy to deploy, extensible and highly scalable cloud-based solutions.

Where You Will Work

Our R&D team is the heart and soul of Manhattan Associates' product portfolio. They design the future of our products ahead of the curve both technically and operationally over our competitors. You will have the opportunity to interact and collaborate with people from a variety of backgrounds and skill sets to enhance your technical and functional knowledge while on a path for career growth at Manhattan Associates.

What you'll be doing
Provide advanced Python development expertise as a key member of a specialized science-based team focused on the research and development of Manhattan Associates' next generation cloud-native Machine Learning platform
Work with data scientists and data engineers to research, design, implement, extend, tune and scale highly performant Python-based Data Science and Machine Learning libraries, frameworks, algorithms, pipelines, and tooling
Applying Advanced High Performance Python programming practices and techniques
Researching, Prototyping, and Implementing new technologies
Work with team leadership to help define the roadmap for our Machine Learning platform
What's Required of Me?
Bachelor's or foreign equivalent degree in computer science, engineering or a related technical field
A minimum of 5 years experience developing, supporting, and implementing application software with Python
Experience developing with a Python ML stack: numpy, pandas, scikit-learn, keras, tensorflow, pyspark,
Experience working with databases: SQL and/or NoSQL
Experience working in Linux and/or Unix
Experience developing with high performance techniques and technologies:
Parallelization/multiprocessing/distributed computing (MPI, Dask, celery, etc.)
GPU computing with large datasets
Using Vectorization, Cython, Numba, etc.
Experience with developing and deploying on Cloud platforms (e.g. AWS, Google, Azure)
Strong verbal and written communication skills
What Would Make Me Stand Out?
Professional experience developing highly scalable distributed systems using Python
Strong applied knowledge of ML productization, deployment, and lifecycle management, especially within a within a Microservices Architecture
Experience working with microservices architectures and using containerization tools (i.e. Docker, Kubernetes)
Experience developing with C/C++
Experience with Big Data processing, such as: Hadoop, Spark, Flink, BigQuery,
#LI-RK1

Manhattan Associates is at the forefront of the most innovative supply chain technologies in the industry. We pride ourselves on promoting a culture that encourages open minds, fosters superior communication and creates opportunity for growth. We are proudly an Equal Employment Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a veteran. In the United States, Manhattan Associates participates in the Employment Eligibility Verification Program (E-Verify) operated by the Department of Homeland Security in partnership with the Social Security Administration. Participation in the E-Verify Program allows Manhattan Associates to confirm the employment eligibility of all newly hired employees after the Employment Eligibility Verification Form (Form I-9) has been completed.",3.8,"Manhattan Associates
3.8","Atlanta, GA","Atlanta, GA",1001 to 5000 employees,1990,Company - Public,Enterprise Software & Network Solutions,Information Technology,$500 million to $1 billion (USD),"Blue Yonder, Oracle, SAP"
Machine Learning Engineer,-1,"Penn Interactive Ventures (PI) is a real-money interactive gaming company headquartered in Philadelphia. As the digital arm to Penn National Gaming (NASDAQ: PENN), the largest regional casino operator in the U.S., we are poised for fast-paced growth in the sports betting and online casino space and are looking for a Machine Learning Engineer to join our expanding Sportsbook team!
The machine learning engineer will design and develop tools and processes to collect, clean, analyze and monitor player and market data in an effort to provide actionable customer insights. You will work with data scientists to fuel quality decision making across all teams at the company. This role will focus on the aspects of machine learning model creation having to do with producing well-crafted, production-grade software: RESTful API creation, error collection, monitoring, process automation, CI/CD.

Work closely with our Product Managers to understand features/game performance
Work closely with data scientists to tune models and bring them to production
Automate and productize reporting to increase analytical efficiency
Automate machine learning model creation and hypothesis testing
Improve experiment design and analysis to test user behavior hypotheses
Perform exploratory analyses to better understand our users
Build predictive models to predict migrations in player lifecycle
Produce actionable insights from quantitative and qualitative data

BS/MS degree in a quantitative discipline required (math, statistics, engineering, economics, physics and computer science, etc.)
2 - 5 years of relevant analytics/data science experience or equivalent combination of education and experience.
An understanding of free-to-play game systems, economies, currencies & balance a big plus
An ability to embrace an environment that moves quickly, iterates rapidly and celebrates failure as much as success
Strong python skills a must.
Strong SQL knowledge and experience
Proficiency in R is a plus.
Foundational understanding of statistics and machine learning
BONUS
Bayesian statistical inference, deep learning esp. sequence-to-sequence modeling, time series forecasting, natural language processing.

Penn Interactive is committed to helping our team members live their best, healthy life. We offer unique and competitive benefits that help our employees, through a private exchange which allows our team members the ability to choose from several coverage levels and insurance carriers (both local and national carriers). Along with medical, prescription, dental, and vision coverage, there are also voluntary plans available to employees. PI also offers our employees office perks such as free catered lunches, snacks, and beverages in the office.",3.1,"Penn National Gaming, Inc.
3.1","Philadelphia, PA","Wyomissing, PA",10000+ employees,1971,Company - Public,Gambling,"Arts, Entertainment & Recreation",$2 to $5 billion (USD),"Caesars Entertainment, MGM Resorts International"
Software Engineer,-1,"As a Software Engineer at Crisis Text Line, you will help architect, build, and scale the world’s largest, free, 24/7 service supporting people in crisis over SMS and other messaging platforms. The technology you develop will help save lives.

About our team:


Crisis Text Line has served over 140 million messages across four countries, trained more than 30,000 Crisis Counselors, and built the largest mental health conversation data set in the world. Now we’re looking to grow rapidly to provide support in other countries and languages.

Our team aspires to reflect the diverse audiences and voices that our products serve. We think that diversity of perspectives, cultures, and ideas makes everything we build better, and we aim to recruit and hire accordingly.

What you'd work on:
Our modern web platform based on Symfony, Node.js, TypeScript, and React, hosted in AWS, where thousands of people in crisis get support every day by connecting with an individual from our corps of trained volunteers
Other custom-built applications to support our volunteer base and the employees that support them
Multiple integrations with 3rd parties including Twilio, Facebook, Salesforce, Okta
Tooling for developing and serving machine learning models developed by our in-house data scientists
Location: Ideally New York City, Durham, NC, the Bay Area, or the Seattle Area

Requirements

We want you to:
Collaborate. We’re looking for empathetic team players who can communicate with Engineers, Product Managers, and other colleagues with kindness and clarity
Teach. You are generous with your time and experience, can mentor junior engineers, and promote technical best practices
Learn. You are flexible with languages and tools and are willing to learn whatever is necessary to get the job done
Build. You should have 2+ years of experience developing web applications and write straightforward, well-structured code

Why you should join
Impact


We are already at a scale where we save many lives every day. You will be joining Crisis Text Line right as we ramp up our international expansion and expand into more languages. The tools and infrastructure that you build will enable us to expand to serving millions of people around the world.

Team


We currently have three collaborative scrum teams with wonderful, caring teammates. We are remote-friendly and leverage tools like Slack and video conferencing tools for open communication. The organization is small enough where it is easy to make improvements when you see something that could be done better.

Opportunity


Massive international expansion opens up many career opportunities. Some of the technical challenges we are starting to think about currently are moving to a multi-tenant architecture that can scale globally, internationalizing our platform to support more languages, and developing systems for coordinating global collaboration. On top of the technical opportunities, we will be growing our team substantially in the next couple of years which means more opportunities for leadership.

Diversity and Inclusion


At Crisis Text Line, we are committed to diversity and inclusion in everything we do. Not only does this help us build a more effective organization, but it also helps us build more inclusive tools and processes to help serve the diversity of texters and our community of volunteers. We are a woman-founded nonprofit, and promote an inclusive culture that stands against racism, sexism, homophobia, and ableism (to name a few). To be explicit, we strongly encourage applicants of all races, ethnicities, political party associations, religions (or lack thereof), national origins, sexual orientations, genders, sexes, ages, abilities, and branches of military service.

Crisis Text Line is an equal opportunity employer.

Logistics


Location: Flexible (Preferred: NYC, Durham, NC, Bay area, Seattle area)

Our headquarters are in NYC and we have an office in Durham, but we are largely a distributed, remote-friendly organization. That said, you will be expected to work hours that overlap 10 am - 4 pm Eastern Time for shared meetings and communication.

Physical demands: This job requires daily use of a computer

Benefits
3 weeks paid vacation
12 weeks paid parental leave (applies to full-time regular employee who's been with the company for at least 6 months and experiences the birth of a child or the placement of a child for adoption or foster care)
Paid Holidays including
Standard federal holidays
Valentine's day
Your birthday
Half day on Halloween
The week between Christmas and New Years
Paid sick/safe and personal leave
Bereavement leave (in the case of death of an immediate family member)
Family or medical leave
403B retirement plan (the nonprofit equivalent of a 401K) that matches 3% of your salary
FSA and Transit Benefits
A selection of Medical and Dental plans at nominal cost to the employee and additional buy up plans if you want more coverage, and vision plans for a small fee
Professional development stipend
Staff retreats
We host 1-2 staff retreats a year for bonding and the ability to meet coworkers (face-to-face when we’re not dealing with COVID-19)
Volunteer sabbatical
4 week volunteer sabbatical after every 2 years of continuous, full-time work to work with a nonprofit anywhere in the world",3.9,"Crisis Text Line
3.9","New York, NY","New York, NY",51 to 200 employees,2013,Nonprofit Organization,Health Fundraising Organizations,Non-Profit,Unknown / Non-Applicable,-1
Software Development Engineer - Machine Learning,"$110K-$174K
(Glassdoor est.)","Amazon Advertising operates at the intersection of eCommerce and advertising, offering a rich array of digital display advertising solutions with the goal of helping our customers find and discover anything they want to buy. We help advertisers reach Amazon customers on Amazon.com, across our other owned and operated sites, on other high quality sites across the web, and on millions of Kindles, tablets, and mobile devices. We start with the customer and work backwards in everything we do, including advertising. If youre interested in joining a rapidly growing team working to build a unique, world-class advertising group with a relentless focus on the customer, youve come to the right place.

Performance Advertisings vision is to enable advertisers of all sizes with self-service products to build their brand and business at Amazon delivering sophisticated automation for novices and powerful controls for expert users. We are focused on continuous exploration of contexts and creative formats where advertising delivers value to customers and advertisers. Our products are auction based, cost-per-click, and drive traffic within the Amazon shopping experience addressing lower and mid-funnel marketing goals. We deliver billions of ad impressions and millions of clicks daily and are breaking fresh ground to create world-class, highly performant advertising products. We are highly motivated, collaborative and fun-loving with an entrepreneurial spirit and bias for action. With a broad mandate to experiment and innovate, we are growing fast with a seemingly endless range of new opportunities.

Our systems and algorithms operate on one of the world's largest product catalogs, matching shoppers with advertised products with a high relevance bar and strict latency constraints. We work hand-in-hand with Machine Learning scientists to come up with novel solutions that deliver highly relevant ads. We consistently strive to improve the customer search and detail page experiences. You will drive appropriate technology choices for the business, lead the way for continuous innovation, and shape the future of e-commerce.

Job Responsibilities:
· Contribute to the technical direction of our offerings and solutions
· Work with many different technologies across the sponsored products organization
· Design, code, troubleshoot, and support scalable machine-learning pipelines and online serving systems
· Work closely with applied scientists to optimize the performance of machine-learning models and infrastructure, and implement end-to-end solutions
Impact and Career Growth:
· Sharpen your Machine Learning skills
· Opportunity to grow and broaden your technical skills as you work in an environment that thrives on creativity, experimentation, and product innovation
· This is an opportunity to make a significant impact on the future of the Amazon vision.
If you are looking to make an impact, this is the team for you. You will not only have the satisfaction of seeing your work deliver results, but also help shape our engineering and product roadmaps. Change the world by accepting this Machine Learning Softward Developement Engineer role today!




Basic Qualifications

· Bachelor's degree in Computer Science or related disciplines
· 2+ years experience with computer science fundamentals in object-oriented design, data structures, algorithm design, problem solving, and complexity analysis
· Exposure to Machine Learning basics (will train for more advanced skills).

Preferred Qualifications

· Experience in building large-scale machine-learning infrastructure for online recommendation, ads ranking, personalization, or search, etc
· Experience with Big Data technologies such as AWS, Hadoop, Spark, Pig, Hive, Lucene/SOLR or Storm/Samza
· Strong proficiency with Java, Python, Scala or C++
· Coursework or thesis in machine learning, data mining, information retrieval, statistics or natural language processing
· Advanced knowledge of performance, scalability, enterprise system architecture, and engineering best practices

Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.",3.9,"Amazon
3.9","Palo Alto, CA","Seattle, WA",10000+ employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),"Google, Microsoft, Walmart"
Data Scientist,"$95K-$151K
(Glassdoor est.)","Requisition ID: 256384
Work Area: Software-Research
Expected Travel: 0 - 10%
Career Status: Professional
Employment Type: Regular Full Time
Career Level: T2
Posting Date : 6/16/2020

COMPANY DESCRIPTION

SAP started in 1972 as a team of five colleagues with a desire to do something new. Together, they changed enterprise software and reinvented how business was done. Today, as a market leader in enterprise application software, we remain true to our roots. That’s why we engineer solutions to fuel innovation, foster equality and spread opportunity for our employees and customers across borders and cultures.
SAP values the entrepreneurial spirit, fostering creativity and building lasting relationships with our employees. We know that a diverse and inclusive workforce keeps us competitive and provides opportunities for all. We believe that together we can transform industries, grow economics, lift up societies and sustain our environment. Because it’s the best-run businesses that make the world run better and improve people’s lives.

Purpose and Objective:

SAP Labs, LLC seeks a Data Scientist at our Palo Alto, CA location to analyze customer’s business problems, use cases and forms the requirements into feasible product feature.

Expectations and Tasks:

Explore data sources, implements data exploration, pre-processing and data cleansing on the historical data. Understand data and evaluate data quality from both data science and business value perspectives. Prepare the data for future models. Develop statistical / machine learning models based on the pre-processed data as a proof-of-concept. Assess and optimize the model quality based on technical level by tuning hyper-parameters, settings or even changing the models. Integrate the statistical / machine learning models into product. Work with application developers, machine learning engineers closely to ensure the model is ported into the product based on the prototyping. Work with product managers and designers to ensure all the features are delivered. Evaluate and improve the model performance under business context. Refine the model by tuning hyper-parameter, adjusting data sources or model approaches to resolve the business problem of customer. 10% travel required.

Education and Qualifications/Skills and Competencies:

Bachelor's degree in Computer Science, Engineering, Mathematics or a related field of study and 5 years of experience required. The company will also accept a Master's degree and 2 years of experience.

Work Experience:

Experience must involve 2 years in the following: ML and data science knowledge to define the next key features for the solution; build features architected for speed and distributed computing; Research, prototyping and development in the big data, machine learning and data science domain and machine learning frameworks. 10% travel required.

Travel:10% travel required.

Internal use only: reference code lhrs4262

EX:OUT

SAP'S DIVERSITY COMMITMENT

To harness the power of innovation, SAP invests in the development of its diverse employees. We aspire to leverage the qualities and appreciate the unique competencies that each person brings to the company.

SAP is committed to the principles of Equal Employment Opportunity and to providing reasonable accommodations to applicants with physical and/or mental disabilities. If you are interested in applying for employment with SAP and are in need of accommodation or special assistance to navigate our website or to complete your application, please send an e-mail with your request to Recruiting Operations Team (Americas: Careers.NorthAmerica@sap.com or Careers.LatinAmerica@sap.com, APJ: Careers.APJ@sap.com, EMEA: Careers@sap.com). Requests for reasonable accommodation will be considered on a case-by-case basis.

EOE AA M/F/Vet/Disability:

Qualified applicants will receive consideration for employment without regard to their age, race, religion, national origin, gender, sexual orientation, gender identity, protected veteran status or disability.

Additional Locations :",4.6,"SAP
4.6","Palo Alto, CA","Walldorf, Germany",10000+ employees,1972,Company - Public,Computer Hardware & Software,Information Technology,$10+ billion (USD),"Salesforce, Oracle, Microsoft"
Senior Principal Machine Learning Engineer (Growth Marketing),"$148K-$255K
(Glassdoor est.)","Coupang is one of the largest and fastest growing e-commerce platforms on the planet. We are on a mission to revolutionize everyday lives for our customers, employees and partners. We solve problems no one has solved before to create a world where people ask, ""How did we ever live without Coupang?""

Coupang is a global company with offices in Beijing, Los Angeles, Seattle, Seoul, Shanghai, and Silicon Valley.

Job Overview:

In Growth Engineering, our goal is to increase the number of transacting Customers while growing their frequency and lifetime value. We build core platforms and services that power Coupang's growth. Various platforms under our portfolio include Search Advertising Platform, Affiliate Platform, Display targeting & re-targeting Platform, CRM, Audience Platform, Push Marketing Platform, and other core marketing services for landing, tracking & attribution. We leverage big data, NoSQL, analytics, real-time processing and Machine Learning to build mission-critical and highly scalable services that are reliable 24/7.

As our Sr. Principal Machine Learning Engineer for Growth Engineering, you will play a strategic role in supporting innovation and be responsible for making our platforms & services data driven and intelligent leveraging data science. You will standardize the ML Platform that will be leveraged across Growth Engineering and collaborate with various teams to build and deploy statistical and optimization models that will directly help grow customers, increase wallet share and improve ROAS. Opportunities to leverage Data Science and Machine Learning to make a strong business and financial impact include customer look-alike models, product feed optimization, promotion recommendation, app push personalization, keyword bidding, product & category recommendations, etc. This is an exceptional opportunity to drive Coupang's growth and create a world where our customers ask, 'How did I ever live without Coupang?'

Key Responsibilities:
Lead and execute all Data Science and Machine Learning Initiatives for the organization
Engage with senior leadership, product owner(s) and engineering mangers in developing and executing data science strategy and roadmap
Play an active role in contributing to company's growth strategy, and identify opportunities to leverage data and insights helping Coupang's growth and customer loyalty
Collaborate with software engineers and data engineers to implement, verify and deploy models to deliver direct business and financial impact
Communicate clearly and concisely with the team members, peers and leadership team
Over time, assist with hiring and mentoring data scientists and ML engineers in the team
Qualifications
PhD in Machine Learning, Statistics, Applied Math or a quantitative field
10+ years of hand-on technical experience in data science working with large data sets to drive significant business/financial impact, preferably in e-commerce
Experience building and productionizing innovative scalable end-to-end machine learning systems
Strong background in statistical modeling and optimization techniques
Proficiency in a statistics tool like R and Big Data tools (Hive, Spark, Presto)
Strong fundamentals in object-oriented design, data structures, algorithm, problem solving and complexity analysis
Preferred:
Exceptional presentation skills and ability to communicate methodologies, results clearly and concisely to company's top executives
Strong interpersonal skills to work with cross-functional and globally distributed teams
Strong sense of ownership, urgency, and drive. High on bias for action
Coupang is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex or gender (including pregnancy, gender identity, gender expression, sexual orientation, transgender status), national origin, age, disability, medical condition, HIV/AIDS or Hepatitis C status, marital status, military or veteran status, use of a trained dog guide or service animal, political activities, affiliations, citizenship, or any other characteristic or class protected by the laws or regulations in the locations where we operate.

If you need assistance and/or a reasonable accommodation in the application or recruiting process due to a disability, please contact us at usrecruiting@coupang.com.",3.6,"Coupang
3.6","Mountain View, CA","Seoul, South Korea",5001 to 10000 employees,2010,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Principal Engineer - AI/Machine Learning,"$121K-$214K
(Glassdoor est.)","U.S. Bank is looking for an Artificial Intelligence/Machine Learning (AI/ML) Principal Engineer to join the Innovation team, supporting some of the largest initiatives in our company. The AI/ML Principal Engineer is a hands-on role that will be primarily responsible for execution and delivery of exploratory concepts, rapid prototypes, and pilot solutions designed to test hypotheses and incubate transformative new AI/ML Principal Engineer will provide solutions to large-scale problems, from ideation through delivery to production, and will bridge the gap between software developers and research/data scientists.

This role will work within the fast-paced Chief Digital Office/Innovation team, which strives for excellence in all phases of execution and lifecycle management. The ideal candidate will have the right attitude and an imaginative mind set, is creative, and has extensive experience with AI/ML solution delivery within industry. The individual will be comfortable working in an innovation-focused environment – in particular, evaluating emerging trends and technologies to assess their feasibility and viability and functioning effectively in a fail-fast environment. The position relies on the individual to be a self-starter and a quick learner, to have a futurist mindset, and to be able to innovate and report on tasks and status proactively.

Job Responsibilities:

• Implements AI/ML solutions through the entire development lifecycle, e.g. rapid prototype, design, build, assemble, test, and pilot.
• Designs, develops, and delivers code to implement AI/ML algorithms for experimentation and eventual adaption within the enterprise.
• Documents and articulates AI/ML solution code design and lessons learned for each exploration and accelerated incubation.
• Collaborates with other organizations within the company to define the optimal AI/ML solution deployment architecture and hosting environment.
• Encourages new transformative thinking and trail blazing, and facilitates imagination and ideation sessions.
• Collaborates with other organizations within the company to identify and flesh out new growth opportunities using AI/ML technologies.
• Maintains current knowledge of technology landscape and emerging developments.
• Works with various Product and Enterprise teams to optimize customer and user experiences.
• Employs practical approach to data access and management and eventual platform integration of AI/ML solutions.

Basic Qualifications:

• Ph.D. in a STEM field (e.g., Physics, Mathematics, Computer Science, Operations Research, Statistics, or related quantitative/technical fields) and at least 2 years of experience in AI/ML solution development and deployment OR a Master’s Degree and at least 5 years of experience OR a Bachelor’s Degree and at least 10 years of experience.
• Strongly Preferred: extensive previous experience in AI/ML solution development in either Conversational AI/NLP or cybersecurity threat detection.
• Advanced working knowledge and extensive experience with programming and software design fundamentals, e.g. object oriented and functional design principles, best practices, etc.
• Extensive experience in developing within cloud-based environments (e.g. Google Cloud, Amazon Web Services, Microsoft Azure), with emphasis on GPU-enabled computing.
• Extensive experience delivering and maintaining AI/ML solutions in production using Continuous Integration/Continuous Delivery (CI/CD) tools (e.g. Jenkins, Kubernetes, GitHub, JIRA/Bitbucket/Bamboo, Artifactory, DataDog) and best practices.
• Experience with Python programming environment or equivalent (e.g. R, Scala) and related open-source technologies such as NumPy, SciPy, Pandas, Scikit-learn, TensorFlow, Keras, Deeplearning4j, etc.
• Experience with API’s or software packages for computer vision, deep learning, voice/speech recognition, and/or NLP, e.g. OpenCV, Gensim, BERT, SpaCy, NLTK, etc.
• Experience with multiple methods of batch and real-time streaming data access in both development and production environments, e.g. Postgres, MongoDB, SQL, NoSQL, RESTful API’s, GraphQL, etc.
• Experience delivering communications in a clear, concise, and compelling manner.
• Willing to travel up to 25> of the time for business purposes.",3.5,"US Bank
3.5","New York, NY","Minneapolis, MN",10000+ employees,1863,Company - Public,Banks & Credit Unions,Finance,$10+ billion (USD),-1
Machine Learning (AI/ML),-1,"Role: Machine Learning (AI / ML) Software Engineer

Location: San Francisco, CA

Start date: ASAP

Job Description

Required Skills

The Artificial Intelligence, Machine Learning (AI / ML) Software Engineer will be responsible for supporting Artificial Intelligence, Machine Learning, and Data Science solutions for the Client. We’re looking for engineers with a passion for Artificial Intelligence to help drive a new generation of data and machine learning enabled services and products to impact healthcare. You will enjoy working with a highly talented and diverse team of data scientists and engineers specializing in deep learning, active learning, and classical machine learning on one of the richest data sets in US healthcare. You'll be equipped with nearly limitless cloud compute resources and be expected to deliver business impact through implementation of a large pipeline of AI models. The ideal candidate will have a background in Python, have experience working with large data sets, and have experience in building and deploying data-driven solutions. You are focused on results, a self-starter, able to put the team-first, and have demonstrated success in using data science to develop and deploy solutions with a focus on impact.

Responsibilities:
Provide technical leadership and implementation for Software Engineering projects supporting our AI and machine learning goals
Modifies, implements, tests, and supports all product related technology and functionality, including software infrastructure in an AWS hosted environment
Demonstrates strong drive to learn and advocate for development best practices (TDD, code reviews, continuous integration, etc.)
Communicates proactively and effectively with team members and other product stakeholders in a highly Agile environment
Self-starter that will take tasks and accomplish them with little oversight according to timelines and budgets agreed upon with business and technology stakeholders
Minimum Qualifications:
You have 2+ years’ experience working on applications of machine learning with strong to expert ability in Python as a primary language
Critical Skills:
Experience building automated processes that are supportable, monitored, and enterprise-scale
Experience working with and integrating services from popular ML packages such as Keras, TensorFlow, XGBoost, SciKit Learn
Above average capabilities with cloud computing techniques or tools such as S3, EC2, EMR, SageMaker, ECS, Lambda, IAM
SQL design and development skills
Additional Knowledge & Skills:
Spark or Pyspark experience preferred
Experience building/consuming REST web services
Demonstrated initiative with learning new technologies
Exceptional interpersonal and communication skills
Job Type: Contract

Pay: $60.00 - $65.00 per hour

Schedule:
Monday to Friday
Experience:
Machine Learning: 2 years (Required)
Artificial Intelligence: 1 year (Required)
Work Remotely:
Temporarily due to COVID-19",-1,Neoiteksys,"San Francisco, CA",-1,-1,-1,-1,-1,-1,-1,-1
NLP Engineer -Data Scientist,-1,"Direct End Client: Medtronic
<strong>Job Title: NLP Engineer -Data Scientist
<strong>Start Date: ASAP
<strong>Location: Northridge, CA
<strong>Position Type: Full Time
<strong>Interview Type: In person or Telephonic or Webcam
<strong>Requirement ID: MED_NLP517_VV

Must Have: Minimum Requirements
Bachelor's with 4+ years of experience, Master's with 2+ years of experience or a Ph.D. with 0+ years of experience.Â
Degree must be in Statistics, Math, Computer Science or similar field.
Experience in Python, R or similar data-science scripting language
Experience with statistical modelling
Experience in using SQL for advanced data analysis and visualization
Nice to Have:
Strong track record in building NLP, NLU models using real-world large datasets, that work in production with positive outcomes
Prior experience with Spark and the AWS stack
Experience with Tensorflow, MXNet or Keras framework
Proficient in relational database management systems with knowledge of non-relational database systems
Background in healthcare & diabetes physiology
Understanding of FDA regulations including (ISO) 13485.
Project: Cross-Diabetes group

Department: Medtronic Diabetes

Responsibilities:
Identify novel ways to apply NLP and NLU technology and help drive our data science roadmap.
Create ontology and entity database to enable advanced information inquiry.
Apply machine learning and advanced statistical methods to improve NLP and NLU technology from vast amounts of medical related conversation.
Design, implement, test and deploy state-of-the-art NLP, NLU in a production environment.
Work closely with the engineering team to operationalize infrastructure for NLP, NLU algorithms.
Access the performance and analyze the risk of designed NLP, NLU algorithms.
Keep up-to-date with the latest techniques and approaches in machine learning and statistical analysis.
Ability to communicate analysis in a clear, precise, and actionable manner

<strong>Responsibilities may include the following and other duties may be assigned:
In new product design roles: develops and programs integrated software algorithms to structure, analyze and leverage data in product and systems applications in both structured and unstructured environments.
Develops and communicates descriptive, diagnostic, predictive and prescriptive insights/algorithms.
In product/systems improvement projects: uses machine language and statistical modeling techniques such as decision trees, logistic regression, Bayesian analysis and others to develop and evaluate algorithms to improve product/system performance, quality, data management and accuracy.
In both theoretical development environments and specific product design, implementation and improvement environments, uses current programming language and technologies to translate algorithms and technical specifications into code.
Completes programming and implements efficiencies, performs testing and debugging.
Completes documentation and procedures for installation and maintenance.
Applies deep learning technologies to give computers the capability to visualize, learn and respond to complex situations.
Adapts machine learning to areas such as virtual reality, augmented reality, artificial intelligence, robotics and other products that allow users to have an interactive experience.
Can work with large scale computing frameworks, data analysis systems and modeling environments.

<strong>V Group Inc. is an IT Services company which supplies IT staffing, project management, and delivery services in software, network, help desk and all IT areas. Our primary focus is the public sector including state and federal contracts. We have multiple awards/contracts with the following states: AR, CA, DE, FL, GA, IL, KY, MD, ME, MI, NC, NJ, NY, OH, OR, PA, SC, TX, VA, and WA. If you are considering applying for a position with V Group, or in partnering with us on a position, please feel free to contact me for any questions you may have regarding our services and the advantages we can offer you as a consultant.Â

Please share my contact information with others working in Information Technology.

Â

Website: www.vgroupinc.com
<strong>Twitter: VGroupITServices@VGroupITService
<strong>Facebook: www.facebook.com/VGroupIT",3.4,"V Group Inc.
3.4","Northridge, CA","Louisville, KY",501 to 1000 employees,1997,Company - Private,Staffing & Outsourcing,Business Services,$100 to $500 million (USD),-1
Senior Data Engineer,-1,"At Afresh, we’re solving the big problems around food waste and the fresh food supply chain--focusing first in grocery. We use cutting-edge AI (we’ve been published in ICML!) combined with thoughtful design to enhance decision-making and optimize store workflows. The results are powerful: in live deployments in grocery stores, we have demonstrated the potential to double profits and reduce food waste by 50%+!
What will you be doing?
Building fast and reliable data pipelines that enable training machine learning models over billions of historical data points collected from tens of thousands of retail stores across the US.
Integrating with our customers’ infrastructure, which includes a variety of contemporary and legacy IT systems. Setting up data feeds from the customers’ systems.
Maintaining transactional, analytic, and NoSQL databases and data lakes over terabytes of data.
Collaborating with an interdisciplinary team of experts in machine learning, data scientists, design, software engineering, and business process optimization
What skills and experience do you need?
Bachelors or Masters in Computer Science or equivalent.2+ years of work experience.
Strong programming and problem-solving skills.
Expert-level knowledge of databases, data lakes, data pipelines, SQL. Experience with big data frameworks such as Apache Spark is a big plus.
Experience working with Microsoft Azure, Amazon Web Services, and other cloud providers.
Familiarity with statistical concepts and/or devops expertise are a plus. Experience with data visualization is a plus.
Background

About 30-40% of food produced worldwide is thrown away, causing nearly a trillion dollars of economic losses, trillions of gallons of wasted water, and billions of tons of greenhouse gas emissions. In the US, about 40% of all food waste occurs at the retail level and downstream, largely driven by insufficient technology and manual processes.

Afresh seeks to tackle some of these big problems around food waste. Born out of Stanford's Computer Science PhD program, Afresh is the first Fresh food supply chain company. We bring the cutting edge of artificial intelligence to Fresh food to minimize food waste.

Our machine learning-powered supply chain solutions are tailored for the nuances of perishables. Our first product is a store-level replenishment tool that optimizes the ordering of items in Fresh categories -- produce, meat, deli, dairy, bakery, and prepared foods. The goal is to minimize waste and maximize in-stock rate, and consequently, profit.

So far, the results are awesome! Like we said above, in live deployments, we have demonstrated the potential to double profits and reduce food waste by 50%+.

We're growing fast: we're in partnership with 4 large regional grocers representing 500+ stores and >$10B in revenue. Our backers include Innovation Endeavors (former Google CEO Eric Schmidt’s firm) and Baseline Ventures (first money in Stitchfix, SoFi, Heroku, Instagram).

Interested? Email us at Careers@afreshtechnologies.com",5.0,"Afresh Technologies
5.0","San Francisco, CA","San Francisco, CA",1 to 50 employees,2016,Company - Private,Grocery Stores & Supermarkets,Retail,Unknown / Non-Applicable,-1
AI/Machine Learning Data Security Engineer (Louisville or Boston),"$44K-$72K
(Glassdoor est.)","Description

The Data Governance Office (DGO) at Humana is seeking an AI and Machine Learning Data Security engineer to support the appropriate and secure use of information assets. DGO coordinates the synthetic data capability for the enterprise that creates widely usable and anonymized data sets by mathematically modeling production data and generating replicas of that data that retain the rich relationships between the data components without compromising individuals’ privacy. The synthetic data capability requires application of generative neural network methodologies supported by considerable amounts of compute, memory, and storage resources within a cloud platform to meet the dynamic demand of the multivariate regression processes. Humana is seeking a Data Science Engineer with AI and Machine Learning experience (particularly in Azure) to operate these processes and to do so with data security disciplines to protect the highly sensitive data required for modeling while in that process.

Responsibilities

Responsibilities

The successful candidate will work within the Machine Learning environment at Humana and with that team to perform activities in support of and related to the build out, maintenance, and enhancement of the Synthetic Data resources. This is a challenging environment that must innovate while respecting the rigors, policies, and constraints of a corporate analytical facility. The Machine Learning team operates in an open environment that encourages sharing of ideas, code, feedback, and documentation of their work.
Tooling includes:
Python, SQL, Bash, PowerScript, Scala
SQL Server, Hadoop, PySpark, Kafka, Databricks
RedHat Enterprise Linux, Windows, Docker, Azure Kubernetes Services
Git, Azure DevOps, Gira, Confluent
Job Description
Design, build out, maintain, monitor, and enhance the Synthetic Data environment in Azure
Interface with Data Scientists, Business Users, and Developers to support their synthetic data requests
Interface with the synthetic data engine vendor(s) to maintain and enhance the operation of their engine in the Azure platform
Research and develop enhancements to the pre-processing of data sets for introduction to the synthetic data engine
Periodically research and present emerging synthetic data innovations from the field to the Data Science community
Mentor and train Data Scientists and Engineers within Humana’s analytics community to operate synthetic data capabilities
Role Essentials
BS in Computer Science, Data Science or related field
5 or more years of experience designing, developing, and testing software applications and infrastructure
3 or more years of machine learning experience
Experience writing maintainable, testable, production-ready, and documented Python code
Experience in big data platforms (Hadoop, Spark, Hive, etc. . .) and big data formats (Parquet, Avro, etc. . .)
Experience with secure development and security features required by cloud infrastructures
Preferred Qualifications
Terraform deployment of Azure infrastructure configurations
Experience with deep learning libraries and frameworks (TensorFlow, PyTorch, Keras, etc. . .)
Master’s Degree in Computer Science, Data Science or related field
Scheduled Weekly Hours

40",3.6,"Humana
3.6","Louisville, KY","Louisville, KY",10000+ employees,1961,Company - Public,Insurance Carriers,Insurance,$10+ billion (USD),"Cigna, Aetna, UnitedHealth Group"
Senior Engineer - Machine Learning and Data Science,-1,"Thornton Tomasetti provides engineering design, investigation and analysis services to clients worldwide on projects of every size and level of complexity. We are a growing 1500+ person firm with 10 practices: Structural Engineering, Forensics, Applied Science, Renewal, Property Loss Consulting, Construction Engineering, Protective Design and Security, Facade Engineering, Sustainability and Transportation. We work on everything from landmark buildings to small-scale specialty structures, from the historic to the high performing, while balancing multiple objectives, including form, function, schedule, sustainability, constructability and budget. TALENT is at the core of our business.

The Applied Science practice leverages a unique combination of technologies and expertise to engineer practical solutions to problems of national and international importance. We apply expertise in solid and fluid dynamics, materials science, acoustics, risk assessments and computational simulation methods to solve complex problems. We perform research, mathematical modeling, software development and design to manage risks to life safety in military platforms and installations, ships and submarines, critical infrastructure, tall buildings, public facilities, industrial and petrochemical plants, and automotive and airborne vehicles. Military, government, corporate and academic clients value the validation of Applied Science’s software and the critical insights gained from correlating analysis with testing.

Our 70 year record of success is driven by the sustained focus of our uniquely qualified and experienced staff of engineers and scientists. We have an immediate need for a Senior Engineer to perform analysis and design work in a demanding, innovative structural assessment capacity. Our interest is in highly motivated, imaginative engineers and scientists who seek to work on unique and challenging problems. Many of the topics of research and engineering in the Applied Science Practice are interdisciplinary and not direct extensions of collegiate coursework, so the successful applicant should be comfortable expanding their skill sets and tackling new problems.

Essential Functions of this Senior Engineer position

The emphasis is on the ability to address difficult physical problems, within the practical constraints of a consulting environment with tangible deliverables and deadlines. As part of a consulting project team engaged on projects in the technical areas of structural mechanics, material modeling and engineering R&D, the candidate must be able to:
Formulate analytical approaches to address engineering and scientific problems,
Demonstrate command of the application of advanced finite element methods and software for nonlinear behavior,
Demonstrate proficiency in the creation, execution, interpretation and reporting of computational mechanics models,
Demonstrate proficiency in the development of Artificial Intelligence / Machine Learning / Data Science approaches to the analysis of complex data sets,
Demonstrate proficiency in the development of robust software implementations for these applications.
Requirements
M. Eng. or higher in structural engineering, mechanical engineering, applied mechanics, or related fields.
This position is intended for engineers and scientists with 0-5 years’ experience.
Strong interpersonal skills and willingness to work in a success-oriented team environment.
Must be able to obtain a US security clearance.
The successful candidate will be supported to gain a professional engineering license on their respective area of technical focus.
Thornton Tomasetti is proud to be an equal employment workplace. Individuals seeking employment at Thornton Tomasetti are considered without regards to age, ancestry, color, gender (including pregnancy, childbirth, or related medical conditions), gender identity or expression, genetic information, marital status, medical condition, mental or physical disability, national origin, protected family care or medical leave status, race, religion (including beliefs and practices or the absence thereof), sexual orientation, military or veteran status, or any other characteristic protected by federal, state, or local laws.

Thornton Tomasetti Global Terms of Use and Privacy Statement

Carefully read these Terms of Use before using this website. Your access to and use of this website and application for a job at Thornton Tomasetti are conditioned on your acceptance and compliance with these terms.

Please access the linked document by clicking here, select the country where you are applying for employment, and review. Before submitting your application you will be asked to confirm your agreement with the terms.",3.6,"Thornton Tomasetti
3.6","New York, NY","New York, NY",1001 to 5000 employees,-1,Company - Private,Architectural & Engineering Services,Business Services,$100 to $500 million (USD),"Arup, AECOM"
Machine Learning Software Engineer,-1,"Machine Learning Software Engineer

DHPC Technologies has an exciting opportunity for a Machine Learning Software Engineer to aid on the development of machine learning models and the software that is needed for the training and deployment of these machine learning model. In addition, the qualified candidate will engineer both structure and unstructured data that will be fed to and taken from the machine learning models. Because the qualified candidate will be working closely with the Data Scientist, the candidate must have general understanding of machine learning. This position is located onsite at Picatinny Arsenal, NJ.

Requirements:
At least a Bachelor’s Degree in Physics, Mathematics, Electrical, Computer, or Software Engineering.
Software development experience in Python and/or C++
Experience in software design and development
Experience in Data Engineering and deployment of machine learning models
Experience with machine learning algorithms such as Neural Networks, Boosting algorithms, Decision Trees, etc.
Experience with TensorFlow and other machine learning libraries.
Familiarity with reinforcement learning and computer vision techniques would be a plus
Good Communication and Presentation skills are a plus.
Experience with Linux is highly desirable.
The successful candidate must be a U.S. Citizen and possess and be able to maintain a DOD Secret Security Clearance, as a qualification and condition for employment.

DHPC Technologies offers a highly competitive salary and benefits package.
Medical, Dental and Vision Insurance
Paid Holidays/Paid Time Off
401k Retirement Plan with Employer Match
Life Insurance
Long and Short-Term Disability
Flexible Spending Account
Discounted Legal Service, Income Protection, Discounted Home & Auto
And more!
DHPC Technologies is an Equal Opportunity/Affirmative Action Employer. Qualified applicants are considered for employment without regard to age, race, color, religion, sex, national origin, sexual orientation, disability, or veteran status.",3.7,"DHPC Technologies
3.7","Picatinny Arsenal, NJ","Woodbridge, NJ",51 to 200 employees,1992,Company - Private,Computer Hardware & Software,Information Technology,$25 to $50 million (USD),-1
Senior Software Engineer - Machine Learning,-1,"Who is Mindstrong?

Mindstrong is a research-driven, consumer-focused mental healthcare company working to unlock a new virtual care model for delivering healthcare to people living with a serious mental illness (SMI) through innovations in measurement science, and care delivery. Our services are offered to people with an SMI through active partnerships with several nationwide health insurance payers.

As a Series C company, we have a blend of science, technology, and healthcare talent to help us unlock this paradigm-shifting approach, including the likes of National Institute for Mental Health, Stanford Center for Neurobiological Imaging, Uber, Facebook, Google, Apple, Oscar Health, and CMS.

We'd love to talk more!

What is the Senior Software Engineer - Machine Learning Role?

We're looking for Machine Learning Engineers to join our growing team of people passionate about changing mental healthcare. In this role, you will work cross functionally and partner with data scientists, product managers, data analysts, and the clinicians who directly deliver care to our Mindstrong members. You will lead projects that derive value from our extensive amount of data and will work on problems related to predicting and measuring mental health outcomes, optimizing our growth funnel, matching clinicians with patients, increasing the efficiency of clinical services, and making recommendations for impactful interventions. Our team works across the company to help influence decision-making, and your work will have a direct impact on our patient population.

What you'll be doing:
Become an expert in building healthcare critical machine learning applications that remap brain circuits from human-computer interaction patterns
Create highly scalable and adaptive online/streaming learning algorithms that impact the lives of millions of people daily
Work with high-performance engineering and data science teams to deploy these applications in a highly scalable and distributed infrastructure
Improve the quality and availability of care for millions of people around the world
Who you are:
You feel good about your work knowing that what you do will affect the lives of millions of people around the world
Eager to thrive in a startup environment
Strong communicator (oral and written)
A good person, highly ethical, and accepting of others
Your background and skills:
4+ years of relevant industry experience in software engineering or production-level data science experience working with large scale data-driven systems
Excellent knowledge of machine learning models and evaluation techniques
Experience training, deploying, and monitoring machine learning models in both research and production environments
Experience with feature engineering and ETL development
Rigor in high code quality, automated testing, and other engineering best practices
Experience working cross functionally across data science and engineering
Detail oriented with strong communication and interpersonal skills
Proven track record of delivering on tight schedules
Experience writing production quality Python code a must; Java or Scala a plus
Competitive Benefits:
Medical, Dental, and Vision coverage
401k
10 paid holidays
Unlimited PTO
Fully stocked kitchen and catered lunches
Casual dress code
Telecommuting benefits
Join us in our journey to transform the future of brain health!

Mindstrong is proud to be an Equal Employment Opportunity employer that celebrates diversity. We are committed to providing equal employment opportunities to all employees and applicants. All individuals seeking employment at Mindstrong are considered without regard to race, color, religion, national origin, age, sex, marital status, ancestry, physical or mental disability, veteran status, gender identity, sexual orientation, or any other characteristic protected by federal, state, or local laws. This policy applies to all terms and conditions of employment. Mindstrong also strives for a safe and robust workplace and prohibits harassment of any kind. If you have a disability or special need that requires accommodation for interviewing, please let us know by emailing contact-recruiting@mindstronghealth.com",3.6,"Mindstrong
3.6","San Francisco, CA","Mountain View, CA",51 to 200 employees,2014,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
"Senior Software Engineer, Applications","$55K-$114K
(Glassdoor est.)","About the Role
As we continue to change the game for GovTech, you will be jumping headfirst into a team of passionate and talented individuals. As a Senior Engineer, you will be asked to challenge your skills as a technologist leader as you build cutting-edge features while mentoring other team members. Beyond enhancing and pushing forward the capabilities of our client-facing Ember application, you will be critical in guiding and developing software that powers our applications.

About Engineering at FiscalNote
Our team has a wealth of diverse life and career experiences that allow us to think outside of the box and ahead of the curve. You'll get the opportunity to work at an institution pushing the boundaries of open data transparency while collaborating with some of the industry’s brightest engineers and data scientists to devise, nurture, and implement cutting-edge solutions to continuously evolving engineering challenges.

Success In This Role Includes:
- Work in a diverse programming environment: Ember, Node, Python, Ruby on Rails- Build web and enterprise integration products that help push the FiscalNote platform forward
- Work across teams to ensure cohesion and collaboration across engineering functions
- Create experiences for the end user by applying your knowledge of the frontend, backend, and integration technologies to deliver a world-class user experience
- Mentor other engineers on software development practices

What Sets You Apart:
- Demonstrated mastery in a frontend framework: Ember.js, React.js, Angular.js or other MVC/MVx framework
- Demonstrated mastery in a backend programming language runtime: Node.js, Python
- Experience in the following: SQL, Elasticsearch, Redis
- 5+ years of experience in the software development industry (not necessarily with the technologies)
- Architecture decision-making experience (preferred)
- Production decision-making experience (preferred)
- Legacy Enterprise Application integration and/or migration experience (preferred)
- Demonstrated experience building successful working relationships with Product + UI/UX teams
- Passion for Customer Experience
- Experience breaking down product specs into engineering components
- Led projects from inception to completion
- A Bachelor's Degree in Computer Science, Computer Engineering, or equivalent experience

Are You
Ambitious. Detail-oriented. Thoughtful. Although proud of how far you’ve come in honing your craft, you look forward to constantly growing in your technical abilities. Even more excited to share your skills and experiences, you thrive in collaborative environments in which the free flow of ideas serves as the catalyst for bold results. Feeding off of a highly competent engineering and product development culture, you yearn to contribute to the foundational growth of a company with unlimited growth and market capture potential.
About Us
FiscalNote is a technology-powered global software data and media company that uses powerful machine learning to provide clients with the right policy information and insights, and at the right time so that they can better navigate market risk and uncertainty and maximize new opportunities.

As the premier hub of domestic and global information for more than 5,000 clients worldwide, FiscalNote’s tools, analysis, news, and award-winning journalism delivers context, clarity, and a competitive edge in a rapidly changing world.

If your background and experience align with the competencies above, we encourage you to apply so that we can review your experience and learn more about how you can add to FiscalNote’s growth and success.

Company Benefits
FiscalNote offers competitive salaries, equity packages, and retirement accounts to ensure we’re all FN owners. We work hard, so our open vacation policy helps us ensure you’re getting the R&R you need. We offer comprehensive health, vision, and dental insurance options supplemented by a flexible spending account (FSA). We have a slew of other benefits which you can check out at careers.FiscalNote.com.

FiscalNote values diversity. We are committed to equal opportunities and creating an inclusive environment for all our employees. We welcome applicants regardless of ethnic origin, national origin, gender, race, religious beliefs, disability, sexual orientation or age. FiscalNote is an EEOC employer.

FiscalNote uses E-Verify to confirm the employment eligibility of all new employees. To learn more about E-Verify, including your rights and responsibilities, please visit www.DHS.gov/E-Verify.

Apply",3.9,"FiscalNote
3.9","Baton Rouge, LA","Washington, DC",201 to 500 employees,2013,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
"Software Engineer, Data Infrastructure",-1,"TRM leverages big data and machine learning to prevent cryptocurrency fraud and financial crime. Our goal is to build a safer financial system for billions of people. To achieve this goal, we need highly available data infrastructure. As such, we're looking for passionate Data Engineers to join our team!

As a Data Engineer at TRM Labs, you will collaborate with an experienced team of data scientists, engineers, and product managers to build scalable data infrastructure for TRM's products and services. You will be deeply involved in the technical details of building highly available infrastructure and ultimately work to build a safer financial system for billions of people.

Your Responsibilities
Building highly reliable data services to integrate with dozens of blockchains
Creating ETL pipelines that transform and process petabytes of structured and unstructured data in real-time, ultimately helping financial institutions and governments fight fraud and criminal activity
Designing data models for optimal storage and retrieval to support sub second latency for querying blockchain data
Deploying and monitor large data base clusters that are performant and highly-available
Working cross-functionally with data scientists, backend engineers and product managers to design and implement, and new data models to support the product
Developing your skills through exceptional training as well as frequent coaching and mentoring from colleagues
Some of the Traits we value
Bachelor's degree (or equivalent) in Computer Science or related field
3+ years of experience building real-time and distributed system architecture, from whiteboard to production
Strong programming skills in Node, Python, and SQL.
Versatility. Experience across the entire spectrum of data engineering, including:
Data stores (e.g., ClickHouse, ElasticSearch, PostGres, MongoDB, Redis, and Neo4j)
Data pipeline and workflow orchestration tools (e.g., Azkaban, Luigi, Airflow, Storm)
Data processing technologies (e.g., Spark)
Deployment and monitoring large data base clusters in public cloud platforms (e.g., Docker, Terraform, Datadog)
Adaptable. Goals can change fast. You anticipate and react quickly.
Autonomous. You own what you work on. You move fast and get things done.
Excellent communication. You will need communicate complex ideas effectively to both technical and non-technical audiences, and both verbally and in writing
Collaborative. You must work collaboratively in a cross-functional team and with people at all levels in an organization
Industry experience building and productionizing innovative end-to-end Machine Learning systems is a plus.
Relevant experience in crypto/blockchain is a plus
Benefits
Stock
$2,000 yearly coupon for books, conferences, and professional coaching
Competitive salary
Paid time off
Volunteer time off
Parental leave
Medical, dental, & vision insurance
Life & disability coverage
401K
Apple equipment
Daily lunch and dinner
Why us

We work with the best. TRM is YC-backed and funded by Blockchain Capital, the leading blockchain VC firm. Our customers include the world's top digital asset companies.

Strong engineering and product culture. Collectively, we've researched machine learning at Harvard and Stanford, led strategy teams at McKinsey, built data pipelines at Facebook and shipped distributed apps at Amazon and OpenDoor.

Our culture is creative, collaborative, and hypothesis-driven. We focus on creating the best products possible with low ego and high productivity.

TRM Labs is an equal opportunity employer.",5.0,"TRM Labs
5.0","San Francisco, CA","San Francisco, CA",1 to 50 employees,2018,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Machine Learning Software Engineer,-1,"RESPONSIBILITIES Kforce has a client in building a team of Machine Learning Software Engineers in Wilmington, Delaware (DE) and Tampa, Florida (FL) and Plano, Texas (TX). This team is focused on developing and delivering cutting edged mobile applications, digital experiences and next generation banking technology solutions to better serve our clients and customers. Summary Our Machine Learning Software Engineers will have the business acumen to understand and analyze problems, define and test hypotheses and develop Machine Learning frameworks and best practices. Additionally, they will be responsible to intricate knowledge of our business domains and data sets which include Systems of Record (SOR), historical and external data. Finally, this individual will take ownership in designing models to deliver performance and accuracy when operationalized as well as inference engines at scale with the business processes and applications. Duties Analyze and conduct learningsimulations with large datasets combining multiple platforms (ex. Hadoop, Spark, AWS), and machine learning frameworks (ex. R, sci-kit, PySpark, Pandas, TensorFlow) Leadmentor a team of data scientists and machine learning engineers, who help the business identify new insights from largerich data sets, and implement data driven strategies that reduces fraud, post-fraud loss and other operational efficiencies REQUIREMENTS 3+ years of hands-on experience Python (or other scripting), Java, HadoopSparkHive andor AWS, and 10+ years of hand-on experience with SQL Expertise across application, data and infrastructure architecture disciplines Advanced knowledge of architecture, design and business processes Experience with Machine Learning, Deep Learning, Data Mining, andor Statistical Analysis tools Operationalize machine learning models using offline and online models, model performance monitoring, frequentautomated model updates, backnow testing, managed test harness and managed feature libraries Ability to automate data exploration and model exploration activities and embed end-to-end model development and deployment into automated CI-CDDevOps pipelines Hands-on data analytics using machine learning, statistical modelling andor data mining to uncover insights from large data sets and develop data and predictive models supporting multiple business domains spanning Fraud, Consumer Banking Operations, Digital Banking and Customer Experience scenarios. Interpret and explain methods using statistical analysis Kforce is an Equal OpportunityAffirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.",-1,Kforce Technology Staffing,"Wilmington, DE",-1,-1,-1,-1,-1,-1,-1,-1
Senior Machine Learning Engineer - Audio Understanding,"$145K-$228K
(Glassdoor est.)","We are looking for a Senior Software Engineer to help us build the next generation of ML-based audio understanding technologies. Our team expands the state of the art in AI-based machine listening technology, which enables intelligent, efficient and intuitive ways to search, re-use, explore or process audio and music. We build products for end users, for artists, for producers, for labels and publishers, for managers, for advertisers - projects that cut across all of Spotify. We build features to improve products and lay the foundations for disruptive new product opportunities.
What you’ll do
Take on complex data-related problems involving some of the most diverse datasets available, leveraging your experience to drive best practices in ML and data engineering.
Work in an agile team spanning software engineers, research scientists, and product managers to productionize ML research at scale for hundreds of millions of active users.
Build best-in-class infrastructure and tooling to accelerate our research-to-product efforts and to enable efficient cloud-based deployment and testing of audio processing models.
Debug and optimize ML models to enable complex inferencing (and training) tasks at high scale.
Determine the feasibility of projects through quick prototyping with respect to performance, quality, time and cost.
Work together with our stakeholders to help define and drive new features forward.
Who you are
You have professional experience working in a product-driven environment.
You have experience working with cloud platforms like GCP / AWS / Azure.
You have experience implementing and maintaining high-scale, production ML systems.
You have experience leveraging high-scale, distributed data processing frameworks (e.g. Apache Beam / Google Dataflow, Hadoop, Scalding, Spark, Storm).
You know how to write distributed, high-volume services in Java or Scala.
You have an interest in learning more about audio processing and music information retrieval and you're excited about building amazing products that use such technologies.
BENEFICIAL: You have previous industry experience with debugging, profiling, code-optimizing or deploying tensorflow models at scale.
BENEFICIAL: You have experience with applying deep learning techniques for content based processing (audio, image, video data).
You are welcome at Spotify for who you are, no matter where you come from, what you look like, or what’s playing in your headphones. Our platform is for everyone, and so is our workplace. The more voices we have represented and amplified in our business, the more we will all thrive, contribute, and be brilliant. So bring us your personal experience, your perspectives, and your background. It's in our differences that we will find the power to keep revolutionizing the way the world listens.
Spotify transformed music listening forever when we launched in 2008. Our mission is to unlock the potential of human creativity by giving a million creative artists the opportunity to live off their art and billions of fans the opportunity to enjoy and be inspired by these creators. Everything we do is driven by our love for music and podcasting. Today, we are the world’s most popular audio streaming subscription service with a community of more than 286 million users.",3.8,"Spotify
3.8","New York, NY","Stockholm, Sweden",1001 to 5000 employees,2006,Company - Public,Internet,Information Technology,Unknown / Non-Applicable,-1
Data Engineer 3,-1,"Data Engineer

About the Position

We are looking for a highly skilled data engineer who has a passion for all things data. You will be responsible for data architecture, building data pipelines using ETL tools, provide data to the data scientist and participate in the re-training of machine learning models. You will be developing both on-prem and cloud solutions. You will be an integral member of our product teams, working very closely with architects and software engineers on different layers of the infrastructure and design. Thus, a commitment to collaborative problem solving, sophisticated design, and product quality is essential.

Requirements:

• Bachelor’s degree in computer science, Information Systems or related discipline; Or 6 years of prior equivalent work-related experience in lieu of a degree.
• Must have leadership skills to lead and deliver projects, be proactive, take ownership, interface with business, represent the team and spread the knowledge.

• Support or collaborate with application developers, database architects, data analysts and data scientists to ensure optimal data delivery architecture throughout ongoing projects/operations.
• Develop highly scalable data management interfaces, as well as software components by employing programming languages and tools.
• Design, document, build, test and deploy data pipelines that assemble large complex datasets from various sources and integrate them into a unified view.
• Experienced in ETL Tools (SSIS, Kafka, Sqoop, Informatica, Nifi)
• Expert SQL knowledge (All types of Joins, CTE’s, Indexes, Stored Procedures, SQL performance)
• Should have knowledge feedback loop into Model Re-Training (Data and model pipelines)
• Should be able to work with the MLOps to build data pipelines to model executions.
• Experience in Python & PySpark using spark ML, spark DL, Hive.
• Experience in data ingestion from various data sources like SQL Server, Oracle, Hive etc.
• Good knowledge in Git, GitHub, Bitbucket.
• Good team player, willing to Experiment, explore and learn fast.

Preferred Experience:

• Knowledge in building machine learning models
• Cloud expertise (AWS, AZURE)
• Knowledge in docker and its orchestrations
• Good understanding of Cyber Security and Architecture standards for enterprise applications
• Experienced in building real-time data feed to provide analysis in an automated fashion.
• Knowledge in Continuous integration suites like Jenkins.
• Knowledge in Web servers (Flask, Gunicorn, NGINX etc)",4.5,"Optomi
4.5","Charlotte, NC","Atlanta, GA",201 to 500 employees,2012,Company - Private,Staffing & Outsourcing,Business Services,$50 to $100 million (USD),-1
Machine Learning Engineer,-1,"Tuknik Government Services (TGS) is looking for exceptionally well qualified Machine Learning Engineers to support our government client in Crystal City, VA.

We offer competitive compensation and an extraordinary benefits package including health, dental and vision insurance, 401K with company matching, flexible spending accounts, paid holidays, three weeks paid time off, and more.

The Joint Artificial Intelligence Center (JAIC) is looking for a high performing candidate to fill a Machine Learning Engineer position supporting the nation's new initiative to coordinate the Artificial Intelligence and Machine Learning (AI/ML) efforts across the Department of Defense. This position requires an experienced person with demonstrated Machine Learning expertise, a high level of technical expertise, superior professional demeanor, and the ability to learn and accomplish a wide variety of day-to-day responsibilities that ensure program success.

Essential Functions
Developing, testing, deploying and updating machine learning (ML) models trained on structured and unstructured (big) data sources in both on-premise and cloud-native environments.
Driving the incorporation of developed ML models and pipelines into production-level ML systems in both on-premise and cloud-based delivery models, by creating robust, scalable and well-engineered ML components that enable delivery convergence.
Collaborating with data engineers, data scientists and infrastructure engineers to develop and deploy data and model pipelines, applying ML and data science techniques in design distributed and large-scale processing systems.
Writing production-level, re-usable, interpretable code in R, Python, Java, C++, Scala, SQL, or other languages, while engaging in collaborative code reviews and providing technical feedback to improve existing ML model performance.
Performing AI research/engineering outreach to ensure best ML modeling practices are leveraged in AI solution design and product development, to include an understanding of AI technology maturity.
Coordinating science and technology (S&T) research and development (R&D), outreach, and engagement efforts to help advance sensitive ML capability development efforts via technical leadership of external ML contracts.
Demonstrating applied understanding of natural language processing (NLP), computer vision (CV), decision networks, neural networks, autonomous systems, and other ML-based regression and classification methodologies.
Working independently and in a collaborative, dynamic, cross-functional environment.
Requirements
PhD in Machine Learning, Computer Science, Software Engineering, Applied Mathematics, Operations Research, or related field with 1 year of experience, or a Master’s degree with proven experience of at least 5 years.
Minimum of two applied and specialized certifications (e.g., Udacity AI/ML Engineer, Coursera Deep Learning).
Minimum of two complementary experience specialty areas outside ML (e.g., full stack developer, cloud architect).
Fluency in Python, R, C++, Java, or other similar programming language.
Experience with multi-modality processing, deep neural networks, Gaussian processes, reinforcement learning, etc.
Understanding of applied autonomous systems and embodied intelligence (e.g., multi-agent systems).
Extensive knowledge of machine learning model evaluation metrics and best practices.
Strong understanding of probability, statistics and mathematics (e.g., statistical learning theory, algorithms).
Experience working with cloud-based platforms and tools (AWS, Azure, GCP, etc.).
Experience working with web services (Redshift, DigitalOcean, etc.).
Experience working with distributed data and computing tools (Hadoop, Hive, Gurobi, MySQL, Spark, S3, etc.).
Experience working with distributed systems (Etcd, zookeeper, consul, etc.).
Experience working with messaging tools (Kafka, RabbitMQ, ZeroMQ, etc.).
Must be a US Citizen, hold a current DoD Secret Clearance, and can obtain a DoD Top Secret/SCI Clearance
Working Environment & Conditions

This position is primarily indoors, consistent with a standard office position and has a noise level of mostly low to moderate. The incumbent is required to stand; walk; sit; use hands to manipulate, handle, or feel objects, tools, or controls; reach with hands and arms; talk and hear. The work load may require the incumbent to sit for extended periods of time. The incumbent must be able to read, perform simple math calculations and withstand moderate amounts of stress. The incumbent must occasionally lift and/or move items that weigh up to 25 lbs. Specific vision abilities required for the job include close vision, distance vision, color vision, depth perception, and the ability to adjust focus.

Our Equal Employment Opportunity Policy

The company is an equal opportunity employer. The company shall not discriminate against any employee or applicant because of race, color, religion, creed, sex, sexual orientation, gender or gender identity (except where gender is a bona fide occupational qualification), national origin, age, disability, military/veteran status, marital status, genetic information or any other factor protected by law. We are committed to equal employment opportunity in all decisions related to employment, promotion, wages, benefits and all other privileges, terms and conditions of employment.

The company is dedicated to seeking all qualified applicants. If you require an accommodation to navigate or to apply to a position on our website, please contact Heaven Wood via e-mail at accommodations@koniag.com or by calling 703-488-9377 to request accommodations.",3.4,"Koniag, Inc.
3.4","Crystal City, VA","Kodiak, AK",501 to 1000 employees,-1,Company - Private,Consulting,Business Services,$100 to $500 million (USD),-1
Machine Learning Engineer - SEAL,-1,"ID: 495553
Type: Researchers
Location: Smyrna, GA
Categories: Algorithm Development, Artificial Intelligence, Electronic Warfare, Embedded Systems, ISR & Tactical Systems, Machine Learning, System Architecture, Testing, High Performance Computing, Modeling/Simulation, Radar, Sensors Integration, Sensors/Optics, Signal Processing, Software Development/Design
Job Description


The Sensors and Electromagnetic Applications Laboratory (SEAL) of the Georgia Tech Research Institute (GTRI) is seeking technical personnel to be part of an established software team that has multiple opportunities for software engineers within the Software Engineering and Architecture Division (SEAD) at Smyrna, GA. The SEAD group mission is to provide world-class software to be used in sensors, signal processing, electronic warfare, tracking, and intelligence surveillance reconnaissance (ISR) systems deployed on land, air and sea. Our software team employs a modern software engineering process to design, code, integrate and test capabilities on a continuous basis resulting in a mature and quality solution for our customers. We strive for technical excellence by drawing upon a diverse workforce whose knowledge base covers the complete spectrum of modern computing languages and platforms.

Job Duties


The successful candidates will be involved in the artificial intelligence (AI) software design, development, integration and testing of the systems. Our real-time machine learning software applications are developed using C++ and Python in a Linux environment. Our group utilizes productive modern (Agile) and industry-proven software development processes and environments. The candidate will get the opportunity to creatively solve problems, design features, and independently and work in a team environment to implement projects.

The candidate will have the opportunity to leverage machine learning techniques to build processes to gather insights from a high volume of data from multiple sources. You will develop systems to efficiently process the data in our platform. The candidate will ultimately be responsible for developing powerful software systems that reinforce our place as a technical research leader in machine learning and deploying software.

Travel Requirements


10% - 25% travel

Education & Length of Experience


Research Engineer/Scientist I
A Bachelor's degree in Computer Engineering, Computer Science, Electrical Engineering, Mathematics, Physics, or related field of study.
Research Engineer/Scientist II
A Master’s degree in Computer Engineering, Computer Science, Electrical Engineering, Mathematics, Physics, or related field of study and three (3) years of relevant full-time experience after completion of that degree,
A Master’s degree in Computer Engineering, Computer Science, Electrical Engineering, Mathematics, Physics, or related field of study and five (5) years of relevant full-time experience after completion of a Bachelor’s degree, or
A Doctoral degree in Computer Engineering, Computer Science, Electrical Engineering, Mathematics, Physics, or related field of study.
Required Minimum Qualifications
Candidates currently enrolled in an accredited Bachelor’s degree program relevant to this position will be considered. Candidate must have a graduation date of no later than May, 2020
Artificial Intelligence algorithms utilized for applications
Knowledge of industry AI tools (e.g., TensorFlow, PyTorch, etc.)
Experience with C and C++
Experience with Linux or Windows
Experience in software engineering and development
Knowledgeable in version control software such as GIT
Knowledgeable in JIRA, Bitbucket and Confluence
Good verbal and written communication skills
Self-starter and ability to work in a team environment
Preferred Qualifications
Knowledge of computer architectures including multi-core environments
Familiarity with software applications requiring multi-threaded programming implementation
Experience in software engineering and development
Complex programs that involved hardware, software, communications and networking
Existing secret clearance, or the ability to obtain an interim clearance within 30 days and full clearance thereafter
U.S. Citizenship Requirements


Due to our research contracts with the US federal government, candidates for this position are required to be US Citizens.

Clearance Type Required


Ability to obtain Secret Clearance upon hire

Diversity & Inclusion


Diversity & Inclusion (D&I) at Georgia Tech Research Institute aims to enhance the Institute’s mission of solving the world’s most complex technical problems by creating a workforce with a shared appreciation for diversity, raising awareness around inclusiveness, and fostering a sense of belonging and appreciation for all members of our community.

Equal Employment Opportunity


Georgia Tech Research Institute is an Equal Opportunity Employer of individuals with disabilities and protected veterans and actively seeks diversity among its employees. Equal Employment Opportunity is the Law.

Posted: 05/01/2020
Closes: 08/01/2020",3.6,"Georgia Tech Research Institute
3.6","Smyrna, GA","Atlanta, GA",1001 to 5000 employees,1943,Subsidiary or Business Segment,Research & Development,Business Services,$100 to $500 million (USD),"MIT Lincoln Laboratory, Johns Hopkins University Applied Physics Laboratory"
Senior Applied Machine Learning Engineer,-1,"The Data Team at ReSci is in a new phase of its evolution. We've scaled our predictive models to 350M+ users and we are looking for a Senior Machine Learning Engineer to help us innovate new models and improve our existing algorithms, to take our predictions to the next level! On our Data Team, you will work closely with other Data Scientists and Data Engineers to create the Machine learning backbone that powers our marketing automation platform (""Cortex"") for commerce brands. Your expertise at algorithms will be paired closely with the software expertise of Data Engineers, and you will jointly own these ML systems.

We are looking for a team player who loves to build data products and wants to be involved in the entire process: working with PMs in product ideation, R&D / prototyping of feature engineering and modeling approaches, to scaling models across hundreds of clients in production. You should have a passion and deep theoretical understanding of Machine learning and can discuss in depth their theory, strengths, and drawbacks. In addition to the fundamentals, you should have experience shipping and scaling ML algorithms.

We ingest billions of user-level signals and use this as a basis for all our predictive models (recommenders, churn predictors, timing, price sensitivity, etc). Our model infrastructure is generalized to run for varieties of clients' data but at the same time tunable to provide clear and tailored results. Your day-to-day work will directly impact 100’s of your favorite brands and 100’s of millions of users!


Responsibilities:
Apply unsupervised and supervised machine learning for predictions that power our products: Cortex and Pocket Data
Maintain and improve product recommendation models, churn predictors, LTV, timing, price sensitivity scoring, bandit models, etc
Communicate methodology and results to technical and non-technical audiences
Build and design ML infrastructure: including ML monitoring, AB testing, Data connectors
Contribute to data pipelines and feature engineering layers for ML to flourish
Design reporting and analytics for clients on key campaign results
Qualifications:
Minimum 5 years in shipping Machine learning or data products at scale
Strong breadth of Machine learning techniques like classification, regression and clustering
MS/PhD strongly preferred in Computer Science, EECS or relevant field (know the maths)
Strong communication skills and able to speak to a non-technical audience about data science and AI
Strong Python, Spark AND Scala are desired but not mandatory
Experience with large-scale data processing tools: Spark, etc
About Us:

ReSci's mission is to make artificial intelligence accessible and usable for brands.

Our values:
- Inspire with passion.
- Persevere with determination.
- Collaborate with unity.
- Grow without bounds.
- Create with impact.
- Lead with character.

Based out of Santa Monica, CA, our team consists of serial entrepreneurs who have all made Retention Science a leader in AI marketing. Our SaaS platform, “Cortex” helps online businesses target, engage, and retain customers. The Cortex marketing platform uses machine-learning algorithms to predict customer behavior by analyzing massive sets of demographic, social, and behavioral data to generate 1-to-1 retention campaigns personalized to each customer. Cortex makes 3.5+ billion predictions per day and processes 5k+ events per second.

Our founders have been recognized as the Ernst & Young Entrepreneurs of the Year, and our company was awarded Top 10 Big Data Startup of the Year by CRN, one of Fast Company's €œInnovation Agents€, Top 10 Software Company in Southern California from SocalTech, and identified by Inc. Magazine as one of the most innovative startups. Retention Science has also been featured in Forbes, the Wall Street Journal, TechCrunch, Bloomberg, and Reuters, among other notable publications. In addition, the most prestigious startup accelerator in LA (part of the TechStar Network), as well as many reputable angel investors and Venture Capital firms have provided their support and backing for our business.

We're passionate about what we do and we put our people first! We are a close-knit family whose members drink too much coffee, work hard, and never cease to brainstorm creative new ways to improve our solutions. We foster a dynamic and exciting start-up environment that is conducive for innovative thought; join us if you are interested in working with our world-class team!",4.4,"Retention Science
4.4","Santa Monica, CA","Santa Monica, CA",51 to 200 employees,2013,Company - Private,Enterprise Software & Network Solutions,Information Technology,$5 to $10 million (USD),"AgilOne, IBM"
Sr. Software Engineer in Test (SET),-1,"LeapYear's secure machine learning platform is deployed by some of the largest enterprises in the world across finance, healthcare, and technology.

Our technology ensures differential privacy, a widely recognized standard of data privacy that enables all data - including sensitive information - to be utilized for analytics, while providing mathematically proven privacy protection.

The LeapYear system is composed of a core set of components that allow private machine learning on data sets that can scale to petabytes. The core includes private algorithms for relational operations, statistical methods and machine learning. A data scientist accesses private data using a Python API. The system includes services for authentication, access control, logging, auditing and support for integration of data from a variety of data sources including SQL/NoSQL Databases, HDFS and S3. Queries are processed using Spark to support to enable fast, distributed processing of massive datasets. Administration is provided via a web-based GUI or an API.

We are looking for a Senior Software Engineer in Test (SET), who will lead the testing of LeapYear products. The role will require testing functionality, scalability, performance and availability. All tests will be automated.

For details on the specific responsibilities and requirements of this role, please see below.
Responsibilities
Work closely with the development team to develop test plans.
Define and implement automation strategies for testing the functionality of LeapYear’s products.
Define and implement an automated framework for scale, performance and availability testing.
Be accountable for the full lifecycle of your code from design to deployment.
Mentor other members of the SET team.
Develop automated systems for tracking quality metrics.
Requirements
Experience testing complex distributed systems that require scalability, reliability and flexibility.
5+ years of professional experience.
At least 3 years of experience in automation and testing.
Proficiency in a programming language such as Python, Java, C, Golang, Scala etc.
BS/MS in Computer Science/Engineering or related discipline.
Excellent oral and written communication skills.
Experience with Continuous Integration/Continuous Deployment tools(e.g. CircleCI, Travis)
Experience with cloud platforms (AWS, Azure, or GCP).
Experience with SQL/NoSQL databases.
Ability to get up to speed quickly on new technologies such as Machine Learning, Spark, differential privacy.
Preferred
Experience with big data technologies like Spark and/or Hadoop.
Experience developing for on-premise enterprise deployments.
A Few of the Perks
Culture of teaching and learning
Competitive compensation package of salary and equity
Catered lunch every day
Company outings
Build your ideal work station
Generous health insurance plan
Relocation support and visa sponsorship",4.2,"LeapYear
4.2","San Francisco, CA","San Francisco, CA",1 to 50 employees,2015,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"Job Title: Data Engineer
Job Location: Lincolnshire, IL
Job Duration: 6 months Temp to Perm

CTO AI services is a central group innovating new AI centric products, supporting Business Units on program acceleration and building an ecosystem that will allow Client to scale its AI components across the business and partners.
As a Data Engineer in computer vision you will have a unique opportunity to design and manage all of our data infrastructure used by our research team to solve real-world applications. You will face a variety of challenges from automating data acquisition and annotation to evaluating our latest cutting-edge algorithms, and you will have access to the best hardware to do the job.

We are focusing on leveraging AI to help solve real-world problems on real-world data. This means embracing noise and complexity, both at the data level and at the methodological level. You will collaborate closely both with both software developers and research scientists to commercialise our products and manage data collection and management requirements.

You will have experience in machine learning and management, either through your studies or industrial R&D projects and will be equally adept at developing production-quality code.

Must have's in a Candidate:
"" Computer vision and applications of machine learning.
"" Collecting, QCing, and analyzing huge datasets.
"" Using the best tools to streamline data acquisition and processing.
"" Assisting research scientists achieve their goals
"" A getting-it-done attitude with a desire to both push the boundary of fundamental knowledge and turn it into great products.
"" A degree in computer science or a quantitative field and at least one year of industrial experience working with data.
"" Strong math skills, a problem-solving aptitude and desire to automate
"" Experience of scientific programming and libraries relevant to image and video processing and management, for example OpenCV.
"" Experience with at least one programming language such as Python, C++, etc.
"" Experience working in a diverse and international team.",4.5,"HireTalent
4.5","Lincolnshire, IL","New York, NY",201 to 500 employees,1997,Company - Private,Staffing & Outsourcing,Business Services,$25 to $50 million (USD),-1
DATA ENGINEER,-1,"Job Overview

We are looking for a savvy Data Engineer to join our growing team of analytics experts. The hire will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. The Data Engineer will support our software developers, database architects, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems and products. The right candidate will be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives.

Responsibilities for Data Engineer:

- Create and maintain optimal data pipeline architecture,

- Assemble large, complex data sets that meet functional / non-functional business requirements.

- Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.

- Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies.

- Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.

- Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.

- Keep our data separated and secure across national boundaries through multiple data centers and AWS regions.

- Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.

- Work with data and analytics experts to strive for greater functionality in our data systems.

Qualifications for Data Engineer:

- Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.

- Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.

- Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.

- Strong analytic skills related to working with unstructured datasets.

- Build processes supporting data transformation, data structures, metadata, dependency and workload management.

- A successful history of manipulating, processing and extracting value from large disconnected datasets.

- Working knowledge of message queuing, stream processing and highly scalable ‘big data’ data stores.

- Strong project management and organizational skills.

- Experience supporting and working with cross-functional teams in a dynamic environment.

Knowledge, Skills, Abilities, and other Characteristics:

Qualifications:
5+ years of experience in a Data Engineer role, who has attained a Master’s degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field.
Industry-recognized certifications in data engineering, data architecture, informatics, machine learning, SQL
Experience with health care data, claim data, EMR systems (Meditech preferred), X.12 data formats, etc.
Experience with big data tools: Hadoop, Spark, Kafka, etc. (Preferred)
Experience with relational SQL and NoSQL databases, including Postgres and Cassandra.
Experience with data pipeline and workflow management tools: Azkaban, Luigi, Airflow, etc.
Experience with Microsoft and AWS cloud services: Azure, EC2, EMR, RDS, Redshift
Experience with stream-processing systems: Storm, Spark-Streaming, etc.
Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.
Experience with statistical programming languages: R, Stata, SAS, etc.
Experience with architectural concepts and schemas: TOGAF, MITA, Star schema, etc.
Skilled in problem-solving with strong attention to detail.
Excellent customer service skills and the ability to react diplomatically and patiently to internal and external customers.
Excellent follow-up skills paired with the ability to multi-task and determine root causes.
Strong written and verbal communication skills coupled with the ability to read, analyze and interpret technical procedures.
Strong response time to phone calls, emails and customer requests.
Adhere to department policies and standards.
Ability to work independently under minimal supervision in stressful situations and meet deadlines.
Ability to prioritize, plan, and organize tasks based upon user requirements.
Ability to multi-manage multiple projects utilizing best practices based on departmental priorities.
Ability to multi-manage multiple projects utilizing best practices based on departmental priorities.
MINIMUM WORK EXPERIENCE:

Bachelors Degree, 5 years of relevant experience including leading projects or 8 years of relevant experience including leading projects and developing teams .

REQUIRED LICENSES, CERTIFICATES, REGISTRATIONS:

MCSE or equivalent is strongly desired but not required",3.0,"Sinai Health System
3.0","Chicago, IL","Chicago, IL",1001 to 5000 employees,1918,Nonprofit Organization,Health Care Services & Hospitals,Health Care,$100 to $500 million (USD),"Resurrection Health Care, UChicago Medicine"
SR Machine Learning Engineer,-1,"Glow Networks is seeking a Senior Machine Learning Engineer to lead complex ML and big data projects as part of our customers new Data Center and Networking AI Team in San Mateo, CA. You will have the opportunity to solve some of the hardest and most interesting technological challenges facing the industry today.

The Team

You will be joining a new team of world-class high-performing and low ego engineers and scientists that have an entrepreneurial and hacker spirit. The team will operate in a very self-driven, agile and fast-paced environment. The team operates by self-organizing, around shared values, vision and objectives.

Qualifications
5-7 years of experience as a software engineer building and shipping production quality code in C/C++, Java, Python, or similar language
Minimum of 2 years of experience working on big data problems (in terabytes) using technologies like Cassandra, Hadoop, and Spark
Experience working on data modeling, data pipelines, and building warehouses projects
Experience deploying machine learning models to production is a MUST
Experience designing and developing infrastructure for the full cycle of machine learning
Experience building container-based applications running in a microservice architecture on Kubernetes or serverless
Comfortable researching and reading research papers and implementing models
Comfortable experimenting with and incorporating cutting-edge techniques into our existing system, such as online learning, transfer learning, and few-shot learning
Deep understanding of model training, what affects performance (hyperparameters, data distribution, etc)
Ability to write an end-to-end pipeline code that is modular, scalable, and easy for future team members to build upon
Education
Masters Degree in computer science or engineering, desired
Bonus
Experience working on time interval problems
Experience with data analysis and visualization
Extract meaningful insights from the data and present to leadership
What would really impress us?

Any side projects or hobbies that have to do with AIML.",3.1,"Glow Networks
3.1","San Mateo, CA","Richardson, TX",51 to 200 employees,2003,Subsidiary or Business Segment,IT Services,Information Technology,$10 to $25 million (USD),-1
Senior Data Engineer,-1,"Job Description
Senior Data Engineer

Position Overview: From software hacking to hardware hacking, we help secure everything from cryptocurrency exchanges and space telescopes to autonomous vehicles and the electric grid. Today, our client is making significant investments in terms of financial and engineering resources to develop a radically new customer experience we call “Security-as-a-Service” to provide customers with a unified, efficient, and data-driven security platform. We they're looking to add the right individual to their growing team supporting the next wave of cybersecurity products and solutions.

As part of that investment, our client is seeking a seasoned Data Engineer with a successful track record in data engineering in a hyper growth company setting. You will have the opportunity to work with some of the best security engineers in the world who hail from organizations such as Amazon, CIA, Facebook, Google, Microsoft, NSA, Redhat, Sun Microsystems, and US Air Force. As an Inc. Best Places to Work, Inc. 500 | 5000, Cybersecurity 500, and Austin Fast 50 Award recipient, we are seeking an individual that understands the professional and personal growth attached to this opportunity and who has the corresponding internal drive to maximize it.

Career opportunity:
Join an industry with massive socio, economic, and political importance in the 21st century
Work alongside some of the best and the brightest minds in the security industry
Leave an indelible mark on a company where individual input has real impact
Be recognized, internally and publicly, for your contributions in a high profile position
Align your career trajectory with a hyper growth company that is on the move
Core responsibilities:
Create pipelines to ingest and maintain complex data sets into our client's data stores for use in machine learning models
Create tools to scour the internet to find important security information and ingest it into their infrastructure
Work with data scientists to create and maintain data ontologies for security
Create the roadmap of how to continually evolve the data engineering infrastructure and techniques to improve our client's ability to find security information
Mentor junior data engineers and teach them how to use data engineering techniques to solve real world problems
Communicate complex concepts to team members
Accountable for:
Creation of data engineering pipelines to find and ingest security vulnerabilities
Creation of data engineering tools to help label and validate data
Required qualifications:
At least 8 years experience designing and building data processing/ETL pipelines
At least 8 years experience in Python and Spark or similar technologies
At least 8 years experience with SQL and relational databases
At least 8 years experience parsing flat files
8+ years development experience
Prior track record in a hyper-growth, high-tech company
Bachelor's degree or equivalent practical experience
Desired qualifications:
Experience working with Google Tensorflow
Experience with modern technology stacks
Experience with micro-services architectures
Experience with cloud platforms and SaaS solutions
Experience with agile/scrum development practices
Experience with test driven development, continuous integration, continuous deployment
Experience with Git, JIRA, Confluence
Experience with Google Compute, Firebase, and GKE
Experience with Docker
Desired behaviors:
Relentless restlessness to turn theory into practice and develop production worthy code that solves real-world customer problems
Determination to always learn and get better and never rest on ones laurels
Personable individual who enjoys working in a team-oriented environment
Comfort dealing with ambiguity in an environment where we build the plane as we fly it
Ability to work within constraints and to challenge the status quo
Ability to self-direct work and truly own the position in a hyper-growth environment
Compensation package:
Competitive compensation
Ownership opportunity through employee stock option plan
Health, dental, and vision insurance
4% company 401K matching vested immediately",5.0,"Uplink Talent Solutions
5.0","Austin, TX","Boston, MA",1 to 50 employees,-1,Company - Private,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
Software Engineer- Machine Learning Infrastructure,-1,"Company Overview

Calling the adventurers ready to join a company that's pushing the limits of nanotechnology to keep the digital revolution rolling. At KLA, we're making technology advancements that are bigger—and tinier—than the world has ever seen.

Who are we? We research, develop, and manufacture the world's most advanced inspection and measurement equipment for the semiconductor and nanoelectronics industries. We enable the digital age by pushing the boundaries of technology, creating tools capable of finding defects smaller than a wavelength of visible light. We create smarter processes so that technology leaders can manufacture high-performance chips—the kind in that phone in your pocket, the tablet on your desk and nearly every electronic device you own—faster and better. We're passionate about creating solutions that drive progress and help people do what wouldn't be possible without us. The future is calling. Will you answer?

Group/Division

With over 40 years of semiconductor process control experience, chipmakers around the globe rely on KLA to ensure that their fabs ramp next-generation devices to volume production quickly and cost-effectively. Enabling the movement towards advanced chip design, KLA's Global Products Group (GPG), which is responsible for creating all of KLA’s metrology and inspection products, is looking for the best and the brightest research scientist, software engineers, application development engineers, and senior product technology process engineers.

First to deliver the best imaging and classification data for every defect or point on any layer at any time.

EBeam’s mission encapsulates its role as the “eyes” of KLA’s product line, providing timely information on defects and critical locations on the wafer at the highest spatial resolution possible. Customers use EBeam products alongside KLA patterned and bare wafer inspectors to quickly understand the nature of defects and other imperfections on product wafers and take action to correct the manufacturing process.

Responsibilities

At KLA we don't just work on bleeding edge, we define bleeding edge. The Software driving our eBeam Inspection/Review tools enables our Customers to create next the generation of processor technologies

We are looking for passionate professionals to join our team!

The successful candidate will be involved in building complex multimillion-dollar products which are a composition of (Software, Electronics, Mechanics and Machine Control). These product(s) are to solve critical modern-day challenges in the fields of nano-technologies and complexities of manufacturing advanced next gen semiconductor chips

Responsibility will include the development, support for highly scalable service orientated infrastructure to execute machine learning algorithms, seamlessly move high volumes of data across components.

Understand the design, architecture of the system/product and the layered software that runs the system.

With an R&D mindset explore, experiment, and bring the cutting-edge open source technologies to the product

Work in an agile based development environment

Attitude:

Share knowledge and willing to learn from others and co-workers

Inquisitive and scientific spirit, eager to learn new technologies, experiment and fail

Team spirit, collaboration, “never-give-up”

Bring the “startup” kind of mindset to blend with an experienced corporate leader in semiconductor related industries

Qualifications

Proficiency in Python, Java, C/C++. Familiarity with DL frameworks (e.g., Tensorflow, Caffe, Torch, etc).

We understand that the languages keep evolving and proliferate. We are not looking for language syntax, we are looking at your basic problem-solving skills in software computing and past exposure to these languages:
Design and Code in Object Oriented Technology
Proven ability to influence cross-functional teams without formal authority
Highly creative and inquisitive; able to multitask effectively
Strong verbal and written communication skills
Minimum Qualifications

Doctorate (Academic)
OR
Master's Level Degree with at least 2 years of experience.
OR
Bachelor's Level Degree with at least 3 years of experience.

Equal Employment Opportunity

KLA is an Equal Opportunity Employer. Applicants will be considered for employment without regard to age, race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability, or any other characteristics protected by applicable law.",3.8,"KLA-Tencor
3.8","Milpitas, CA","Milpitas, CA",5001 to 10000 employees,1976,Company - Public,Industrial Manufacturing,Manufacturing,$2 to $5 billion (USD),"Applied Materials, Nanometrics"
"Software Engineer, Data Visualization",-1,"About CharterUP

CharterUP aims to be the leading charter bus platform in the world and is looking for people that want to be along for the ride! We are disrupting the highly fragmented bus industry by connecting supply-side bus companies to demand-side clients (corporations, non-profits, and governmental entities). We strive towards having as many enthusiastic customers as possible, which leads to increased group travel and a greener earth.
About This Role

As a Data Visualization Software Engineer, you are expected to own end-to-end visual analytics solutions from ideation to production through rigorous field studies for domains ranging from business, machine learning, urban computing, experimentation, to autonomous vehicle data.
What You’ll Do
Develop data-intensive applications and advanced user interfaces for data producers and consumers across the company
Architect production-level applications using modern Web and Visualization technologies such as React/Redux, GraphQL, WebGL, and D3
Work closely with customers ranging from data scientists, operations, security investigators, researchers, and urban planners
What You’ll Need
Bachelor’s Degree in Computer Science or related field from a top-ranked institution
Experience building and maintaining large-scale batch and/or real-time data processing pipelines
Understanding a users’ role in complex data and machine learning systems
Contribution to open-source software libraries
Application Process

The selection process for this role differs from our traditional tech team application process. A member of our team will reach out to you if you qualify for the next step.

CharterUP Principles

At CharterUP, we don’t compromise on quality. We hire smart, high-energy, trustworthy people and keep them as motivated and happy as possible. Do that by adhering to our principles, which are:

Customer First
We always think about how our decisions will impact our clients; earning and keeping customer trust is our top priority
We are not afraid of short-term pain for long-term customer benefit
Create an Environment for Exceptional People
We foster intellectual curiosity
We identify top performers, mentor them, and empower them to achieve
Every hire and promotion will have a higher standard
Everyone is an Entrepreneur / Owner
No team member is defined by their function or job title; no job is beneath anyone
We do more with less; we are scrappy and inventive
We think long-term
Relentlessly High Standards
We don’t accept “that’s how it’s always been done”; we constantly innovate and question established routines to improve processes
We actively push to be proved wrong and welcome different ideas; the best idea wins
We don’t compromise on quality
Clarity & Speed
When in doubt, we act; we can always change course
We focus on the key drivers of a process that will deliver the most results
Mandate to Dissent & Commit
We are confident in expressing our opinions; it is our obligation to express our disagreement
Once we decide, we enthusiastically move together in the agreed upon direction",4.7,"CharterUP
4.7","Atlanta, GA","Atlanta, GA",51 to 200 employees,2017,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
"Staff Software Engineer, Machine Learning","$156K-$254K
(Glassdoor est.)","Vungle's software engineers build machine learning systems to work at scale and in real-time, evaluating and ranking millions of possibilities each second. Every improvement to our recommendation models has a direct impact on Vungle's mission, and that means we get the chance to push our machine learning algorithms to their limits.

We're looking for hardcore software engineers who love applying their skills to all sorts of problems in the machine learning domain. At Vungle, you'll work on a small engineering team responsible for the design and implementation of high-performance, scalable, and reliable ML architecture. You'll collaborate closely with our Data Scientists and work on everything from feature engineering to database design to custom implementations of state-of-the-art machine learning algorithms. Most importantly, you'll have the chance to get your ideas into production, measure their impact, and keep improving.

What you'll do:
Design and scale predictive models to handle production-level loads of billions of daily requests
Identify new features, better algorithms, and performance optimizations; test your ideas on live traffic and take them from prototype to production
Work with data science and ML toolkits like scikit-learn, numpy, TensorFlow, Theano and the like
Use big data technologies like Spark to build efficient and reliable data pipelines specifically designed to support problems in the machine learning domain
Use your expert coding skills across a number of languages such as Python, Scala and Go
Be technology agnostic and always pick the right tool for the job
Be an evangelist for quality software engineering practices
Requirements:
MS in Computer Science or equivalent with 6+ years professional experience as a software developer, or a BS with 8+ years of experience
2+ years experience with machine learning, artificial intelligence or related field (either academic or industry)
Strong programmer with a background in OOP (Python, Java, C++, Scala or equivalent), capable of writing high performance production quality code
Strong understanding of CS fundamentals, data structures and algorithms and complexity analysis
Familiarity with core ML concepts, common supervised and unsupervised algorithms, feature engineering and feature selection, bias/variance, etc
Comfortable conducting and participating in thorough design and code reviews
Preferred:
Previous experience in back end development
MS in Computer Science or related field with coursework in machine learning or artificial intelligence
2+ years professional experience working with popular machine learning libraries such as scikit-learn, TensorFlow, Theano or similar
Experience implementing and maintaining high performance back end systems
Experience working with distributed frameworks and big data technologies like Spark


About Vungle:

Vungle is the trusted guide for growth and engagement, transforming how people discover and experience apps. Mobile application developers partner with Vungle to monetize their apps through innovative in-app ad experiences that are inspired by insight and crafted with creativity. Advertisers depend on Vungle to reach, acquire, and retain high-value users worldwide. Vungle develops tools that include data-led buying and UX recommendations, ad format innovation, creative automation, and more. Vungle's data-optimized ads run on over 1 billion unique devices to drive engagement and increase returns for publishers and advertisers ranging from indie studios to powerhouse brands, including Rovio, Zynga, Pandora, and Microsoft. The company is headquartered in San Francisco and has offices around the world in London, Berlin, Beijing, Tokyo, Seoul, and Singapore. For more information, visit www.vungle.com or follow the company on Twitter @Vungle

#LI-JH1",3.6,"Vungle
3.6","San Francisco, CA","San Francisco, CA",201 to 500 employees,2011,Company - Private,Internet,Information Technology,$100 to $500 million (USD),"AdColony, Unity, AppLovin"
Machine Learning Software Engineer,-1,"RESPONSIBILITIES:

Kforce has a client in building a team of Machine Learning Software Engineers in Wilmington, Delaware (DE) and Tampa, Florida (FL) and Plano, Texas (TX). This team is focused on developing and delivering cutting edged mobile applications, digital experiences and next generation banking technology solutions to better serve our clients and customers.

Summary:
Our Machine Learning Software Engineers will have the business acumen to understand and analyze problems, define and test hypotheses and develop Machine Learning frameworks and best practices. Additionally, they will be responsible to intricate knowledge of our business domains and data sets which include Systems of Record (SOR), historical and external data. Finally, this individual will take ownership in designing models to deliver performance and accuracy when operationalized as well as inference engines at scale with the business processes and applications.

Duties:
Analyze and conduct learning/simulations with large datasets combining multiple platforms (ex. Hadoop, Spark, AWS), and machine learning frameworks (ex. R, sci-kit, PySpark, Pandas, TensorFlow)
Lead/mentor a team of data scientists and machine learning engineers, who help the business identify new insights from large/rich data sets, and implement data driven strategies that reduces fraud, post-fraud loss and other operational efficiencies
REQUIREMENTS:
3+ years of hands-on experience: Python (or other scripting), Java, Hadoop/Spark/Hive and/or AWS, and 10+ years of hand-on experience with SQL
Expertise across application, data and infrastructure architecture disciplines
Advanced knowledge of architecture, design and business processes
Experience with Machine Learning, Deep Learning, Data Mining, and/or Statistical Analysis tools
Operationalize machine learning models using offline and online models, model performance monitoring, frequent/automated model updates, back/now testing, managed test harness and managed feature libraries; Ability to automate data exploration and model exploration activities and embed end-to-end model development and deployment into automated CI-CD/DevOps pipelines
Hands-on data analytics using machine learning, statistical modelling and/or data mining to uncover insights from large data sets and develop data and predictive models supporting multiple business domains spanning Fraud, Consumer Banking Operations, Digital Banking and Customer Experience scenarios. Interpret and explain methods using statistical analysis
Kforce is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.",4.1,"Kforce
4.1","Wilmington, DE","Tampa, FL",10000+ employees,1966,Company - Public,Staffing & Outsourcing,Business Services,$1 to $2 billion (USD),-1
Software Development Engineer - Machine Learning,-1,"Prime Video is changing the way millions of customers interact with video content. The Prime Video team delivers high-quality video to Amazon customers through subscriptions (Amazon Prime) as well as purchases and rentals. Amazon believes so deeply in the mission of our video offering that we've launched our own studio to create original and exclusive content.

PV Customer engagement Optimization team owns product development of an intelligent channel agnostic engagement automation designed to provide a holistic view of a prime video customer's lifecycle state, recommendations, they have seen, and/or marketing messages they have (or have not) received. Using smart rules and machine learning, self learning system sends relevant, timely, and personalized content on a fully automated basis. We are building a multi-channel campaign management system powered by customer profile data, engagement propensity models and recommendations to enable automated customer segmentation and targeting.

Are you looking for an opportunity to use machine learning and add a valuable skill to your developer toolkit? Are you prepared to take on manual and partially automated business processes and replace them with high-velocity AI enabled services? We are looking for software developers willing to embrace ML, re-invent established business processes, replace them with an algorithm driven platform and most of all, think out side the box for our customers. Prior experience with machine learning is not required, though will be helpful.

You will join a development team that interacts with marketing and data scientist teams. Our team researches and builds channels through which we engage and stay connected with our customers, such as dynamic video ads, personalized e-mail recommendations, amazon retail websites and social media. The services we build rely on leading edge machine learning techniques to learn about our customer needs and to match them with a wide array of video content. In short, we have exciting challenges in an industry that's doubling in size every year, and you can be a part of it!

You should expect to exercise both your coding skills and creative abstract thinking as you map real world processes to automated systems. Please be aware that even though diving deep into machine learning algorithms is not a requirement for this position, a small, but statistically significant percentage of developers find their propensity for math dangerously elevated over time.

If you are ready to truly make an impact on a product that interacts with millions of people around the world, including your own friends and family, then we would love to talk to you!

Amazon is an Equal Opportunity-Affirmative Action Employer - Minority/Female/Disability/Vet
Basic Qualifications
4+ years of non-internship professional software development experience
Programming experience with at least one modern language such as Java, C++, or C# including object-oriented design
1+ years of experience contributing to the architecture and design (architecture, design patterns, reliability and scaling) of new and current systems.
* Bachelor's Degree in Computer Science or related field
Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.",-1,Amazon Corporate LLC,"Seattle, WA",-1,-1,-1,-1,-1,-1,-1,-1
"Senior Software Engineer, Deep Learning","$167K-$178K
(Glassdoor est.)","Join a small, rapidly growing, and dynamic software team building workflows for next generation GPU based applications, such as machine learning and deep learning. The position involves driving requirements for developing a deep learning platform for data scientists. The position will be part of a fast-paced crew that designs and builds scalable distributed computation systems for Machine Learning/Deep Learning.

What we need to see:
BS or MS in CS or CE
At least 6+ years of relevant systems software development
Outstanding communication and planning skills
Self driven with a focus on execution and quality
Strong academic background in Computer Science or related degree
Excellent development skills with emphasis on C/C++, Java and Python
Experience with open source big data technologies such as Spark, Airflow, Mesos, Yarn, Zookeeper, Kafka, Docker, Oozie, Hadoop Map-Reduce, ElasticSearch, Hue.
Ways to stand out from the crowd:
Experience with deep learning is a strong plus, including Tensor Flow, Theanos, Caffe, Torch etc
Experience with Scala and Go
Experience with Docker ecosystem
Familiarity with AWS deployment infrastructure
NVIDIA is widely considered to be one of the technology world’s most desirable employers. We have some of the most forward-thinking and hardworking people in the world working for us. If you are creative and autonomous, we want to hear from you!

NVIDIA’s invention of the GPU 1999 sparked the growth of the PC gaming market, redefined modern computer graphics, and revolutionized parallel computing. More recently, GPU deep learning ignited modern AI — the next era of computing — with the GPU acting as the brain of computers, robots, and self-driving cars that can perceive and understand the world.

Today, we are increasingly known as “the AI computing company”. We growing our company and the team with the smartest people in the world. We are looking for you to join the Tesla driver team. You are expected to design, develop, and deliver driver solutions for new Tesla GPU designs on current and future Linux and Windows platforms.

NVIDIA is committed to fostering a diverse work environment and proud to be an equal opportunity employer. As we highly value diversity in our current and future employees, we do not discriminate (including in our hiring and promotion practices) on the basis of race, religion, color, national origin, gender, gender expression , sexual orientation, age, marital status, veteran status, disability status or any other characteristic protected by law.",4.6,"NVIDIA
4.6","Santa Clara, CA","Santa Clara, CA",10000+ employees,1993,Company - Public,Computer Hardware & Software,Information Technology,$5 to $10 billion (USD),-1
Senior Software Engineer - Machine Learning - Time Series,"$138K-$237K
(Glassdoor est.)","Senior Software Engineer - Machine Learning - Time Series

Team: Applied ML

Location: Sunnyvale, CA

ABOUT THE ROLE

Petuum is seeking outstanding MS or PhD-level engineers in machine learning management, distributed systems, deep learning, natural language understanding, and other related fields. You will be part of a team of world-class engineers, designers, and scientists, working together to democratize the building and deployment of AI and Machine Learning systems. You will have ownership over the projects you work on and have the flexibility to influence the design and execution of your team's work. A hard-working entrepreneur spirit is highly valued and rewarded in the company.

What You Will Do:
Design, implement and evaluate new models and software prototypes to solve problems in machine learning and systems engineering.
Create software design and programming support to machine learning projects.
Implement and evaluate machine learning algorithms.
Report and present software developments including clear and efficient status and results both internally and externally, verbally and in writing.
Architect and implement software libraries.
Experience leading a team of Machine Learning Engineers, Data Scientists, and Software Engineers.
Review code and mentor junior engineers on best practices.
Build the code architecture on which any future development might be based on.
Other duties as assigned.
What You've Already Done:
You have a Master's Degree in Computer Science or related quantitative field. A Ph.D. or equivalent practical work experience is a plus.
You have 4+ years of experience.
Experience with implementing statistical or machine learning algorithms, algorithm design and software engineering.
Experience in machine learning, recommendation systems, pattern recognition, analytics or artificial intelligence. Proven ability to translate insights into business recommendations.
Experience with filesystems, server architectures, and distributed systems is a plus.
Startup experience is a plus.
What You Already Know:
Languages: Python, C++
What We Offer for your Valuable Work:

Petuum offers Medical, Dental, Vision, Life/Disability, Paid Time Off, Parental Leave, and more.

Petuum is a welcoming workplace that considers applicants for employment without regard to, and does not discriminate on the basis of, gender, race, protected veteran status, disability, or any other legally protected status. Petuum is an at-will employer.",2.5,"Petuum
2.5","Sunnyvale, CA","Pittsburgh, PA",51 to 200 employees,2016,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
"Data Engineer Lead, Machine Learning",-1,"BICP is partnered with an iconic retail client to hire a Machine Learning Data Engineer Lead to join the global Data, Analytics & AI team. Our clients singular focus is to revolutionize and redefine the apparel business. The global Data, Analytics & AI is best framed up as having the vibe of a startup but with considerable technology assets at your fingertips, where you will have a chance to work with the latest and greatest technologies to deliver cutting edge solutions that will significantly impact how we do business. As a ML Data Engineer Lead, you will work on a broad set of domains that power a data driven transformation of our standard business procedures across channels and organizations. You will be responsible for developing and deploying novel algorithms along with optimizing existing machine learning systems to maximize their business value and increase consumer satisfaction at every brand touchpoint.

We’re looking to hire a technology-agnostic polymath committed to a lifelong journey of continuous learning and exploration of innovative scientific ideas and will bring thoughtful perspectives, empathy, creativity, and a positive attitude to solve problems at scale. This role is ideal for someone looking to extend their algorithm design and software engineering skills into a part mentor, part IC, part thought partner role. You will serve a large role in driving the client’s transformation into a data-driven enterprise.

Job Responsibilities
Architect, build, maintain, and improve new and existing suite of algorithms and their underlying systems.
Implement end-to-end solutions for batch and real-time algorithms along with requisite tooling around monitoring, logging, automated testing, performance testing and A/B testing.
Utilize your entrepreneurial spirit to identify new opportunities to optimize business processes and improve consumer experiences, and prototype solutions to demonstrate value with a crawl, walk, run mindset.
Work closely with data scientists and analysts to create and deploy new product features on the ecommerce website, in-store portals and the company’s mobile app.
Establish scalable, efficient, automated processes for data analyses, model development, validation and implementation
Write efficient and well-organized software to ship products in an iterative, continual-release environment
Contribute to and promote good software engineering practices across the team
Mentor and educate team members to adopt best practices in writing and maintaining production machine learning code
Communicate clearly and effectively to technical and non-technical audiences equally well
Actively contribute to and re-use community best practices
Embody the values and passions that characterize our organization with empathy to engage with colleagues from a wide range of backgrounds
Required Skills
University or advanced degree in engineering, computer science, mathematics, or a related field
5+ years’ experience developing and deploying machine learning systems into production
Strong experience working with a variety of relational SQL and NoSQL databases
Strong experience working with big data tools: Hadoop, Spark, Kafka, etc.
Experience with at least one cloud provider solution (AWS, GCP, Azure)
Strong experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.
Ability to work in a Linux environment
Industry experience building and productionizing innovative end-to-end Machine Learning systems
Ability to quickly prototype ideas and solve complex problems by adapting creative approaches
Experience working with distributed systems, service oriented architectures and designing APIs
Strong knowledge of data pipeline and workflow management tools
Expertise in standard software engineering methodology, e.g. unit testing, test automation, continuous integration, code reviews, design documentation
Relevant working experience with Docker and Kubernetes is a big plus
Additional Key Metrics
Preference will be given to candidates either based in, or willing to relocate to, Dallas/Ft. Worth or San Francisco area.
US Citizens, Green Card & H1B Visa holders are eligible for consideration and welcome to apply. Client has ability to transfer H1B’s and sponsor.
Start date is ASAP and compensation is negotiable contingent on experience and qualifications.
Job Type: Full-time

Pay: $160,000.00 - $180,000.00 per year

Benefits:
401(k)
Dental Insurance
Employee Discount
Health Insurance
Paid Time Off
Vision Insurance
Supplemental Pay:
Signing Bonus
Experience:
AWS, Azure or GCP: 1 year (Preferred)
Scala: 1 year (Preferred)
Kafka: 1 year (Preferred)
Java: 1 year (Preferred)
SQL: 3 years (Required)
Python: 1 year (Required)
Machine Learning: 1 year (Required)
NoSQL: 1 year (Preferred)
Spark: 1 year (Preferred)
Education:
Bachelor's (Required)
Work authorization:
United States (Required)
Additional Compensation:
Bonuses
Store Discounts
This Company Describes Its Culture as:
Innovative -- innovative and risk-taking
Stable -- traditional, stable, strong processes
People-oriented -- supportive and fairness-focused
Schedule:
Monday to Friday
Day shift
Work Remotely:
Temporarily due to COVID-19",5.0,"BICP
5.0","Fort Worth, TX","Carlsbad, CA",1 to 50 employees,2009,Company - Private,IT Services,Information Technology,$10 to $25 million (USD),-1
Senior Software Engineer (Data Platform),-1,"About us:
Oncora is an oncology software and data company dedicated to helping physicians and scientists collect and use real-world data to improve outcomes for cancer patients. Our machine learning algorithms, which are deployed in active clinical environments, accurately predict oncology outcomes such as unplanned hospitalization, survival, and recurrence. Our software products include: a data capture system for radiation oncology clinical care, a data warehouse that leverages connections other healthcare software systems such as EMRs, PACS, to amass real-world, regulatory-grade oncology data, a machine learning platform to train and validate predictive models of key oncology events, a publicly machine learning API to power external software tools, and a virtual clinical trial platform that allows pharma and device companies to leverage automated medical image analysis to advance new technologies in the fight to cure cancer. We work with world-leading cancer centers such as MD Anderson and Northwell Health, global device companies such as Varian Medical Systems, and innovative biopharma companies. Our team is mission-driven to its core.

About the role:
We are looking for an experienced engineer to join our mission driven team to help develop our data platform that integrates and transforms multiple imperfect and messy healthcare data sources into clean, usable data so that we can learn from every cancer patient.

We are a small team trying to tackle a large problem, so we need teammates that are ultimately accountable to themselves and continuously push the product and the organization forward. You will need to play a vital role in developing and operating our core data platform and help to scale it to serve additional hospitals.

Responsibilities:
Designing and implementing improvements to our data extraction and transformation processes to increase performance and stability
Overseeing and monitoring our existing data platforms for stability, performance and accuracy
Incrementally evolving our platform architecture without disrupting operations
Working with Product and Engineering to define, document, and build transformations to extract intelligence from multiple incomplete and siloed data sources
Building pipelines to de-identify and consolidate cross-institutional data to fuel predictive analytics, research, and clinical trials
Building visibility into all aspects of our data platform (workflow status, system health, data lineage, etc.)

Qualifications:
Demonstrated experience independently leading complex software projects
Experience designing and building data pipelines (real-time or batch)
Deep understanding of data persistence technologies, relational, document, key/value, columnar, etc (we use MongoDB, Postgres, Redis, and ElasticSearch)
Experience building asynchronous and distributed systems (we use RabbitMQ)
Fluency with a functional or imperative language (we use Python & JS)
A focus on writing understandable, testable, and maintainable code
Familiarity with modern containerized environments (we use Docker & Kubernetes)
Experience with healthcare data standards and integrations (HL7, FHIR, DICOM, etc.)

Compensation, Benefits, and Perks:
Salary: $100k-130k
401k, health and dental insurance, flexible vacation, paid parental leave
eBooks, online courses, home office budget
Work with smart, passionate people on a product that will have a direct impact on the lives of cancer patients

Oncora is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, age, sex, religious creed, disability, ancestry, national origin, sexual orientation, gender identity, or gender expression.",-1,Oncora Medical,"Philadelphia, PA","Philadelphia, PA",1 to 50 employees,-1,Company - Private,Health Care Services & Hospitals,Health Care,Unknown / Non-Applicable,-1
Senior Data Engineer/Data Scientist,-1,"We are a recruiting agency that works hard to tailor the right synergy between candidate and company. We do this by looking at the career experience and goals of each candidate and clarifying the specific needs of the job with each hiring manager and team.

We are currently seeking a Senior Data Engineer/Data Scientist for an entertainment company in Burbank. The Data Engineer will lead an exciting team in developing innovative technology and delivering uniquely creative content globally. The salary for the Data Engineer starts at $90 per hour.

Please, only apply if you are able to work directly for a U.S. company for the next three years. We are not currently able to work with C2C, H1, or OPT for this position.

Duties & Responsibilities:
Build and optimize performance of Hadoop and Spark batch jobs (Spark, Kafka, Cassandra, etc.).
Construct and improve ElasticSearch performance.
Build data pipelines orchestration.
Create the design and architecture for data-lake, data-marts, data-models, and data-warehouse.
Ensure efficiency of data science workflows and advanced machine learning algorithms.
Contribute to open source solutions and communities.
Stay current on emerging tools and technologies.
Collaborate cross-functionally with other software engineers and their teams.
Establish and demonstrate technologies, solutions, and leading practices.
Balance resources, requirements, and complexity.
Qualifications:
At least, 5 years Data Engineer experience.
Bachelors in Computer Science or similar field.
Possess a passion for coding.
Knowledge of distributed systems and computation.
Experience with Scala, Java, Python, and Go-Lang.
Experience with Apache Hadoop/Spark ecosystem.
Demonstrated working knowledge of data modeling.
Stellar interpersonal and communication skills.
Required Experience:
Git, Unix/Linux, Unit, Integration, Load Testing, developing REST APIs, Ant, Maven, SBT, Gradle, and Docker containers building and deployment.
Experience, preferred:
Jenkins, GraphQL, Amazon AWS (or other cloud services), Kubernetes, Apache Spark (MLib and Graph X).
Salary for the Data Scientist:
Starts at $90/hour.
Powered by JazzHR",-1,Evolvinc,"Burbank, CA","Los Angeles, CA",1 to 50 employees,2005,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Machine Learning Engineer - Simply Biotech,-1,"Machine Learning Engineer - Simply BiotechAre you looking for a new career opportunity with an exciting biotech company?! Then we have got the right team for you! In this role, you are responsible for the duties listed below. Immediate opening for a Machine Learning Engineer in Palo Alto, CA who possess: -PhD, MS, or BS in computer science, engineering, statistics, or similar -2+ years of technical industry experience (biotech and software engineering preferred) -Must have experience with development and deployment in a production environment -Significant experience with Python -Significant experience with a deep learning framework (high preference for PyTorch & TensorFlow) Email your resumes to mdaniels@simplybiotech.com or call 858.239.2849 FULL DESCRIPTION: As a (Senior) Machine Learning Engineer, you will lead the development and deployment of advanced machine learning models that will give greater resolution into the health and molecular state of patients. You will work closely with an inter-disciplinary team of laboratory scientists, data scientists, and engineers to ensure the company meets its key milestones and objectives as well as identify additional opportunities where machine learning can bring real business value. You will also have the advantageous opportunity to collaborate on the data generation process itself. The selected candidate will further possess: -Experience with developing and deploying in a cloud platform e.g. AWS, GCP, Azure -Fundamental knowledge of probability and statistics in their application to developing and deploying machine learning models -Ability to communicate and collaborate with an inter-disciplinary team -Ability to translate business-level and scientific-level objectives to engineering objectives -Experience with clinical or biological data e.g. genomics, proteomics, imaging, EMR -Experience in NLP or image recognition applications -Experience with knowledge graphs For immediate and confidential consideration, please email your resume to mdaniels@simplybiotech.com or call 858.239.2849 More information can be found at www.SimplyBiotech.com",4.6,"TalentZok
4.6","Palo Alto, CA","San Diego, CA",51 to 200 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
"Sr. Backend Engineer, Machine Learning","$130K-$198K
(Glassdoor est.)","At Globality, we're proud to embody the core values of innovation, collaboration, and trust in both our culture and product.
We're creating ground-breaking technology utilizing a world-class, AI-powered Platform that revolutionizes how businesses buy and sell services. We are an open, inclusive, and diverse organization and our employees are at the heart of the great products we create.

We've raised over $172M and are supported by an impressive group of prominent investors, including Al Gore and SoftBank Vision Fund. Our co-founders, Joel Hyatt and Lior Delgo, are seasoned entrepreneurs who bring an extensive business-building experience to our organization. Our impressive board includes Dennis Nally (former Global Chairman of PwC) and Ron Johnson (former SVP of Apple).

Role Summary:
We seek an engineer with a passion for building machine learning and data pipeline solutions to power intelligent product features at scale.

Does this sound like you?

Are you excited about separating signal from noise in web-scale datasets?

Do you enjoy building software that improves user experience by helping users reach the right conclusions?

Does your ideal work environment involve collaborating within multi-functional teams in a dynamic startup environment?

Are you motivated by directly impacting the core technologies that power a meaningful business platform?

If so, you should join our team.

What you will be doing:
Be a lead contributor to the design and implementation of our core infrastructure and data pipeline, powering our Machine Learning and NLP products. In collaboration with our data scientists and senior engineers, you'll be improving indexing logic, tuning relevancy, and optimizing performance, towards the overall goal of delivering a delightful user experience to our end-users and internal users, across a range of ML-powered products
Wrangle messy data. Real-world data, especially as found on the web, comes in all shapes and sizes, and can often be noisy. Working alongside our NLP engineers, drive solutions for cleaning noisy text, normalizing it and ensuring high-quality data through-out our ML pipeline.
What we are looking for:
You have at least 5 years of software development experience in crafting high performance, reliable and scalable production systems
You have strong engineering experience in Python, in particular in the context of ML applications, using frameworks such as pandas, nltk, Pattern, spaCy.
You have experience working with noisy textual data, and are familiar with the various text normalization methodologies that are employed to index such data effectively
Deep understanding of core computer science fundamentals and distributed systems
Bonus: You have ample experience with Information Retrieval and Web Search systems, such as Elasticsearch, ideally cloud-based deployments such as via AWS or Elastic Cloud.
We are an equal opportunity employer and a participant in the E-Verify program. We believe diversity makes teams better and that discrimination based on race, gender, or anything else is self-defeating.",4.4,"Globality, Inc.
4.4","Menlo Park, CA","Menlo Park, CA",201 to 500 employees,2015,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Artificial Intelligence/Machine Learning Applications Engineer,"$64K-$116K
(Glassdoor est.)","We are looking for engineers with a passion for using machine learning to create intelligent applications. In this highly accomplished, deeply technical and close-knit team of data scientists and machine learning engineers, you will create tools that are used by the warfighter. You will design and implement new machine learning algorithms and techniques and collaborate with the most innovative product development teams in the world. Our team researches new machine learning algorithms, models and techniques that will power amazingly intelligent capabilities for our nation. We want new ambitious team members to join our research AI/ML group. In this role, we create new models and algorithms, and actively engage with the best and brightest at Torch. You will also have the opportunity to contribute to IRAD, and use your data science, machine learning and artificial intelligence skills to transfer your ideas into solutions for some of the most challenging technical problems for our Nation.


Job Requirements

Key Qualifications

Experience applying machine learning to solve practical problems
Solid understanding of foundational statistics concepts and ML algorithms
Experience working with time-series sensor data (optical, electrical, motion, and other)
Experience building/working with data pipelines
Strong software development skills, with proficiency in Python and C++ preferred
Creative, collaborative, & product focused
Bachelors in Engineering/Science required, MS/PhD in Machine learning, EE, Statistics, Computer Science, Physics, or related field with 3-5 years industry experience is desirable

If you are a qualified individual with a disability or a disabled veteran, you have the right to request a reasonable accommodation if you are unable or limited in your ability to use or access https://torchtechnologies.hua.hrsmart.com/ats as a result of your disability. You can request reasonable accommodations by sending an email to human.resources@torchtechnologies.com. Thanks for your interest in Torch Technologies.",4.5,"Torch Technologies
4.5","Huntsville, AL","Huntsville, AL",1001 to 5000 employees,2002,Company - Private,Aerospace & Defense,Aerospace & Defense,$100 to $500 million (USD),-1
Software Engineer (Java API),-1,"Job Description
All candidates must take a Coding Assessment.

Position Description:
This Software Engineering position is in the Connected Consumer and GDIA domains and is a highly technical position.
The position is responsible for. Delivery of Java APIs and Mobile Apps that allow our customers to move while staying connected to their vehicle.
Work as part of a product team to lead the engineering, development and coding of complex solutions that enable critical Connected Consumer and Vehicle Features.
Deliver software craftsmanship principles in the projects and be able to share the successful implementation.
Develop tools and processes to automate the delivery of new features/capabilities while elimination waste.
Experiment with new and innovative software projects that automates and improves performance of the software that enables Mobile App and Vehicle Communication.
Lead software engineers to understand platform vision, break out tasks and help them solve challenging issues.
Work hand to hand with Data Scientists to shape the future vision of our Data Science platform
Skills Required:
Basic Qualifications: Bachelor""s degree in Information Technology or a related field of study.
7+ years of object oriented development experience in API, Cloud, Mobile App or Machine Learning Technologies.
7+ years of experience in designing and developing scalable features
Preferred Qualifications:
Excellent software engineering knowledge; OO Design Principles.
eXtreme Programming (XP) disciplines including paired programming and Test-First/Test Driven Development (TDD).
Experience with Spring Cloud and deploying to cloud platforms, preferably Pivotal Cloud Foundry or Cloud Foundry.
Experience with Android and deploying to the Google Play Store.
Highly effective in working with other technical specialists, Product Managers, UI/UX Designers and Product Owners.
Delivered products that include web front-end development; JavaScript, client-side MVC frameworks like Angular, React, etc. Capable in Continuous Integration/Continuous Delivery tools and pipelines such as Jenkins, Maven, Gradle, etc. Understanding or desire to learn BI end to end technology stack (Tools such as Kubeflow, Kubernetes, SeldonCore, H2O, Data Robot, Anaconda, OpenScale, pytorch, tensorflow, xgboost etc)
Education Required:
B.S. Information Systems, Computer Science or equivalent work experience in the requested field",5.0,"BlueStone Staffing Solutions
5.0","Taylor, MI","Palatine, IL",51 to 200 employees,2002,Company - Private,IT Services,Information Technology,$10 to $25 million (USD),-1
Machine Learning Engineer,"$40K-$75K
(Glassdoor est.)","We deliver our customers peace of mind every day by helping them protect what they value most. Our passion for placing the customer at the center of everything we do is driving a transformational shift at Liberty Mutual. Operating as a tech startup within a Fortune 100 company, we are leading a digital disruption that will redefine how people experience insurance.
Job Introduction:

The Analytic Platform and Service organization is looking to hire a Machine Learning Engineer to their team. This candidate will participate in the software development within an Agile team and work on the internally developed analytics application.
About the job:
Build out our Real Time Scoring platform and working with our data scientist partners to support the deployment of predictive models and deliver business value from AI and Machine Learning.
Develop Java application that is intended to allow analytics teams to quickly create, manage and terminate their own scalable high-performance cloud computing and storage environments to support analytics, machine learning and big data projects.
Work directly with data science teams in all markets to assist them with their projects and gather new requirements and insights to support the ongoing development.
Respond quickly to change, pick up new technologies and adapt to changing requirements.
Demonstrate competence at writing, testing and debugging Python and Java code.

Desired skills:

Bachelor's or Master's degree in technical or business discipline or equivalent experience.
Minimum 2+ years of professional development experience in Python and Java.
Foundational knowledge or proficient with data science and machine learning tools and techniques
Experience in new and emerging technologies such as AWS, Azure and Cloud, DevOps, CI/CD and Microservices.
Excellent analytical, problem solving, and communication and collaboration skills.
General knowledge of agile software development concepts and processes.
Must be proactive, demonstrate initiative and be a logical thinker.
Experience with layered system architectures and layered solutions; understanding of shared software concepts.
Highly competitive candidates will have:

R Language
Spark
Go Language
We take care of our employees...

We strongly believe that a great job should keep you happy both at work-and in life. That's why we offer:
Workplace Flexibility
Wellness Perks
Collaborative workspaces
Sit/stand desks
Career development, programs and classes
Diversity & Inclusion programs
Commuter Benefits
Adoption Assistance
College Savings Plan
Education reimbursement
Hackathon Events
Liberty Mutual was named as a '2016 Great Place to Work' by Great Place to Work US.
For more info about our benefits -
https://libertymutualgroup.com/careers/working-here/benefits
Learn more about Tech at Liberty Mutual - http://www.jobs.libertymutualgroup.com/careers/technology-jobs

Check out our Tech at Liberty Mutual YouTube playlist - https://www.youtube.com/playlist?list=PLxUNmyJ_IIGx9yoUJfQ8k5APAK3-KAa6j",3.4,"Liberty Mutual Insurance
3.4","Wausau, WI","Boston, MA",10000+ employees,1912,Company - Private,Insurance Carriers,Insurance,$10+ billion (USD),"Travelers, Allstate, State Farm"
"Software Engineer, Data Platform / Python / Spark / AWS / Machine Learning",-1,"Software Engineer – Data Platform

Job Description:

A Software Engineer – Data Platform who is an expert at leveraging technology to scale backend systems with large throughputs of financial data and complex computations. They are on the cutting edge of Big Data technology and are interested in solving complex problems around performance speed-ups, code efficiency and large-scale database management.

Role and Responsibilities

· Architect data infrastructure and code bases

· Implement best-of-breed database technologies

· Optimize systems to quickly process data and evaluate models

· Design processes for scraping and storing large amounts of web data

· Develop and maintain out platform for Data Scientists at the firm

· Hire and groom new Data Engineers to execute on the firm’s engineering strategies

Ideal Candidate

· 2+ years of experience at a technology company as a Data Engineer, or Backend Engineer focused on data systems and architecture

· Excellent programming skills in Python 2 & 3 including Pandas, Numpy and Scipy

· Knowledge of Cython, C, and JIT compilation preferred

· Deep understanding of both relational databases (MySQL) and NOSQL databases (MongoDB)

· Expert at working with Amazon AWS (S3, EC2) or other Infrastructure as a Service

· Experience with creating and/or maintain code and database backends

· Strong web scraping skills and some experience implementing machine learning techniques

· Self-driven person with excellent verbal and written communication skills

· Plus: Background in distributed computing frameworks (Spark)

· Plus: Graduate degree in STEM field

· Plus: Knowledge of advanced data science techniques and statistical modeling concepts

Company Background:

We are transforming the private equity industry akin to how hedge fund quants transformed investing in the public markets.

We are the first investment and operating firm founded on Predictive Unit Economics.

Predictive Unit Economics forecasts business drivers – how customer purchasing behavior, customer acquisition costs, and operating levers change over time.

Leveraging 25 years of academic research, we use proprietary statistical analyses and models to precisely value and operationally optimize businesses.

Please send your resume to Jerald@motektech.com",3.1,"MoTek Technologies
3.1",Remote,"San Jose, CA",1 to 50 employees,2009,Company - Private,IT Services,Information Technology,$1 to $5 million (USD),-1
REMOTE Senior Data Engineer,-1,"REMOTE Senior Data Engineer
We are one of the fastest-growing medical device companies in the world! We are publicly traded, have a global presence, but still operate like a startup. We have an agile, fast-paced team and are looking for Data Engineers that thrive in that kind of environment.

Our Data Engineering team is growing and we have urgent openings for Mid-to-Senior level Data Engineers to join our team!

100% Remote.

If this sounds like a good fit, please apply today!
What You Will Be Doing
- Build enterprise-level ETL pipelines
- Develop real-time streaming pipelines and queue-based event processing systems
- Work closely with machine learning and data scientists to scale model training and explore new data sources and model features
What You Need for this Position
Must have:
- 3+ years of experience as a Data Engineer or in a similar role
- Experience with data modeling, data warehousing, and building ETL pipelines
- Software Engineering background
- Python
- Spark
- AWS

Nice to haves:
- Kafka
- Pandas
- Airflow
- Snowflake
What's In It for You
Base Salary: $140,000 - $185,000
- Stock options
- Bonus
- Quarterly flights to our headquarters
- Health, Dental, and Vision
- 401K
- Unlimited PTO
- Remote
So, if you are a Senior Data Engineer with experience, please apply today!
-
Applicants must be authorized to work in the U.S.


CyberCoders, Inc is proud to be an Equal Opportunity Employer

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, protected veteran status, or any other characteristic protected by law.

Your Right to Work In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification document form upon hire.

CyberCoders will consider for Employment in the City of Los Angeles qualified Applicants with Criminal Histories in a manner consistent with the requirements of the Los Angeles Fair Chance Initiative for Hiring (Ban the Box) Ordinance.",4.2,"CyberCoders
4.2","Los Angeles, CA","Irvine, CA",201 to 500 employees,1999,Subsidiary or Business Segment,Staffing & Outsourcing,Business Services,$100 to $500 million (USD),-1
Senior Machine Learning Engineer,-1,"Passage AI is the leading conversational AI platform in the world. Our mission is to make it trivial for a business to launch a conversational interface on a website, mobile app, or as a chatbot on Facebook Messenger, SMS, Slack, WhatsApp or WeChat, or as a skill on Amazon Alexa or Google Home devices.

If you are excited by artificial intelligence, deep learning and natural language understanding and processing, Passage AI is the place for you! You get to work at an early-stage startup that's backed by some of the leading investors in Silicon Valley.

Job Description

You will work with the Core Algorithms team at Passage AI to apply neural networks and advanced machine learning algorithms to enhance the natural language understanding and processing capabilities of our platform. Apply knowledge and expertise of deep learning technologies to improve our software prototypes and analytic models. Work with some of the best AI and Machine Learning Engineers and Data Scientists in the industry to understand and interpret end-users intent and respond back with precise answers to their questions.

Key Qualifications
4-6 years experience in machine learning, large scale data processing and analytics.
In-depth understanding of deep learning algorithms and workflows.
Strong background in algorithms development for mining patterns from large scale data.
Excellent understanding of key metrics that impact deep learning algorithms.
Expertise in common neural network architectures.
Strong ability to leverage complex technologies to solve real world problems and consumer use cases.
Good communications skills
Experience in Python and C/C++
M.S. or PhD in Computer Science, preferably with strong coursework in Artificial Intelligence

Job Type: Full-time",-1,Passage AI,"Mountain View, CA","Mountain View, CA",1 to 50 employees,-1,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Senior Machine Learning Software Engineer - 3DML,"$171K-$189K
(Glassdoor est.)","Posted: Apr 7, 2020
Role Number:
200164253
Apple 3DML team is looking for software engineers to develop and deploy computer vision technologies (2D and 3D) for next generation of Apple products. You’ll join a phenomenal team of researchers and engineers with deep experience in deep learning, machine learning, computer vision and software engineering. The team has an outstanding track record in shipping high visibility products empowering Apple new hardwares. More specifically, you will be working closely with ML Applied research scientists in the team to bring CVML prototypes to life and deploy them on shipping frameworks. You’ll participate in crafting systems, algorithm, and optimization efforts to ship product with impact. No matter whether you have worked on computer vision and machine learning before, we provide you with the best experience, to learn, grow and contribute.
Key Qualifications
Take cutting edge perception models from the lab to a mission critical system.
Work with CVML scientists in the teams to harden models for deployment.
Implement optimized algorithms that perform within platform constraints.
Develop and support tools that accelerate development and deployment.
Design and implement iOS demo apps to show case CVML prototypes
Take responsibility for design, development, deployment and test.
Minimum 3 years of professional software development experience in modern C++
Proven track record of delivering production software.
Experience working with a large and complex software stack.
Familiarity with Objective C, Swift is a plus
Proficient understanding of algorithms and data structures.
Excellent interpersonal skills. You collaborate optimally with other teams.
Familiarity with one of the major ML frameworks (TensorFlow/PyTorch) is a plus
Familiarity with Computer Vision and 3D Vision is plus
Description
The Video Computer Vision org is a centralized applied research and engineering organization responsible for developing real-time on-device Computer Vision and Machine Perception technologies across Apple products. We balance research and product to deliver Apple quality, state-of-the-art experiences, innovating through the full stack, and partnering with HW, SW and ML teams to influence the sensor and silicon roadmap that brings our vision to life. Examples include FaceID, Animoji/Memoji, Scene Understanding, People Understanding and Positional Tracking (VIO/SLAM).
Education & Experience
B.S. IN COMPUTER SCIENCE WITH 6+ YEARS EXPERIENCE
M.S. in Computer Science with 4+ years experience

PhD. in Computer Science with 1+ years experience",4.1,"Apple
4.1","Santa Clara, CA","Cupertino, CA",10000+ employees,1976,Company - Public,Computer Hardware & Software,Information Technology,$10+ billion (USD),"Google, Microsoft, Samsung Electronics"
Senior Machine Learning Engineer - Data Science,"$97K-$166K
(Glassdoor est.)","Sr Data Engineer - GE07BE

You are a driven and motivated problem solver ready to pursue meaningful work. You strive to make an impact every day & not only at work, but in your personal life and community too. If that sounds like you, then you've landed in the right place.

Senior Machine Learning Engineer

The mission for the Data Science as a Service (DSaaS) core team is to partner with Segment Data Science teams and IT organizations across The Harford to enable deployment of Data Science assets (data, model, business rules) into business workflows in batch and/or real-time mode. The DSaaS team is responsible for creating playbooks and modular code to enable adoption of best practices within the Data Science organization. Learning from recent deployments using existing architectural patterns, the goal is to evolve the playbook to support the cloud adoption on the AWS platform. The team consults on use cases to provide a high level view of cost, time and effort associated with batch vs real-time implementations. The team is responsible for guiding the Data Science practice to allow for faster, cheaper, consistent, and reliable deployments while enabling transparency and reproducibility of modeling assets.

The Senior Machine Learning Engineer is responsible for hands-on deployments of data science artifacts into business workflows and works closely with the Data Scientists to understand the inputs and outputs of the models. The Senior Machine Learning Engineer will establish logging, error handling, and error recovery criteria to support model failures in production deployments. The engineer will also establish the testing criteria for validating the model deployments in collaboration with the front end engineering teams. The engineer must have an understanding of model deployment pipelines incorporating data from internal systems and third party sources. Expertise in Linux, SQL, Hadoop, and Spark is essential for this role. The engineer should be able to write Python code using object oriented software engineering principles and delivering modularized, reusable code. Understanding of CI/CD tools to automate pipelines and code delivery is preferred.

Responsibilities
Understand sources of data within The Hartford, and work with SME’s to describe and understand data lineage and suitability for a use case.
Create summary statistics/reports from data warehouses, marts, and operational data stores to establish testing criteria and create model training and validation data sets.
Produce code artifacts and documentation for reproducibility and hand-off to other data science teams.
Contribute to the design, implementation, and evaluation of ML models in production in agile framework. Execute testing (integration, performance, regression).
Prototype new approaches and productionize model code to be deployed to business applications
Adhere to requirements for scale, performance, and availability
Support implementation and testing of assets into production work and manage and estimate work for junior engineers to deliver the requirements for each project.
Describe technical work to non-technical audiences.
Establish best practices for code management, issue management, data and storage management.
Perform code review and mentor engineers on team, set timelines and delivery scope and develop success criteria for project increment delivery.
Interact with engineers, architects, product owners, and asset owners to propose a technical solution and provide work estimates to deliver the software. Call out risks and issues and establish escalation criteria for product based on final solution.
Provide L3 support for production assets in conjunction with IT production support teams, Data Scientists, and the model Product Owner.
Basic knowledge of modeling tools and data science platforms is preferred.
Ability to provide input as consultant on projects as a technical expert.
Ability to identify and investigate potential data errors during model development or deployment phases.
Ability to respond to change, interested in continuous learning, adopting new technologies to enable data science asset deployment into production.
Understand tiered application architectures, understand and implement API based predictive and scoring services
Establish production support documentation and process with on-shore and off-shore teams.
Configure deployments in containerized environments.
Experience & Skills
2+ years of experience in implementing machine learning algorithms (regression, dimensionality reduction, recommendation systems, outlier detection, and predictive models)
Experience in leading projects from incubation to large scale production deployments
5+ years’ experience in object oriented programming and design patterns.
BA, BS, MS, PHD in Computer Science and Engineering
Experience deploying on the AWS platform, certification is preferred but not required.
Candidates must have the technical skills to transform, manipulate and store data, the analytical skills to relate the data to the business processes that generates it and the communication skills to disseminate information regarding the availability, quality, and other characteristics of the data to a diverse audience.
3+ years of writing object oriented code in in Python
Determine business solutions and translate into actionable steps for self and junior engineers on the team.
Demonstrate a passion for learning new skills and creating best practices and standards within the organization.
Results oriented with the ability to multi-task and adjust priorities when necessary
Equal Opportunity Employer/Females/Minorities/Veterans/Disability/Sexual Orientation/Gender Identity or Expression/Religion/Age


Equal Opportunity Employer/Females/Minorities/Veterans/Disability/Sexual Orientation/Gender Identity or Expression/Religion/Age",3.9,"The Hartford
3.9","Hartford, CT","Hartford, CT",10000+ employees,1810,Company - Public,Insurance Carriers,Insurance,$10+ billion (USD),-1
Machine Learning Engineer (Imaging),"$80K-$138K
(Glassdoor est.)","Position Summary

Samsung Austin Semiconductor is one of the most advanced semiconductor manufacturing facilities in the world with more than 3,000 employees and 2.45 million square feet of floor space. Samsung Austin Semiconductor has broad semiconductor process technology offerings serving customers in various application areas including mobile, consumer, networking/high performance computing, Internet of Things, RF and automotive. Since 1996, SAS has invested approximately $17 billion in its Austin, TX campus, making it one of the largest direct foreign investments in United States history. Samsung Austin Semiconductor is a US-based subsidiary of Samsung Electronics Co., Ltd. The Austin facility is one of the few semiconductor plants the company has outside South Korea. Visit www.samsung.com/us/sas.

SAS is focused on being the World’s Best Foundry product supplier.

Role and Responsibilities
Our company creates some of the world’s most high-tech semiconductor manufacturing line for CPUs, GPUs, and IoT sensors.
We are currently in search of a Machine Learning developer to find and optimize signals from data from various resources, transform data, implement new features, and design machine learning models for business value.
Looking for a Machine Learning engineer with a passion for data, and enjoys being a part of a small high performing team developing and maintaining in-house models.
Be a member of the Defect Engineering Systems group which provides data summarization across many key dashboards.
Helps by directing the focus of the factory and continuously improving time to detection, accuracy, and throughput.
Working with key members of the organization to obtain stronger predictive data.
Feature Engineering to improve model performance.
Attend team meetings and offer solutions to challenging problems.
Collaborate with peer data scientists across the organization on best methods for data modeling.
Other duties as needed.
Experience building and extending machine learning models.
Experience with open source frameworks (Tensorflow, PyTorch).
Comfortable working with command line interfaces (Ubuntu experience a plus).
Ability to summarize results to a broad range of audiences.
Ability to learn quickly and keep deadlines while applying good design principals.
Experience with CNNs, Auto-Encoders, Manifold Learning, and Recommendation Systems.
Ability to use VM container software (Docker / Kubernetes).
Familiar with Atlassian software (BitBucket, Confluence, Jira).
Semiconductor process knowledge (specifically defect domain knowledge: detection, classification, determining impact) is a plus.
Enjoy solving challenging problems and eager to learn new technologies.
Working with a small highly motivated team to develop and implement new ideas.
Work days and hours: M-F, 8am to 5pm/1st shift
Skills and Qualifications
B.S or M.S Engineering Degree.
3- 7 years of Data Science/Machine Learning experience is a must
Proficient with Python, SQL, and data manipulation is required.
Prefer experience with Tensorflow image processing and modeling
Excellent communication, interpersonal, initiation, & troubleshooting skills.
Fundamental understanding of analytic techniques is a plus.
Fast learner with the ability to develop and maintain.
* Please visit Samsung membership to see Privacy Policy, which defaults according to your location. You can change Country/Language at the bottom of the page. If you are European Economic Resident, please click here.

* Samsung Electronics America, Inc. and its subsidiaries are committed to employing a diverse workforce, and provide Equal Employment Opportunity for all individuals regardless of race, color, religion, gender, age, national origin, marital status, sexual orientation, gender identity, status as a protected veteran, genetic information, status as a qualified individual with a disability, or any other characteristic protected by law.",2.9,"Samsung Austin Semiconductor
2.9","Austin, TX","Austin, TX",1001 to 5000 employees,1996,Subsidiary or Business Segment,Electrical & Electronic Manufacturing,Manufacturing,Unknown / Non-Applicable,"GLOBALFOUNDRIES, Intel Corporation, TSMC"
Principal Data Scientist,"$135K-$211K
(Glassdoor est.)","At the heart of Defining Possible is our commitment to missions. In rapidly changing global security environments, Northrop Grumman brings informed insights and software-secure technology to enable strategic planning. We're looking for innovators who can help us keep building on our wide portfolio of secure, affordable, integrated, and multi-domain systems and technologies that fuel those missions. By joining in our shared mission, we'll support yours of expanding your personal network and developing skills, whether you are new to the field or an industry thought-leader. At Northrop Grumman, you'll have the resources, support, and team to do some of the best work of your career.

The Engineering & Sciences (E&S) organization pushes the boundaries of innovation, redefines engineering capabilities, and drives advances in various sciences. Our team is chartered with providing the skills, innovative technologies to develop, design, produce and sustain optimized product lines across the sector while providing a decisive advantage to the warfighter. Come be a part of our mission!

Join a program that has been around for 16 years and under contract to go at least another 9 years. The team is currently completely revamping the architecture and bringing it up to date utilizing modern constructs and tools. You will work closely with our customers and their contractor team to lead an ongoing effort to optimize complex cyber systems. Daily you will face complex technical problems involving telecommunications, network engineering, and large data sets requiring strong statistical and data visualization skills. Solving complex technical problems, including the ability to conduct independent research and develop prototype analytical algorithms is needed. You will be analyzing performance of modern internet applications such as streaming video, VoIP or other internet transmission protocols and providing recommendations for system performance improvements. You will utilize your verbal and written skills to communicate to fellow team members and our customer. New areas of interest include Model Based System Engineering, Machine Learning and Artificial Intelligence.

Northrop Grumman Mission Systems (NGMS) is looking for you to join our team as a Principal Data Scientist based out of San Jose, CA.

A current active Top Secret Clearance is required. Applicants without a clearance may be considered with the understanding that employment will not begin until a TS/SCI clearance is obtained.

CIMS

Qualifications:

Basic Qualifications: Systems Engineer
Bachelor's Degree in a STEM discipline (Science, Technology, Engineering, or Math) with 4 years relevant work experience; or a Master's degree in a STEM discipline with 2 years relevant work experience; or a PhD in a STEM discipline with 0 years' experience.
US Citizenship is required with the ability to obtain and maintain a Top Secret/SCI level Clearance.
Knowledgeable with at least one software or scripting language (C, C++, PERL, Python, Java, etc.), Python preferred.
Preferred Qualifications:
Current Top Secret/SCI clearance with CI poly.
Experience developing software solutions on the Unix OS platform.
Experience working with Big Data.
Experience developing and executing test plans.
Graduate Degree in Electrical Engineering, Computer Science, Physics, Mathematics.
Knowledge of Machine Learning/Artificial Intelligence.
Background in a telecommunications and/or network management.
Experience with software and hardware interface development.
Experience with system software development/configuration/ management.
Software integration experience.
Understanding network performance profiling and optimization.
Experience developing software solutions on the Unix OS platform.
Experience utilizing Data analytics tools.
Experience working with Big Data.
Understanding of IP protocols
What We Can Offer You:

Northrop Grumman provides a comprehensive benefits package and a work environment that encourages your growth and supports the mutual success of our people and our company. Northrop Grumman benefits give you the flexibility and control to choose the benefits that make the most sense for you and your family. Your benefits will include the following:

Health Plan

Savings Plan

Paid Time Off

Education Assistance

Training and Development

Flexible Work Arrangements

https://benefits.northropgrumman.com/us/en2/BenefitsOverview/Pages/default.aspx

Additional Northrop Grumman Information:

Northrop Grumman has approximately 85,000 employees in all 50 states and in more than 25 countries, we strive to attract and retain the best employees by providing an inclusive work environment wherein employees are receptive to diverse ideas, perspectives and talents to help solve our toughest customer challenges: to develop and maintain some of the most technically sophisticated products, programs and services in the world.

Our Values. The women and men of Northrop Grumman Corporation are guided by Our Values. They describe our company as we want it to be. We want our decisions and actions to demonstrate these Values. We believe that putting Our Values into practice creates long-term benefits for shareholders, customers, employees, suppliers, and the communities we serve.

Our Responsibility. At Northrop Grumman, we are committed to maintaining the highest of ethical standards, embracing diversity and inclusion, protecting the environment, and striving to be an ideal corporate citizen in the community and in the world.

Northrop Grumman is committed to hiring and retaining a diverse workforce. We are proud to be an Equal Opportunity/Affirmative Action Employer, making decisions without regard to race, color, religion, creed, sex, sexual orientation, gender identity, marital status, national origin, age, veteran status, disability, or any other protected class. For our complete EEO/AA and Pay Transparency statement, please visit www.northropgrumman.com/EEO. U.S. Citizenship is required for most positions.",3.8,"Northrop Grumman
3.8","San Jose, CA","Falls Church, VA",10000+ employees,1939,Company - Public,Aerospace & Defense,Aerospace & Defense,$10+ billion (USD),-1
Sr. Software Engineer - Infrastructure,-1,"LeapYear's secure machine learning platform is deployed by some of the largest enterprises in the world across finance, healthcare, and technology.

Our technology ensures differential privacy, a widely recognized standard of data privacy that enables all data - including sensitive information - to be utilized for analytics, while providing mathematically proven privacy protection.

The LeapYear system is composed of a core set of components that allow private machine learning on data sets that can scale to petabytes. The system includes private algorithms for relational operations, statistical methods and machine learning. A data scientist accesses private data using a Python API. Administration is provided via a web-based GUI or an API.

LeapYear's Infrastructure team builds the tools that build our software and scales our test infrastructure such that all developers can contribute to automated test suites. For deployments of LeapYear, Infrastructure engineers write sophisticated, parameterized installers for enterprise environments, and automate deployment into cloud environments.

We are looking for versatile problem solvers that are interested in developer productivity, automation, and cloud infrastructure.
Responsibilities
Build the network and scale our existing systems using Infrastructure as Code
Partner with product management to define problems and identify iterative solutions
Balance immediate business objectives against a long-term architectural vision
Contribute to an engineering-wide culture of code quality and shared responsibility for testing
Contribute to other engineer's personal development by sharing knowledge, mentoring, and coaching
Requirements
7+ years of general software programming experience, including regular use of major scripting languages (Python, Bash, Ruby, Java)
5+ years of experience building network infrastructure, preferably with Infrastructure as Code tools
2+ years of experience using Infrastructure as Code tools such as Terraform, AWS CloudFormation, Ansible, and Packer
2+ years of experience building infrastructure with containers and using tools such as Kubernetes, Docker Compose or Docker
Enterprise experience with Linux systems administration, command line tools, and various distributions of Linux (Red Hat, Centos, Ubuntu, etc).
Experience with Continuous Integration/Continuous Deployment tools such as CircleCi, Jenkins or Spinnaker (CircleCI preferred)
Experience with services provided by AWS, GCP, VMware and Azure (AWS and GCP preferred)
Preferred
Experience with administering and running Hadoop and Spark clusters
Experience working in a startup environment
Experience with security best practices in Linux system administration and cloud infrastructure
Experience using secret management tools such as Vault or AWS/GCP secret manager
Experience testing the results of statistical analysis, preferably machine learning
Experience with Maven, Bazel, Gradle, or other modern build systems
Acquainted with and interested in functional programming (Haskell, OCaml, Clojure, Erlang, Scala)
A Few of the Perks
Culture of teaching and learning
Competitive compensation package of salary and equity
Catered lunch every day
Company outings
Build your ideal work station
Generous health insurance plan
Relocation support and visa sponsorship",4.2,"LeapYear
4.2","San Francisco, CA","San Francisco, CA",1 to 50 employees,2015,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Software Engineer II - CTJ with Security Clearance,"$95K-$138K
(Glassdoor est.)","Are you interested in working for one of the most exciting products at Microsoft to help advance Microsoft's AI Platform? Are you excited about being part of a product group working with Microsoft researchers, data scientists and AI engineering teams to ensure success as they move forward with cloud computing in Azure? If so, then look no further than the AI Platform team. AI Platform is responsible for the Azure Machine Learning (Azure ML) and Cognitive Services products. Azure ML is building the machine learning development platform that makes it easy for all data scientists and AI developers to create and deploy robust and highly scalable ML and AI solutions in the cloud using the best of the open source ecosystem and innovation from inside the company along with the latest breakthroughs in research. Artificial intelligence (AI) is dramatically transforming people's work and life now, and Cognitive Services bring AI within reach of every developer-without requiring machine-learning expertise. All it takes is an API call to embed the ability to see, hear, speak, search, understand, and accelerate decision-making into your apps. We are hiring engineers who are passionate about building scalable, distributed, highly available, and secure cloud services for Microsoft AI Platform. We value creativity and a desire to learn new technologies, agility and accountability. Join our team and help us build the best AI Platform for the world! Responsibilities As a member of our team, you will participate in developing innovative solutions across AI Platform. Responsibilities include the following. * Write concise and clean code with unit tests * Build scalable, high-performance services that are highly reliable * Design and implement new features as well as add functionality to existing systems * Investigate pre-production and production issues, implement and deploy fixes * Participate in an on-call rotation (typically 24/7 for one week every 6-8 weeks) * Being enthusiastic, self-motivated, and a great collaborator * Being passionate about making customers successful Qualifications Qualifications: * A minimum of a Bachelor's degree in Computer Science or Engineering, or a related field, or equivalent alternative education, skills, and/or practical experience is required. * 5 years of software development experience in C#, Java, Scala, C++, Go, Python or similar languages. * Solid Computer Science fundamentals, fluent in multi-threaded programming, experience/inclination for architecting at scale * Demonstrated technical design, problem solving, coding and debugging skills * Experience with distributed systems design and implementation, especially microservices architecture, and Kubernetes, Linux, and related technologies is a plus * Good written and oral communication skills Security Clearance Requirements: * Citizenship Verification: This position requires verification of US Citizenship to meet federal government security requirements * Candidates must have an active TS and be willing to upgrade to TS/SCI (with polygraph) or have an active TS/SCI and be willing to upgrade to TS/SCI (with polygraph). This role will require candidates to maintain the TS/SCI (with polygraph) clearance. * Microsoft Cloud Background Check: This position will be required to pass the Microsoft Cloud background check upon hire/transfer and every two years thereafter Ability to meet Microsoft, customer and/or government security screening requirements are required for this role. These requirements include, but are not limited to the following specialized security screenings: Microsoft Cloud Background Check: This position will be required to pass the Microsoft Cloud background check upon hire/transfer and every two years thereafter. #AIPLATFORM# #AIPLATREF# Microsoft is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable laws, regulations and ordinances. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. If you need assistance and/or a reasonable accommodation due to a disability during the application or the recruiting process, please send a request via the Accommodation request form . Benefits/perks listed below may vary depending on the nature of your employment with Microsoft and the country where you work.",4.3,"Microsoft Corporation
4.3","Elkridge, MD","Redmond, WA",10000+ employees,1975,Company - Public,Computer Hardware & Software,Information Technology,$10+ billion (USD),"Google, Amazon, Apple"
Senior Machine Learning Research Engineer,-1,"About the RoleAs a Senior Machine Learning Research Engineer, you will work on Freenome's ML research platform, developing and deploying ML pipelines. As part of an interdisciplinary R&D team, you will work in close collaboration with computational biologists, machine learning scientists and software engineers. You will develop cutting edge solutions at the intersection of machine learning, genetic sequencing technology, and distributed systems. These contributions will drive our mission to diagnose cancer at its most actionable and early stages.Responsibilities:* Work at the intersection of machine learning research, software engineering and biological data* Lead the development of Freenome's ML research framework and internal tools* Participate in cutting edge research in statistical modeling and inference of biological problems (including cancer research, genomics, computational biology/bioinformatics, immunology, therapeutics, and more)* Build for significant growth and scaling challenges as we transition from research to product development* Engineer robust and reproducible data pipelines that enable cutting edge liquid biopsy research* Improve the reliability and scalability of our ML platform as it grows* Develop software and workflows that support a long term vision for ML research and production* Enable data driven science discoveries in biology and healthcareWhat We're Looking For:* 5+ years of experience with production infrastructure, automation, and software engineering* B.S. or M.S. in computer science, a related technical field, or comparable experience* Expertise building and launching large-scale ML frameworks that supports the experimental needs of a research team* Experience in analyzing and troubleshooting data management systems* Expertise in software design and development, especially in Python* Thorough understanding of machine learning fundamentals, such as cross-validation, hyper-parameter search, model optimization and bias-variance tradeoff.* Experience building and launching projects in a production software environment, including use of automated testing, version control, and deployment systems* A systematic problem-solving approach, effective communication skills and a strong desire to own and drive your workNice to Haves:* Machine learning and data science tools, such as Sklearn, TensorFlow, pyTorch, Jupyter, or Kubeflow* Experience with containerized cloud computing environments, such as Docker in GCP or AWS* Data pipelines, such as Metaflow, Flyte, Kafka, Spark, Airflow, Argo, Hadoop, or Flink* Experience with high performance programming languages such as C/C++, Go, or Rust* Job orchestration and distributed systems, such as Kubernetes, Terraform or Ansible* Genomics or bioinformatics background* Large-scale and/or high-performance storage systems, such as PostgreSQL, MySQL, Redis, HBase, Spanner, or CassandraAbout FreenomeFreenome is on a mission to empower everyone with the tools they need to detect, treat, and ultimately prevent diseases.By applying advanced machine learning techniques to recent breakthroughs in genomic science, Freenome is developing simple blood tests to detect early-stage cancer and make treatments more effective. The company has raised $238 million from investors such as RA Capital, Polaris Partners, Perceptive Advisors, Andreessen Horowitz, funds and accounts advised by T. Rowe Price Associates, Inc., GV (formerly Google Ventures), Roche Venture Fund, Kaiser Permanente Ventures, American Cancer Society's BrightEdge Ventures, Data Collective Venture Capital, Novartis and Verily Life Sciences (formerly Google Life Sciences).Our ScienceFreenome is building technology to gain an understanding of the body through several analytes derived from blood. These signals include cell-free DNA, methylation of cell-free DNA, cell-free RNA, circulating proteins, and immune profiling derived from thousands of prospective samples. By developing novel statistical learning methods and applying them to integrate various -omics datasets, Freenome is a leader in modeling specific biological mechanisms to capture disease dependent signatures such as gene expression, immune response, tumor burden, the tissue of origin, and 3D chromatin structure.By building comprehensive discovery datasets and modeling critical biological systems, Freenome is learning what biological changes are present within the blood between a variety of different disease states including cancer, autoimmune disorders, infections, drug response, and aging. With the combination of Freenome's datasets, cross-functional technical expertise, and mission to uncover the biological truth, we seek to positively change the lives of millions through the early detection and early treatment of disease.Our CultureFreenomers are technical and creative, visionary and grounded, empathetic and passionate. We build teams around divergent expertise, which allows us to solve problems and uncover opportunities in unique ways. Freenomers are some of the most talented experts in their fields, coming together to advance healthcare one breakthrough at a time.We value empathy, integrity, and trust in one another. That means embracing other's perspectives, those of our coworkers and those of the patients and communities we serve. It means knowing when to push, and when to listen. At Freenome, we give each other the benefit of the doubt in the belief that we're all working as a team toward the same goals, and empower others to grow in a collaborative environment.What does a successful person look like at Freenome?Those who thrive at Freenome prioritize, manage, and execute their own goals in alignment with those of the company. They embrace our values of empathy, integrity, and trust, and hold themselves and their team accountable. They crave collaboration with brilliant minds from unfamiliar fields of study and believe that hiring and mentorship are fundamental to our success. Above all, they welcome and provide constructive feedback and criticism, trusting in the good intentions of others, and secure in the knowledge that embracing mistakes is the best way to learn and move on. For those who crave challenges, understudied problems, and the chance to see their work impact the lives of millions of people affected by cancer every year, there's no better place to be.Freenome is proud to be an equal opportunity employer, we value diversity in every way. Freenome does not discriminate on the basis of race, religion, color, sex, gender identity, sexual orientation, age, non-disqualifying physical or mental disability, national origin, veteran status or any other basis covered by appropriate law.",5.0,"Freenome
5.0","South San Francisco, CA","South San Francisco, CA",51 to 200 employees,2014,Company - Private,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,Unknown / Non-Applicable,-1
Sr. Software Engineer - AI Infrastructure and Parallel Computing,"$131K-$149K
(Glassdoor est.)","Sr. Software Engineer AI Infrastructure and Parallel Computing


Location: Campbell, CA

Start Date: Immediate

STAR Labs

STAR Labs (Samsung Technology & Advanced Research Labs) is headed by Pranav Mistry with a mission to undertake independent initiatives to create end-to-end new businesses and expand growth areas for Samsung. At STAR Labs, we are building new immersive and intelligent services that is making science fiction a reality. STAR Labs consists of best of the best from domains such as computer science, business strategy, engineering, design; and diverse set of experiences from places like MIT, Stanford, Oxford, CMU, Nasa, Google, Microsoft and many more. NEON is a venture from STAR Labs (http://neon.life)

The team builds upon their outstanding track record of creating products that have real-world impact at global scale. We are rapidly expanding and is looking for the best to join and help us build foundation for our next magical technology stack. We value our differences and are excited to learn what you can add to STAR Labs.

Requirements
Collaborate within the team across product, design, product, infrastructure, strategy and engineering.
Mentor, learn and share knowledge with others along the way.
Have impact and have fun
Working outside your comfort zone
Skills
MS of PhD from leading university in Computer Science and/or 4+ years of relevant industry experience
Minimum 3 years of experience developing C/C++ software, including modern C/C++ (C++11/14) and multithreading, resource management and compute graph optimization
Understanding of modern GPU architectures for parallel computing
Experience with at least one of the following: imaging software, CUDA/OpenCL, SIMD, multithreading, computer vision
Apply your software architecture skills to design consistent C/C++/Python API's, write code running on CPU and/or GPU, and advocate for best coding practices amongst the group
Partner with the vision & machine learning scientists to develop robust, performant software pipelines
Experience with any of the deep learning frameworks: Tensorflow, PyTorch, Caffe, Keras and others.
Experience working with multi-node/distributed training, data loading and image/video processing
Previous experience of scaling up and optimizing HPC, computer vision or deep learning training pipelines to terabyte scale datasets is a huge plus.
Samsung is an EEO/Veterans/Disabled/LGBT employer. We welcome and encourage diversity as we strive to create an inclusive workplace",3.5,"Samsung Research America
3.5","Campbell, CA","Mountain View, CA",1001 to 5000 employees,1988,Subsidiary or Business Segment,Computer Hardware & Software,Information Technology,$50 to $100 million (USD),"Sony, LG Electronics, Nokia"
Sr. Software Engineer - AI Infrastructure and Parallel Computing,"$138K-$235K
(Glassdoor est.)","ServiceNow is changing the way people work. With a service-orientation toward the activities, tasks and processes that make up day-to-day work life, we help the modern enterprise operate faster and be more scalable than ever before.

If you thought you knew about ServiceNow and what we do, take a look again! Our products lines are diverse and robust. The Enterprise Cloud is dynamic, scalable to billions of transactions weekly, and global in scope and size.

As a part of the core Platform as a Service offering, the Intelligent Automation Development team is building the core machine learning/AI/predictive analytics technology that will power revenue generating business use-cases using customer data to predict desired outcomes automatically; hence delivering significant increase in productivity of business processes of ServiceNow customers. The team focuses on operationalizing machine learning and predictive analytics use cases for all ServiceNow business applications.

We employ only the brightest, innovative and most intuitive data scientists on the planet. We have offices in San Diego, San Francisco, Santa Clara and Hyderabad and work as a distributed team. Come join the Intelligent Automation team and make your mark in the most challenging problem area - helping customers derive the insights from their own data on ServiceNow platform.

What you get to do in this role:

Specifically, you will
Work on various ServiceNow client data sets and focus on solving applied problems in classic ML solutions such as Classification, Similarity, Clustering, Natural Language Understanding, Text Mining, Anomaly Detection, Forecasting, etc., by leveraging statistical/mathematical concepts and core machine learning/AI tools and techniques
Opportunity to learn, work and contribute to the innovative and enterprise grade ServiceNow’s Machine Learning and Artificial Intelligence engine as part of the overall Platform-as-a-Service offering
Understand the business needs of Platform BU's customers
Translate the business needs into data requirements
Design and experiment (proof of concept), code, execute and iterate to retrieve business value/knowledge discovery from client’s data
Define and document success criteria/measures for the POC to prove the feasibility of the design experiment
Communicate and collaborate with appropriate teams and important stakeholders from the business units on the complete lifecycle of the experiment
Retrieve, clean/sanitize/normalize client’s data available in multiple data sources in ServiceNow instance
Choose an appropriate Statistical/ML/AI model, engineer the features and define appropriate model evaluation metrics
Plan to generalize, scale and integrate the model at the platform level making it available as a core feature/functionality to all ServiceNow client base
Monitor, support, fix bugs, iterate and improve model performance to a desired level over a definitive time period
Completely own the quality and metrics (response times, scalability, etc.) of the deployed model
Develop innovative patentable ideas that ensures the competitiveness of this product within the domain of similar work being done in the industry
Lead and deliver key asks from internal constituents by example
Advance the natural language capabilities of the ServiceNow platform
To be successful in this role, we need someone who has:
10+ years of research experience with 5+ years of core Machine Learning Engineering/AI experience
5+ years of java programming experience
Advanced degree in the field of data science/computer science/mathematics/statistics will be a definite plus
Working experience in Machine Learning based solutions such as classification, similarity, clustering is highly preferred
Deep understanding of Statistics/Linear Algebra/Calculus and various optimization algorithms is a must
Hands-on experience on various supervised/semi-supervised/unsupervised ML/AI algorithms like SVM, Random Forests, Clustering, Linear/Logistic Regression, Classification, PCA, Time Series Forecasting, Deep Neural Nets and Sequential speech/language models
Strong leadership and influencing skills with an ability to crisply communicate/articulate model performance/experience results to Key stakeholder’s and wider audience with appropriate visualization techniques
Ardent data enthusiast with experience and interest in engaging with data science communities like Kaggle and various online forums
Ability to translate business needs into data requirements Experience working in Agile/Scrum environment is desired
Experienced in various forms of decision sciences and optimization software development
Exceptional debugging, testing, and problem-solving skills
Self-starter, with quick learning curve
Strong written and verbal communication skills and an ability and interest to mentor other junior data scientists.
Working experience within product development teams is a must
Must have demonstrated work experience through multiple life cycles of a product within a single company
Must have demonstrated capabilities to create patentable ideas.
We provide competitive compensation, generous benefits and a professional atmosphere. This is a very collaborative and inclusive work environment where individuals strong on aptitude and attitude will have an opportunity to grow their professional careers through working with some of the most advanced technology and talented developers in the business.

This position is based in Santa Clara,CA.",3.7,"Samsung Research America
3.5","Campbell, CA","Santa Clara, CA",10000+ employees,2004,Company - Public,Enterprise Software & Network Solutions,Information Technology,$2 to $5 billion (USD),"BMC Software, CA Technologies, Salesforce"
Algo Software Engineer (C++/Python),"$141K-$180K
(Glassdoor est.)","At HRT, we program computers to intelligently trade on the stock market. We make the world's markets more financially efficient using smart algorithms. To get the job done, we hire some of the smartest computer scientists in the world to develop both our low latency trading platform and our massive distributed research platform.

Algo Software Engineers (AE) are programmers that are embedded in HRT's trading teams and work hand-in-hand with Algo Strategy Developers (AD). Whereas ADs tend to use their math skills to make smarter strategies, AEs focus on the software that powers trading and research. Because of this close collaboration, AEs tend to be the type of engineers that thrive on constant interaction and discussion. Hearing how their most recently deployed system allowed for whole new types of research would make their week. AEs are the type of engineers that don't mind juggling a few projects at once and have a varied portfolio of project types, from long-term ambitious new systems to fire-fighting live issues.

Our environment is particularly well suited to driven, self-motivated programmers. For one, the company's Partners are all programmers. Team Leads spend a majority of their time doing technical work. Algo teams run on a very bottom-up approach that encourages everyone on the teams to come up with ideas and dictate the direction of each team together. Finally, there is very little emphasis placed on project management process (almost no meetings and no project managers) and there is a lot of emphasis placed on engineering process such as automated testing, design/code reviews, and technical training.

We are a Linux/Unix shop with a codebase written primarily in C++ and Python. If you are not a C++ or Python or Linux expert, that's probably OK. We really care more about your technical fundamentals, practical experience and that intense desire to make things better for other people. That being said, we want someone who is familiar with a non-scripting language such as C++ or Java.

Here are a few examples of programmers who are currently AEs at HRT:
When he's not solving riddles and dancing salsa, David's writing distributed computing APIs. He regularly solves bugs like ""one out of a million jobs are dying on only these machines and only on Tuesdays"". He likes bridging the gap between Algo Strategy Developers and Systems Engineers to explore how to use distributed computing to run research. He really enjoys coming up with ways to make millions of jobs more efficient.
Kai came to HRT after 3.5 years of programming C++ at a company that provides large amounts of data to the finance industry. He plays several musical instruments and has tasted thousands of wines, yet he finds his work to be an even more rewarding experience. He builds tools to discover opportunities and aid live trading. He is excited about automating strategies and implementing ideas from his teammates, in addition to applying his technical skills to the world of trading.
Aaron started programming at age 5 and previously ran the research team at a music software company, bringing over 7 years of experience to HRT. He cooks and practices partner acrobatics in his free time. He gets joy from his teammates' happiness when their research runs twice as fast, from building them tools that help them visualize their strategies, and from keeping code organized and maintainable. He's gotten coworkers from other teams involved in latency improvements to his group's live trading. He enjoys the collaborative environment and learning from his coworkers.
Culture:
Hudson River Trading (HRT) brings a scientific approach to trading financial products. We have built one of the world's most sophisticated computing environments for research and development. Our researchers are at the forefront of innovation in the world of algorithmic trading.

At HRT we come from all sorts of backgrounds: mathematics, computer science, statistics, physics, and engineering. We're a community of self-starters who are motivated by the excitement of being at the cutting edge of automated trading. Our culture celebrates great ideas whether they come from HRT veterans or new hires. At HRT we're friends and colleagues, whether we are sharing a meal, playing the latest board game, or writing elegant code. We embrace a culture of togetherness that extends far beyond the walls of our office.

Seem like something you might be interested in? Our goal is to find the best people and bring them together to do great work in a place where everyone is valued. HRT is proud of our diverse staff; we have offices all over the globe and benefit from our varied and unique perspectives. HRT is an equal opportunity employer; so whoever you are we'd love to get to know you.",5.0,"Hudson River Trading
5.0","New York, NY","New York, NY",201 to 500 employees,2002,Company - Private,Financial Analytics & Research,Finance,Unknown / Non-Applicable,-1
"Bioinformatics Engineer, Algorithm","$74K-$106K
(Glassdoor est.)","Invitae is a healthcare technology company that leverages genetic information to empower doctors and patients to make informed medical decisions. Our development team works on a variety of projects ranging from innovations in healthcare systems to taming the chaos of biology. We are constantly improving our tools and technologies to deliver the highest quality actionable information to doctors and patients. Behind every sample that comes in through the door we know there is an individual and a family looking for answers.

As part of our bioinformatics modeling and algorithms team, you will help ensure our methods and tools are of the highest caliber. Frequently in the team, you will own the problem from conception to release and help drive execution by convincing key stakeholders with data. You will apply your knowledge of computer science, statistics, and NGS to analyze, improve, and develop techniques and algorithms for calling genetic events across an expanding set of modern assays. You will work and learn among an extraordinary set of peers: bioinformaticians, molecular biologists, and software engineers. Your work will directly improve the quality of our product and positively impact each tested patient.

What you will do:


Build and evaluate algorithms and statistical models to improve existing genetics applications within and beyond NGS technologies and create novel ones
Drive genetics technology development in a cross-disciplinary setting by critically analyzing and deriving insights from experimental data (including NGS, arrays, and novel technologies) using open source NGS tools and building custom tools when needed
Working with wet lab scientists to independently design experiments and communicate conclusions for internal review
Develop reproducible analysis for research and development purposes
What you will bring:


Advanced graduate degree in bioinformatics, statistics, computer science or a related discipline, or 5+ years of experience working in a bioinformatics role
Have deep knowledge and experience analyzing genetics data including NGS and/or arrays, either from industry or academia
Familiarity or experience with NGS Primary analysis (image processing, machine learning, quality metrics) is a plus
Understand the detailed statistical and algorithmic workings of modern variant calling packages (preferably GATK)
Comfortable reading source code for large open source projects with preference for Python
Excellent communication (written and verbal) and data presentation skills
Preferred: PhD in bioinformatics, statistics, computer science or a related discipline, or 7+ years working in bioinformatics role
Preferred: Candidates with working experience with somatic or low input DNA assays
At Invitae, we value diversity and provide equal employment opportunities (EEO) to all employees and applicants without regard to race, color, religion, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. We will consider for employment qualified applicants with criminal histories in a manner consistent with the requirements of the San Francisco Fair Chance Ordinance.",4.3,"Invitae
4.3","Austin, TX","San Francisco, CA",1001 to 5000 employees,2010,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,$100 to $500 million (USD),-1
Principal Cybersecurity Software Engineer for Machine Learning Applications,-1,"DESCRIPTION


MORSE is looking a Principal Cybersecurity Software Engineer to improve the security of deployed machine learning models. The candidate will be among the first cybersecurity experts at MORSE, but will have a support team full of excellent software developers, data scientists, and engineers. Therefore, the candidate is expected to grow a team focused on upon cybersecurity for machine learning, with freedom to explore other areas of cybersecurity. Our machine learning applications provide cutting-edge, algorithmic-based simulation, situational awareness, and mission planning capabilities to a wide variety of DoD customers.

Skills and Requirements


The Principal Cybersecurity Software Engineer will be responsible to highlight security vulnerabilities in models, create a practical plan for increasing security, then implementing and deploying those security enhancements. A successful candidate will be able to communicate well and learn new areas quickly. Creative candidates who want to make an immediate impact will thrive in the MORSE environment. Additionally, the candidate must be eager to learn new technologies and stay on top of the latest cybersecurity and machine learning trends.
US CITIZENSHIP REQUIRED or the ability to obtain a U.S. Security Clearance
10 or more years professional experience in cybersecurity
5 or more years leading cybersecurity teams
Expertise in Python, Java, C, and/or C++
Proficiency in relational databases
Experience with version control systems
Experience with Agile development (Scrum or Kanban)
Strong communication skill
Self-starter and driven
BS or MS (preferred) in computer science or equivalent degree, or significant professional experience
Desired Skills
Experience with machine learning models
Experience with cloud computing, such as AWS and GovCloud",5.0,"MORSE Corp
5.0","Cambridge, MA","Cambridge, MA",1 to 50 employees,2014,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Software Engineer - Product Services,-1,"Location - Anywhere US or Canada
Expand and enhance the serverless platform that allows anyone to deploy AI and ML at any scale
Join a company that has always been remote-friendly - work anywhere in the US or Canada including your sofa, the beach, or our Seattle waterfront office
Experience rapid growth in the first AI startup to be funded by Google
Algorithmia is a single solution for all stages of the ML operations (MLOps) and management lifecycle. We enable ML and operations teams to work together on complex machine learning applications in one central location. We make it seamless to deploy ML at scale, with tools to connect data sources and orchestration engines, use any major framework, platform, or ML language, and govern and secure your ML architecture. More than 100,000 engineers and data scientists trust Algorithmia, including the United Nations and numerous Fortune 500 companies.

Due to unprecedented growth, we're hiring Software Engineers to participate in the design and development of the underlying Algorithmia platform. You'll join a passionate, remote-friendly team delivering a platform that already supports over 60k engineers and processes millions of AI and ML workloads. We work with Scala, Docker, Kubernetes, large-scale distributed systems, modern microservices architecture, and cutting-edge cloud infrastructure on AWS, Azure, and on-premises with VMWare. We offer our engineers an unparalleled opportunity to learn, grow, and impact an enormous user community.

As a Software Engineer at Algorithmia, you will:
Work with a passionate, distributed team on the cutting edge of AI/ML infrastructure
Use Scala to create stateless and stateful backend services in the cloud, with a focus on AWS, Docker, Kubernetes, and RDS to enable rapid deployment and iteration
Take pride in building and running secure, reliable, and performant distributed services that support a global customer base
Have meaningful opportunities for career growth, mentorship, promotion, technical leadership, and/or people management based on your interests
Work from anywhere in the USA or Canada. We have teams in Seattle and Toronto - or go 100% remote from home (Snuggie, bunny slippers, and all - no judgment!)
And we might make a great match if you:
Have excellent fundamentals in computer science, algorithms, and software design
3 or more years of experience in a software engineering role
Are a skilled software engineer with experience in expertise in at least one compiled language (such as Java, Scala, Golang, C++. We do a lot of Scala - and will be happy to teach you)
Have deep empathy for users, and understand that Algorithmia would not exist without them
Bonus points for experience working on distributed systems, data science, any kind of AI/ML projects, distributed or parallel computing, interesting public code
As a Software Engineer at Algorithmia you'll join a passionate team that's changing the way the world uses AI and ML. You'll solve real problems, make an impact, and work in a flexible environment that encourages collaboration and exploration. You'll be welcomed into an intelligent, fun, and diverse group and gain access to fantastic perks beyond the salary, equity, and insurance benefitsfrom your work location of choice.

If this sounds like you APPLY NOW, or learn more at algorithmia.com

Algorithmia is an equal opportunity employer and we value diversity at our core. We will never discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status and encourage everyone to apply.",4.5,"Algorithmia
4.5",Remote,"Seattle, WA",51 to 200 employees,2013,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Sr. Machine Learning Engineer,-1,"Where good people build rewarding careers.

Think that working in the insurance field cant be exciting, rewarding and challenging? Think again. Youll help us reinvent protection and retirement to improve customers lives. Well help you make an impact with our training and mentoring offerings. Here, youll have the opportunity to expand and apply your skills in ways you never thought possible. And youll have fun doing it. Join a company of individuals with hopes, plans and passions, all using and developing our talents for good, at work and in life.
Job Description
The Data Science & Analytics Engineering team builds software products specifically tailored to Allstates mission to improve customer's lives by re-inventing protection. We are creating scalable platforms for the deployment of cutting-edge predictive analytics, machine learning, and randomized experiments across the enterprise. We succeed by maintaining a steadfast focus on our customers using Lean Startup and Agile principles.

We are looking for a Senior Machine Learning Engineer to help us develop AI software products on a cloud-based platform which is already processing millions of unstructured objects a day. Youll help design and implement a framework that allows machine learning/deep learning models using natural language and image data to be scored in a production environment. You will have high visibility, great potential for growth, and a opportunity to make a distinct impact on how we do data science at Allstate. If you understand mathematics, general data science concepts, and full stack engineering necessary to design self-running software to automate models and analytics, we'd like to meet you. You'll also need to be a strong communicator as you will be working regularly with data science clients, as well as technology, architecture, and applications groups.

In this role, you will:
Help design machine learning systems
Research and implement/enhance machine learning model deployment platform
Run machine learning tests and experiments
Fully own production code, highly preferably REST APIs / microservices
Deploy machine learning applications into production
Work directly with data scientists, cloud engineer, and other stakeholders
Extend existing machine learning libraries and frameworks
Lead projects, including the planning and prioritization of tasks
Ability to context switch and manage multiple projects
Mentor team members and provide guidance on execution
Keep abreast of developments in the field
Job Qualifications
3+ years proven experience as a Machine Learning Engineer or similar role
Understanding of data structures, data modeling and software architecture
Working knowledge of REST APIs/Microservices
Intermediate/advanced Docker
Strong DevOps and CI/CD skills
Ability to write robust code in Python
Good knowledge of Python packages, e.g. Flask, Requests, Pandas, NumPy
Knowledge of math, probability, statistics and algorithms
Familiarity with machine learning frameworks (like Keras or PyTorch) and libraries (like scikit-learn)
Knowledge of AWS/PCF a plus
Familiarity with unstructured data a plus
Familiarity with Java application development is a plus
Excellent interpersonal communicator and collaborator
Outstanding analytical and problem-solving skills
BSc in Computer Science, Mathematics or similar field; Masters degree is a plus
The candidate(s) offered this position will be required to submit to a background investigation, which includes a drug screen.

Good Work. Good Life. Good Hands®.

As a Fortune 100 company and industry leader, we provide a competitive salary but thats just the beginning. Our Total Rewards package also offers benefits like tuition assistance, medical and dental insurance, as well as a robust pension and 401(k). Plus, youll have access to a wide variety of programs to help you balance your work and personal life -- including a generous paid time off policy.

Learn more about life at Allstate. Connect with us on Twitter, Facebook, Instagram and LinkedIn or watch a video.

Allstate generally does not sponsor individuals for employment-based visas for this position.

Effective July 1, 2014, under Indiana House Enrolled Act (HEA) 1242, it is against public policy of the State of Indiana and a discriminatory practice for an employer to discriminate against a prospective employee on the basis of status as a veteran by refusing to employ an applicant on the basis that they are a veteran of the armed forces of the United States, a member of the Indiana National Guard or a member of a reserve component.

For jobs in San Francisco, please click ""here"" for information regarding the San Francisco Fair Chance Ordinance.

For jobs in Los Angeles, please click ""here"" for information regarding the Los Angeles Fair Chance Initiative for Hiring Ordinance.

It is the policy of Allstate to employ the best qualified individuals available for all jobs without regard to race, color, religion, sex, age, national origin, sexual orientation, gender identity/gender expression, disability, and citizenship status as a veteran with a disability or veteran of the Vietnam Era.",3.4,"Allstate
3.4","Charlotte, NC","Northbrook, IL",10000+ employees,1931,Company - Public,Insurance Agencies & Brokerages,Insurance,$10+ billion (USD),"Progressive Insurance, State Farm, Farmers Insurance Group"
Senior Software Engineer - Data,-1,"Who we are:

fuboTV is the fastest growing video streaming startup (backed by some of the world's largest media companies) that is reinventing live television for the entire household in the cord cutting era.

Originally founded as a soccer streaming service, fuboTV is the leading sports-first cable replacement in the U.S.

fuboTV broadcasts most NFL, MLB, NBA and NHL games, all major soccer leagues, and a wide range of college and other sports. fuboTV also broadcasts a wide variety of news, movies, and entertainment programming including the FOX, NBC, CBS, and Turner broadcast catalogs, plus Showtime, AMCand much more! fuboTV can be accessed on multiple platforms, including web, Android, iOS, tvOS, Fire TV, Android TV, Roku and Chromecast.

About the Role:

fuboTV is looking for exceptional Senior Sofware Engineers with a passion for processing data at scale with speed.

As a Senior Software Engineer you will get to build highly-available systems, ingest troves of data, and help power our cutting edge experiences on Android, iOS, Web, Roku, and FireTV. fuboTV's data team has a unique opportunity to build and continuously improve greenfield services.

We are looking for Senior Software Engineers who care about code quality, uptime, performance, continuous deployment, SOLID design principles, test-driven development, and agile methodologies.

Our tech stack:

Go/Golang with govendor

Docker and Kubernetes

Apache Beam with Java/Scala

Redis, Google PubSub, BigTable, BigQuery, and PostgreSQL

fuboTV Software Engineers have the following responsibilities
Architect, design, develop, test, maintain and improve data pipelines and systems
Collaborate with other engineers and members of the fuboTV team to determine priorities and best practices, and refine functional requirements
All fuboTV Senior Software Engineers must:
Have 5+ years of experience in delivering working software.
Experience in processing and serving data at scale
Write clean, well-tested code
Be familiar with BigData pipelines for batch and realtime streaming
Have experience with distributed processing frameworks, filesystems, NoSQL databases (Hadoop, AWS, Google ecosystems)
Experience working closely with data scientists to production-ize machine learning algorithms
Have mastery of at least one modern backend stack, with a willingness to learn new technologies and methodologies
Requires at least a Bachelor's Degree in Computer Science, Engineering, Information Technology, Management Information Systems (MIS), Computer Information Systems (CIS) or related field or equivalent as determined by a professional credentials evaluation.
Perks & Benefits:
fuboTV provides a highly competitive compensation based on experience and market standards.
Robust benefit package including stock options, Health/Dental/Vision coverage sponsored up to 100% for employees, 401k, Life Insurance, and commuter benefits
Free Premium fuboTV Account
Health and Wellness initiatives including discounts on Gym Memberships.
Unlimited PTO days and regular company-wide activities.
fuboTV's main Headquarters are located in Midtown Manhattan.
fuboTV is an e-verified company",4.6,"FuboTV
4.6","New York, NY","New York, NY",51 to 200 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Engineer All Levels,-1,"At DataSync Technologies, our data engineering professionals touch every area of our company. Their insights drive our decisions and their innovations fuel projects. When you join our team of data experts, youre helping DataSyncs customers make better, smarter and faster decisions every day. See how you can help us solve some our customers most challenging data problems while you grow your skills and build your own future.

Job Description

DataSync Technologies is seeking Data Engineers to support a mission critical program within the Intelligence Community.

ONLY CANDIDATES WITH ACTIVE GOVERNMENT SECURITY CLEARANCES AND APPROPRIATE POLY WILL BE CONSIDERED. MUST BE A U.S. CITIZEN.

Responsibilities will vary by specific data engineer role Data Architect, Data Scientist, Database Engineer, Data Governance to include the following:
Design and develop methods, processes, and systems to consolidate and analyze structured and unstructured data from diverse sources including big data sources.
Develop and use advanced software programs, algorithms, query techniques, model complex business problems, and automated processes to cleanse, integrate, and evaluate datasets.
Analyze the requirements and evaluate technologies for data science capabilities including one or more of the following: Natural Language Processing, Machine Learning, predictive modeling, statistical analysis and hypothesis testing.
Develop information tools, algorithms, dashboards, and queries to monitor and improve business performance. Maintain awareness of emerging analytics and big-data technologies.
Designs, implement, and maintain standard data interfaces for data ingest including Extract/Transform/Load (ETL) methodology and implementation, APIs, RESTful Web Services, data quality, and data cleansing.
Provide data services, data administration, data management, and Big Data support in client/server, virtual machine, Hadoop, and cloud infrastructure environment and/or migrations between these environments.
Database installation, configuration, and the upgrading of database server software and related products, backup and recovery policies and procedures, database implementation, security, optimization, multi-domain operation, and performance management.
Hadoop, cloud, and other technologies associated with data storage, processing, management, and use.
The migration/transition of database capability into cloud based technologies and/or creation of interfaces between classic relational databases and key indexes to cloud based columnar databases and map reduce index capabilities.
Preferred Qualifications (All not required):
Databases/Data Stores: Oracle, MySQL, HIVE, HBASE, and HDFS
Frameworks: Hadoop, Rails, JavaScript Frameworks, SOA/WebServices, JSP
Indexing: SOLR and Lucine
Development/Scripting Languages: JAVA (J2EE), Python, Ruby, JavaScript, MapReduce, Pig, XML, SQL, JAQL, HTML, CSS, XML, BASH, ANT, and Perl
________________________

What makes DataSync Technologies different?

Leadership Training: We provide employees with a variety of learning opportunities, including access to exclusive classes, professional growth training and more.

Feedback & Mentoring: We believe in talkingoften. So we have one-on-one feedback sessions for every employee.

Community Service: We believe in helping the community where we work. DataSync and its employees donate time and services on a regular basis to local military charities. We believe in helping, both inside and outside of the office.

Social Events: We plan social events on a regular basis to help our employees relax and socialize so we get to know one another outside of our job titles.

Equal Employment Opportunity
DataSync is an EEO and Affirmative Action Employer of Female/Minorities/Veterans/Individuals with Disabilities. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.

Information about Equal Employment Opportunity (EEO) and Employee Polygraph Act (EPPA) provisions in addition to other Federal labor laws can be found at the Department of Labor's Website.

DataSync is committed to providing veteran employment opportunities to our service men and women.

Find out more about DataSync on Social Media.
www.datasynctech.com
www.facebook.com/DatasyncTechnologies
www.twitter.com/Jobs at DataSync (@DatasyncJobs)
www.twitter.com/datasynctech
#datasynctech on Instagram
Interested in Joining Our Team? - Check out this YouTube video!
#CJ

Powered by JazzHR",5.0,"DataSync Technologies, Inc
5.0","Reston, VA","Reston, VA",1 to 50 employees,2003,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Senior Software Engineer - Machine Learning [Remote Opportunity],-1,"We are looking for a Machine Learning (Client) Engineer to help us create artificial intelligence products. Client Engineer responsibilities include creating machine learning models and retraining systems. Your ultimate goal will be to shape and build efficient self-learning applications.

You are:
You can design and build web scale distributed systems. You are passionate about data science and machine learning. You are excited about recommender systems and comfortable reading research papers, interacting with data scientists and implementing Client algorithms from proof of concept to production. Additionally, you understand the constraints of working with a growing team and thrive in an environment that is fast-paced and sometimes scrappy. You understand that serving a user-facing model comes with a set of
restrictions and you know how to be creative to solve them. Finally, you are business focused and proactively thinking about new projects that could have a high impact result for the company.

If this sounds like you, please apply!

We value:Â
Team player
Problem solver
Radical candor
Testing rigor
Humility
Responsibilities:Â
Study and transform data science prototypes
Design and develop machine learning systems for data scientist to create, train and deploy Client models
Research and implement appropriate Client algorithms and tools
Develop machine learning applications according to requirements
Run machine learning tests and experiments
Perform statistical analysis and fine-tuning using test results
Train and retrain systems when necessary
Extend existing Client libraries and frameworks
Keep abreast of developments in the field
Requirements:Â
Proven experience as a Client Engineer or similar role
Understanding of data structures, data modeling and software architecture
Familiarity with machine learning frameworks (like Keras or PyTorch) and libraries (like scikit-learn)
Experience in applying machine learning, predictive analytics and classification techniques towards real product and problems
Ability to write robust code in Python or Java or equivalent modern programming language
Proficiency in SQL, big data technologies and working with large data sets
BS in Computer Science, Mathematics or similar field; Master's degree is a plus
Works independently, able to manage multiple projects simultaneously
Deep curiosity and a demonstrated ability to craft original solutions
Highly communicative with collaborators and manager
Proactive in seeking opportunities for innovation
Pluses:Â
Designed and built web scale distributed systems
Deep knowledge of math, probability, statistics and algorithms
Experience in the media industry

Call or Text:
Sriram
646-877-0206",4.7,"RPO Services
4.7",Alabama,"Visakhapatnam, India",1 to 50 employees,2011,Company - Private,Staffing & Outsourcing,Business Services,Less than $1 million (USD),-1
"Sr. Distributed Systems Research Scientist/Engineer, Software","$82K-$164K
(Glassdoor est.)","This is a unique opportunity to join the applied research team at Real-Time Innovations (RTI). As a Senior Distributed Systems Research Engineer on our research team, you will be part of a team that is maintaining our strategic lead in technology and thought leadership for building software communications frameworks for smart machines and critical real-world systems like the Kennedy Space Center launch system and Hyperloop. The RTI Connext software enables 1000s of applications and devices to exchange data in a timely and reliable way. Our software features direct peer-to-peer connections, reliable multicast, automated application discovery, and unique, contractual quality-of-service control.

Our team values creativity, risk-taking, innovation, and open communication. Our research spans an ever-growing range of interesting topics, including for example, advanced compression, machine learning, edge communications and processing, software-defined networking, hardware and software cybersecurity, resiliency, simulation and gaming engines, fault tolerance, embedded computing, microkernels, flight safety and software verification, and much more. Our government customers span a wide array of organizations – and, we continue to have an excellent record of bringing in funding (millions per year).

Real-Time Innovations (RTI) is the largest software framework provider for smart machines and real-world systems. Our software runs the largest power plants on the continent, connects perception to control in over 200 autonomous vehicles, drives the new generation of medical robotics, controls hyperloop and flying cars, and provides 24x7 medical intelligence to hospital patients and emergency victims. We are the best positioned small company in the world to create the very real future of intelligent, distributed systems.

RTI leads the world market for software that connects real-world devices. Our diverse and global workforce believes in working hard and enjoying the journey. We recognize employees for their achievements, offer great opportunities for career growth and development, and provide the tools they need to succeed. We also offer great benefits and flexibility. We commit to making your life as satisfying as your career. And, RTI's team is unmatched; our collaborative, transparent, and creative culture truly sets us apart from the rest.

We solve some of the greatest challenges in technology. Our mission is to transform industries: automotive, medical, power, defense, and control. Our core values emphasize excellence, teamwork, and your potential. Few small companies can truly claim to make the world run better like RTI. Come help make a real difference.

Responsibilities


You will be part of a team of experts researching emerging technologies, coming up with solutions for the problems posed by our research sponsors, exploring new concepts for products, prototyping ideas, and leading small teams to develop and to enhance advanced features related to RTI's secure real-time middleware platform. This is an individual contributor role. Duties will include:
Innovate new solutions that will form the foundation of secure, adaptable, and fast distributed systems
Create and execute long-term strategic research activities
Work with the business development team to define research areas of interest and define interesting research proposal topics
Write research proposals and project reports
Execute and lead research contracts to push our technology forward. Serve in the role of Principal Investigator on externally-funded research projects.
Actively interface with research project sponsors, customers, research partners, and prospects
Participate in and drive industry standards
Communicate technical innovations through papers and presentations
Support the transition of promising technical innovations to product including customer trials, coordinating with product management, design, development, testing and support groups
Requirements
PhD in Computer Science/Engineering, Robotics, Autonomy, Smart Machines, Distributed Systems or related field.
New graduates are welcome; some experience preferred.
Experience in distributed systems research
Excellent written communications skills, and evidence of research publications
Experience writing and winning proposals, and research project management
Solid understanding of computer network protocols; network and system programming, and real-time and/or high-performance applications
Solid programming skills (e.g. C/C++, Java, scripting languages)
Ability to work successfully / actively engage with a highly distributed team
(Preferred, not required!) Experience using OMG Data-Distribution Service (DDS) middleware, including development of distributed applications using DDS
U.S. citizenship required. Work to be performed for this position relates to federal government contracts which require U.S. citizenship.
Job Location

This position could be located at our new office in the Denver Metropolitan Area, Colorado, remote, or at headquarters in Sunnyvale, California.

About RTI


We have a collaborative and inclusive environment where individuals strong on aptitude and attitude will have an opportunity to grow their professional careers. Our culture embraces transparency, learning, and fun. We offer an attractive compensation package consisting of competitive salary, benefits, vacation bonuses, and equity participation.

RTI is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, religion, color national origin, sex, age status as a protected veteran, or status as a qualified individual with disability.",4.9,"Real-Time Innovations
4.9","Denver, CO","Sunnyvale, CA",201 to 500 employees,1995,Company - Private,Computer Hardware & Software,Information Technology,$25 to $50 million (USD),"ADLINK Technology, Wind River, Green Hills Software"
Data Analyst BI Engineer,-1,"Data Analytics BI Engineer
Remote for client based in Jacksonville, FL
Long term contract

Job Description
We are looking for a Business Intelligence (BI) Developer to create and manage BI and analytics solutions that turn data into knowledge. In this role, you should have a background in data and business analysis. You should be analytical and an excellent communicator. If you also have a strong business acumen with problem-solving aptitude, we’d like to speak with you.

Essential Functions:
Translate business needs to technical specifications
Design, build and deploy BI solutions (e.g. reporting tools)
Maintain and support data analytics platforms (e.g. MicroStrategy)
Create tools to store data (e.g. OLAP cubes)
Conduct unit testing and troubleshooting
Evaluate and improve existing BI systems
Collaborate with teams to integrate systems
Develop and execute database queries and conduct analyses
Create visualizations and reports for requested projects
Develop and update technical documentation
Job Requirements:
Experience delivering business intelligence solutions
Experience with OLTP and OLAP database models
Good analytical and problem-solving skills
Fluent in relational database concepts and flat file processing concepts
Must be knowledgeable in software development lifecycles/methodologies i.e. agile as strong presentation and collaboration skills and can communicate all aspects of the job requirements including the creation of formal documentation
Database Technology: SQL Server, Netezza, Hadoop, Cloudera
Knowledge of SQL queries, SQL Server Reporting Services (SSRS) and SQL Server Integration Services (SSIS)
ETL Technology: SSIS, DataStage, Talend, CRON scripting, Perl
BI Technology: SSRS, SSAS, Tableau, MicroStrategy
Proficient Intime series analysis, clustering, decision trees and neural networks
Strong problem solving, time management and organizational skills
Required Experience:
5+ years in an advanced analytical or data science role
5-8 years of Professional experience as a BI Developer or data scientist
Reporting Development, SQL Databases, Converting reports from legacy systems to new systems
Front end/back end database project experience
Required Education:
Related Bachelor’s degree in Data Science, Applied Mathematics, Computer science (e.g. specialization: Machine learning/Artificial Intelligence /Visualization, databases, and Big Data), Statistics, Epidemiology, or closely related field with Data Science specialization or additional related equivalent work experience
Preferred Experience:
React/Node. JS Environmental experience (building out reports within a React UI environment)
Expert in creating SQL Data Marts and high performing reporting structures
Expert in working with healthcare data
Big Data experience
SSAS Tabular Services experience
Additional skill set would be Highly Preferred:
UI React environment and Node.JS, and the PowerBI Development. Candidates who have worked with developers on projects using Node and React will be needed because of the reporting development that will occur on upcoming projects
Reporting Development, SQL Databases, Converting reports from legacy systems to new systems
Front end back end database project experience",4.1,"Alluvion Staffing
4.1","Jacksonville, FL","Jacksonville, FL",1 to 50 employees,2000,Company - Private,Staffing & Outsourcing,Business Services,Less than $1 million (USD),-1
Machine Learning Engineer,-1,"Penn Interactive Ventures (PI) is a real-money interactive gaming company headquartered in Philadelphia. As the digital arm to Penn National Gaming (NASDAQ: PENN), the largest regional casino operator in the U.S., we are poised for fast-paced growth in the sports betting and online casino space and are looking for a Machine Learning Engineer to join our expanding Sportsbook team!
The machine learning engineer will design and develop tools and processes to collect, clean, analyze and monitor player and market data in an effort to provide actionable customer insights. You will work with data scientists to fuel quality decision making across all teams at the company. This role will focus on the aspects of machine learning model creation having to do with producing well-crafted, production-grade software: RESTful API creation, error collection, monitoring, process automation, CI/CD.

Work closely with our Product Managers to understand features/game performance
Work closely with data scientists to tune models and bring them to production
Automate and productize reporting to increase analytical efficiency
Automate machine learning model creation and hypothesis testing
Improve experiment design and analysis to test user behavior hypotheses
Perform exploratory analyses to better understand our users
Build predictive models to predict migrations in player lifecycle
Produce actionable insights from quantitative and qualitative data

BS/MS degree in a quantitative discipline required (math, statistics, engineering, economics, physics and computer science, etc.)
2 - 5 years of relevant analytics/data science experience or equivalent combination of education and experience.
An understanding of free-to-play game systems, economies, currencies & balance a big plus
An ability to embrace an environment that moves quickly, iterates rapidly and celebrates failure as much as success
Strong python skills a must.
Strong SQL knowledge and experience
Proficiency in R is a plus.
Foundational understanding of statistics and machine learning
BONUS
Bayesian statistical inference, deep learning esp. sequence-to-sequence modeling, time series forecasting, natural language processing.

Penn Interactive is committed to helping our team members live their best, healthy life. We offer unique and competitive benefits that help our employees, through a private exchange which allows our team members the ability to choose from several coverage levels and insurance carriers (both local and national carriers). Along with medical, prescription, dental, and vision coverage, there are also voluntary plans available to employees. PI also offers our employees office perks such as free catered lunches, snacks, and beverages in the office.",3.1,"Penn National Gaming, Inc.
3.1","Philadelphia, PA","Wyomissing, PA",10000+ employees,1971,Company - Public,Gambling,"Arts, Entertainment & Recreation",$2 to $5 billion (USD),"Caesars Entertainment, MGM Resorts International"
Machine Learning Engineer Lead,-1,"JOB DESCRIPTION


At Levi Strauss & Co, we are revolutionizing the apparel business and redefining the way denim is made.

We are taking one of the world’s most iconic brands into the next century:

from creating machine learning-powered denim finishes to using block-chain for our factory workers’ wellbeing, to building algorithms to better meet the needs of our consumers and optimize our supply chain.

Be a pioneer in the fashion industry by joining our global Data, Analytics & AI “startup with assets,” where you will have the chance to build exciting solutions to improve our Americas business and at the same time be part of a bigger, across-continents, data community.

As a Machine Learning Engineer, you will work on a broad set of domains that power a data-driven transformation of our standard business procedures across channels and organizations. You will develop and deploy novel algorithms along with optimizing existing machine learning systems to maximize their value and increase consumer satisfaction at every brand touchpoint. You will also get the invaluable opportunity to mentor a team of diverse and enterprenuerial data engineers and shape their career trajectory through your expertise.

We are looking for someone who is a technology-agnostic polymath—committed to a lifelong journey of learning and exploration of new scientific ideas—and will bring thoughtful perspectives, empathy, creativity, and a positive attitude to solve problems at scale. This role is ideal for someone looking to extend their algorithm design and software engineering skills into a part mentor, part IC, part advisor role.

Example Projects:

In addition to driving the transformation of Levi’s into a data-driven enterprise in general, here are some specific projects you will get to work on and contribute towards:
Personalized in-session product recommendation engine
Customer Segmentation
Automated text summarization and clustering
Next-Best offer prediction
Designing Microassortments for Next-Gen stores
Anomaly detection and Root Cause Analysis
Unified consumer profile with probabilistic record linkage
Visual search for similar and complementary products
About the Job:
Architect, build, maintain, and improve new and existing suite of algorithms and their underlying systems.
Implement end-to-end solutions for batch and real-time algorithms along with requisite tooling around monitoring, logging, automated testing, performance testing and A/B testing
Utilize your entrepreneurial spirit to identify new opportunities to optimize business processes and improve consumer experiences, and prototype solutions to demonstrate value with a crawl, walk, run mindset.
Work closely with data scientists and analysts to create and deploy new product features on the ecommerce website, in-store portals and the Levi’s mobile app
Establish scalable, efficient, automated processes for data analyses, model development, validation and implementation
Write efficient and well-organized software to ship products in an iterative, continual-release environment
Contribute to and promote good software engineering practices across the team
Mentor and educate team members to adopt best practices in writing and maintaining production machine learning code
Communicate clearly and effectively to technical and non-technical audiences equally well
Actively contribute to and re-use community best practices
Embody the values and passions that characterize Levi Strauss & Co., with empathy to engage with colleagues from a wide range of backgrounds
About You:
University or advanced degree in engineering, computer science, mathematics, or a related field
5+ years experience developing and deploying machine learning systems into production
Experince working with a variety of relational SQL and NoSQL databases
Experience working with big data tools: Hadoop, Spark, Kafka, etc.
Experience with at least one cloud provider solution (AWS, GCP, Azure)
Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.
Ability to work in a Linux environment
Industry experience building and productionizing creative end-to-end Machine Learning systems
Experience working with distributed systems, service oriented architectures and designing APIs
Knowledge of data pipeline and workflow management tools
Expertise in standard software engineering methodology, e.g. unit testing, test automation, continuous integration, code reviews, design documentation
Relevant working experience with Docker and Kubernetes is a big plus
We put a lot of thought into our programs to provide you with a benefits package that matters. Whether it is for medical care, taking time off, improving your health or planning for retirement, we've got you covered. Here's a small snapshot:
401K match: $1.25 for every $1.00 you contribute up to the first 6% of pay you save.
Five hours of paid volunteer time per month with nonprofit organizations
Product discount of 50% off regular-price merchandise
LOCATION
San Francisco, CA, USA
FULL TIME/PART TIME
Full time",3.8,"Levi Strauss
3.8","San Francisco, CA","San Francisco, CA",10000+ employees,1853,Company - Public,"Department, Clothing, & Shoe Stores",Retail,$2 to $5 billion (USD),"Gap, VF, NIKE"
Junior Modeling & Simulation Engineer,-1,"Applied Research Associates, Inc. is looking for a Junior Modeling and Simulation Engineer to join our multi-disciplinary team of engineers and scientists in the Capital Area Division, located in Alexandria, VA. The ideal candidate has a passion for predicting the behavior of physical systems in challenging environments and operational impact on mission success. Models will be developed, used, and improved to support a Department of Homeland Security customer to safeguard the nation’s borders and interior from chemical, biological, radiological, nuclear, and explosive materials, equipment, technologies, and their actors. Models may be based on the underlying physics or may be process or agent based to predict operational performance and impact. Modeling and analysis may require the use and development of 3D virtual worlds or geospatial data. Models will be verified and validated, and they will be used in support of test and evaluation activities of systems intended to detect and identify threats. The candidate may participate in test and evaluation activities to support the verification, validation, and overall improvement of models. Models may become part of larger, integrated modeling and simulation activities, and may require the use of high performance computing technologies and federated simulations.

This position is contingent upon award of a contract expected in Summer 2020 supporting the Department of Homeland Security.

Required Qualifications:
Ability to program in a high level programming language, such as Fortran, C++, or Java
Eagerness to learn new tools and techniques
Strong verbal and written communication skills
Must be a U.S. Citizen with the ability to obtain and maintain a security clearance
Bachelor’s degree with minimum of 2 years of experience or greater in a physical science (physics, chemistry, biology), engineering-related discipline (nuclear, chemical, civil, mechanical, electrical), or modeling& simulation disciple (computer modeling, computational science, operations research)
Desired Experience and Qualifications:
Experience modeling CBRNE detectors or effects
Experience using any software tools such as MCNP, GadRas, SWORD, ExtendSim, Arena, SolidWorks, Fluent, ArcGIS, QGIS, VisIt, ParaView, or Cubit
Experience creating 3D models of systems, i.e., CAD
Experience developing and using discrete event or agent based models and simulations to predict and assess system performance
Experience developing machine learning models
Background in a physical science or engineering discipline, such as Physics, Chemistry, Biology, Mechanical Engineering, Nuclear Engineering
Active DoD Secret or Top Secret clearance, DoE Q clearance, or DHS Suitability
COMPANY INFORMATION:

Applied Research Associates, Inc. is an employee-owned international research and engineering company recognized for providing technically superior solutions to complex and challenging problems in the physical sciences. The company, founded in Albuquerque, NM, in 1979, currently employs over 1200 professionals. ARA offices throughout the United States and Canada provide a broad range of technical expertise in defense technologies, civil technologies, computer software and simulation, systems analysis, environmental technologies, and testing and measurement. The corporation also provides sophisticated technical products for environmental site characterization, pavement analysis, and robotics.

At ARA, employees are our greatest assets. The corporation realizes that employee ownership spawns greater creativity and initiative along with higher performance and customer satisfaction levels. ARA gives its employees the tools, training, and opportunities to take more active roles as owners. The culture is challenging; innovation and experimentation are the norm. Employees are eligible for contributions which not only add to the company’s success, but also their own through the Employee Stock Ownership Plan (ESOP). The motto,“Engineering and Science for Fun and Profit” sums up the ARA experience. For additional information and an opportunity to join this unique workplace, please visit our website atwww.ara.com.",3.5,"Applied Research Associates
3.5","Alexandria, VA","Albuquerque, NM",1001 to 5000 employees,1979,Company - Private,Federal Agencies,Government,$100 to $500 million (USD),-1
Software Engineer,-1,"As a Software Engineer at Crisis Text Line, you will help architect, build, and scale the world’s largest, free, 24/7 service supporting people in crisis over SMS and other messaging platforms. The technology you develop will help save lives.

About our team:


Crisis Text Line has served over 140 million messages across four countries, trained more than 30,000 Crisis Counselors, and built the largest mental health conversation data set in the world. Now we’re looking to grow rapidly to provide support in other countries and languages.

Our team aspires to reflect the diverse audiences and voices that our products serve. We think that diversity of perspectives, cultures, and ideas makes everything we build better, and we aim to recruit and hire accordingly.

What you'd work on:
Our modern web platform based on Symfony, Node.js, TypeScript, and React, hosted in AWS, where thousands of people in crisis get support every day by connecting with an individual from our corps of trained volunteers
Other custom-built applications to support our volunteer base and the employees that support them
Multiple integrations with 3rd parties including Twilio, Facebook, Salesforce, Okta
Tooling for developing and serving machine learning models developed by our in-house data scientists
Location: Ideally New York City, Durham, NC, the Bay Area, or the Seattle Area

Requirements

We want you to:
Collaborate. We’re looking for empathetic team players who can communicate with Engineers, Product Managers, and other colleagues with kindness and clarity
Teach. You are generous with your time and experience, can mentor junior engineers, and promote technical best practices
Learn. You are flexible with languages and tools and are willing to learn whatever is necessary to get the job done
Build. You should have 2+ years of experience developing web applications and write straightforward, well-structured code

Why you should join
Impact


We are already at a scale where we save many lives every day. You will be joining Crisis Text Line right as we ramp up our international expansion and expand into more languages. The tools and infrastructure that you build will enable us to expand to serving millions of people around the world.

Team


We currently have three collaborative scrum teams with wonderful, caring teammates. We are remote-friendly and leverage tools like Slack and video conferencing tools for open communication. The organization is small enough where it is easy to make improvements when you see something that could be done better.

Opportunity


Massive international expansion opens up many career opportunities. Some of the technical challenges we are starting to think about currently are moving to a multi-tenant architecture that can scale globally, internationalizing our platform to support more languages, and developing systems for coordinating global collaboration. On top of the technical opportunities, we will be growing our team substantially in the next couple of years which means more opportunities for leadership.

Diversity and Inclusion


At Crisis Text Line, we are committed to diversity and inclusion in everything we do. Not only does this help us build a more effective organization, but it also helps us build more inclusive tools and processes to help serve the diversity of texters and our community of volunteers. We are a woman-founded nonprofit, and promote an inclusive culture that stands against racism, sexism, homophobia, and ableism (to name a few). To be explicit, we strongly encourage applicants of all races, ethnicities, political party associations, religions (or lack thereof), national origins, sexual orientations, genders, sexes, ages, abilities, and branches of military service.

Crisis Text Line is an equal opportunity employer.

Logistics


Location: Flexible (Preferred: NYC, Durham, NC, Bay area, Seattle area)

Our headquarters are in NYC and we have an office in Durham, but we are largely a distributed, remote-friendly organization. That said, you will be expected to work hours that overlap 10 am - 4 pm Eastern Time for shared meetings and communication.

Physical demands: This job requires daily use of a computer

Benefits
3 weeks paid vacation
12 weeks paid parental leave (applies to full-time regular employee who's been with the company for at least 6 months and experiences the birth of a child or the placement of a child for adoption or foster care)
Paid Holidays including
Standard federal holidays
Valentine's day
Your birthday
Half day on Halloween
The week between Christmas and New Years
Paid sick/safe and personal leave
Bereavement leave (in the case of death of an immediate family member)
Family or medical leave
403B retirement plan (the nonprofit equivalent of a 401K) that matches 3% of your salary
FSA and Transit Benefits
A selection of Medical and Dental plans at nominal cost to the employee and additional buy up plans if you want more coverage, and vision plans for a small fee
Professional development stipend
Staff retreats
We host 1-2 staff retreats a year for bonding and the ability to meet coworkers (face-to-face when we’re not dealing with COVID-19)
Volunteer sabbatical
4 week volunteer sabbatical after every 2 years of continuous, full-time work to work with a nonprofit anywhere in the world",3.9,"Crisis Text Line
3.9","New York, NY","New York, NY",51 to 200 employees,2013,Nonprofit Organization,Health Fundraising Organizations,Non-Profit,Unknown / Non-Applicable,-1
Data Scientist,"$95K-$151K
(Glassdoor est.)","Requisition ID: 256384
Work Area: Software-Research
Expected Travel: 0 - 10%
Career Status: Professional
Employment Type: Regular Full Time
Career Level: T2
Posting Date : 6/16/2020

COMPANY DESCRIPTION

SAP started in 1972 as a team of five colleagues with a desire to do something new. Together, they changed enterprise software and reinvented how business was done. Today, as a market leader in enterprise application software, we remain true to our roots. That’s why we engineer solutions to fuel innovation, foster equality and spread opportunity for our employees and customers across borders and cultures.
SAP values the entrepreneurial spirit, fostering creativity and building lasting relationships with our employees. We know that a diverse and inclusive workforce keeps us competitive and provides opportunities for all. We believe that together we can transform industries, grow economics, lift up societies and sustain our environment. Because it’s the best-run businesses that make the world run better and improve people’s lives.

Purpose and Objective:

SAP Labs, LLC seeks a Data Scientist at our Palo Alto, CA location to analyze customer’s business problems, use cases and forms the requirements into feasible product feature.

Expectations and Tasks:

Explore data sources, implements data exploration, pre-processing and data cleansing on the historical data. Understand data and evaluate data quality from both data science and business value perspectives. Prepare the data for future models. Develop statistical / machine learning models based on the pre-processed data as a proof-of-concept. Assess and optimize the model quality based on technical level by tuning hyper-parameters, settings or even changing the models. Integrate the statistical / machine learning models into product. Work with application developers, machine learning engineers closely to ensure the model is ported into the product based on the prototyping. Work with product managers and designers to ensure all the features are delivered. Evaluate and improve the model performance under business context. Refine the model by tuning hyper-parameter, adjusting data sources or model approaches to resolve the business problem of customer. 10% travel required.

Education and Qualifications/Skills and Competencies:

Bachelor's degree in Computer Science, Engineering, Mathematics or a related field of study and 5 years of experience required. The company will also accept a Master's degree and 2 years of experience.

Work Experience:

Experience must involve 2 years in the following: ML and data science knowledge to define the next key features for the solution; build features architected for speed and distributed computing; Research, prototyping and development in the big data, machine learning and data science domain and machine learning frameworks. 10% travel required.

Travel:10% travel required.

Internal use only: reference code lhrs4262

EX:OUT

SAP'S DIVERSITY COMMITMENT

To harness the power of innovation, SAP invests in the development of its diverse employees. We aspire to leverage the qualities and appreciate the unique competencies that each person brings to the company.

SAP is committed to the principles of Equal Employment Opportunity and to providing reasonable accommodations to applicants with physical and/or mental disabilities. If you are interested in applying for employment with SAP and are in need of accommodation or special assistance to navigate our website or to complete your application, please send an e-mail with your request to Recruiting Operations Team (Americas: Careers.NorthAmerica@sap.com or Careers.LatinAmerica@sap.com, APJ: Careers.APJ@sap.com, EMEA: Careers@sap.com). Requests for reasonable accommodation will be considered on a case-by-case basis.

EOE AA M/F/Vet/Disability:

Qualified applicants will receive consideration for employment without regard to their age, race, religion, national origin, gender, sexual orientation, gender identity, protected veteran status or disability.

Additional Locations :",4.6,"SAP
4.6","Palo Alto, CA","Walldorf, Germany",10000+ employees,1972,Company - Public,Computer Hardware & Software,Information Technology,$10+ billion (USD),"Salesforce, Oracle, Microsoft"
Data Science Algorithm Software Development Engineer,"$69K-$135K
(Glassdoor est.)","Requisition Number: 207646Position Title: Data Science Engineer (III)External Description:Job SummaryTeradata's Product Development Group is seeking exceptional candidates proficient in advanced analytics to join our research and development organization. Members of Teradata's Product Group are highly accomplished and many hold PhDs from top colleges and universities in the world. As a member of the analytics team, the Data Science Algorithmic Development Engineer will work in collaboration with other members of engineering to design and implement Teradata Analytics Platform highly parallel functions that span Mathematical Statistics, Numerical Analysis, Statistical Pattern Recognition, Time Series, Machine Learning, Game Theory, and Deep Learning. Teradata's Analytics Platform functions are enterprise quality functions that can process massive data at linear scalability and high performance.We encourage our scientists and engineers to participate in developing key intellectual property (IP) for Teradata by writing patents, publishing in international conferences and journals, and attending conferences.Responsibilities:* Research, Prototype, Design and implementation of highly scalable parallel advanced analytics and machine learning algorithms, running on MPP Advanced Analytics Platform, using C function APIs* Collaborate closely with platform, Quality Assurance and UI engineering for end to end design and implementation of the analytic functions and features* Work with the QA team to develop tests and verify metrics for analytic functions results and model prediction quality* Evaluate, investigate, and optimize the performance of the analytic functions for various input configurations* Drive the development and support of key analytic features and functions throughout its life cycle, from conception to support and enhancement* Support continuous improvement by investigating alternative algorithms and technologies and presenting them for architectural reviewQualifications* Mastery in C* Experience with Java and C++* Object Oriented analysis and design using common design patterns* Experience with numerical analysis programming* Ability to design and implement complex analytics and machine learning algorithms, and in particular linearly scalable parallel algorithms* Ability and passion to iteratively assess, tune and improve the quality to make highly competitive products* Effective communication and presentation skills* Good understanding of distributed systems and parallel data processing* Strong knowledge in relational database and SQL* Experience in performance optimization, and building of high performance data processing applications* Ability to prioritize and work on multiple projects* Experience with test-driven development* Ability to work closely and collaborate with others in the team and across functional groupsPreferred Qualifications:* PhD degree in computer science/mathematics/statistics/physics/engineering preferred (or equivalent work experience)* Exceptional Master of Science graduates will be given consideration* Experience in developing database applications a plus* Experience with R, MATLAB, and/or SAS* Experience in Hadoop, Spark, TensorFlow, and related technologies a plus* Experience with Python a plusWhy you should consider this position and our companyThis is your opportunity to be heard and to make an impact! We are big enough to work with technology used by the world's largest companies and small enough for you to see the exact impact of the work that you're doing. While our group works as a collaborative unit in order to constantly advance learning, you individually will ""own"" the development of specific functions. You will see direct results of your work within the product and will see how our customers are utilizing that to make important decisions within their business.The Teradata culture isn't just about one kind of person. So many individuals make up who we are, making us that much more unique. It's what sets apart the dynamic, diverse and collaborative environment that is Teradata. But even as individuals, there's one thing that we all share -our united goal of making Teradata and our people, the best we can be. Come join us today!CountryEEOText_Description: Teradata invites all identities and backgrounds in the workplace. We work with deliberation and intent to ensure we are cultivating collaboration and inclusivity across our global organization. We are proud to be an equal opportunity and affirmative action employer. We do not discriminate based upon race, color, ancestry, religion, creed, sex (including pregnancy, childbirth, breastfeeding, or related conditions), national origin, sexual orientation, age, citizenship, marital status, disability, medical condition, genetic information, gender identity or expression, military and veteran status, or any other legally protected status.City: Santa ClaraState: CaliforniaCommunity / Marketing Title: Data Science Algorithm Software Development EngineerJob Category: EngineeringCompany Profile:Considering COVID-19, we are still hiring but conducting virtual interviews to keep our candidates and employees safe. Many roles will be temporarily remote or work from home to comply with current safety regulations. These roles will be required to be in the office once it is safe or restrictions are lifted. Read more on our response here: Teradata Response to COVID-19With all the investments made in analytics, it's time to stop buying into partial solutions that overpromise and underdeliver. It's time to invest in answers. Only Teradata leverages all of the data, all of the time, so that customers can analyze anything, deploy anywhere, and deliver analytics that matter most to them. And we do it at scale, on-premises, in the Cloud, or anywhere in between.We call this Pervasive Data Intelligence. It's the answer to the complexity, cost, and inadequacy of today's analytics. And it's the way Teradata transforms how businesses work and people live through the power of data throughout the world. Join us and help create the era of Pervasive Data Intelligence.Location_formattedLocationLong: Santa Clara, California US",3.7,"Teradata Corporation
3.7","Santa Clara, CA","San Diego, CA",10000+ employees,1979,Company - Public,Computer Hardware & Software,Information Technology,$2 to $5 billion (USD),"Cloudera, IBM, Oracle"
Software Development Engineer - Deep Learning Platform,"$123K-$192K
(Glassdoor est.)","Interested in machine learning and AI ? Do you want to work on cutting edge technologies at the intersection of AI and DevOps ?

The mission of AWS AI is to make machine learning easy, fast, and universal across all of our customers. Our world class platform provides the services that runs 85% of all on-cloud machine learning through performance optimizations, machine learning tools, and SDKs to democratize machine learning. Our customers include scientists, data analysts, and ML engineers all building and deploying models across AWS.

In this role, you will be responsible for building toolkits, libraries to integrate and optimize ML frameworks with AWS AI services. You will work with global teams of engineers, influencing the formation of future DL/ML solutions used by millions of users on a daily basis.




Basic Qualifications

· 2+ years of non-internship professional software development experience
· Programming experience with at least one modern language such as Java, C++, or C# including object-oriented design
· 1+ years of experience contributing to the architecture and design (architecture, design patterns, reliability and scaling) of new and current systems.
· Experience with golang and Kubernetes
· Experience with Kubeflow and related technologies
· Expertise building software solutuons using AWS technologies

Preferred Qualifications

· Master's Degree in computer science, engineering, mathematics, or related field.
· Experience with machine learning/deep learning frameworks and libraries (TensorFlow, PyTorch, MXNet, Chainer, Caffe, Scikit, etc.)
· 7+ years of professional experience in the field.
· Experience in High Performance Computing or Data Mining or AWS infrastructure.

Amazon is an Equal Opportunity-Affirmative Action Employer Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation/ Age",3.9,"Amazon
3.9","East Palo Alto, CA","Seattle, WA",10000+ employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),"Google, Microsoft, Walmart"
Software Development Engineer - Machine Learning,"$110K-$174K
(Glassdoor est.)","Amazon Advertising operates at the intersection of eCommerce and advertising, offering a rich array of digital display advertising solutions with the goal of helping our customers find and discover anything they want to buy. We help advertisers reach Amazon customers on Amazon.com, across our other owned and operated sites, on other high quality sites across the web, and on millions of Kindles, tablets, and mobile devices. We start with the customer and work backwards in everything we do, including advertising. If youre interested in joining a rapidly growing team working to build a unique, world-class advertising group with a relentless focus on the customer, youve come to the right place.

Performance Advertisings vision is to enable advertisers of all sizes with self-service products to build their brand and business at Amazon delivering sophisticated automation for novices and powerful controls for expert users. We are focused on continuous exploration of contexts and creative formats where advertising delivers value to customers and advertisers. Our products are auction based, cost-per-click, and drive traffic within the Amazon shopping experience addressing lower and mid-funnel marketing goals. We deliver billions of ad impressions and millions of clicks daily and are breaking fresh ground to create world-class, highly performant advertising products. We are highly motivated, collaborative and fun-loving with an entrepreneurial spirit and bias for action. With a broad mandate to experiment and innovate, we are growing fast with a seemingly endless range of new opportunities.

Our systems and algorithms operate on one of the world's largest product catalogs, matching shoppers with advertised products with a high relevance bar and strict latency constraints. We work hand-in-hand with Machine Learning scientists to come up with novel solutions that deliver highly relevant ads. We consistently strive to improve the customer search and detail page experiences. You will drive appropriate technology choices for the business, lead the way for continuous innovation, and shape the future of e-commerce.

Job Responsibilities:
· Contribute to the technical direction of our offerings and solutions
· Work with many different technologies across the sponsored products organization
· Design, code, troubleshoot, and support scalable machine-learning pipelines and online serving systems
· Work closely with applied scientists to optimize the performance of machine-learning models and infrastructure, and implement end-to-end solutions
Impact and Career Growth:
· Sharpen your Machine Learning skills
· Opportunity to grow and broaden your technical skills as you work in an environment that thrives on creativity, experimentation, and product innovation
· This is an opportunity to make a significant impact on the future of the Amazon vision.
If you are looking to make an impact, this is the team for you. You will not only have the satisfaction of seeing your work deliver results, but also help shape our engineering and product roadmaps. Change the world by accepting this Machine Learning Softward Developement Engineer role today!




Basic Qualifications

· Bachelor's degree in Computer Science or related disciplines
· 2+ years experience with computer science fundamentals in object-oriented design, data structures, algorithm design, problem solving, and complexity analysis
· Exposure to Machine Learning basics (will train for more advanced skills).

Preferred Qualifications

· Experience in building large-scale machine-learning infrastructure for online recommendation, ads ranking, personalization, or search, etc
· Experience with Big Data technologies such as AWS, Hadoop, Spark, Pig, Hive, Lucene/SOLR or Storm/Samza
· Strong proficiency with Java, Python, Scala or C++
· Coursework or thesis in machine learning, data mining, information retrieval, statistics or natural language processing
· Advanced knowledge of performance, scalability, enterprise system architecture, and engineering best practices

Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.",3.9,"Amazon
3.9","Palo Alto, CA","Seattle, WA",10000+ employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),"Google, Microsoft, Walmart"
Data Scientist,"$65K-$107K
(Glassdoor est.)","Title: Data Scientist / Machine Learning Engineer
Location: Minnetonka, MN or Virtual
Department: Transportation
Reports to: Manager, Big Data

Our Company
Trimble Transportation is in business for optimizing the movement of freight by providing shippers and carriers both mobility, enterprise and visibility software tools they need to run their businesses more efficiently. As the leading provider of Transportation Management Software (TMS), Asset Management Software (AMS), and Fleet Management Software (FMS) we are devoted to propelling companies in the trucking industry toward increased efficiency, lower costs and optimized operations.

Position Overview:

Trimble Transportation, a leader in transportation technology, is expanding its data insights organization. This role requires an individual with a strong data analytics, machine learning, and programming foundation to join an exciting, high-growth environment. The Machine Learning Engineer will have the opportunity to solve complex issues in the transportation industry by applying cutting edge technology and the latest algorithms. This will require working with stakeholders to translate business problems into predictive models and optimization programs, and implementing these with professional software engineering skills. We highly value creative individuals who are strong problem solvers, continual learners, and passionate about data and analytics. If you love solving complex problems using data this will be the job for you .

Primary Responsibilities:

25% Define: Work across multiple teams and stakeholders to solve business problems using a data-driven approach
Work with stakeholders to understand and analyze highly complex business requirements
Translate business requirements into innovative, data-driven solutions that leverage Machine Learning
Apply best practices to document and communicate proposed solutions
Define data requirements to build complex predictive models
60% Develop: Build production-grade Machine Learning pipelines
Work in a team environment to plan, coordinate, and execute project tasks
Perform data analysis, visualization, data mining, and feature engineering
Implement software to efficiently clean and transform large data sets
Apply expertise in Machine Learning and Statistical Methods to develop predictive models and optimization programs
Apply industry best practices to evaluate Machine Learning models
Develop scalable, efficient, and automated Machine Learning pipelines that are ready for production
15% Deploy and Monitor: Successfully deploy models to production and ensure they maintain accuracy over time
Collaborate across teams to deploy Machine Learning pipelines to production
Develop tools and methods to monitor for and correct model drift
Required Skills:
Bachelor's degree in Engineering, Computer Science, Mathematics, Statistics or related field OR an equivalent combination of education, experience, knowledge, skills, and abilities
3+ years experience performing data analysis, data engineering, and Machine Learning model design and development
3+ years experience using the Python language and the Python based machine learning stack (including numpy, scikit-learn, Pandas, Jupyter)
3+ years experience using Big Data tools such as Spark, Hadoop, and Kafka
Experience with data science methodologies (particularly CRISP-DM)
Fluent in Unsupervised and Supervised Machine Learning techniques including Regression, Decision Trees, Clustering, Neural Networks, and Anomaly Detection
Experience using model validation techniques and metrics (accuracy, precision, recall, etc.)
Fluent in SQL
Experience with SQL and NoSQL data stores (such as SQL Server, PostgreSQL, MongoDB, Elasticsearch)
Experience using Agile development methodologies (particularly Scrum)
Experience with modern source code management tools (such as Git)
Ability to take on a high level of responsibility, initiative, and accountability
Ability to work effectively in a highly collaborative team environment
Ability to manage time and workload effectively which includes planning, organizing, and prioritizing with attention to details
Excellent verbal, written, and interpersonal communication skills
Continual learner with a desire and ability to learn new skills and technologies
Preferred Skills:
Masters degree or higher in a quantitative field (Statistics, Artificial Intelligence, etc.)
Prior experience in Operations Research
Prior experience in transportation, logistics, or fleet management
Trimble Inc. is proud to be an Equal Opportunity and Affirmative Action Employer and considers qualified applicants for employment without regard to race, gender, age, color, religion, national origin, marital status, disability, sexual orientation, status as a covered veteran in accordance with applicable federal, state and local laws, or any other protected factor. EOE/M/F/V/D

#engineering",3.9,"Trimble
3.9","Minnetonka, MN","Sunnyvale, CA",10000+ employees,1978,Company - Public,Computer Hardware & Software,Information Technology,$2 to $5 billion (USD),-1
Principal Engineer - AI/Machine Learning,"$121K-$214K
(Glassdoor est.)","U.S. Bank is looking for an Artificial Intelligence/Machine Learning (AI/ML) Principal Engineer to join the Innovation team, supporting some of the largest initiatives in our company. The AI/ML Principal Engineer is a hands-on role that will be primarily responsible for execution and delivery of exploratory concepts, rapid prototypes, and pilot solutions designed to test hypotheses and incubate transformative new AI/ML Principal Engineer will provide solutions to large-scale problems, from ideation through delivery to production, and will bridge the gap between software developers and research/data scientists.

This role will work within the fast-paced Chief Digital Office/Innovation team, which strives for excellence in all phases of execution and lifecycle management. The ideal candidate will have the right attitude and an imaginative mind set, is creative, and has extensive experience with AI/ML solution delivery within industry. The individual will be comfortable working in an innovation-focused environment – in particular, evaluating emerging trends and technologies to assess their feasibility and viability and functioning effectively in a fail-fast environment. The position relies on the individual to be a self-starter and a quick learner, to have a futurist mindset, and to be able to innovate and report on tasks and status proactively.

Job Responsibilities:

• Implements AI/ML solutions through the entire development lifecycle, e.g. rapid prototype, design, build, assemble, test, and pilot.
• Designs, develops, and delivers code to implement AI/ML algorithms for experimentation and eventual adaption within the enterprise.
• Documents and articulates AI/ML solution code design and lessons learned for each exploration and accelerated incubation.
• Collaborates with other organizations within the company to define the optimal AI/ML solution deployment architecture and hosting environment.
• Encourages new transformative thinking and trail blazing, and facilitates imagination and ideation sessions.
• Collaborates with other organizations within the company to identify and flesh out new growth opportunities using AI/ML technologies.
• Maintains current knowledge of technology landscape and emerging developments.
• Works with various Product and Enterprise teams to optimize customer and user experiences.
• Employs practical approach to data access and management and eventual platform integration of AI/ML solutions.

Basic Qualifications:

• Ph.D. in a STEM field (e.g., Physics, Mathematics, Computer Science, Operations Research, Statistics, or related quantitative/technical fields) and at least 2 years of experience in AI/ML solution development and deployment OR a Master’s Degree and at least 5 years of experience OR a Bachelor’s Degree and at least 10 years of experience.
• Strongly Preferred: extensive previous experience in AI/ML solution development in either Conversational AI/NLP or cybersecurity threat detection.
• Advanced working knowledge and extensive experience with programming and software design fundamentals, e.g. object oriented and functional design principles, best practices, etc.
• Extensive experience in developing within cloud-based environments (e.g. Google Cloud, Amazon Web Services, Microsoft Azure), with emphasis on GPU-enabled computing.
• Extensive experience delivering and maintaining AI/ML solutions in production using Continuous Integration/Continuous Delivery (CI/CD) tools (e.g. Jenkins, Kubernetes, GitHub, JIRA/Bitbucket/Bamboo, Artifactory, DataDog) and best practices.
• Experience with Python programming environment or equivalent (e.g. R, Scala) and related open-source technologies such as NumPy, SciPy, Pandas, Scikit-learn, TensorFlow, Keras, Deeplearning4j, etc.
• Experience with API’s or software packages for computer vision, deep learning, voice/speech recognition, and/or NLP, e.g. OpenCV, Gensim, BERT, SpaCy, NLTK, etc.
• Experience with multiple methods of batch and real-time streaming data access in both development and production environments, e.g. Postgres, MongoDB, SQL, NoSQL, RESTful API’s, GraphQL, etc.
• Experience delivering communications in a clear, concise, and compelling manner.
• Willing to travel up to 25> of the time for business purposes.",3.5,"US Bank
3.5","New York, NY","Minneapolis, MN",10000+ employees,1863,Company - Public,Banks & Credit Unions,Finance,$10+ billion (USD),-1
"Full-Stack Software Engineer, Machine Learning Platform",-1,"Our client is looking for a full-stack software engineer to join the machine learning operations teams to help define and drive development of our client's brand new offering for enterprise-grade machine learning operations platform. You will be working with a team responsible for driving the product from inception, to design, building and delivering the software. This role requires a startup-mindset to build features incrementally and pivot according to feedback from customers. You will have to work in close collaboration with data scientists, product managers and UX designers.

We look for an action-driven candidate who has a desire to solve hard problems, break down the hard problems into smaller tasks, deliver software on time, gather feedback from customers and continually improve the product. You must be willing to learn new things, be self-motivated, innovative and proactive.

The role offers significant opportunities for growth.

Responsibilities:

Help build a platform for production machine learning operations for enterprise customers.

Design, code, and implement elegant, scalable, enterprise-quality application services

Work to enhance developer velocity and team agility

Build strong relationships and collaborate with platform and UI engineers, quality engineers, and UX designers as well as with Product Management, Field Engineering, and other external partners

Qualifications:

5+ years of experience backend experience using Java, Python, Ruby, or C++.

Experience with microservices development (Go, GRPC, SQL).

Experience with server-side JavaScript tooling such as Node. js, npm, webpack, babel, etc.

Experience with cloud technologies (AWS, GCE, Azure).

Self-driven and motivated, with a strong sense of ownership and craftsmanship.

Strong written and verbal communication skills.

Pluses:

Experience with data science and machine learning tools (R, Python, Tensorflow, Spark).

Experience with containerization (Kubernetes).

Experience building scalable, robust and secure Enterprise applications.

Full-stack web services development skills, such as experience with modern JavaScript frameworks such as Angular, React, Ember, Vue, etc.

#GDTech

Andiamo is an Equal Opportunity Employer

Andiamo provides equal employment opportunities to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability or genetics. In addition to federal law requirements, Andiamo complies with applicable state and local laws governing nondiscrimination in employment in every location in which the company has facilities. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.

All qualified candidates are encouraged to apply by submitting their resume as an MS word document including a cover letter with a summary of relevant qualifications, highlighting clearly any special or relevant experience.",3.5,"Andiamo
3.5","Austin, TX","Warren, MI",201 to 500 employees,-1,Company - Private,Casual Restaurants,"Restaurants, Bars & Food Services",$1 to $5 million (USD),-1
Senior Principal Machine Learning Engineer (Growth Marketing),"$148K-$255K
(Glassdoor est.)","Coupang is one of the largest and fastest growing e-commerce platforms on the planet. We are on a mission to revolutionize everyday lives for our customers, employees and partners. We solve problems no one has solved before to create a world where people ask, ""How did we ever live without Coupang?""

Coupang is a global company with offices in Beijing, Los Angeles, Seattle, Seoul, Shanghai, and Silicon Valley.

Job Overview:

In Growth Engineering, our goal is to increase the number of transacting Customers while growing their frequency and lifetime value. We build core platforms and services that power Coupang's growth. Various platforms under our portfolio include Search Advertising Platform, Affiliate Platform, Display targeting & re-targeting Platform, CRM, Audience Platform, Push Marketing Platform, and other core marketing services for landing, tracking & attribution. We leverage big data, NoSQL, analytics, real-time processing and Machine Learning to build mission-critical and highly scalable services that are reliable 24/7.

As our Sr. Principal Machine Learning Engineer for Growth Engineering, you will play a strategic role in supporting innovation and be responsible for making our platforms & services data driven and intelligent leveraging data science. You will standardize the ML Platform that will be leveraged across Growth Engineering and collaborate with various teams to build and deploy statistical and optimization models that will directly help grow customers, increase wallet share and improve ROAS. Opportunities to leverage Data Science and Machine Learning to make a strong business and financial impact include customer look-alike models, product feed optimization, promotion recommendation, app push personalization, keyword bidding, product & category recommendations, etc. This is an exceptional opportunity to drive Coupang's growth and create a world where our customers ask, 'How did I ever live without Coupang?'

Key Responsibilities:
Lead and execute all Data Science and Machine Learning Initiatives for the organization
Engage with senior leadership, product owner(s) and engineering mangers in developing and executing data science strategy and roadmap
Play an active role in contributing to company's growth strategy, and identify opportunities to leverage data and insights helping Coupang's growth and customer loyalty
Collaborate with software engineers and data engineers to implement, verify and deploy models to deliver direct business and financial impact
Communicate clearly and concisely with the team members, peers and leadership team
Over time, assist with hiring and mentoring data scientists and ML engineers in the team
Qualifications
PhD in Machine Learning, Statistics, Applied Math or a quantitative field
10+ years of hand-on technical experience in data science working with large data sets to drive significant business/financial impact, preferably in e-commerce
Experience building and productionizing innovative scalable end-to-end machine learning systems
Strong background in statistical modeling and optimization techniques
Proficiency in a statistics tool like R and Big Data tools (Hive, Spark, Presto)
Strong fundamentals in object-oriented design, data structures, algorithm, problem solving and complexity analysis
Preferred:
Exceptional presentation skills and ability to communicate methodologies, results clearly and concisely to company's top executives
Strong interpersonal skills to work with cross-functional and globally distributed teams
Strong sense of ownership, urgency, and drive. High on bias for action
Coupang is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex or gender (including pregnancy, gender identity, gender expression, sexual orientation, transgender status), national origin, age, disability, medical condition, HIV/AIDS or Hepatitis C status, marital status, military or veteran status, use of a trained dog guide or service animal, political activities, affiliations, citizenship, or any other characteristic or class protected by the laws or regulations in the locations where we operate.

If you need assistance and/or a reasonable accommodation in the application or recruiting process due to a disability, please contact us at usrecruiting@coupang.com.",3.6,"Coupang
3.6","Mountain View, CA","Seoul, South Korea",5001 to 10000 employees,2010,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Machine Learning (AI/ML),-1,"Role: Machine Learning (AI / ML) Software Engineer

Location: San Francisco, CA

Start date: ASAP

Job Description

Required Skills

The Artificial Intelligence, Machine Learning (AI / ML) Software Engineer will be responsible for supporting Artificial Intelligence, Machine Learning, and Data Science solutions for the Client. We’re looking for engineers with a passion for Artificial Intelligence to help drive a new generation of data and machine learning enabled services and products to impact healthcare. You will enjoy working with a highly talented and diverse team of data scientists and engineers specializing in deep learning, active learning, and classical machine learning on one of the richest data sets in US healthcare. You'll be equipped with nearly limitless cloud compute resources and be expected to deliver business impact through implementation of a large pipeline of AI models. The ideal candidate will have a background in Python, have experience working with large data sets, and have experience in building and deploying data-driven solutions. You are focused on results, a self-starter, able to put the team-first, and have demonstrated success in using data science to develop and deploy solutions with a focus on impact.

Responsibilities:
Provide technical leadership and implementation for Software Engineering projects supporting our AI and machine learning goals
Modifies, implements, tests, and supports all product related technology and functionality, including software infrastructure in an AWS hosted environment
Demonstrates strong drive to learn and advocate for development best practices (TDD, code reviews, continuous integration, etc.)
Communicates proactively and effectively with team members and other product stakeholders in a highly Agile environment
Self-starter that will take tasks and accomplish them with little oversight according to timelines and budgets agreed upon with business and technology stakeholders
Minimum Qualifications:
You have 2+ years’ experience working on applications of machine learning with strong to expert ability in Python as a primary language
Critical Skills:
Experience building automated processes that are supportable, monitored, and enterprise-scale
Experience working with and integrating services from popular ML packages such as Keras, TensorFlow, XGBoost, SciKit Learn
Above average capabilities with cloud computing techniques or tools such as S3, EC2, EMR, SageMaker, ECS, Lambda, IAM
SQL design and development skills
Additional Knowledge & Skills:
Spark or Pyspark experience preferred
Experience building/consuming REST web services
Demonstrated initiative with learning new technologies
Exceptional interpersonal and communication skills
Job Type: Contract

Pay: $60.00 - $65.00 per hour

Schedule:
Monday to Friday
Experience:
Machine Learning: 2 years (Required)
Artificial Intelligence: 1 year (Required)
Work Remotely:
Temporarily due to COVID-19",-1,Neoiteksys,"San Francisco, CA",-1,-1,-1,-1,-1,-1,-1,-1
Data/Machine Learning Engineer - Data Team,-1,"Come join our team, and together we’ll realize the true potential of gene therapy!

Who we are

Dyno Therapeutics is a Cambridge based, VC-backed biotech startup that uses next-gen DNA technologies and machine learning to engineer Adeno-associated Virus (AAV) capsids for the effective delivery of gene therapies.

What we offer you

As a member of our quickly growing company, you’ll help us shape Dyno into a startup that takes its scientific mission seriously and provides a positive and supportive workplace environment. Dyno will have the opportunity to benefit from your insight, skills, and talent while enriching your professional and scientific experience as we grow the company together.

Our mission

At Dyno, we are expanding the boundaries of gene therapy. AAV capsids are currently the vector of choice for gene therapy, but they are only a starting point in the gene therapy revolution. Dyno aims to dramatically extend the reach of gene therapy by overcoming the limitations of existing AAV capsids, allowing more therapies to reach the clinic. Doing so will enable treatment for millions of patients with currently incurable, often disabling and deadly diseases.

How?

Dyno’s groundbreaking engineering pipeline harnesses advances in DNA library synthesis, high-throughput sequencing, and machine learning to generate transformative gene therapy vectors. We target the major barriers that separate AAV gene therapy research from real-world therapies, including delivery efficiency, tissue and cell-type specificity, immune evasion, and more. Our vectors will accelerate the transition of gene therapies from the lab to the clinic for the benefit of patients worldwide.

Where?

Dyno is located near Kendall Square in Cambridge. Situated within the dynamic LabCentral community, Dyno is working alongside other startups that are also creating the future of biomedicine.



Available position

Data/ Machine Learning Engineer - Data Team

General role

The data science team is at the heart of Dyno’s platform, and your work as a part of this team can have a major impact on the future of gene therapy. Our team's responsibilities span from analyzing biological data in a statistically rigorous manner to building machine learning models, developing computational optimization approaches, and contributing to experimental design of high-throughput viral libraries. A successful candidate will take a leading role in developing and implementing reliable distributed data pipelines that are used by dyno’s data science and/or machine learning services. Additionally, a candidate will implement, expand, deploy, and maintain machine learning models. The candidate will collaborate with machine learning scientists, computational biologists, and software developers,

As an early member of our team, you will have the opportunity to help craft our approach, shape our culture, and positively impact people’s lives. You will work closely with a group of talented, driven, and fun scientists. We are located in Lab Central in a dynamic community of biotech startups. The guideline below should give you a rough picture of who we are looking for, but depending on your background, you may bring different qualities to our team. Don't hesitate to write to us if you think you are a good fit. We offer competitive benefits.

Basic qualifications
BS, MS, or Ph.D. in a quantitative field or equivalent experience
2+ years of industry experience as a Software, Data, or ML Engineer.
Expertise in Python.
Design and implement distributed data pipelines.
Proficiency with data warehousing concepts, data architectures, infrastructure components, and environments (e.g. AWS databases, MongoDB).
Proficiency with cloud-based computing and related technologies (e.g. Kubernetes, Spark, Hive, MapReduce).
Ability to communicate and collaborate with scientists and engineers of different backgrounds.
Experience with at least one machine learning library (such as Tensorflow or pyTorch) as well as the ability to run them on large datasets in a distributed manner.

Preferred qualifications

Experience in designing and building data/ML pipelines from scratch.
Demonstrated ability to implement state-of-the-art machine learning algorithms.

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

Job Type: Full-time, Internship",-1,Dyno Therapeutics,"Cambridge, MA","Cambridge, MA",1 to 50 employees,-1,Company - Public,-1,-1,Unknown / Non-Applicable,-1
NLP Engineer -Data Scientist,-1,"Direct End Client: Medtronic
<strong>Job Title: NLP Engineer -Data Scientist
<strong>Start Date: ASAP
<strong>Location: Northridge, CA
<strong>Position Type: Full Time
<strong>Interview Type: In person or Telephonic or Webcam
<strong>Requirement ID: MED_NLP517_VV

Must Have: Minimum Requirements
Bachelor's with 4+ years of experience, Master's with 2+ years of experience or a Ph.D. with 0+ years of experience.Â
Degree must be in Statistics, Math, Computer Science or similar field.
Experience in Python, R or similar data-science scripting language
Experience with statistical modelling
Experience in using SQL for advanced data analysis and visualization
Nice to Have:
Strong track record in building NLP, NLU models using real-world large datasets, that work in production with positive outcomes
Prior experience with Spark and the AWS stack
Experience with Tensorflow, MXNet or Keras framework
Proficient in relational database management systems with knowledge of non-relational database systems
Background in healthcare & diabetes physiology
Understanding of FDA regulations including (ISO) 13485.
Project: Cross-Diabetes group

Department: Medtronic Diabetes

Responsibilities:
Identify novel ways to apply NLP and NLU technology and help drive our data science roadmap.
Create ontology and entity database to enable advanced information inquiry.
Apply machine learning and advanced statistical methods to improve NLP and NLU technology from vast amounts of medical related conversation.
Design, implement, test and deploy state-of-the-art NLP, NLU in a production environment.
Work closely with the engineering team to operationalize infrastructure for NLP, NLU algorithms.
Access the performance and analyze the risk of designed NLP, NLU algorithms.
Keep up-to-date with the latest techniques and approaches in machine learning and statistical analysis.
Ability to communicate analysis in a clear, precise, and actionable manner

<strong>Responsibilities may include the following and other duties may be assigned:
In new product design roles: develops and programs integrated software algorithms to structure, analyze and leverage data in product and systems applications in both structured and unstructured environments.
Develops and communicates descriptive, diagnostic, predictive and prescriptive insights/algorithms.
In product/systems improvement projects: uses machine language and statistical modeling techniques such as decision trees, logistic regression, Bayesian analysis and others to develop and evaluate algorithms to improve product/system performance, quality, data management and accuracy.
In both theoretical development environments and specific product design, implementation and improvement environments, uses current programming language and technologies to translate algorithms and technical specifications into code.
Completes programming and implements efficiencies, performs testing and debugging.
Completes documentation and procedures for installation and maintenance.
Applies deep learning technologies to give computers the capability to visualize, learn and respond to complex situations.
Adapts machine learning to areas such as virtual reality, augmented reality, artificial intelligence, robotics and other products that allow users to have an interactive experience.
Can work with large scale computing frameworks, data analysis systems and modeling environments.

<strong>V Group Inc. is an IT Services company which supplies IT staffing, project management, and delivery services in software, network, help desk and all IT areas. Our primary focus is the public sector including state and federal contracts. We have multiple awards/contracts with the following states: AR, CA, DE, FL, GA, IL, KY, MD, ME, MI, NC, NJ, NY, OH, OR, PA, SC, TX, VA, and WA. If you are considering applying for a position with V Group, or in partnering with us on a position, please feel free to contact me for any questions you may have regarding our services and the advantages we can offer you as a consultant.Â

Please share my contact information with others working in Information Technology.

Â

Website: www.vgroupinc.com
<strong>Twitter: VGroupITServices@VGroupITService
<strong>Facebook: www.facebook.com/VGroupIT",3.4,"V Group Inc.
3.4","Northridge, CA","Louisville, KY",501 to 1000 employees,1997,Company - Private,Staffing & Outsourcing,Business Services,$100 to $500 million (USD),-1
Computer Vision & Deep Learning Engineer - Autonomous Vehicles,"$134K-$228K
(Glassdoor est.)","Intelligent machines powered by Artificial Intelligence computers that can learn, reason and interact with people are no longer science fiction. Today, a self-driving car powered by AI can meander through a country road at night and find its way. An AI-powered robot can learn motor skills through trial and error — this is truly an extraordinary time and the era of AI has begun. Image recognition and speech recognition — GPU Deep Learning has provided the foundation for machines to learn, perceive, reason and solve problems. The GPU started out as the engine for simulating human creativity, conjuring up the amazing virtual worlds of video games and Hollywood films.

Now, NVIDIA's GPU runs Deep Learning algorithms, simulating human intelligence, and acts as the brain of computers, robots and self-driving cars that can perceive and understand the world. Just as human imagination and intelligence are linked, computer graphics and AI come together in our architecture. Two modes of the human brain, two modes of the GPU. This may explain why NVIDIA GPUs are used broadly for Deep Learning, and NVIDIA is increasingly known as “the AI computing company.” Come, join our Deep Learning team, where you can help build the real-time, cost-effective computing platform driving our success in this exciting and quickly growing field.

We are seeking the best Computer Vision Scientists with background in the following, to partner with system software engineers to build the next generation of vision algorithms.

What you’ll be doing:
Develop computer vision, visual geometry and Deep Learning algorithms for autonomous cars, mapping and localization - Focused on Parking applications
Experiment with new or early stage algorithms
Solidify existing algorithms working with large amounts of real data
Maximize the quality of algorithmic results
Partner with system software engineering specialists to build shipping industrial strength codes
Minimize inefficiencies and latency to maximize performance
What we need to see:
BS or MS in Computer Science, Computer Engineering or Electrical Engineering
8+ years of relevant experience
Experience in Parking spot detection/classification
Experience in embedded Computer Vision, SIMD and parallel computing, with a deep understanding of CV algorithms and multimedia image formats
Fluent in C & C++, as well as experience in CUDA
Efficient in SW development in Linux, with a deep understanding about mobile operating system e.g. Linux, Android
Good knowledge in SoCs e.g. Tegra, with efficient use of Software development tools like debuggers
Outstanding written and verbal interpersonal skills in English, as well as dedication to the work
Good organization skills, with a logical approach to problem solving, good time management and task prioritization skills
Ways to stand out from the crowd:
Experience with visual geometry and Deep Learning in a shipping product context
Experience in Parking spot detection/classification in a shipping product context
Experience developing real-time Image Processing and/or Computer Vision systems
Software development on embedded platforms or large scale cloud services
Experience with GPGPU programming (CUDA and OpenGL)
NVIDIA is committed to fostering a diverse work environment and proud to be an equal opportunity employer. As we highly value diversity in our current and future employees, we do not discriminate (including in our hiring and promotion practices) on the basis of race, religion, color, national origin, gender, gender expression , sexual orientation, age, marital status, veteran status, disability status or any other characteristic protected by law.#deeplearning",4.6,"NVIDIA
4.6","Santa Clara, CA","Santa Clara, CA",10000+ employees,1993,Company - Public,Computer Hardware & Software,Information Technology,$5 to $10 billion (USD),-1
Senior Data Engineer,-1,"At Afresh, we’re solving the big problems around food waste and the fresh food supply chain--focusing first in grocery. We use cutting-edge AI (we’ve been published in ICML!) combined with thoughtful design to enhance decision-making and optimize store workflows. The results are powerful: in live deployments in grocery stores, we have demonstrated the potential to double profits and reduce food waste by 50%+!
What will you be doing?
Building fast and reliable data pipelines that enable training machine learning models over billions of historical data points collected from tens of thousands of retail stores across the US.
Integrating with our customers’ infrastructure, which includes a variety of contemporary and legacy IT systems. Setting up data feeds from the customers’ systems.
Maintaining transactional, analytic, and NoSQL databases and data lakes over terabytes of data.
Collaborating with an interdisciplinary team of experts in machine learning, data scientists, design, software engineering, and business process optimization
What skills and experience do you need?
Bachelors or Masters in Computer Science or equivalent.2+ years of work experience.
Strong programming and problem-solving skills.
Expert-level knowledge of databases, data lakes, data pipelines, SQL. Experience with big data frameworks such as Apache Spark is a big plus.
Experience working with Microsoft Azure, Amazon Web Services, and other cloud providers.
Familiarity with statistical concepts and/or devops expertise are a plus. Experience with data visualization is a plus.
Background

About 30-40% of food produced worldwide is thrown away, causing nearly a trillion dollars of economic losses, trillions of gallons of wasted water, and billions of tons of greenhouse gas emissions. In the US, about 40% of all food waste occurs at the retail level and downstream, largely driven by insufficient technology and manual processes.

Afresh seeks to tackle some of these big problems around food waste. Born out of Stanford's Computer Science PhD program, Afresh is the first Fresh food supply chain company. We bring the cutting edge of artificial intelligence to Fresh food to minimize food waste.

Our machine learning-powered supply chain solutions are tailored for the nuances of perishables. Our first product is a store-level replenishment tool that optimizes the ordering of items in Fresh categories -- produce, meat, deli, dairy, bakery, and prepared foods. The goal is to minimize waste and maximize in-stock rate, and consequently, profit.

So far, the results are awesome! Like we said above, in live deployments, we have demonstrated the potential to double profits and reduce food waste by 50%+.

We're growing fast: we're in partnership with 4 large regional grocers representing 500+ stores and >$10B in revenue. Our backers include Innovation Endeavors (former Google CEO Eric Schmidt’s firm) and Baseline Ventures (first money in Stitchfix, SoFi, Heroku, Instagram).

Interested? Email us at Careers@afreshtechnologies.com",5.0,"Afresh Technologies
5.0","San Francisco, CA","San Francisco, CA",1 to 50 employees,2016,Company - Private,Grocery Stores & Supermarkets,Retail,Unknown / Non-Applicable,-1
AI/Machine Learning Data Security Engineer (Louisville or Boston),"$44K-$72K
(Glassdoor est.)","Description

The Data Governance Office (DGO) at Humana is seeking an AI and Machine Learning Data Security engineer to support the appropriate and secure use of information assets. DGO coordinates the synthetic data capability for the enterprise that creates widely usable and anonymized data sets by mathematically modeling production data and generating replicas of that data that retain the rich relationships between the data components without compromising individuals’ privacy. The synthetic data capability requires application of generative neural network methodologies supported by considerable amounts of compute, memory, and storage resources within a cloud platform to meet the dynamic demand of the multivariate regression processes. Humana is seeking a Data Science Engineer with AI and Machine Learning experience (particularly in Azure) to operate these processes and to do so with data security disciplines to protect the highly sensitive data required for modeling while in that process.

Responsibilities

Responsibilities

The successful candidate will work within the Machine Learning environment at Humana and with that team to perform activities in support of and related to the build out, maintenance, and enhancement of the Synthetic Data resources. This is a challenging environment that must innovate while respecting the rigors, policies, and constraints of a corporate analytical facility. The Machine Learning team operates in an open environment that encourages sharing of ideas, code, feedback, and documentation of their work.
Tooling includes:
Python, SQL, Bash, PowerScript, Scala
SQL Server, Hadoop, PySpark, Kafka, Databricks
RedHat Enterprise Linux, Windows, Docker, Azure Kubernetes Services
Git, Azure DevOps, Gira, Confluent
Job Description
Design, build out, maintain, monitor, and enhance the Synthetic Data environment in Azure
Interface with Data Scientists, Business Users, and Developers to support their synthetic data requests
Interface with the synthetic data engine vendor(s) to maintain and enhance the operation of their engine in the Azure platform
Research and develop enhancements to the pre-processing of data sets for introduction to the synthetic data engine
Periodically research and present emerging synthetic data innovations from the field to the Data Science community
Mentor and train Data Scientists and Engineers within Humana’s analytics community to operate synthetic data capabilities
Role Essentials
BS in Computer Science, Data Science or related field
5 or more years of experience designing, developing, and testing software applications and infrastructure
3 or more years of machine learning experience
Experience writing maintainable, testable, production-ready, and documented Python code
Experience in big data platforms (Hadoop, Spark, Hive, etc. . .) and big data formats (Parquet, Avro, etc. . .)
Experience with secure development and security features required by cloud infrastructures
Preferred Qualifications
Terraform deployment of Azure infrastructure configurations
Experience with deep learning libraries and frameworks (TensorFlow, PyTorch, Keras, etc. . .)
Master’s Degree in Computer Science, Data Science or related field
Scheduled Weekly Hours

40",3.6,"Humana
3.6","Louisville, KY","Louisville, KY",10000+ employees,1961,Company - Public,Insurance Carriers,Insurance,$10+ billion (USD),"Cigna, Aetna, UnitedHealth Group"
Senior Engineer - Machine Learning and Data Science,-1,"Thornton Tomasetti provides engineering design, investigation and analysis services to clients worldwide on projects of every size and level of complexity. We are a growing 1500+ person firm with 10 practices: Structural Engineering, Forensics, Applied Science, Renewal, Property Loss Consulting, Construction Engineering, Protective Design and Security, Facade Engineering, Sustainability and Transportation. We work on everything from landmark buildings to small-scale specialty structures, from the historic to the high performing, while balancing multiple objectives, including form, function, schedule, sustainability, constructability and budget. TALENT is at the core of our business.

The Applied Science practice leverages a unique combination of technologies and expertise to engineer practical solutions to problems of national and international importance. We apply expertise in solid and fluid dynamics, materials science, acoustics, risk assessments and computational simulation methods to solve complex problems. We perform research, mathematical modeling, software development and design to manage risks to life safety in military platforms and installations, ships and submarines, critical infrastructure, tall buildings, public facilities, industrial and petrochemical plants, and automotive and airborne vehicles. Military, government, corporate and academic clients value the validation of Applied Science’s software and the critical insights gained from correlating analysis with testing.

Our 70 year record of success is driven by the sustained focus of our uniquely qualified and experienced staff of engineers and scientists. We have an immediate need for a Senior Engineer to perform analysis and design work in a demanding, innovative structural assessment capacity. Our interest is in highly motivated, imaginative engineers and scientists who seek to work on unique and challenging problems. Many of the topics of research and engineering in the Applied Science Practice are interdisciplinary and not direct extensions of collegiate coursework, so the successful applicant should be comfortable expanding their skill sets and tackling new problems.

Essential Functions of this Senior Engineer position

The emphasis is on the ability to address difficult physical problems, within the practical constraints of a consulting environment with tangible deliverables and deadlines. As part of a consulting project team engaged on projects in the technical areas of structural mechanics, material modeling and engineering R&D, the candidate must be able to:
Formulate analytical approaches to address engineering and scientific problems,
Demonstrate command of the application of advanced finite element methods and software for nonlinear behavior,
Demonstrate proficiency in the creation, execution, interpretation and reporting of computational mechanics models,
Demonstrate proficiency in the development of Artificial Intelligence / Machine Learning / Data Science approaches to the analysis of complex data sets,
Demonstrate proficiency in the development of robust software implementations for these applications.
Requirements
M. Eng. or higher in structural engineering, mechanical engineering, applied mechanics, or related fields.
This position is intended for engineers and scientists with 0-5 years’ experience.
Strong interpersonal skills and willingness to work in a success-oriented team environment.
Must be able to obtain a US security clearance.
The successful candidate will be supported to gain a professional engineering license on their respective area of technical focus.
Thornton Tomasetti is proud to be an equal employment workplace. Individuals seeking employment at Thornton Tomasetti are considered without regards to age, ancestry, color, gender (including pregnancy, childbirth, or related medical conditions), gender identity or expression, genetic information, marital status, medical condition, mental or physical disability, national origin, protected family care or medical leave status, race, religion (including beliefs and practices or the absence thereof), sexual orientation, military or veteran status, or any other characteristic protected by federal, state, or local laws.

Thornton Tomasetti Global Terms of Use and Privacy Statement

Carefully read these Terms of Use before using this website. Your access to and use of this website and application for a job at Thornton Tomasetti are conditioned on your acceptance and compliance with these terms.

Please access the linked document by clicking here, select the country where you are applying for employment, and review. Before submitting your application you will be asked to confirm your agreement with the terms.",3.6,"Thornton Tomasetti
3.6","New York, NY","New York, NY",1001 to 5000 employees,-1,Company - Private,Architectural & Engineering Services,Business Services,$100 to $500 million (USD),"Arup, AECOM"
Big Data Software Engineer (Partial Remote),-1,"SummaryAs a Big Data Sofware Engineer come join a dynamic team and have a high impact on big data projects at the leading edge of biomedical research.The Jackson Laboratory for Genomic Medicine in Farmington, CT is seeking a Senior Software Engineer for Data Engineering. This position reports to the Associate Director of Computational Sciences Scientific Computing (CSSC) team that is primarily responsible for developing software applications for scientific research programs.This role will have a high impact on big data projects supporting research at the forefront of genetics and genomics. This is an exciting opportunity to work creatively solving tough problems with truly big data. The solutions you develop will lead to better understanding of highly complex biological systems, and support the search for cures to cancer, diabetes, Alzheimer's disease and other genetic disorders.Responsibilities* Leading the development of scientific software applications and systems to support research at The Jackson Laboratory.* Lead the development of large complex projects with team members including software engineers, bioinformatics analysts, statisticians and scientists.* Identify and lead big data opportunities within the organization and enhance the team's expertise with managing large scale data both on-premise and in the cloud* Demonstrate knowledge of a cross section of tools and techniques relating to support of large-scale data analysis* Function as part of a highly productive software team and will work closely with researchers across all three campuses to develop tools to aid in their research.Qualifications* Minimum of five (5) years of experience in software development* A BS degree or higher in computer science, information science or equivalent on-the-job experience* Experience with a variety of database management systems beyond relational databases* Experience with operational tools such as Git, JetBrains IDE products (PyCharm, Idea), CI Tools such as Jenkins or Bamboo, Atlassian Suite* Experience with and capable of working in an agile development environment* Experience or knowledge with machine learning applications at scale* Experience in identifying and developing software applications in the biomedical sciences and/or bioinformatics and implementing systems for analyzing large-scale scientific data is a plus* Strong knowledge of Linux environments* Knowledge in statistics, biology, genomics are considered a plusAbout UsThe Jackson Laboratory (JAX, www.jax.org) is a nonprofit biomedical research institute with over 2,000 employees whose mission is to discover precise genomic solutions for human disease and empower the global biomedical community in the shared quest to improve human health. A National Cancer Institute-designated Cancer Center, JAX has a mammalian genetics headquarters in Bar Harbor, Maine, a facility in Sacramento, California, and a genomic medicine facility, The Jackson Laboratory for Genomic Medicine (JAX-GM), in Farmington, Connecticut.JAX-GM is transforming medicine by improving patient care, lowering costs, and increasing life span and health span. JAX-GM's research focuses on the complex genetic causes of disease and on the development of genomic solutions tailored to each person's unique genetic makeup.JAX-GM sits on a 17-acre site on the campus of the University of Connecticut Health Center. The 183,500-square-foot facility opened in the fall of 2014. Now, it houses over 300 biomedical researchers, technicians, and support staff in state-of-the-art computing facilities and laboratories.JAX-GM resides in the scenic town of Farmington, in the state's capitol region. The Hartford region, which offers some of the best public schools in the country, is made up of both bigger cities and smaller, charming historic New England towns. JAX-GM is also geographically located within 2 hours of Boston and New York and is close to multiple transportation systems, including bus lines, highways, railroads and international airports.JAX employees work in a collaborative, value-driven, and team-based environment where the focus is on advancing science and improving patients' lives. Researchers apply genetics to increase the understanding of human disease and advance treatments and cures for cancer, neurological and immune disorders, diabetes, aging, and heart disease. JAX was voted among the top 15 ""Best Places to Work in Academia"" in the United States in a poll conducted by The Scientist magazine!Our Values:INTEGRITY - Courage and commitment to do what is rightPEOPLE - Inspiring our people to enhance the health of allONE TEAM - Unified by our promise to transform medicine and scienceEXCELLENCE - Achieving world-class resultsINNOVATION - Leading with discovery and creative solutionsSTEWARDSHIP - Caring for and enhancing the resources entrusted to usWhat do we have to offer?JAX offers a dynamic and supportive work environment, competitive salaries, and a comprehensive benefits package, including a medical plan, outstanding retirement plan, generous paid time off, and tuition reimbursement including an MBA program. Our campus offers a fitness center with an award-winning wellness program and an onsite full service cafeteria.Most importantly, every position contributes to JAX's mission of discovering precise genomic solutions for human disease and empowering the global biomedical community in our shared quest to improve human health.The Jackson Laboratory provides equal employment opportunities to all employees and applicants for employment in all job classifications without regard to race, color, religion, age, mental disability, physical disability, medical condition, gender, sexual orientation, genetic information, ancestry, marital status, national origin, veteran status, and other classifications protected by applicable state and local non-discrimination laws.Learn more about career opportunities at JAX: http://www.jax.org/careers.",3.8,"Jackson Laboratory
3.8","Farmington, CT","Bar Harbor, ME",1001 to 5000 employees,1929,Nonprofit Organization,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,$100 to $500 million (USD),"Charles River Laboratories, Taconic Biosciences"
Lead Software Engineer,"$49K-$106K
(Glassdoor est.)","Headquartered in Durham, North Carolina, a small start up employs a team of data scientists, engineers, developers, business people, and agronomists, serving a rapidly growing customer base across the U.S. They are a wholly-owned subsidiary of ICL, a leading global specialty minerals company. The company employs over 11,000 people worldwide, and its 2019 revenues totaled approximately $5.3 billion.

Their technology platform collects and structures user-generated, environmental, business-related, and machine-generated agricultural data. These data power agile creation, and simple execution of precise planting, fertilization, and crop protection plans that aim to optimize resource use and mitigate the farmer's financial risk. They are hiring a Lead Software Engineer to:

* Building new Web and Mobile Applications from the ground up
Building and deploying API services to support your applications
Implementing TDD best practices and test automation for both frontend and backend
Coordinating with product stakeholders to determine feature requirements
Coordinating with our Data Architect, DevOps, and Pipeline Engineers to ensure that our API services are performant, scalable and secure
Leading a team of additional Full Stack Engineers as we continue to grow
Fostering an environment of continuous improvement

Qualifications:
7+ years of professional experience with full-stack web development
Fluency in SQL, Python, ES2016+, and TypeScript
Extensive knowledge of React, React-Native, and Expo.io
Experience with GraphQL, Socket.io and real-time event streaming
Experience NodeJS HTTP Frameworks such as Express, Koa and Hapi
Experience with ORM frameworks such as Sequelize
Experience with front-end testing frameworks such as Cypress.io
Experience with the AWS ecosystem and familiarity with services such as ECS, Lambda, and S3
Experience with Docker and related containerization technologies.
Ability to communicate well and work directly with customers
Desire to work in a small agile team and participate in cross-functional collaboration

About Aerotek:

We know that a company's success starts with its employees. We also know that an individual's success starts with the right career opportunity. As a Best of Staffing® Client and Talent leader, Aerotek's people-focused approach yields competitive advantage for our clients and rewarding careers for our contract employees. Since 1983, Aerotek has grown to become a leader in recruiting and staffing services. With more than 250 non-franchised offices, Aerotek's 8,000 internal employees serve more than 300,000 contract employees and 18,000 clients every year. Aerotek is an Allegis Group company, the global leader in talent solutions. Learn more at Aerotek.com.",3.4,"Aerotek
3.4","Durham, NC","Hanover, MD",5001 to 10000 employees,1983,Company - Private,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
Senior Software Engineer - Machine Learning,-1,"Who is Mindstrong?

Mindstrong is a research-driven, consumer-focused mental healthcare company working to unlock a new virtual care model for delivering healthcare to people living with a serious mental illness (SMI) through innovations in measurement science, and care delivery. Our services are offered to people with an SMI through active partnerships with several nationwide health insurance payers.

As a Series C company, we have a blend of science, technology, and healthcare talent to help us unlock this paradigm-shifting approach, including the likes of National Institute for Mental Health, Stanford Center for Neurobiological Imaging, Uber, Facebook, Google, Apple, Oscar Health, and CMS.

We'd love to talk more!

What is the Senior Software Engineer - Machine Learning Role?

We're looking for Machine Learning Engineers to join our growing team of people passionate about changing mental healthcare. In this role, you will work cross functionally and partner with data scientists, product managers, data analysts, and the clinicians who directly deliver care to our Mindstrong members. You will lead projects that derive value from our extensive amount of data and will work on problems related to predicting and measuring mental health outcomes, optimizing our growth funnel, matching clinicians with patients, increasing the efficiency of clinical services, and making recommendations for impactful interventions. Our team works across the company to help influence decision-making, and your work will have a direct impact on our patient population.

What you'll be doing:
Become an expert in building healthcare critical machine learning applications that remap brain circuits from human-computer interaction patterns
Create highly scalable and adaptive online/streaming learning algorithms that impact the lives of millions of people daily
Work with high-performance engineering and data science teams to deploy these applications in a highly scalable and distributed infrastructure
Improve the quality and availability of care for millions of people around the world
Who you are:
You feel good about your work knowing that what you do will affect the lives of millions of people around the world
Eager to thrive in a startup environment
Strong communicator (oral and written)
A good person, highly ethical, and accepting of others
Your background and skills:
4+ years of relevant industry experience in software engineering or production-level data science experience working with large scale data-driven systems
Excellent knowledge of machine learning models and evaluation techniques
Experience training, deploying, and monitoring machine learning models in both research and production environments
Experience with feature engineering and ETL development
Rigor in high code quality, automated testing, and other engineering best practices
Experience working cross functionally across data science and engineering
Detail oriented with strong communication and interpersonal skills
Proven track record of delivering on tight schedules
Experience writing production quality Python code a must; Java or Scala a plus
Competitive Benefits:
Medical, Dental, and Vision coverage
401k
10 paid holidays
Unlimited PTO
Fully stocked kitchen and catered lunches
Casual dress code
Telecommuting benefits
Join us in our journey to transform the future of brain health!

Mindstrong is proud to be an Equal Employment Opportunity employer that celebrates diversity. We are committed to providing equal employment opportunities to all employees and applicants. All individuals seeking employment at Mindstrong are considered without regard to race, color, religion, national origin, age, sex, marital status, ancestry, physical or mental disability, veteran status, gender identity, sexual orientation, or any other characteristic protected by federal, state, or local laws. This policy applies to all terms and conditions of employment. Mindstrong also strives for a safe and robust workplace and prohibits harassment of any kind. If you have a disability or special need that requires accommodation for interviewing, please let us know by emailing contact-recruiting@mindstronghealth.com",3.6,"Mindstrong
3.6","San Francisco, CA","Mountain View, CA",51 to 200 employees,2014,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Engineer / Data Scientist - Contributor,"$64K-$85K
(Glassdoor est.)","Who we are?

The Hyperloop is revolutionizing transportation.

At Hyperloop Transportation Technologies (HyperloopTT) we are pioneers: we are turning Hyperloop into a reality across the world (www.hyperloop.global).

Are you a very talented and passionate Data Scientist / Machine Learning Engineer, who is ready for this huge challenge that will change mobility as we know it today?

You will work together with our highly talented team and with leading technology partners; you will work with cutting-edge technology; you will work on exciting projects; you will have flexibility; and you will have an impact!

We are seeking a Data Engineer / Data Scientist - Contributor. As a contributor you will work around 5-10/hrs a week in exchange for stock options.

Key duties & responsibilities
Design and develop tools and algorithms for recommendation and predictive engines
Create and maintain optimal data pipeline architecture
Identify, obtain and prepare data sets for training and testing algorithms
Use Machine Learning to solve modeling and ranking problems across discovery and search
Evaluate potential improvements, prototype, validate, and productionize these strategies
Integration of data from multiple sources including third party sources.
Requirements and qualifications
5+ years of relevant experience as a Data Engineer, Data Scientist or Machine Learning Engineer
Strong software development experience in languages such as Python, Java, Scala, R or C++
Experience working with large data sets using tools like Hadoop, Spark, or ElasticSearch
Knowledge of Machine Learning systems, data mining, search, ranking, recommendations
Experience with relational (SQL) and NoSQL Databases
Sharp analytical and problem-solving skills
Great team player with good communication skills
Good organizational and time-management skills
High level (spoken & written) of English
In addition
You have a passion for the Hyperloop as a fast, safe, clean and new mode of transportation
You are committed and highly motivated
You are results-oriented, quality-driven, dynamic and hands-on
You are proactive, self-motivated, self-directed and you can work well with remote or limited supervision
You are accurate, versatile, creative, curious, rigorous, adaptable and flexible
You are an independent thinker but also a team worker and a continuous learner",4.5,"Hyperloop Transportation Technologies
4.5","Los Angeles, CA","Los Angeles, CA",501 to 1000 employees,2013,Company - Private,Transportation Management,Transportation & Logistics,Unknown / Non-Applicable,-1
"Senior Software Engineer, Applications","$55K-$114K
(Glassdoor est.)","About the Role
As we continue to change the game for GovTech, you will be jumping headfirst into a team of passionate and talented individuals. As a Senior Engineer, you will be asked to challenge your skills as a technologist leader as you build cutting-edge features while mentoring other team members. Beyond enhancing and pushing forward the capabilities of our client-facing Ember application, you will be critical in guiding and developing software that powers our applications.

About Engineering at FiscalNote
Our team has a wealth of diverse life and career experiences that allow us to think outside of the box and ahead of the curve. You'll get the opportunity to work at an institution pushing the boundaries of open data transparency while collaborating with some of the industry’s brightest engineers and data scientists to devise, nurture, and implement cutting-edge solutions to continuously evolving engineering challenges.

Success In This Role Includes:
- Work in a diverse programming environment: Ember, Node, Python, Ruby on Rails- Build web and enterprise integration products that help push the FiscalNote platform forward
- Work across teams to ensure cohesion and collaboration across engineering functions
- Create experiences for the end user by applying your knowledge of the frontend, backend, and integration technologies to deliver a world-class user experience
- Mentor other engineers on software development practices

What Sets You Apart:
- Demonstrated mastery in a frontend framework: Ember.js, React.js, Angular.js or other MVC/MVx framework
- Demonstrated mastery in a backend programming language runtime: Node.js, Python
- Experience in the following: SQL, Elasticsearch, Redis
- 5+ years of experience in the software development industry (not necessarily with the technologies)
- Architecture decision-making experience (preferred)
- Production decision-making experience (preferred)
- Legacy Enterprise Application integration and/or migration experience (preferred)
- Demonstrated experience building successful working relationships with Product + UI/UX teams
- Passion for Customer Experience
- Experience breaking down product specs into engineering components
- Led projects from inception to completion
- A Bachelor's Degree in Computer Science, Computer Engineering, or equivalent experience

Are You
Ambitious. Detail-oriented. Thoughtful. Although proud of how far you’ve come in honing your craft, you look forward to constantly growing in your technical abilities. Even more excited to share your skills and experiences, you thrive in collaborative environments in which the free flow of ideas serves as the catalyst for bold results. Feeding off of a highly competent engineering and product development culture, you yearn to contribute to the foundational growth of a company with unlimited growth and market capture potential.
About Us
FiscalNote is a technology-powered global software data and media company that uses powerful machine learning to provide clients with the right policy information and insights, and at the right time so that they can better navigate market risk and uncertainty and maximize new opportunities.

As the premier hub of domestic and global information for more than 5,000 clients worldwide, FiscalNote’s tools, analysis, news, and award-winning journalism delivers context, clarity, and a competitive edge in a rapidly changing world.

If your background and experience align with the competencies above, we encourage you to apply so that we can review your experience and learn more about how you can add to FiscalNote’s growth and success.

Company Benefits
FiscalNote offers competitive salaries, equity packages, and retirement accounts to ensure we’re all FN owners. We work hard, so our open vacation policy helps us ensure you’re getting the R&R you need. We offer comprehensive health, vision, and dental insurance options supplemented by a flexible spending account (FSA). We have a slew of other benefits which you can check out at careers.FiscalNote.com.

FiscalNote values diversity. We are committed to equal opportunities and creating an inclusive environment for all our employees. We welcome applicants regardless of ethnic origin, national origin, gender, race, religious beliefs, disability, sexual orientation or age. FiscalNote is an EEOC employer.

FiscalNote uses E-Verify to confirm the employment eligibility of all new employees. To learn more about E-Verify, including your rights and responsibilities, please visit www.DHS.gov/E-Verify.

Apply",3.9,"FiscalNote
3.9","Baton Rouge, LA","Washington, DC",201 to 500 employees,2013,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Modeling and Simulation / MBSE Tools Data Scientist,-1,"Overview

The GBS Group, an engineering and technical consulting firm, is seeking a Modeling and Simulation / MBSE Tools Data Scientist at our Virginia Beach, VA location. The GBS Group designs and delivers high technology services and solutions to most advanced naval and maritime ships, as well as to special purpose platforms and assets. Our Headquarters is located within 10 miles of the Virginia Beach resort area and downtown Norfolks Waterside District and includes a 24x7 Operational Support Center monitoring all client installations in North America as well as a world class lab with configurations of all client hardware and software systems.

Responsibilities include but are not limited to:
Provide software life cycle support following System Engineering Process (SEP) with applicable Capability Maturity Model Integrated (CMMI) and Institute of Electrical and Electronics Engineers (IEEE) standards and specifications.
Develop and/or modify control system cybersecurity software and hardware solutions.
Develop and/or modify computer code in the following languages: C/C++, C#, Java, Visual Basic, MATLAB, and Labview as well as other related high-level programming languages along with a range of Integrated Development Environments (IDEs) including but not limited to Visual Studio and Eclipse.
Establish methodologies for capturing and managing data associated with complex integrated HM&E, Combat, Navigation, and C4I systems.
Develop and/or modify logical data models enabling and enforcing concordance and mapping between system, subsystem, interface, mission thread, process, and other data sets.
Develop and/or modify logical data models that store data elements to support data call responses, information flow analyses, operations analysis, performance evaluations, mission thread analysis, cybersecurity assessments, and engineering change evaluations.
Develop and/or modify data models and/or simulations to capture the attributes of adversarial and non-adversarial threats targeting critical systems.
Work with stakeholders as required to conduct systems and data research in support of development and sustainment of data models and/or simulations.
Research the application of M&S techniques as applicable to critical systems and/or cybersecurity, as well as specific data models, to acquisition, engineering, and logistics support applications and develop associated data management and reporting capabilities.
Support development of requirements for and support the application of a collaborative data modeling environment for both stand-alone users and remote access users at multiple classifications.
Utilize Knowledge Representation & Reasoning (KR&R) tools and techniques to support development, modification, and application of data models linking critical systems concepts to critical cybersecurity data elements and mission concepts
Modify and use databases
Qualifications

Candidates for this position must possess the following professional experience and qualifications:
Bachelors Degree in Electrical, Mechanical or Computer Engineering from an ABET accredited college/university
Seven (7) years of professional experience within industry as a systems engineer, electrical, computer and /or electronics engineer.
Two (2) years of experience in MATLAB, SIMULINK, R, Python or other analytical programming language.
One (1) year of experience developing or applying Machine Learning and/or Knowledge Representation & Reasoning (KR&R) tools, techniques, and/or algorithms
One (1) or more years of experience developing or applying Semantic Web technologies including but not limited to: Web Ontology Language (WOL) and Resource Description Framework (RDF)
Two (2) years of professional experience developing software using one or more high-level languages such as C/C++ or Java.
Ability to obtain and maintain a secret clearance
EEO Statement

The GBS Group is proud to be an equal opportunity employer. We pledge equal access to employment, facilities, and programs, regardless of race, color, religion, sex/gender, sexual orientation, national origin, age, disability, marital or familial status, pregnancy, veteran status, genetic information, or any other characteristic protected by law.",3.3,"The GBS Group
3.3","Virginia Beach, VA","Virginia Beach, VA",51 to 200 employees,2005,Company - Private,Architectural & Engineering Services,Business Services,Unknown / Non-Applicable,-1
Machine Learning Software Engineer,-1,"RESPONSIBILITIES Kforce has a client in building a team of Machine Learning Software Engineers in Wilmington, Delaware (DE) and Tampa, Florida (FL) and Plano, Texas (TX). This team is focused on developing and delivering cutting edged mobile applications, digital experiences and next generation banking technology solutions to better serve our clients and customers. Summary Our Machine Learning Software Engineers will have the business acumen to understand and analyze problems, define and test hypotheses and develop Machine Learning frameworks and best practices. Additionally, they will be responsible to intricate knowledge of our business domains and data sets which include Systems of Record (SOR), historical and external data. Finally, this individual will take ownership in designing models to deliver performance and accuracy when operationalized as well as inference engines at scale with the business processes and applications. Duties Analyze and conduct learningsimulations with large datasets combining multiple platforms (ex. Hadoop, Spark, AWS), and machine learning frameworks (ex. R, sci-kit, PySpark, Pandas, TensorFlow) Leadmentor a team of data scientists and machine learning engineers, who help the business identify new insights from largerich data sets, and implement data driven strategies that reduces fraud, post-fraud loss and other operational efficiencies REQUIREMENTS 3+ years of hands-on experience Python (or other scripting), Java, HadoopSparkHive andor AWS, and 10+ years of hand-on experience with SQL Expertise across application, data and infrastructure architecture disciplines Advanced knowledge of architecture, design and business processes Experience with Machine Learning, Deep Learning, Data Mining, andor Statistical Analysis tools Operationalize machine learning models using offline and online models, model performance monitoring, frequentautomated model updates, backnow testing, managed test harness and managed feature libraries Ability to automate data exploration and model exploration activities and embed end-to-end model development and deployment into automated CI-CDDevOps pipelines Hands-on data analytics using machine learning, statistical modelling andor data mining to uncover insights from large data sets and develop data and predictive models supporting multiple business domains spanning Fraud, Consumer Banking Operations, Digital Banking and Customer Experience scenarios. Interpret and explain methods using statistical analysis Kforce is an Equal OpportunityAffirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.",-1,Kforce Technology Staffing,"Wilmington, DE",-1,-1,-1,-1,-1,-1,-1,-1
Machine Learning Engineer - Secret Clearance Required,-1,"A data analytics company with offices in Northern VA has an URGENT need for a Machine Learning Engineer. This person will be responsible for leveraging cloud services to feed multiple data sources into machine learning engines, coordinating the creation, validation, and use of models and the integrattion of predictive results into application workflows. The developer will work within a broader system leveraging multiple distributed processing technologies like Spark, Knime, Elastic Search, and Amazon Web Services. The developer will need to collaborate with data scientists, data integrators, application
developers, and clients in driving innovation, communicating plans/possibilities, and overseeing delivery tasks on small
agile teams.

Responsibilities:
• Ensuring successful deployment of client’s analytics solutions and leveraging pre-existing analytics industry
knowledge and technical integration and development skills to ensure project success
• Disseminating broad knowledge of analytics tools, applications and techniques
• Develop applications which analyze data using descriptive, exploratory, predictive, explanatory, and prescriptive
methods via automation using the latest machine learning, business intelligence, search, and intelligent data
technologies.
• Create and modify applications using Java, distributed processing, and web technologies as part of a broader
development team.
• Research, design, develop, analyze, and modify Cloud-based enterprise-wide systems and applications software.
• Support Agile software development lifecycle management and deliver software meeting customer requirements
and compliance standards.
• Evaluate the interface between hardware and software, operational requirements, and characteristics of the overall
system, identify optimizations, and convincingly communicate recommendations to customers and team.
• Provide expertise in the use of Cloud architectures and solutions to support software development in a DevOps
environment.
• Leverage complete comprehension and wide application of technical principles, theories, and concepts in the field
and apply general knowledge of other related disciplines.
• Provide technical solutions to a wide range of difficult problems.
• Determine and provide analysis for approach to solutions.

Requirements

• US Citizenship Required; Top Secret Clearance preferred
• BS degree in CS, Statistics, Mathematics, Physics, Engineering, or similar applied quantitative discipline
• Experience in trouble-shooting very complex distributed environments, including following stack traces back to
code and come up with a root cause
• Experience with Extract, Transform, and Load (ETL) processes, preferable including document parsing techniques
and managing large data sets
• Able to develop using at least Java, SQL, XML, and JSON although JavaScript, Python, Scala, and R are desirable
• Experience working with Web Services environments, languages, and formats, especially RESTful APIs
• Experience creating multi-step, multi-variate, time series forecasting models
• Familiarity with distributed data processing architectures and frameworks, such as Hadoop, Hive, Spark, SOLR,
Elastic Search, Kafka, Impala, and Cassandra
• Familiarity with Amazon Web Services (AWS), such as EMR, Glue, Athena, Lambda, and S3
• Experience with Qlik, Oracle BI, Knime, H20.ai, Celect, Informatica, or other Business Intelligence (BI), and machine
learning technologies a plus
• Applied statistics or data science experience a plus",-1,Fawkes IDM,"Springfield, VA",-1,-1,-1,-1,-1,-1,-1,-1
Senior Machine Learning Engineer - Audio Understanding,"$145K-$228K
(Glassdoor est.)","We are looking for a Senior Software Engineer to help us build the next generation of ML-based audio understanding technologies. Our team expands the state of the art in AI-based machine listening technology, which enables intelligent, efficient and intuitive ways to search, re-use, explore or process audio and music. We build products for end users, for artists, for producers, for labels and publishers, for managers, for advertisers - projects that cut across all of Spotify. We build features to improve products and lay the foundations for disruptive new product opportunities.
What you’ll do
Take on complex data-related problems involving some of the most diverse datasets available, leveraging your experience to drive best practices in ML and data engineering.
Work in an agile team spanning software engineers, research scientists, and product managers to productionize ML research at scale for hundreds of millions of active users.
Build best-in-class infrastructure and tooling to accelerate our research-to-product efforts and to enable efficient cloud-based deployment and testing of audio processing models.
Debug and optimize ML models to enable complex inferencing (and training) tasks at high scale.
Determine the feasibility of projects through quick prototyping with respect to performance, quality, time and cost.
Work together with our stakeholders to help define and drive new features forward.
Who you are
You have professional experience working in a product-driven environment.
You have experience working with cloud platforms like GCP / AWS / Azure.
You have experience implementing and maintaining high-scale, production ML systems.
You have experience leveraging high-scale, distributed data processing frameworks (e.g. Apache Beam / Google Dataflow, Hadoop, Scalding, Spark, Storm).
You know how to write distributed, high-volume services in Java or Scala.
You have an interest in learning more about audio processing and music information retrieval and you're excited about building amazing products that use such technologies.
BENEFICIAL: You have previous industry experience with debugging, profiling, code-optimizing or deploying tensorflow models at scale.
BENEFICIAL: You have experience with applying deep learning techniques for content based processing (audio, image, video data).
You are welcome at Spotify for who you are, no matter where you come from, what you look like, or what’s playing in your headphones. Our platform is for everyone, and so is our workplace. The more voices we have represented and amplified in our business, the more we will all thrive, contribute, and be brilliant. So bring us your personal experience, your perspectives, and your background. It's in our differences that we will find the power to keep revolutionizing the way the world listens.
Spotify transformed music listening forever when we launched in 2008. Our mission is to unlock the potential of human creativity by giving a million creative artists the opportunity to live off their art and billions of fans the opportunity to enjoy and be inspired by these creators. Everything we do is driven by our love for music and podcasting. Today, we are the world’s most popular audio streaming subscription service with a community of more than 286 million users.",3.8,"Spotify
3.8","New York, NY","Stockholm, Sweden",1001 to 5000 employees,2006,Company - Public,Internet,Information Technology,Unknown / Non-Applicable,-1
Data Engineer 3,-1,"Data Engineer

About the Position

We are looking for a highly skilled data engineer who has a passion for all things data. You will be responsible for data architecture, building data pipelines using ETL tools, provide data to the data scientist and participate in the re-training of machine learning models. You will be developing both on-prem and cloud solutions. You will be an integral member of our product teams, working very closely with architects and software engineers on different layers of the infrastructure and design. Thus, a commitment to collaborative problem solving, sophisticated design, and product quality is essential.

Requirements:

• Bachelor’s degree in computer science, Information Systems or related discipline; Or 6 years of prior equivalent work-related experience in lieu of a degree.
• Must have leadership skills to lead and deliver projects, be proactive, take ownership, interface with business, represent the team and spread the knowledge.

• Support or collaborate with application developers, database architects, data analysts and data scientists to ensure optimal data delivery architecture throughout ongoing projects/operations.
• Develop highly scalable data management interfaces, as well as software components by employing programming languages and tools.
• Design, document, build, test and deploy data pipelines that assemble large complex datasets from various sources and integrate them into a unified view.
• Experienced in ETL Tools (SSIS, Kafka, Sqoop, Informatica, Nifi)
• Expert SQL knowledge (All types of Joins, CTE’s, Indexes, Stored Procedures, SQL performance)
• Should have knowledge feedback loop into Model Re-Training (Data and model pipelines)
• Should be able to work with the MLOps to build data pipelines to model executions.
• Experience in Python & PySpark using spark ML, spark DL, Hive.
• Experience in data ingestion from various data sources like SQL Server, Oracle, Hive etc.
• Good knowledge in Git, GitHub, Bitbucket.
• Good team player, willing to Experiment, explore and learn fast.

Preferred Experience:

• Knowledge in building machine learning models
• Cloud expertise (AWS, AZURE)
• Knowledge in docker and its orchestrations
• Good understanding of Cyber Security and Architecture standards for enterprise applications
• Experienced in building real-time data feed to provide analysis in an automated fashion.
• Knowledge in Continuous integration suites like Jenkins.
• Knowledge in Web servers (Flask, Gunicorn, NGINX etc)",4.5,"Optomi
4.5","Charlotte, NC","Atlanta, GA",201 to 500 employees,2012,Company - Private,Staffing & Outsourcing,Business Services,$50 to $100 million (USD),-1
Machine Learning Engineer - SEAL,-1,"ID: 495553
Type: Researchers
Location: Smyrna, GA
Categories: Algorithm Development, Artificial Intelligence, Electronic Warfare, Embedded Systems, ISR & Tactical Systems, Machine Learning, System Architecture, Testing, High Performance Computing, Modeling/Simulation, Radar, Sensors Integration, Sensors/Optics, Signal Processing, Software Development/Design
Job Description


The Sensors and Electromagnetic Applications Laboratory (SEAL) of the Georgia Tech Research Institute (GTRI) is seeking technical personnel to be part of an established software team that has multiple opportunities for software engineers within the Software Engineering and Architecture Division (SEAD) at Smyrna, GA. The SEAD group mission is to provide world-class software to be used in sensors, signal processing, electronic warfare, tracking, and intelligence surveillance reconnaissance (ISR) systems deployed on land, air and sea. Our software team employs a modern software engineering process to design, code, integrate and test capabilities on a continuous basis resulting in a mature and quality solution for our customers. We strive for technical excellence by drawing upon a diverse workforce whose knowledge base covers the complete spectrum of modern computing languages and platforms.

Job Duties


The successful candidates will be involved in the artificial intelligence (AI) software design, development, integration and testing of the systems. Our real-time machine learning software applications are developed using C++ and Python in a Linux environment. Our group utilizes productive modern (Agile) and industry-proven software development processes and environments. The candidate will get the opportunity to creatively solve problems, design features, and independently and work in a team environment to implement projects.

The candidate will have the opportunity to leverage machine learning techniques to build processes to gather insights from a high volume of data from multiple sources. You will develop systems to efficiently process the data in our platform. The candidate will ultimately be responsible for developing powerful software systems that reinforce our place as a technical research leader in machine learning and deploying software.

Travel Requirements


10% - 25% travel

Education & Length of Experience


Research Engineer/Scientist I
A Bachelor's degree in Computer Engineering, Computer Science, Electrical Engineering, Mathematics, Physics, or related field of study.
Research Engineer/Scientist II
A Master’s degree in Computer Engineering, Computer Science, Electrical Engineering, Mathematics, Physics, or related field of study and three (3) years of relevant full-time experience after completion of that degree,
A Master’s degree in Computer Engineering, Computer Science, Electrical Engineering, Mathematics, Physics, or related field of study and five (5) years of relevant full-time experience after completion of a Bachelor’s degree, or
A Doctoral degree in Computer Engineering, Computer Science, Electrical Engineering, Mathematics, Physics, or related field of study.
Required Minimum Qualifications
Candidates currently enrolled in an accredited Bachelor’s degree program relevant to this position will be considered. Candidate must have a graduation date of no later than May, 2020
Artificial Intelligence algorithms utilized for applications
Knowledge of industry AI tools (e.g., TensorFlow, PyTorch, etc.)
Experience with C and C++
Experience with Linux or Windows
Experience in software engineering and development
Knowledgeable in version control software such as GIT
Knowledgeable in JIRA, Bitbucket and Confluence
Good verbal and written communication skills
Self-starter and ability to work in a team environment
Preferred Qualifications
Knowledge of computer architectures including multi-core environments
Familiarity with software applications requiring multi-threaded programming implementation
Experience in software engineering and development
Complex programs that involved hardware, software, communications and networking
Existing secret clearance, or the ability to obtain an interim clearance within 30 days and full clearance thereafter
U.S. Citizenship Requirements


Due to our research contracts with the US federal government, candidates for this position are required to be US Citizens.

Clearance Type Required


Ability to obtain Secret Clearance upon hire

Diversity & Inclusion


Diversity & Inclusion (D&I) at Georgia Tech Research Institute aims to enhance the Institute’s mission of solving the world’s most complex technical problems by creating a workforce with a shared appreciation for diversity, raising awareness around inclusiveness, and fostering a sense of belonging and appreciation for all members of our community.

Equal Employment Opportunity


Georgia Tech Research Institute is an Equal Opportunity Employer of individuals with disabilities and protected veterans and actively seeks diversity among its employees. Equal Employment Opportunity is the Law.

Posted: 05/01/2020
Closes: 08/01/2020",3.6,"Georgia Tech Research Institute
3.6","Smyrna, GA","Atlanta, GA",1001 to 5000 employees,1943,Subsidiary or Business Segment,Research & Development,Business Services,$100 to $500 million (USD),"MIT Lincoln Laboratory, Johns Hopkins University Applied Physics Laboratory"
Data Scientist/Machine Learning Engineer - Top Secret Clearance,-1,"Job Description
An analytics and data solutions company that delivers customized solutions to clients, is seeking a qualified Data Scientist/Machine Learning Engineer with TS clearance to join their growing team.

Responsibiliies:
Lead developer of distributed machine learning for applications which seek to detectemerging threats, forecast behaviors, and optimize related courses of action. T
Leverage cloud services to feed multiple data sources into machine learning engines; coordinate the creation, validation, and use of models; integrate predictive results into application workflows; and support the interactions of userexperiences to meet customer requirements.
The developer will work within a broadersystem leveraging multiple distributed processing technologies like Spark, Knime, ElasticSearch, and Amazon Web Services. The developer will need to collaborate with data scientists, data integrators, application developers, and clients in driving innovation,communicating plans/possibilities, and overseeing delivery tasks on small agile teams.
Disseminating broad knowledge of analytics tools, applications and techniques. Develop applications which analyze data using descriptive, exploratory, predictive,explanatory, and prescriptive methods via automation using the latest machine learning, business intelligence, search, and intelligent data technologies.
Create and modify applications using Java, distributed processing, and web technologies as part of a broader development team.
Research, design, develop, analyze, and modify Cloud-based enterprise-wide systems and applications software.
Requirements
BS degree in CS, Statistics, Mathematics, Physics, Engineering, or similar appliedquantitative discipline
Experience in trouble-shooting very complex distributed environments, including following stack traces back to code and come up with a root cause
Experience with Extract, Transform, and Load (ETL) processes, preferable including
document parsing techniques and managing large data sets
Able to develop using at least Java, SQL, XML, and JSON although JavaScript,
Python, Scala, and R are desirable
Experience working with Web Services environments, languages, and formats,
especially RESTful APIs
Experience creating multi-step, multi-variate, time series forecasting models
Familiarity with distributed data processing architectures and frameworks, such as
Hadoop, Hive, Spark, SOLR, Elastic Search, Kafka, Impala, and Cassandra
Familiarity with Amazon Web Services (AWS), such as EMR, Glue, Athena, Lambda,
and S3
Experience with Qlik, Oracle BI, Knime, H20.ai, Celect, Informatica, or other
Business Intelligence (BI), and machine learning technologies a plus
Applied statistics or data science experience a plus",-1,Fawkes IDM,"Washington, DC",-1,-1,-1,-1,-1,-1,-1,-1
Front-End Development Engineer - Computer Vision,"$66K-$161K
(Glassdoor est.)","Are you interested in building state of the art and scalable data platform that will power AWS Machine Learning services making a lasting impact on society?

The AWS Computer Vision Data Platform team is expanding to New York City! We are looking for talented software development engineers who has the passion to tackles ambiguous and challenging problems by bringing cutting edge deep learning technologies to customer facing computer vision products like Amazon Rekognition (https://aws.amazon.com/rekognition/) and Amazon Textract (https://aws.amazon.com/textract/).

The mission of the AWS Computer Vision Data Platform team is to build an end to end data platform (data collection, selection/active learning, annotation and training) and feature specific annotation tooling to deliver high quality computer vision training datasets at scale. The team owns the systems and pipelines that enable data acquisition, ingestion, classification, visualization, annotation, training and evaluation and active learning.

In Front-end Software Engineer role, you will:
· Operate at all levels, diving deep into the details while providing strategic inputs for the product
· Design and build scalable UIs
· Partner with research team to innovate and solve Computer Vision problems using ML
· Lead small to midsize complex project from requirements through launch.
· Work closely with data scientists and UX designers to develop the best user experience designs and solutions
· Establish the best processes and drive improvements in design, development and operations.
· Mentor and guide junior engineers on design, coding, troubleshooting and operational excellence





Basic Qualifications

· Experience with object-oriented design
· 2+ years of professional non-internship experience with front end, web or mobile software development using JavaScript, HTML and CSS
· Bachelors degree in Computer Science or equivalent work experience
· 2+ years experience with web technologies, including HTML5, CSS 3.0 & JavaScript Libraries/Frameworks
· Proficiency in, at least, one modern programming language such as Java/Scala/Go/C#/Python on Unix/Linux.
· Experience in translating design mockups and prototypes into working applications
· Excellent communication skills, both written and verbal

Preferred Qualifications

· Masters degree in Computer Science or related field
· Strong problem solving and analytical abilities
· Experience with highly distributed systems with focus on the front-end stack development
· Experience with AWS technologies and frameworks.
· Experience developing software using modern frameworks such as AngularJS, React, Spring or Node
· Passion for usability and creating efficient, scalable user interfaces
· Excellent debugging and troubleshooting skills, with an enthusiastic attitude to support and resolve customer problems
· Demonstrated leadership abilities in driving operational excellence and software engineering best practices
Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.",3.9,"Amazon
3.9","New York, NY","Seattle, WA",10000+ employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),"Google, Microsoft, Walmart"
Sr. Software Engineer in Test (SET),-1,"LeapYear's secure machine learning platform is deployed by some of the largest enterprises in the world across finance, healthcare, and technology.

Our technology ensures differential privacy, a widely recognized standard of data privacy that enables all data - including sensitive information - to be utilized for analytics, while providing mathematically proven privacy protection.

The LeapYear system is composed of a core set of components that allow private machine learning on data sets that can scale to petabytes. The core includes private algorithms for relational operations, statistical methods and machine learning. A data scientist accesses private data using a Python API. The system includes services for authentication, access control, logging, auditing and support for integration of data from a variety of data sources including SQL/NoSQL Databases, HDFS and S3. Queries are processed using Spark to support to enable fast, distributed processing of massive datasets. Administration is provided via a web-based GUI or an API.

We are looking for a Senior Software Engineer in Test (SET), who will lead the testing of LeapYear products. The role will require testing functionality, scalability, performance and availability. All tests will be automated.

For details on the specific responsibilities and requirements of this role, please see below.
Responsibilities
Work closely with the development team to develop test plans.
Define and implement automation strategies for testing the functionality of LeapYear’s products.
Define and implement an automated framework for scale, performance and availability testing.
Be accountable for the full lifecycle of your code from design to deployment.
Mentor other members of the SET team.
Develop automated systems for tracking quality metrics.
Requirements
Experience testing complex distributed systems that require scalability, reliability and flexibility.
5+ years of professional experience.
At least 3 years of experience in automation and testing.
Proficiency in a programming language such as Python, Java, C, Golang, Scala etc.
BS/MS in Computer Science/Engineering or related discipline.
Excellent oral and written communication skills.
Experience with Continuous Integration/Continuous Deployment tools(e.g. CircleCI, Travis)
Experience with cloud platforms (AWS, Azure, or GCP).
Experience with SQL/NoSQL databases.
Ability to get up to speed quickly on new technologies such as Machine Learning, Spark, differential privacy.
Preferred
Experience with big data technologies like Spark and/or Hadoop.
Experience developing for on-premise enterprise deployments.
A Few of the Perks
Culture of teaching and learning
Competitive compensation package of salary and equity
Catered lunch every day
Company outings
Build your ideal work station
Generous health insurance plan
Relocation support and visa sponsorship",4.2,"LeapYear
4.2","San Francisco, CA","San Francisco, CA",1 to 50 employees,2015,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Software Engineer - Tools & Cloud Infrastructure,-1,"Position Overview

Beyond Limits is seeking a software engineer to join our Tools & Cloud Infrastructure team to help work on dev ops and deployment. This team is responsible for building internal tools and systems focused on streamlining the release process. This team has a focus on efficiency, automation, and reliability. In this role, you will have the opportunity to work with modern cloud technologies and help to deploy next-generation AI software.

Job Duties/Responsibilities
Administer, monitor, and deploy systems and services on AWS cloud services
Automate processes using open source tools and custom Python code
Collaborate with engineers, data scientists, and other cross-functional teams
Develop highly repeatable processes and have a keen interest in automation
Minimum Qualifications
B.S. or M.S. in Computer Science or a related degree.
Minimum of 3+ years’ experience in AWS and related cloud technologies.
Experience working with Python, or a similar scripting language
Proficiency with automation in the areas of deployment, processes, operations
Must be well versed in generic administration tasks of managing Docker images, container networking and standard infrastructure maintenance tasks on Docker and Kubernetes.
You have a strong knowledge of the infrastructure and automation of CI/CD pipelines using Jenkins.
Experience with at least one configuration or provisioning tools, such as Terraform, Ansible, Puppet, or Chef
Desired Experience
Have the ability to set up and maintain monitoring, alerting and logging solution
Core understanding of computer science and software engineering fundamentals
Previous experience creating a reproducible infrastructure for production, staging and development environments with IaaS
About Beyond Limits

Beyond Limits is a pioneering Artificial Intelligence engineering company creating advanced software solutions that go beyond conventional AI. Founded in 2014 with a legacy in space exploration, Beyond Limits is transforming proven technologies from Caltech and NASA’s Jet Propulsion Laboratory into advanced AI solutions, hardened to industrial strength, and put to work for forward-looking companies on earth. We leverage this unparalleled innovation portfolio, along with proprietary cognitive technologies, to help companies solve tough, complex, mission-critical problems and transform their business. We apply a unique hybrid approach to AI, combining numeric AI techniques like machine learning with higher order symbolic AI and expert human knowledge to deliver intuitive cognitive reasoning and information. Our cognitive computing technology mimics human thought processes and provides explainable reasoning to aid human-like decision-making.

Beyond Limits provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability or genetics. In addition to federal law requirements, Beyond Limits complies with applicable state and local laws governing nondiscrimination in employment in every location in which the company has facilities. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.

Beyond Limits expressly prohibits any form of workplace harassment based on race, color, religion, gender, sexual orientation, gender identity or expression, national origin, age, genetic information, disability, or veteran status. Improper interference with the ability of Beyond Limit’s employees to perform their job duties may result in discipline up to and including discharge.",4.2,"Beyond Limits
4.2","Glendale, CA","Glendale, CA",51 to 200 employees,2014,Company - Private,Research & Development,Business Services,Unknown / Non-Applicable,-1
Machine Leaner Engineer,-1,"5+ years experience developing and deploying machine learning systems into production Strong experience working with a variety of relational SQL and NoSQL databases Strong experience working with big data tools Hadoop, Spark, Kafka, etc. Experience with at least one cloud provider solution (AWS, GCP, Azure) Strong experience with object-orientedobject function scripting languages Python, Java, C++, Scala, etc. Ability to work in a Linux environment Industry experience building and productionizing innovative end-to-end Machine Learning systems Ability to quickly prototype ideas and solve complex problems by adapting creative approaches Experience working with distributed systems, service oriented architectures and designing APIs Strong knowledge of data pipeline and workflow management tools Expertise in standard software engineering methodology, e.g. unit testing, test automation, continuous integration, code reviews, design documentation Relevant working experience with Docker and Kubernetes is a big plus Architect, build, maintain, and improve new and existing suite of algorithms and their underlying systems. Implement end-to-end solutions for batch and real-time algorithms along with requisite tooling around monitoring, logging, automated testing, performance testing and AB testing Utilize your entrepreneurial spirit to identify new opportunities to optimize business processes and improve consumer experiences, and prototype solutions to demonstrate value with a crawl, walk, run mindset. Work closely with data scientists and analysts to create and deploy new product features on the ecommerce website, in-store portals and the mobile app Establish scalable, efficient, automated processes for data analyses, model development, validation and implementation Write efficient and well-organized software to ship products in an iterative, continual-release environment Contribute to and promote good software engineering practices across the team Mentor and educate team members to adopt best practices in writing and maintaining production machine learning code Communicate clearly and effectively to technical and non-technical audiences equally well Actively contribute to and re-use community best practices",3.2,"s.com
3.2","San Francisco, CA","Pembroke Pines, FL",201 to 500 employees,1993,Company - Public,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
DATA ENGINEER,-1,"Job Overview

We are looking for a savvy Data Engineer to join our growing team of analytics experts. The hire will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. The Data Engineer will support our software developers, database architects, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems and products. The right candidate will be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives.

Responsibilities for Data Engineer:

- Create and maintain optimal data pipeline architecture,

- Assemble large, complex data sets that meet functional / non-functional business requirements.

- Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.

- Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies.

- Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.

- Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.

- Keep our data separated and secure across national boundaries through multiple data centers and AWS regions.

- Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.

- Work with data and analytics experts to strive for greater functionality in our data systems.

Qualifications for Data Engineer:

- Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.

- Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.

- Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.

- Strong analytic skills related to working with unstructured datasets.

- Build processes supporting data transformation, data structures, metadata, dependency and workload management.

- A successful history of manipulating, processing and extracting value from large disconnected datasets.

- Working knowledge of message queuing, stream processing and highly scalable ‘big data’ data stores.

- Strong project management and organizational skills.

- Experience supporting and working with cross-functional teams in a dynamic environment.

Knowledge, Skills, Abilities, and other Characteristics:

Qualifications:
5+ years of experience in a Data Engineer role, who has attained a Master’s degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field.
Industry-recognized certifications in data engineering, data architecture, informatics, machine learning, SQL
Experience with health care data, claim data, EMR systems (Meditech preferred), X.12 data formats, etc.
Experience with big data tools: Hadoop, Spark, Kafka, etc. (Preferred)
Experience with relational SQL and NoSQL databases, including Postgres and Cassandra.
Experience with data pipeline and workflow management tools: Azkaban, Luigi, Airflow, etc.
Experience with Microsoft and AWS cloud services: Azure, EC2, EMR, RDS, Redshift
Experience with stream-processing systems: Storm, Spark-Streaming, etc.
Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.
Experience with statistical programming languages: R, Stata, SAS, etc.
Experience with architectural concepts and schemas: TOGAF, MITA, Star schema, etc.
Skilled in problem-solving with strong attention to detail.
Excellent customer service skills and the ability to react diplomatically and patiently to internal and external customers.
Excellent follow-up skills paired with the ability to multi-task and determine root causes.
Strong written and verbal communication skills coupled with the ability to read, analyze and interpret technical procedures.
Strong response time to phone calls, emails and customer requests.
Adhere to department policies and standards.
Ability to work independently under minimal supervision in stressful situations and meet deadlines.
Ability to prioritize, plan, and organize tasks based upon user requirements.
Ability to multi-manage multiple projects utilizing best practices based on departmental priorities.
Ability to multi-manage multiple projects utilizing best practices based on departmental priorities.
MINIMUM WORK EXPERIENCE:

Bachelors Degree, 5 years of relevant experience including leading projects or 8 years of relevant experience including leading projects and developing teams .

REQUIRED LICENSES, CERTIFICATES, REGISTRATIONS:

MCSE or equivalent is strongly desired but not required",3.0,"Sinai Health System
3.0","Chicago, IL","Chicago, IL",1001 to 5000 employees,1918,Nonprofit Organization,Health Care Services & Hospitals,Health Care,$100 to $500 million (USD),"Resurrection Health Care, UChicago Medicine"
SR Machine Learning Engineer,-1,"Glow Networks is seeking a Senior Machine Learning Engineer to lead complex ML and big data projects as part of our customers new Data Center and Networking AI Team in San Mateo, CA. You will have the opportunity to solve some of the hardest and most interesting technological challenges facing the industry today.

The Team

You will be joining a new team of world-class high-performing and low ego engineers and scientists that have an entrepreneurial and hacker spirit. The team will operate in a very self-driven, agile and fast-paced environment. The team operates by self-organizing, around shared values, vision and objectives.

Qualifications
5-7 years of experience as a software engineer building and shipping production quality code in C/C++, Java, Python, or similar language
Minimum of 2 years of experience working on big data problems (in terabytes) using technologies like Cassandra, Hadoop, and Spark
Experience working on data modeling, data pipelines, and building warehouses projects
Experience deploying machine learning models to production is a MUST
Experience designing and developing infrastructure for the full cycle of machine learning
Experience building container-based applications running in a microservice architecture on Kubernetes or serverless
Comfortable researching and reading research papers and implementing models
Comfortable experimenting with and incorporating cutting-edge techniques into our existing system, such as online learning, transfer learning, and few-shot learning
Deep understanding of model training, what affects performance (hyperparameters, data distribution, etc)
Ability to write an end-to-end pipeline code that is modular, scalable, and easy for future team members to build upon
Education
Masters Degree in computer science or engineering, desired
Bonus
Experience working on time interval problems
Experience with data analysis and visualization
Extract meaningful insights from the data and present to leadership
What would really impress us?

Any side projects or hobbies that have to do with AIML.",3.1,"Glow Networks
3.1","San Mateo, CA","Richardson, TX",51 to 200 employees,2003,Subsidiary or Business Segment,IT Services,Information Technology,$10 to $25 million (USD),-1
Data Scientist / Data Engineer,-1,"Company Background

We are an early stage start-up developing technology and data intelligence

underlying radically more efficient logistics businesses. Serving the $730bn US motor

freight market, Haulistix has been developed with the ambition to create a hyper growth

business. The company leverages the latest operations research, data and machine

intelligence at scale to have a real-life impact on the operational and financial

performance of hundreds of thousands of small and medium-sized trucking companies.

To achieve this, we pay equal attention to developing cutting-edge technology,

understanding real-life user behavior and creating innovative business models

Using machine intelligence, we arrange single truck loads from across the freight

market into highly profitable freight trips and sell them to small and medium-sized

trucking companies.

By doing this, we digitize the cognitively most challenging aspects of a motor

carriers' dispatch function and attack their tremendous inefficiency at one of its

root causes.

Unlike with simple load bookings directly through brokers or expensive software

solutions, we offer carriers and brokers access to cutting-edge technology whilst

materially improving their profitability one business transaction at a time.

Role

We are currently hiring Data Scientists and Data Engineers to become part of the

first ten employees of our company and core members of our early-stage team. Working

directly with the founders, the data scientists/engineers will be interfacing cross-

functionally with our technology development team, relevant academic advisers, our in-

house operations team as well as external contractors and select clients. Key focus of

our early-stage work will be on expanding the current algorithms to become a full-fledged

model architecture, core to the functioning of our business, including but not limited to

demand prediction, data-driven route optimization, pricing and revenue management

modeling, etc.

Responsibility

Building demand prediction models for future shipping orders (in terms of both

the volume and the price)

Integrating the demand prediction model with our current route optimization

model for truck drivers trip planning

Building real-time and stochastic models for the events of traffic delay,

warehouse loading delay, accidents, etc.

Working closely with our scientific advisors in developing state-of-the-art models

for routing planning, revenue management, and robust sequential decision

making.

Skills

Critical Skills

Currently has obtained, or is in the process of obtaining Masters or Ph.D. degree

in highly quantitative field (CS, mathematics, statistics, operations research) or

equivalent experience

Experience applying various machine learning techniques on large-scale

datasets in Python or R

Experience in data visualization and exploratory data analysis

Experience building optimization models and designing dynamic programming

algorithms for real-world problems

Development experience in at least one scripting language, Python, Perl, or R

Thrive in the environment of a start-up, have a bias for action and be a thoughtful

and highly dedicated contributor and collaborator,

Have superior communication skills.

Preferred Skills:

Experience in web crawling and scrapping that ensure data integrity and create

data pipelines

Experience in route optimization and revenue management

Understanding of the mathematical underpinnings of the learning and

optimization models and algorithms, such as algorithms for convex, linear,

integer programs and Markov Decision Processes/Reinforcement Learning.

Strong programming skills in Java / Javascript

Employment Type

Full-time.

We sponsor H1B visa for qualified candidates.

Haulistix Inc is an equal employment opportunity employer. We celebrate diversity. We
do not discriminate against employees or job applicants on the basis of race, culture,
color, national origin, sex, sexual orientation, gender identity, gender expression,
pregnancy, age, religion, marital status, height, weight, familial status, disability, military
service, genetic information, or any other category protected by federal, state or local law.

Powered by JazzHR",4.1,"IntelliPro Group Inc.
4.1","Redwood City, CA","Santa Clara, CA",201 to 500 employees,-1,Company - Private,-1,-1,$10 to $25 million (USD),-1
Sr. Data Scientist/Machine Learning Engineer – Manage and Analyze at Seal Software – a DocuSign Company,"$160K-$262K
(Glassdoor est.)","Sr. Data Scientist/Machine Learning Engineer – Manage and Analyze at Seal Software – a DocuSign Company
Engineering & Tech Operations | Walnut Creek, CA

Our agreement with employees
DocuSign is committed to building trust and making the world more-agreeable for our employees, customers and the communities in which we live and work. You can count on us to listen, be honest, and try our best to do what's right, every day. At DocuSign, everything is equal. We each have a responsibility to ensure every team member has an equal opportunity to succeed, to be heard, to exchange ideas openly, to build lasting relationships, and to do the work of their life. Best of all, you will be able to feel deep pride in the work you do, because your contribution helps us make the world better than we found it. And for that, you'll be loved by us, our customers, and the world in which we live.

The team
The Analyze and Manage team builds and operates industry-leading analytics products that utilize AI, machine learning and cutting-edge NLP to provide deep insights from procurement, derivative and other contracts to financial institutions, manufacturers and others. We are the worldwide leader in AI-driven contract analytics. The Machine Learning (ML) team's primary goal is to maintain and enhance the core analysis engine. In order to keep up with the rapidly evolving field of Natural Language Processing (NLP) and ML, certain time is allotted for research. This allows us to lead the trend of automating the contract analysis processes by testing and evaluating the latest ML technology and methods in an inhouse designed lab. As such, we hire people who are excited about working on a groundbreaking and technically challenging AI vision that will be one of DocuSign's key investments over the next 5 years.

This position
DocuSign is looking for a passionate, talented, and inventive machine learning engineer to help build industry-leading state of the art machine learning solutions. You will be leveraging data mining, deep learning, content understanding, image processing and more. You will integrate and deploy machine learning models that deliver more personalized and automated customer experiences.

This position is an Individual Contributor role and reports to an Engineering Lead.

Responsibilities
Feature extraction and data preparation
Algorithm development and evaluation of existing and emerging NLP/ML methods and technologies that could be effectively applied to contractual/legal data
Apply NLP techniques to maintain and extend the current rule-based, supervised and unsupervised models
Apply ML algorithms and technologies to NLP tasks such as Named Entity Recognition, POS tagging, Parsing, Sentiment Analysis, Clustering, etc.
Understanding of the entire software development end-to-end process as well as the product code and release management process
Understand, assist and improved the existing training data maintenance and enrichment process
Is ""hands-on"" and takes the initiative

Basic Qualifications
6+ years of experience in designing, developing, deploying and monitoring models, specifically in the context of text processing/NLP
Experience with Python programming, especially in the context of established deep learning frameworks.
Bachelor's degree in computer science, data science, applied mathematics, or an equally computational field

Preferred Qualifications
Experience with containerization and orchestration of machine learning models in production.
Masters or PhD in computer science, data science, machine learning, applied mathematics, or an equally computational field.
Demonstrated experience with text-based deep learning (NLP, NLU).
Demonstrated experience in extracting, cleansing, and manipulating large, diverse unstructured datasets.
Strong desire to stay ahead of industry trends & technologies with a commitment to continuous research and learning.

About us
DocuSign® helps organizations connect and automate how they prepare, sign, act on, and manage agreements. As part of the DocuSign Agreement Cloud, DocuSign offers eSignature: the world's #1 way to sign electronically on practically any device, from almost anywhere, at any time. Today, hundreds of thousands of customers and hundreds of millions of users in over 180 countries use DocuSign to accelerate the process of doing business and simplify people's lives. Plus, we save more trees together! And that's a good thing.

DocuSign is an Equal Opportunity Employer. DocuSign is committed to building a diverse team of talented individuals who bring different perspectives to the discussion and who feel a sense of inclusion and belonging when they join our team. Individuals seeking employment at DocuSign are considered without regards to race, ethnicity, color, age, sex, religion, national origin, ancestry, pregnancy, sexual orientation, gender identity, gender expression, genetic information, physical or mental disability, registered domestic partner status, caregiver status, marital status, veteran or military status, citizenship status, or any other legally protected category.
#LI-DS1",4.6,"DocuSign
4.6","Walnut Creek, CA","San Francisco, CA",5001 to 10000 employees,2003,Company - Public,Computer Hardware & Software,Information Technology,$1 to $2 billion (USD),"EchoSign, Inc"
Senior Data Engineer,-1,"Job Description
Senior Data Engineer

Position Overview: From software hacking to hardware hacking, we help secure everything from cryptocurrency exchanges and space telescopes to autonomous vehicles and the electric grid. Today, our client is making significant investments in terms of financial and engineering resources to develop a radically new customer experience we call “Security-as-a-Service” to provide customers with a unified, efficient, and data-driven security platform. We they're looking to add the right individual to their growing team supporting the next wave of cybersecurity products and solutions.

As part of that investment, our client is seeking a seasoned Data Engineer with a successful track record in data engineering in a hyper growth company setting. You will have the opportunity to work with some of the best security engineers in the world who hail from organizations such as Amazon, CIA, Facebook, Google, Microsoft, NSA, Redhat, Sun Microsystems, and US Air Force. As an Inc. Best Places to Work, Inc. 500 | 5000, Cybersecurity 500, and Austin Fast 50 Award recipient, we are seeking an individual that understands the professional and personal growth attached to this opportunity and who has the corresponding internal drive to maximize it.

Career opportunity:
Join an industry with massive socio, economic, and political importance in the 21st century
Work alongside some of the best and the brightest minds in the security industry
Leave an indelible mark on a company where individual input has real impact
Be recognized, internally and publicly, for your contributions in a high profile position
Align your career trajectory with a hyper growth company that is on the move
Core responsibilities:
Create pipelines to ingest and maintain complex data sets into our client's data stores for use in machine learning models
Create tools to scour the internet to find important security information and ingest it into their infrastructure
Work with data scientists to create and maintain data ontologies for security
Create the roadmap of how to continually evolve the data engineering infrastructure and techniques to improve our client's ability to find security information
Mentor junior data engineers and teach them how to use data engineering techniques to solve real world problems
Communicate complex concepts to team members
Accountable for:
Creation of data engineering pipelines to find and ingest security vulnerabilities
Creation of data engineering tools to help label and validate data
Required qualifications:
At least 8 years experience designing and building data processing/ETL pipelines
At least 8 years experience in Python and Spark or similar technologies
At least 8 years experience with SQL and relational databases
At least 8 years experience parsing flat files
8+ years development experience
Prior track record in a hyper-growth, high-tech company
Bachelor's degree or equivalent practical experience
Desired qualifications:
Experience working with Google Tensorflow
Experience with modern technology stacks
Experience with micro-services architectures
Experience with cloud platforms and SaaS solutions
Experience with agile/scrum development practices
Experience with test driven development, continuous integration, continuous deployment
Experience with Git, JIRA, Confluence
Experience with Google Compute, Firebase, and GKE
Experience with Docker
Desired behaviors:
Relentless restlessness to turn theory into practice and develop production worthy code that solves real-world customer problems
Determination to always learn and get better and never rest on ones laurels
Personable individual who enjoys working in a team-oriented environment
Comfort dealing with ambiguity in an environment where we build the plane as we fly it
Ability to work within constraints and to challenge the status quo
Ability to self-direct work and truly own the position in a hyper-growth environment
Compensation package:
Competitive compensation
Ownership opportunity through employee stock option plan
Health, dental, and vision insurance
4% company 401K matching vested immediately",5.0,"Uplink Talent Solutions
5.0","Austin, TX","Boston, MA",1 to 50 employees,-1,Company - Private,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
"Software Engineer, Mapping & Localization",-1,"Who We Are


Nuro is a robotics start-up whose mission is to accelerate the benefits of robotics for everyday life. We have an elite team of entrepreneurs and engineers, designers, and scientists. We believe AI and robotics are at the cusp of transforming daily life and we are dedicated to building meaningful products with this technology. Join us and play a critical role in our mission.

About the Role


Our robotics team is growing and we are looking for a Software Engineer to join our mapping and localization team. We're searching for an engineer with an advanced degree and experience building mapping and localization systems that work with real data in uncertain environments, and a strong desire to contribute to the future of robot navigation for logistics and transportation.

About the Work
Research, develop and implement algorithms to solve large-scale mapping and real-time localization problems for our fleet of self-driving delivery robots
Build well-tested C++ software and deploy on systems scaling from real-time embedded processors up to large distributed cloud-based infrastructure
Work in a small, focused team to deliver high-quality mapping and localization solutions that power the next generation of mobile robots
About You
Deep experience with state estimation, SLAM, nonlinear optimization, probabilistic filtering, and 3D/visual geometry
You have proven experience designing, implementing and extending novel algorithms
Strong C++ programming skills
In-depth knowledge of state-of-the-art 3D computer vision and machine learning techniques/methods
You possess experience working with real-time systems, large-scale scalable software architectures, and large data sets
Experience with multiple sensors (e.g. GPS, IMU, LIDAR, camera, odometry, radar)
PhD and/or Masters Degree in computer science, electrical engineering, robotics, or related field
Nuro is an equal opportunity employer and expressly prohibits any form of workplace harassment based on race, color, religion, gender, sexual orientation, gender identity or expression, national origin, age, genetic information, disability, or veteran status.",4.4,"Nuro
4.4","Mountain View, CA","Mountain View, CA",201 to 500 employees,2016,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
"Software Engineer, Data Visualization",-1,"About CharterUP

CharterUP aims to be the leading charter bus platform in the world and is looking for people that want to be along for the ride! We are disrupting the highly fragmented bus industry by connecting supply-side bus companies to demand-side clients (corporations, non-profits, and governmental entities). We strive towards having as many enthusiastic customers as possible, which leads to increased group travel and a greener earth.
About This Role

As a Data Visualization Software Engineer, you are expected to own end-to-end visual analytics solutions from ideation to production through rigorous field studies for domains ranging from business, machine learning, urban computing, experimentation, to autonomous vehicle data.
What You’ll Do
Develop data-intensive applications and advanced user interfaces for data producers and consumers across the company
Architect production-level applications using modern Web and Visualization technologies such as React/Redux, GraphQL, WebGL, and D3
Work closely with customers ranging from data scientists, operations, security investigators, researchers, and urban planners
What You’ll Need
Bachelor’s Degree in Computer Science or related field from a top-ranked institution
Experience building and maintaining large-scale batch and/or real-time data processing pipelines
Understanding a users’ role in complex data and machine learning systems
Contribution to open-source software libraries
Application Process

The selection process for this role differs from our traditional tech team application process. A member of our team will reach out to you if you qualify for the next step.

CharterUP Principles

At CharterUP, we don’t compromise on quality. We hire smart, high-energy, trustworthy people and keep them as motivated and happy as possible. Do that by adhering to our principles, which are:

Customer First
We always think about how our decisions will impact our clients; earning and keeping customer trust is our top priority
We are not afraid of short-term pain for long-term customer benefit
Create an Environment for Exceptional People
We foster intellectual curiosity
We identify top performers, mentor them, and empower them to achieve
Every hire and promotion will have a higher standard
Everyone is an Entrepreneur / Owner
No team member is defined by their function or job title; no job is beneath anyone
We do more with less; we are scrappy and inventive
We think long-term
Relentlessly High Standards
We don’t accept “that’s how it’s always been done”; we constantly innovate and question established routines to improve processes
We actively push to be proved wrong and welcome different ideas; the best idea wins
We don’t compromise on quality
Clarity & Speed
When in doubt, we act; we can always change course
We focus on the key drivers of a process that will deliver the most results
Mandate to Dissent & Commit
We are confident in expressing our opinions; it is our obligation to express our disagreement
Once we decide, we enthusiastically move together in the agreed upon direction",4.7,"CharterUP
4.7","Atlanta, GA","Atlanta, GA",51 to 200 employees,2017,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,"$98K-$129K
(Glassdoor est.)","Work directly with the Program Director for Data Science and data science
team to advance data engineering and infrastructure with Northwell, as well as
migrate and support machine learning projects into production. Define and build the next iteration of
features for the data science team and will be responsible for modifying,
expanding and optimizing our data warehouse to include big data and cloud
technologies. Work collaboratively with
members from both the Information Technology and clinical communities to support
data scientists, systems and initiatives at both the department and the
enterprise level.
Assist
data scientists, data engineers, cloud architects, and subject matter advisors in
testing, deploying, and maintaining artificial intelligence and machine learning
algorithms.
Work collaboratively to develop, construct,
test, and maintain large scale data processing systems and databases.
Participate
in projects to architect (research, recommend, design, develop and deploy)
advanced systems for the collection, aggregation and analysis of those data in
alignment with business objectives.
Provide big
data technology assessments, strategies, and roadmaps in several technical
domains and act as a subject matter advisor on big data.
Participate
in configuring the architecture and advise data scientists on efficient
performance.
Develop
and optimize ETL processes, implement transformations and quality check results.
Work with
cross functional research leadership, technical and analytical teams to
understand current and future enterprise-wide big data analytics goals spanning
disparate platforms and datatypes.
Assist in ensuring that systems are implemented
to support Health System initiatives and goals to improve the quality of
patient care, to maximize patient safety, and to provide operational
efficiencies.
Serve as a resource to the Director of Quality
Informatics and Program Director of Data Science.
Demonstrate familiarity with current hospital
information systems.
Performs other duties as
assigned
Bachelor’s Degree in Computer Science,
Informatics, Statistics, Engineering, Data Science, or related field, required.
Master’s Degree, preferred.
Minimum of two (2) years of experience with Apache Hadoop, NoSQL, setting up cloud
clusters, Apache Spark, and other advanced data science and big data
technologies, required.
Experience in software development in enterprise/ web/ cloud applications, solutioning, architecture and
frameworks.
Big data expertise with cloud and enterprise
leveldesign/implementation.
Experience in
architecting data warehouses and/or data lakes with traditional database
enterprise-class RDBMS technologies.
Strong knowledge of programming
languages/tools including: Java,
Python, Spark, SQL, R, and Shell Scripts.
Experience with or understanding of how
to build, test, and deploy code to run on cloud infrastructure.
Fluent with functional, imperative and
object-oriented languages and methodologies and Design Patterns.
Strong knowledge of Business
Intelligence & Analytics concepts and platforms, inclusive of data
virtualization, data preparation, data visualization and advanced analytics
technologies.
Experience with Unix/Linux systems with
scripting experience, open source programming languages for large data, and
AWS/CPG/Azure platforms.
Strong
interpersonal skills, capable of working collaboratively with clinicians and
administrators.",4.0,"Northwell Health
4.0","New Hyde Park, NY","Lake Success, NY",10000+ employees,1997,Nonprofit Organization,Health Care Services & Hospitals,Health Care,$10+ billion (USD),"Catholic Health System, NewYork-Presbyterian Hospital"
Software Engineer - Python Developer,-1,"Do you want to work for a mission-driven non-profit, building systems and writing software that will contribute to helping millions of coffee farmers out of poverty? Enveritas is a young ""startup non-profit"" looking to hire experienced engineers in the New York City area. You can learn more about our engineering team at: http://www.enveritas.org/jobs/engineering/

About Our Engineering Team

Our engineering and data team designs and builds tools for our country teams to collect data, machine learning systems for analyzing images for coffee, mobile applications for field-use, and data analytical tools for our managers and clients. In addition to our core data and analytics platform, we have interesting challenges in machine learning and mobile development, from farm-detection in satellite imagery to data availability in low-resource environments.

We're a small, collegial team of four engineers, two data scientists, a product manager, and a UX designer -- and looking to add two more talented and experienced engineers to our team.

What You'll Be Doing

We're looking for a senior software engineer with 7+ years experience of working on software teams to join our New York City team on a full-time basis. Our current task is to build an internal survey authoring and country management platform using in Python3 / Flask. We're at the enviable point of having a clear product (with good wireframes!) and having the support to build a core platform to give Enveritas the ability to make a real impact for coffee farmers.

Who You Are
7+ years experience writing software in teams.
Experience with Flask, Python3, and PostgreSQL.
A history of working on small, nimble teams that run with best practices (GitHub, Pull Requests, code reviews, etc).
CS degree strongly preferred.
A love of travel and excitement for our mission of improving the lives of coffee farmers.
About Working With Us
Our New York team, located near Grand Central, is a diverse, quirky, and humble group of 13^H4.
Field visits once or twice a year to our Country Ops teams in coffee-growing countries such as Costa Rica, Ethiopia, and Indonesia.
Flexible work hours and generous vacation -- 4 weeks vacation in addition to 12 standard holidays and personal/sick time.
Full benefits, including 401k with matching contributions, Medical/Dental/Vision, Flexible Spending Account (FSA), and Transportation benefit plan
Annual education budget for conferences, books, and other professional development opportunities.
Unlimited quantities of amazing pour-over coffee -- some of which were grown by our own employees!",5.0,"Enveritas
5.0","New York, NY","New York, NY",1 to 50 employees,2016,Nonprofit Organization,Social Assistance,Non-Profit,Unknown / Non-Applicable,-1
Software Engineer- Machine Learning Infrastructure,-1,"Company Overview

Calling the adventurers ready to join a company that's pushing the limits of nanotechnology to keep the digital revolution rolling. At KLA, we're making technology advancements that are bigger—and tinier—than the world has ever seen.

Who are we? We research, develop, and manufacture the world's most advanced inspection and measurement equipment for the semiconductor and nanoelectronics industries. We enable the digital age by pushing the boundaries of technology, creating tools capable of finding defects smaller than a wavelength of visible light. We create smarter processes so that technology leaders can manufacture high-performance chips—the kind in that phone in your pocket, the tablet on your desk and nearly every electronic device you own—faster and better. We're passionate about creating solutions that drive progress and help people do what wouldn't be possible without us. The future is calling. Will you answer?

Group/Division

With over 40 years of semiconductor process control experience, chipmakers around the globe rely on KLA to ensure that their fabs ramp next-generation devices to volume production quickly and cost-effectively. Enabling the movement towards advanced chip design, KLA's Global Products Group (GPG), which is responsible for creating all of KLA’s metrology and inspection products, is looking for the best and the brightest research scientist, software engineers, application development engineers, and senior product technology process engineers.

First to deliver the best imaging and classification data for every defect or point on any layer at any time.

EBeam’s mission encapsulates its role as the “eyes” of KLA’s product line, providing timely information on defects and critical locations on the wafer at the highest spatial resolution possible. Customers use EBeam products alongside KLA patterned and bare wafer inspectors to quickly understand the nature of defects and other imperfections on product wafers and take action to correct the manufacturing process.

Responsibilities

At KLA we don't just work on bleeding edge, we define bleeding edge. The Software driving our eBeam Inspection/Review tools enables our Customers to create next the generation of processor technologies

We are looking for passionate professionals to join our team!

The successful candidate will be involved in building complex multimillion-dollar products which are a composition of (Software, Electronics, Mechanics and Machine Control). These product(s) are to solve critical modern-day challenges in the fields of nano-technologies and complexities of manufacturing advanced next gen semiconductor chips

Responsibility will include the development, support for highly scalable service orientated infrastructure to execute machine learning algorithms, seamlessly move high volumes of data across components.

Understand the design, architecture of the system/product and the layered software that runs the system.

With an R&D mindset explore, experiment, and bring the cutting-edge open source technologies to the product

Work in an agile based development environment

Attitude:

Share knowledge and willing to learn from others and co-workers

Inquisitive and scientific spirit, eager to learn new technologies, experiment and fail

Team spirit, collaboration, “never-give-up”

Bring the “startup” kind of mindset to blend with an experienced corporate leader in semiconductor related industries

Qualifications

Proficiency in Python, Java, C/C++. Familiarity with DL frameworks (e.g., Tensorflow, Caffe, Torch, etc).

We understand that the languages keep evolving and proliferate. We are not looking for language syntax, we are looking at your basic problem-solving skills in software computing and past exposure to these languages:
Design and Code in Object Oriented Technology
Proven ability to influence cross-functional teams without formal authority
Highly creative and inquisitive; able to multitask effectively
Strong verbal and written communication skills
Minimum Qualifications

Doctorate (Academic)
OR
Master's Level Degree with at least 2 years of experience.
OR
Bachelor's Level Degree with at least 3 years of experience.

Equal Employment Opportunity

KLA is an Equal Opportunity Employer. Applicants will be considered for employment without regard to age, race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability, or any other characteristics protected by applicable law.",3.8,"KLA-Tencor
3.8","Milpitas, CA","Milpitas, CA",5001 to 10000 employees,1976,Company - Public,Industrial Manufacturing,Manufacturing,$2 to $5 billion (USD),"Applied Materials, Nanometrics"
Lead Data Scientist,"$96K-$153K
(Glassdoor est.)","Join a team recognized for leadership, innovation and diversity


The future is what you make it. When you join Honeywell, you become a member of our global team of thinkers, innovators, dreamers and doers who make the things that make the future. That means changing the way we fly, fueling jets in an eco-friendly way, keeping buildings smart and safe and even making it possible to breathe on Mars. Working at Honeywell isnt just about developing cool things. Thats why all of our employees enjoy access to dynamic career opportunities across different fields and industries. Are you ready to help us make the future?

Join a company that is transforming from a traditional industrial company to a contemporary digital industrial business, harnessing the power of cloud, big data, analytics, Internet of Things, AI/ML (Machine Learning), Automation and design thinking. You will support change that brings value to our customers, partners, and shareholders through the creation of innovative software and data-driven products and services. You will help engineer contemporary applications and services, constructing solutions that remain scalable, adaptable and replicable. You will be part of transforming Honeywell's IT organization through the delivery of technology products that will directly impact the company's growth.

You will be part of the Automation and Cognitive Services Technology group and in this role, you will work on the design and implementation of state-of-the-art Machine Learning/Deep Learning and AI Cognitive Services enhanced business use cases. This Data Science Manager role will work with the Automation Delivery team, IT business partners, Functional consultants, and infrastructure/technology teams to meet customer requirements. You will focus primarily on the end-to-end delivery of ML/AI use cases from pilot/design to release, driving the evolution of ML/AI infrastructure/process, and enabling Cognitive Automation, AI ChatBot, etc.

Key Responsibilities:
Build and maintain our cutting edge and scalable AI/ML platform and solution portfolio
Identify business requirements and opportunities for Machine Learning use cases and work with key stakeholders to create new project / business case.
Define best practices and consistent solutions/tools for deployment of advanced Machine Learning, Reinforcement learning and Deep Learning Models/algorithms to enhance existing business processes with predictive and intelligent decision making.
Drive operational excellence activities required to ensure a streamlined production process of data science deliveries.
Provide guidance and oversight on the AI/ML solution and implementation throughout the project life cycle.
Work in a startup-type environment to design and build innovative applications using Automation, Machine Learning/Cognitive Service, business / functional proofs-of-concepts to scalable, production ready solutions across a strategic business group
Actively lead, analyze and recommend highly complex business opportunities, through assessments/workshops, detailed data analysis/modeling and overall end-end solutioning to propose predictive, AI Driven solutions that drive the most business value with sustained impact.
Research, actively experiment to stay abreast of the emerging ML and Cognitive Automation trends
Work within project planning constraints, communicating any identified project risks and issues to the delivery/project manager and provide inputs to the change control process
Help develop standard operation practices and support the Operations Teams through UAT and after go-live .
Work closely with the operations team to change, optimize existing Automation and AI/ML processes and help build effective model performance monitoring, alert and notification framework to proactively identify problems/issues before business impact
Partner and effectively communicate with Non-IT / Business users, functional counterparts and stakeholders to understand the underlying business problem, and work with the extended team to define and communicate the right technical solution
CORPIT2020

YOU MUST HAVE
Bachelors in Computer Science, Data Science or Engineering fields
7 years of IT experience in solution architect / data scientist / software development for large corporate/organizations
5 years of experience in building and deploying Machine Learning solutions using various supervised/unsupervised ML algorithms such as Linear/Logistic Regression, Support Vector Machines, (Deep) Neural Networks, Random Forest, etc
5 years of hands-on experience with Python and/or R programming and statistical packages, and ML libraries such as scikit-learn, Keras, TensorFlow, PyTorch, MXNet, etc, and/or natural language processing using NLTK, spaCy, Gensim, etc.
2 years of experience in building IT use cases / solutions especially around AI/ML cognitive services, based on Cloud infrastructure and services such as AWS and/or Azure cloud platforms.
WE VALUE
Work experience / education in data science, data engineering and analytics
Excellent understanding of Machine Learning techniques and proficiency in feature analysis, algorithm selection and model hyperparameter tuning.
Demonstrated hands-on experience in working with Hadoop, Hive, Apache Spark, etc.
Project experience with NLP/NLG, AI Conversational Agent (Chatbot), OCR
Experience with Domino Data Lab, NiFi, Airflow, etc.
Development experience in RPA Tools & Platform & Implementations: Examples - UiPath, Automation Anywhere and other leading RPA platform vendors
Experience in Web Service/Restful API Integration
Experience in ERP platform integration, preferably with SAP
Working Experience in an Agile/Scrum/Scaled Agile and DevOps based team environment
Project management skills and experience
Certifications AI / ML and Cloud platforms
Great communication skills
Additional Information
JOB ID: req234223
Category: Engineering
Location: 715 Peachtree Street, N.E.,Atlanta,Georgia,30308,United States
Exempt
Engineering (GLOBAL)

Honeywell is an equal opportunity employer. Qualified applicants will be considered without regard to age, race, creed, color, national origin, ancestry, marital status, affectional or sexual orientation, gender identity or expression, disability, nationality, sex, or veteran status.",3.8,"Honeywell
3.8","Atlanta, GA","Charlotte, NC",10000+ employees,1885,Company - Public,Computer Hardware & Software,Information Technology,$10+ billion (USD),"GE, Johnson Controls, United Technologies"
Data Scientist Expert,"$82K-$133K
(Glassdoor est.)","Requisition ID: 254844
Work Area: Software-Design and Development
Expected Travel: 0 - 10%
Career Status: Professional
Employment Type: Regular Full Time

COMPANY DESCRIPTION

SAP started in 1972 as a team of five colleagues with a desire to do something new. Together, they changed enterprise software and reinvented how business was done. Today, as a market leader in enterprise application software, we remain true to our roots. That’s why we engineer solutions to fuel innovation, foster equality and spread opportunity for our employees and customers across borders and cultures.
SAP values the entrepreneurial spirit, fostering creativity and building lasting relationships with our employees. We know that a diverse and inclusive workforce keeps us competitive and provides opportunities for all. We believe that together we can transform industries, grow economics, lift up societies and sustain our environment. Because it’s the best-run businesses that make the world run better and improve people’s lives.

Data Scientist Expert

Now more than ever before businesses around the world need to accelerate the transformation of core processes in a flexible way. To support this, our new business unit SAP S/4HANA Consumer Industries Cloud will focus on building new cloud products for customer in the Consumer Product, Retail, Wholesale and Life Science industries.

Taking a start-up approach, SAP S/4HANA Consumer Industries Cloud will be an incubator for new cloud applications, bringing together product strategy and management will all the necessary cloud business functions such as architecture, engineering and operations. Development in this unit will focus on cloud-native applications and has a strategic growth plan from now to 2025.

EXPECTATIONS AND TASKS
7+ years of solving data science problems
Be part of a diverse team that defines the science algorithms that are an integral part of Eureka’s products
Be a team player, good listener, and effective communicator
Work directly with peers, as well as industry and technology experts to translate our customers’ business needs into mathematical models and functional prototypes
Work closely with the engineering team to help transition prototypes into products, assist them in evaluating and defining strategies for delivering high quality product features and capabilities of the product
Work closely with product management and end users to incorporate feedback on science functionality
Demonstrate solid understanding of topics in some major data science area such as machine learning, optimization, statistical modeling, and other techniques for mathematical modeling of business problems
Strong coding skills in at least one Data Science prototyping language (R, Python, MatLab, etc)
Be self-driven and stay updated on latest research trends, and be willing to focus on generating competitive advantage for our customers
Lead small project teams of researchers or participate as key contributor, perform functional and empirical analysis on data science topics, conduct research on data science tools and algorithms, evaluate and select best data science methods to deliver results, implement prototypes and validate them on real data. Be mindful of practicality, quality, and effort requirements
Embrace creative destruction – be open to look at challenges in new ways and to articulate reasons for change to peers and managers
Document findings, publish research internally and externally, attend and present at professional events, create best practices for data science topics, and collaborate with universities and research institutes
Be willing to serve as mentor or advisor to more junior team members
PREFERRED QUALIFICATIONS
PhD in Mathematics, Engineering, Computer Science, or other related math-intensive field. MSc degree with proven solid data science work experience also considered
Industry experience in Retail and Consumer Products a plus but not required
Some degree of familiarity with modern and cloud-specific ML software paradigms and frameworks also a plus but not required (Google AI Platform, AWS Sagemaker, Azure Databricks, etc)
#SAPICCareers

WHAT YOU GET FROM US
Success is what you make it. At SAP, we help you make it your own.
A career at SAP can open many doors for you. If you’re searching for a company that’s dedicated to your ideas and individual growth, recognizes you for your unique contributions, fills you with a strong sense of purpose, and provides a fun, flexible and inclusive work environment – apply now.

SAP'S DIVERSITY COMMITMENT
To harness the power of innovation, SAP invests in the development of its diverse employees. We aspire to leverage the qualities and appreciate the unique competencies that each person brings to the company.

SAP is committed to the principles of Equal Employment Opportunity and to providing reasonable accommodations to applicants with physical and/or mental disabilities. If you are interested in applying for employment with SAP and are in need of accommodation or special assistance to navigate our website or to complete your application, please send an e-mail with your request to Recruiting Operations Team. (Americas:Careers.NorthAmerica@sap.com or Careers.LatinAmerica@sap.com, APJ: Careers.APJ@sap.com, EMEA: Careers@sap.com). Requests for reasonable accommodation will be considered on a case-by-case basis. Successful candidates might be required to undergo a background verification with an external vendor.

EOE AA M/F/Vet/Disability:
Qualified applicants will receive consideration for employment without regard to their age, race, religion, national origin, gender, sexual orientation, gender identity, protected veteran status or disability.

Successful candidates might be required to undergo a background verification with an external vendor.
Additional Locations:",4.6,"SAP
4.6","Newport Beach, CA","Walldorf, Germany",10000+ employees,1972,Company - Public,Computer Hardware & Software,Information Technology,$10+ billion (USD),"Salesforce, Oracle, Microsoft"
"Lead Data Engineer (SaaS, Docker, Kubernetes, Elasticsearch)","$161K-$290K
(Glassdoor est.)","Cohesity Bringing Google-Like Simplicity to Data Management: One Platform. One UI.Cohesity eliminates mass data fragmentation with one web-scale data management platform that radically simplifies the way companies protect, control and extract value from their data. This software-defined platform spans across Clouds and data centers, can be managed from a single GUI, and enables independent apps to run in the same environment.""We use web-scale design principles to revolutionize an area of IT that hasn't seen innovation in decades"" by Mohit Aron, CEO/FounderArticle Cohesity Announces $250 Million in Series E FundingVideo How Cohesity Redefines Data ManagementBrochure Corporate Brochure PDFAbout This Role:At Cohesity, we are building the next generation data management and analytics platform as a service, a first of its kind in the industry. This builds upon the unique tech stack Cohesity is known for. Join us and be a part of this big company initiative, and help make the first release. This is an amazing opportunity for a hands-on leader who can not only define but also lead and implement technical projects.Responsibilities* Tech lead responsibility, along with being a top class developer* Work with product managers to understand customer requirements and design and deliver cloud SaaS services* Perform the role of data scientist within the team* Work with functional leads to understand their data requirements and design and deliver data pipelines to scale to billions of events* Collaborate with operations to establish KPI for different services and own end to end delivery and lifecycle management* Establish core data management principles and best practices* Lead initiatives and projects across multiple geos* Provide technical leadership, and mentoring to team membersWhat we are looking for:* MS/PhD in Computer Science* 10+ years of relevant experience in building production software products* We run on all major public clouds. Hands-on experience with at least one of the three AWS/GCP/Azure required.* Experience building data lakes and data-warehouses a must. Expertise in either BigQuery, Snowflakes or Redshift preferred.* Experience in either streaming or batch ETL pipelines required. Expertise in Kafka and Spark preferred.* Experience with microservices and containers. A must with hands on Kubernetes experience* Experience in either Elasticsearch or Solr required.* Experience with cloud native Machine Learning service a big plus.* Experience in NoSQL engines a plus.* Strong analytical and problem solving skills* Hands on coding skills (in golang, python or java) - strong data structures, design, algorithms are a must* Knowledge in Storage, Filesystems or Data Protection is a plus* Motivated to solve complex problems and challenges.* Openings are for experienced senior level engineers who can take the lead on complex projects and driven to own problems to solution.",3.3,"Cohesity
3.3","San Jose, CA","San Jose, CA",1001 to 5000 employees,2013,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Field-Programmable Gate Array (FPGA) Software Engineer,-1,"Field-Programmable Gate Array (FPGA) Software EngineerOverview:As an FPGA Software Engineer you will be a key player in IIA's innovation and growth efforts. You will support software and firmware design, development, and integration. You will support the porting and acceleration of machine learning and other algorithms from desktop to Field-Programmable Gate Arrays and other embedded devices. You will also participate in the corporate innovation laboratory, open source projects, and strategic business capture. This is a Full-Time position and work location is negotiable among locations in Herndon, VA, McLean, VA, and Clarksville, MD or remote.Job Responsibilities:* Work collaboratively in agile, mixed team environment with other FPGA engineers, software developers, data scientists and geospatial experts to port machine learning and other algorithms from CPU to FPGA with tight memory constraints and complex mission requirements* Support testing, evaluation, installation and configuration of algorithms on FPGAs* Support production maintenance activities that include the development of automated scripts and scheduled tasks, application/system monitoring, software/security updates and patching, archiving/disposition of system logs and/or data records* Work with the Chief Technology Officer and Business Development teams to advance corporate capabilities, including the innovation laboratory and open source projects* Support white paper development, strategic captures, and proposals in your areas of expertise and experience* Envision and collaborate on open source or proprietary proof of concept pilots or projectsRequired Skills:* Highly skilled programmer in relevant languages, such as C/C++ and Java* Ability to analyze existing code and rewrite and optimize for FPGA board, such as the Xilinx Kintex Ultrascale* Ability to work in an Agile DevSecOps environment using tools like Jira, Confluence, Bitbucket, and Slack* Ability to deploy applications in various on premise and public cloud environments* Excellent written and verbal communication skills* Ability to work independently and collaboratively* Ability to identify and pursue opportunities for program growthDesirable Skills:As part of a multidisciplinary, cutting-edge team, the following optional experience is also viewed favorably:* Development of machine learning inferencing engine* FPGA in aerospace environments* GPU and Internet of Things embedded systems programming experience* Deep learning and machine learning frameworks, libraries, and models, like Caffe2, PyTorch, TensorFlow, and YOLO, and languages such as Python, Go, Julia, Javascript, and shell scripts* Open source or proprietary geospatial software* Signals and communications processing* Hybrid multicloud containerization and serverless computing experience, such as Docker, Kubernetes, CI/CD.* Interest in emerging computing architectures* Business developmentEducation:Bachelor's Degree required, Master's Degree preferred in electrical engineering, computer engineering, physics, mathematics or related field.Clearance Requirements:You do not need a current/active clearance to apply, but must be able to pass and hold a government Public Trust (SF-85) background investigation. You must either be a US Citizenship or Green Card Holder to be eligible.IIA is proud to be an EEO/AA employer M/F/D/V.",3.7,"Information International Associates
3.7","Mc Lean, VA","Oak Ridge, TN",201 to 500 employees,1988,Company - Private,IT Services,Information Technology,$50 to $100 million (USD),-1
"Staff Software Engineer, Machine Learning","$156K-$254K
(Glassdoor est.)","Vungle's software engineers build machine learning systems to work at scale and in real-time, evaluating and ranking millions of possibilities each second. Every improvement to our recommendation models has a direct impact on Vungle's mission, and that means we get the chance to push our machine learning algorithms to their limits.

We're looking for hardcore software engineers who love applying their skills to all sorts of problems in the machine learning domain. At Vungle, you'll work on a small engineering team responsible for the design and implementation of high-performance, scalable, and reliable ML architecture. You'll collaborate closely with our Data Scientists and work on everything from feature engineering to database design to custom implementations of state-of-the-art machine learning algorithms. Most importantly, you'll have the chance to get your ideas into production, measure their impact, and keep improving.

What you'll do:
Design and scale predictive models to handle production-level loads of billions of daily requests
Identify new features, better algorithms, and performance optimizations; test your ideas on live traffic and take them from prototype to production
Work with data science and ML toolkits like scikit-learn, numpy, TensorFlow, Theano and the like
Use big data technologies like Spark to build efficient and reliable data pipelines specifically designed to support problems in the machine learning domain
Use your expert coding skills across a number of languages such as Python, Scala and Go
Be technology agnostic and always pick the right tool for the job
Be an evangelist for quality software engineering practices
Requirements:
MS in Computer Science or equivalent with 6+ years professional experience as a software developer, or a BS with 8+ years of experience
2+ years experience with machine learning, artificial intelligence or related field (either academic or industry)
Strong programmer with a background in OOP (Python, Java, C++, Scala or equivalent), capable of writing high performance production quality code
Strong understanding of CS fundamentals, data structures and algorithms and complexity analysis
Familiarity with core ML concepts, common supervised and unsupervised algorithms, feature engineering and feature selection, bias/variance, etc
Comfortable conducting and participating in thorough design and code reviews
Preferred:
Previous experience in back end development
MS in Computer Science or related field with coursework in machine learning or artificial intelligence
2+ years professional experience working with popular machine learning libraries such as scikit-learn, TensorFlow, Theano or similar
Experience implementing and maintaining high performance back end systems
Experience working with distributed frameworks and big data technologies like Spark


About Vungle:

Vungle is the trusted guide for growth and engagement, transforming how people discover and experience apps. Mobile application developers partner with Vungle to monetize their apps through innovative in-app ad experiences that are inspired by insight and crafted with creativity. Advertisers depend on Vungle to reach, acquire, and retain high-value users worldwide. Vungle develops tools that include data-led buying and UX recommendations, ad format innovation, creative automation, and more. Vungle's data-optimized ads run on over 1 billion unique devices to drive engagement and increase returns for publishers and advertisers ranging from indie studios to powerhouse brands, including Rovio, Zynga, Pandora, and Microsoft. The company is headquartered in San Francisco and has offices around the world in London, Berlin, Beijing, Tokyo, Seoul, and Singapore. For more information, visit www.vungle.com or follow the company on Twitter @Vungle

#LI-JH1",3.6,"Vungle
3.6","San Francisco, CA","San Francisco, CA",201 to 500 employees,2011,Company - Private,Internet,Information Technology,$100 to $500 million (USD),"AdColony, Unity, AppLovin"
ML Software Engineer,-1,"Company OverviewCalling the adventurers ready to join a company that's pushing the limits of nanotechnology to keep the digital revolution rolling. At KLA, we're making technology advancements that are bigger-and tinier-than the world has ever seen.Who are we? We research, develop, and manufacture the world's most advanced inspection and measurement equipment for the semiconductor and nanoelectronics industries. We enable the digital age by pushing the boundaries of technology, creating tools capable of finding defects smaller than a wavelength of visible light. We create smarter processes so that technology leaders can manufacture high-performance chips-the kind in that phone in your pocket, the tablet on your desk and nearly every electronic device you own-faster and better. We're passionate about creating solutions that drive progress and help people do what wouldn't be possible without us. The future is calling. Will you answer?Group/DivisionKLA has always had a close relationship with physics and data. Our optical and electron beam inspection and measurement tools use cutting edge physics models, both for hardware design and as part of their algorithms. AI, including several traditional machine learning techniques and deep learning are routinely used to process this data to meet application requirements.The AI & Modeling Center of Excellence, centered in KLA's R&D facility in Ann Arbor, MI, was setup with the mission of advancing KLA's traditional strengths in physics and data and providing implementation solutions for multiple KLA Inspection and Metrology products targeted at the semiconductor manufacturing industry.As a part of this group, you will be part of a world class team of physicists, HPC system designers, machine learning and application engineers who build cutting edge solutions for modeling complex imaging techniques and semiconductor processes. You will also work with a data scientists and AI infrastructure engineers whose mission is to build and scale machine learning based solutions for our semiconductor customers.We are looking for engineers in a few different fields. If you are passionate about Physics Modeling, High Performance Computing - HPC (including GPU), ML, Data, or Cloud technologies - this is the place for you!ResponsibilitiesEngineers in the HPC Software team will be working on building and maintaining infrastructure necessary for large scale experimentation and deployment of HPC solutions. Domains in which a successful candidate will be expected to contribute will include data management and data loading, support for machine learning and deep learning model training, experimentation and deployment.Although familiarity with Machine Learning and Deep Learning solutions would be a big plus, this is primarily a Software Engineering position. Successful candidates are passionate about software, and will have exceptional skills and hands on experience with development in C/C++ and Python in a Linux environment. Deep conceptual understanding of multi-threaded, multi process and distributed software systems as well as operating systems is necessary.Essential Skills* Object Oriented Design & Programing in Java or C++* Scripting languages like Java Script, Python;* Data Structures and algorithms* Linux System Programming* Distributed systemsDesirable Skills* Cloud technologies for network, storage, containerization and compute clusters.* Building and configuring Linux kernels, and designing and troubleshooting network infrastructure;* Linux Device Driver Development* Understanding of various networking stacks* GPU Architectures and CUDA (CuGraph, CuData, CuML etc).* Distributing computing frameworks like Apache Spark, DASK;* Creating the techniques and methods to integrate multiple hardware and software subsystems to solve advanced technical challenges;* Data science skills to acquire, transform and present data from various sources to build powerful debugging and analysis software.QualificationsBachelor's Level DegreeMust have flexibility to travel outside of Michigan based on business needs.Minimum QualificationsMaster's Level DegreeORBachelor's Level Degree with at least 1 years of experience.Equal Employment OpportunityKLA is an Equal Opportunity Employer. Applicants will be considered for employment without regard to age, race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability, or any other characteristics protected by applicable law.",3.8,"Kla-tencor
3.8","Ann Arbor, MI","Milpitas, CA",5001 to 10000 employees,1976,Company - Public,Industrial Manufacturing,Manufacturing,$2 to $5 billion (USD),"Applied Materials, Nanometrics"
Data Scientist - Data Intelligence Engineer,-1,"Location: Round Rock TX
Duration: 3 Months (Strong possibility of going perm)
Design, develop, test, and implement high quality machine learning and AI code into dev, test, and production environments.
Develop software and collaborate within an integrated development team as business requirements are discovered, refined, and implemented across multiple end user personas.
Maintain a professional attitude at all times, provide thought leadership, and display problem solving skills. Be prepared to present 1x1 or in a group setting.
Qualifications:
Master's Degree or PhD Required (Computer Science, Statistics, Economics, Mathematics, or Physics Preferred).
Fluent in R or Python
Must also have Object Oriented software design experience and understand UML design principles.
Must have Git Hub experience and comfort with version control procedures.
Deep Learning experience with Keras required.
NLP and Reinforcement Learning experience preferred.

Regards,
Vikas",4.1,"APN Software Services Inc.
4.1","Round Rock, TX","Newark, CA",51 to 200 employees,-1,Company - Private,Computer Hardware & Software,Information Technology,$25 to $50 million (USD),-1
Research and Development Engineer (Computer Vision and Metrology Systems Engineer),-1,"CURRENT EMPLOYEES OR STUDENTS:If you are a current employee (faculty, staff, technical service, or student) at Penn State, please login to Workday to complete the internal application process. If you are a current student at Penn State and seeking employment with Penn State, please login to Workday to complete the student application process.JOB DESCRIPTION AND POSITION REQUIREMENTS:The Electro-Optics Center (EOC), located in Freeport PA, a Division of the Applied Research Laboratory (ARL) at Penn State, is seeking a Computer Vision Systems Engineer to work closely with a multi-disciplinary team of engineers and scientists to design computer vision and imaging systems supporting various military and intelligence community customers.Responsibilities include:* Lead and contribute to key technical efforts in the development of broad range of novel electro-optical sensor systems* Software and algorithm development for computer vision, image processing, machine learning, data fusion, automated test systems, control systems and custom graphical user interfaces to push the state of the art of these systems* Guide system development from desk/bench-top and field-testable prototype to transitioned, field-deployable product* Support operationalization of techniques through field integration and testing activities, data analysis, and lab experimentation* Document work in memoranda, sponsor briefs, conference proceedings, and journal articles* Brief senior leadership and sponsors, as required* Work with leadership to develop project/staffing plans, participate in strategic business planning, new business development and internal research and development (IR&D) efforts, as required.This job will be filled as a level 2, level 3, or level 4, depending upon the successful candidate's competencies, education, and experience. Typically requires a Bachelor's degree or higher in an Engineering or Science discipline or higher plus two years of related experience, or an equivalent combination of education and experience for a level 2. Additional experience and/or education and competencies are required for higher level jobs. A Master's degree in Electrical Engineering, Computer Science, Physics, Optics, or a related field is highly desired.Experience in the following is preferred:* Fifteen years of directly-relevant experience in computer vision-related industry, consulting, or academia with some experience building products for Department of Defense or intelligence Community customers* Experience with real time/embedded application development and control systems theory* CUDA, GPGPU computing libraries* Writing software design documents and ICDs* Three dimensional data processing and visualization* GPS and positioning systems* Simultaneous location and mapping (SLAM) and deep experience with active or passive remote sensing systems* Distributed Aperture Systems, Visual Augmentation Systems, Unmanned Aerial Systems (UAS), and EO System Modeling tools.* An active Secret security clearance with eligibility for TS/SCI is highly desirable.Experience in the following is required:* Two years of direct experience developing computer vision, imaging systems, or machine learning systems for military or intelligence community customers* Familiarity with remote sensing physics and theory, detection and estimation theory, image processing, active or passive camera systems, photogrammetry/stereo imaging, metrology and inspection, image display technologies, multispectral and hyperspectral systems, and augmented reality technology* Experience with C and C++, Java, C#, MATLAB or CUDA* Windows, Linux and real-time operating environments* OpenCV* Experience interfacing with hardware via an ICD* Ability to adapt to changing requirements.The successful candidate will have:* Excellent written (including technical writing), verbal, and interpersonal skills, including a comfort level briefing to very senior and large audiences* Strong organizational and planning skills, with a demonstrated ability to effectively lead and inspire high performance teams of technical staff in solving complex problems* A demonstrated ability to collaborate in technical activities, as evidenced by co-authorship of technical papers, presentations, proposals, and white papers with authors from other organizations* Identify as a self-starter in practical initiation and execution of research projects* Holds the ability to work independently or as part of a multidisciplinary team and adapt to changing requirementsCandidates selected will be subject to a government security investigation. You must be a U.S. Citizen to apply. Employment with the Applied Research Laboratory will require successful completion of a pre-employment drug screen.The Applied Research Laboratory (ARL) at Penn State University is committed to diversity, equity, and inclusion; we believe this is central to our success as a Department of Defense designated University Affiliated Research Center (UARC). We are at our best when we draw on the talents of all parts of society, and our greatest accomplishments are achieved when diverse perspectives are part of our workforce.This is a one-year, fixed-term renewable appointment.CAMPUS SECURITY CRIME STATISTICS:Pursuant to the Jeanne Clery Disclosure of Campus Security Policy and Campus Crime Statistics Act and the Pennsylvania Act of 1988, Penn State publishes a combined Annual Security and Annual Fire Safety Report (ASR). The ASR includes crime statistics and institutional policies concerning campus security, such as those concerning alcohol and drug use, crime prevention, the reporting of crimes, sexual assault, and other matters. The ASR is available for review here.EEO is the LawPenn State is an equal opportunity, affirmative action employer, and is committed to providing employment opportunities to all qualified applications without regards to race, color, religion, age, sex, sexual orientation, gender identify, national origin, disability or protected veteran status. If you are unable to use our online application process due to an impairment or disability, please contact 814-865-1473.Affirmative ActionPenn State PoliciesCopyright InformationHotlinesUniversity Park, PA",4.2,"Penn State University
4.2","University Park, PA","University Park, PA",10000+ employees,1855,College / University,Colleges & Universities,Education,$5 to $10 billion (USD),-1
Data Engineer,"$96K-$107K
(Glassdoor est.)","Responsibilities


As a data scientist within our team, you will be working with our clients to design, create, evaluate, and maintain solutions using your experience and expertise in data science and machine learning. In your role you will work with various teams to identify, manage, research, develop, and present data analytics projects and solutions for various national security and intelligence missions.

Our team consists of developers, scientists, engineers, researchers, and analysts that have served federal, state, and local government clients on high-consequence problems in data analytics and AI/ML for over 20 years. Our team is engaged across the intelligence community and has been instrumental in making our customers’ programs successful.

Client Engagement
· Support and lead evolving business development efforts by applying technical and functional expertise to develop business solutions. · Lead proposal sections for small or limited competition proposals and actively participate in teaming strategy discussions
Qualifications


Required Qualifications:

• You have a BA/BS (or higher) in a data analytics, engineering, computer science, mathematics or related discipline and at least 5 years of hands-on experience in analytic methods and tools in applied math/statistics, computation, and visualization.

• You have hands-on experience with some of the following languages and/or tools:

o Programming and Scripting: Python, SQL, Hadoop, Spark, C, C++, Java, Git, Bash, awk

o Statistics, Visualization, and Geospatial analysis: R, Tableau, ArcGIS

o Operating Systems: Linux, Centos, RHEL, Windows

• You have knowledge and hands-on experience with some of the following:

o performing academic and open source literature reviews

o developing data analytics for relationships/discovery, situational awareness, and systems modeling

o engineering solutions to optimize, monitor, and measure performance of algorithms

o project management concepts

• You desire to work in an agile and cross functional team environment, understand team goals and generate appropriate, innovative analytical insights to drive process and experience improvement

• You challenge the status quo, are hungry to explore, evaluate, and understand new technologies, and wish to share insights and mentor your peers

• You possess a TS/SCI security clearance

• You have experience working with USG clients, operational components, and stakeholders

Beyond the requirements above, our ideal colleague:

• has strong written and verbal communication skills (e.g., technical writing)

• has led technical training on data science topics

• has a background in DevOps, engineering lifecycle software solutions, and designing and implementing enterprise systems.

• has led programs related to data science, training, and engineering

Overview


Noblis and our wholly owned subsidiary, Noblis ESI, are solving difficult problems that help our government and our country. We bring the best of scientific thought, management, and engineering expertise with a reputation for independence and objectivity. We support a wide range of government and industry clients in the areas of national security, intelligence, transportation, healthcare, environmental sustainability, and enterprise engineering. Learn more at Noblis -About Us

Why work at a Noblis company?

Our employees find greater meaning in their work and balance the other things in life that matter to them. Our people are our greatest asset. They are exceptionally skilled, knowledgeable, team-oriented, and mission-driven individuals who want to do work that matters and benefits the public.

Noblis has won numerous workplace awards. Noblis maintains a drug-free workplace and is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, veteran status or other characteristics protected by law.",4.0,"Noblis
4.0","Reston, VA","Reston, VA",1001 to 5000 employees,1996,Nonprofit Organization,Consulting,Business Services,$100 to $500 million (USD),"Booz Allen Hamilton, SAIC, LMI"
"Software Engineer, Backend Infrastructure","$97K-$111K
(Glassdoor est.)","Forward is on a bold mission to make high quality healthcare available to a billion people across the globe. We’re building the world’s most advanced healthcare platform from the ground up, combining hardware, software and doctors under one roof. We are scaling our engineering team and looking for world-class engineers with experience and expertise in distributed systems and data infrastructure. As an early member of our engineering team, you’ll have a key role in building the future of healthcare from first principles.

Forward was founded in January 2016 by former executives and engineering leaders from Google and Uber. We are funded by some of the world's best investors and entrepreneurs including Founder's Fund, Khosla Ventures, First Round Capital, Eric Schmidt (Google/Alphabet Chairman), Marc Benioff (Salesforce Founder), Joe Lonsdale (Palantir Founder), Joshua Kushner (Oscar co-Founder) and Garrett Camp (Uber co-Founder).

You can read our story here or check out a quick YouTube video.
WHAT YOU'LL DO:
Tackle problems on the boundary of software, hardware, and the real world.
Build the engine that serves data at scale to product teams, data scientists, and ML engineers across the company.
Collaborate with domain experts in fields like AI and NLP. Our engineers made major contributions to projects such as Amazon Go and TensorFlow.
Work with top-flight software and hardware engineering talent from places like Google, Amazon, Nvidia, Palantir, and NASA JPL.
Own entire projects while working alongside cross-functional teams of doctors, designers, and operators.
Your work will directly contribute to saving and improving people’s lives. For real. :)
WHAT WE'RE LOOKING FOR:
Impact - You’re deeply mission-driven and you think there’s more to life than software that enables puppy ears to be superimposed on photos. Although we concede those are cute.
Distributed Systems - You have experience building and operating highly scalable infrastructure in the cloud.
Data Engineering - You have firsthand experience with cloud storage (eg. S3, HDFS), job scheduling (Airflow, et al), message queues and streams (eg. Kafka, Kinesis, RabbitMQ), and distributed computation (Hadoop, Spark, etc) for Analytics and Machine Learning use cases.
Product passion - You care about the bits you ship ending up in users’ hands, and work backwards from user needs to come up with solutions to problems.
Entrepreneurship - You’re a self-starter who loves to own things end-to-end. You don’t ask for permission - you’re too busy making things happen.
Team player - You know how to make those around you better and feed off their energy. You take care of your teammates.
You have a BS or MS in computer science or a related technical field
2+ years production scale experience
WHY JOIN FORWARD?

We don’t want to just move dollars around the healthcare industry - we want to rebuild it and fix it. All of it. You’d be a major part of the story behind one of the most ambitious startup attempts of the past decade and you’d work with a team of people who want to use their talents for good.

We are an equal opportunity employer. In accordance with anti-discrimination law, it is the purpose of this policy to effectuate these principles and mandates. We prohibit discrimination and harassment of any type and affords equal employment opportunities to employees and applicants without regard to race, color, religion, sex, national origin, disability status, protected veteran status, or any other characteristic protected by law. We conform to the spirit as well as to the letter of all applicable laws and regulations. Pursuant to the San Francisco Fair Chance Ordinance and the Los Angeles Fair Chance Initiative for Hiring, we will consider for employment qualified applicants with arrest and conviction records.",4.8,"Forward
4.8","San Francisco, CA","San Francisco, CA",Unknown,2016,Company - Private,Health Care Services & Hospitals,Health Care,Unknown / Non-Applicable,-1
Software Development Engineer - Machine Learning,-1,"Prime Video is changing the way millions of customers interact with video content. The Prime Video team delivers high-quality video to Amazon customers through subscriptions (Amazon Prime) as well as purchases and rentals. Amazon believes so deeply in the mission of our video offering that we've launched our own studio to create original and exclusive content.

PV Customer engagement Optimization team owns product development of an intelligent channel agnostic engagement automation designed to provide a holistic view of a prime video customer's lifecycle state, recommendations, they have seen, and/or marketing messages they have (or have not) received. Using smart rules and machine learning, self learning system sends relevant, timely, and personalized content on a fully automated basis. We are building a multi-channel campaign management system powered by customer profile data, engagement propensity models and recommendations to enable automated customer segmentation and targeting.

Are you looking for an opportunity to use machine learning and add a valuable skill to your developer toolkit? Are you prepared to take on manual and partially automated business processes and replace them with high-velocity AI enabled services? We are looking for software developers willing to embrace ML, re-invent established business processes, replace them with an algorithm driven platform and most of all, think out side the box for our customers. Prior experience with machine learning is not required, though will be helpful.

You will join a development team that interacts with marketing and data scientist teams. Our team researches and builds channels through which we engage and stay connected with our customers, such as dynamic video ads, personalized e-mail recommendations, amazon retail websites and social media. The services we build rely on leading edge machine learning techniques to learn about our customer needs and to match them with a wide array of video content. In short, we have exciting challenges in an industry that's doubling in size every year, and you can be a part of it!

You should expect to exercise both your coding skills and creative abstract thinking as you map real world processes to automated systems. Please be aware that even though diving deep into machine learning algorithms is not a requirement for this position, a small, but statistically significant percentage of developers find their propensity for math dangerously elevated over time.

If you are ready to truly make an impact on a product that interacts with millions of people around the world, including your own friends and family, then we would love to talk to you!

Amazon is an Equal Opportunity-Affirmative Action Employer - Minority/Female/Disability/Vet
Basic Qualifications
4+ years of non-internship professional software development experience
Programming experience with at least one modern language such as Java, C++, or C# including object-oriented design
1+ years of experience contributing to the architecture and design (architecture, design patterns, reliability and scaling) of new and current systems.
* Bachelor's Degree in Computer Science or related field
Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.",-1,Amazon Corporate LLC,"Seattle, WA",-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Outbound Communications is one of the fastest growing strategic businesses within Amazon. Our team is responsible for creating the best interactive notification experience for customers wherever they go on Amazon. We are passionate about building scalable, well-designed software which processes billions of transactions and very large TPS. We constantly improve our technical foundation and customer experience.

As a Data Engineer on the Analytics team, you'll have huge impact on how customers, even friends and family, engage with Amazon through building infrastructure to answer questions with data, using software engineering best practices, data management fundamentals, and recent advances in distributed systems (i.e. MapReduce, noSQL databases). You will work with passionate scientists, business intelligence engineers, software development engineers and product managers, to deliver a variety of stable and performant data feeds used for developing business insights as well as offline machine learning use cases.

We love to work with smart people who have a strong sense of ownership and strong engineering mindset. You are a technical leader for your team and a great mentor. You provide perspective and context for technology choices. You're up to the challenge of realtime notification strategies, latency, TPS, mobile network limitations, device fragmentation, and building an end-to-end platform that internal Amazon teams integrate with. You motivate your team to pursue ambiguous situations and rapidly produce prototypes for a more personalized experience. You outline paths from prototype to product. You deeply invest in each colleague's career growth, improving their technical knowledge, and defining your team's operational metrics.

CORE RESPONSIBILITIES:
Contribute to the architecture, design and implementation of next generation BI solutions - including streaming data applications.
Manage AWS resources including EC2, RDS, Redshift, Kinesis, EMR, Lambda etc.
Collaborate with data scientists, BIEs and BAs to deliver high quality data architecture and pipelines.
Interface with other technology teams to extract, transform, and load data from a wide variety of data sources
Continually improve ongoing reporting and analysis processes, automating or simplifying self-service support for customers
Amazon.com is an Equal Opportunity-Affirmative Action Employer - Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation.
Basic Qualifications
Bachelor's degree in computer science, engineering, mathematics, or a related technical discipline
4+ years of industry experience in software development, data engineering, business intelligence, data science, or related field with a track record of manipulating, processing, and extracting value from large datasets
Experience using big data technologies (Hadoop, Hive, Hbase, Spark, EMR, etc.)
Knowledge of data management fundamentals and data storage principles
Knowledge of distributed systems as it pertains to data storage and computing
Hands-on experience and advanced knowledge of SQL
Basic knowledge of UNIX shell scripting
Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.",-1,Amazon Corporate LLC,"Seattle, WA",-1,-1,-1,-1,-1,-1,-1,-1
Data Scientist / Engineer (Machine Learning /R),-1,"DTS is looking for Data Scientist Engineer (Machine Learning R) for a long term contract with our direct client Position in Charlotte, NC. No third party C2C allowed. Candidates have to work directly with us on our W-2. Required Skills We are currently looking for an experienced Data Scientist with deep technical and statistical knowledge and a proven track record to drive business value using advanced data analysis and machine learning techniques. This position will collaborate with executives and other business departments to execute a variety of analytical projects to improve processes and create efficiencies. PRINCIPAL DUTIES AND RESPONSIBILITIES Analyze complex data sets to reduce costs and improve customer experience. Create systems for gathering, extracting, preparing data from multiple sources. Understand operational key performance indicators, report trends and patterns. Effectively communicate analysis with proper measurements and testing. Formulate enhancements through system optimizations and continual data analysis. Champion process improvements assessing pre-and post-process change. Collaborate across Operations, Compliance, IT, Finance, or other departments. QUALIFICATIONS Bachelorrsquos or Master's or PHD in Statistics, Mathematics, Computer Science, or another quantitative field. 5+ years of experience manipulating data sets and building statistical models. Hands-on experience using statistical computer languages (Python, R) to manipulate data and draw insights from large data sets. 4+ years of programming experience using R and Python You understand data structures, data modeling, and the basics of software architecture. You enjoy building end-to-end data products leveraging both structured and unstructured datasets.. Proven experience solving complex business problems using Statistical and Machine Learning techniques. Strong SQL and data-wrangling skills ndash experience building datasets from scratch. Please forward your resume to itjobsdts-it.com Contact Ajay 248-243-1381",1.0,"Digital Technology Solutions
1.0","Charlotte, NC","Belgrade, Serbia",1 to 50 employees,-1,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Senior Software Engineer - Machine Learning - Time Series,"$138K-$237K
(Glassdoor est.)","Senior Software Engineer - Machine Learning - Time Series

Team: Applied ML

Location: Sunnyvale, CA

ABOUT THE ROLE

Petuum is seeking outstanding MS or PhD-level engineers in machine learning management, distributed systems, deep learning, natural language understanding, and other related fields. You will be part of a team of world-class engineers, designers, and scientists, working together to democratize the building and deployment of AI and Machine Learning systems. You will have ownership over the projects you work on and have the flexibility to influence the design and execution of your team's work. A hard-working entrepreneur spirit is highly valued and rewarded in the company.

What You Will Do:
Design, implement and evaluate new models and software prototypes to solve problems in machine learning and systems engineering.
Create software design and programming support to machine learning projects.
Implement and evaluate machine learning algorithms.
Report and present software developments including clear and efficient status and results both internally and externally, verbally and in writing.
Architect and implement software libraries.
Experience leading a team of Machine Learning Engineers, Data Scientists, and Software Engineers.
Review code and mentor junior engineers on best practices.
Build the code architecture on which any future development might be based on.
Other duties as assigned.
What You've Already Done:
You have a Master's Degree in Computer Science or related quantitative field. A Ph.D. or equivalent practical work experience is a plus.
You have 4+ years of experience.
Experience with implementing statistical or machine learning algorithms, algorithm design and software engineering.
Experience in machine learning, recommendation systems, pattern recognition, analytics or artificial intelligence. Proven ability to translate insights into business recommendations.
Experience with filesystems, server architectures, and distributed systems is a plus.
Startup experience is a plus.
What You Already Know:
Languages: Python, C++
What We Offer for your Valuable Work:

Petuum offers Medical, Dental, Vision, Life/Disability, Paid Time Off, Parental Leave, and more.

Petuum is a welcoming workplace that considers applicants for employment without regard to, and does not discriminate on the basis of, gender, race, protected veteran status, disability, or any other legally protected status. Petuum is an at-will employer.",2.5,"Petuum
2.5","Sunnyvale, CA","Pittsburgh, PA",51 to 200 employees,2016,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
"Data Engineer Lead, Machine Learning",-1,"BICP is partnered with an iconic retail client to hire a Machine Learning Data Engineer Lead to join the global Data, Analytics & AI team. Our clients singular focus is to revolutionize and redefine the apparel business. The global Data, Analytics & AI is best framed up as having the vibe of a startup but with considerable technology assets at your fingertips, where you will have a chance to work with the latest and greatest technologies to deliver cutting edge solutions that will significantly impact how we do business. As a ML Data Engineer Lead, you will work on a broad set of domains that power a data driven transformation of our standard business procedures across channels and organizations. You will be responsible for developing and deploying novel algorithms along with optimizing existing machine learning systems to maximize their business value and increase consumer satisfaction at every brand touchpoint.

We’re looking to hire a technology-agnostic polymath committed to a lifelong journey of continuous learning and exploration of innovative scientific ideas and will bring thoughtful perspectives, empathy, creativity, and a positive attitude to solve problems at scale. This role is ideal for someone looking to extend their algorithm design and software engineering skills into a part mentor, part IC, part thought partner role. You will serve a large role in driving the client’s transformation into a data-driven enterprise.

Job Responsibilities
Architect, build, maintain, and improve new and existing suite of algorithms and their underlying systems.
Implement end-to-end solutions for batch and real-time algorithms along with requisite tooling around monitoring, logging, automated testing, performance testing and A/B testing.
Utilize your entrepreneurial spirit to identify new opportunities to optimize business processes and improve consumer experiences, and prototype solutions to demonstrate value with a crawl, walk, run mindset.
Work closely with data scientists and analysts to create and deploy new product features on the ecommerce website, in-store portals and the company’s mobile app.
Establish scalable, efficient, automated processes for data analyses, model development, validation and implementation
Write efficient and well-organized software to ship products in an iterative, continual-release environment
Contribute to and promote good software engineering practices across the team
Mentor and educate team members to adopt best practices in writing and maintaining production machine learning code
Communicate clearly and effectively to technical and non-technical audiences equally well
Actively contribute to and re-use community best practices
Embody the values and passions that characterize our organization with empathy to engage with colleagues from a wide range of backgrounds
Required Skills
University or advanced degree in engineering, computer science, mathematics, or a related field
5+ years’ experience developing and deploying machine learning systems into production
Strong experience working with a variety of relational SQL and NoSQL databases
Strong experience working with big data tools: Hadoop, Spark, Kafka, etc.
Experience with at least one cloud provider solution (AWS, GCP, Azure)
Strong experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.
Ability to work in a Linux environment
Industry experience building and productionizing innovative end-to-end Machine Learning systems
Ability to quickly prototype ideas and solve complex problems by adapting creative approaches
Experience working with distributed systems, service oriented architectures and designing APIs
Strong knowledge of data pipeline and workflow management tools
Expertise in standard software engineering methodology, e.g. unit testing, test automation, continuous integration, code reviews, design documentation
Relevant working experience with Docker and Kubernetes is a big plus
Additional Key Metrics
Preference will be given to candidates either based in, or willing to relocate to, Dallas/Ft. Worth or San Francisco area.
US Citizens, Green Card & H1B Visa holders are eligible for consideration and welcome to apply. Client has ability to transfer H1B’s and sponsor.
Start date is ASAP and compensation is negotiable contingent on experience and qualifications.
Job Type: Full-time

Pay: $160,000.00 - $180,000.00 per year

Benefits:
401(k)
Dental Insurance
Employee Discount
Health Insurance
Paid Time Off
Vision Insurance
Supplemental Pay:
Signing Bonus
Experience:
AWS, Azure or GCP: 1 year (Preferred)
Scala: 1 year (Preferred)
Kafka: 1 year (Preferred)
Java: 1 year (Preferred)
SQL: 3 years (Required)
Python: 1 year (Required)
Machine Learning: 1 year (Required)
NoSQL: 1 year (Preferred)
Spark: 1 year (Preferred)
Education:
Bachelor's (Required)
Work authorization:
United States (Required)
Additional Compensation:
Bonuses
Store Discounts
This Company Describes Its Culture as:
Innovative -- innovative and risk-taking
Stable -- traditional, stable, strong processes
People-oriented -- supportive and fairness-focused
Schedule:
Monday to Friday
Day shift
Work Remotely:
Temporarily due to COVID-19",5.0,"BICP
5.0","Fort Worth, TX","Carlsbad, CA",1 to 50 employees,2009,Company - Private,IT Services,Information Technology,$10 to $25 million (USD),-1
Senior Data Software Engineer,-1,"About CrunchbaseCrunchbase helps the world discover and connect with the
companies that matter. Our data platform is the foundation on top of
which all these connections can be made - it not only powers the data
at the heart of Crunchbase, but also hundreds of external sites and
applications around the world. Our mission is to democratize the way
innovators connect to opportunities, and over 50 million
professionals including entrepreneurs, investors, market researchers,
and salespeople trust Crunchbase to inform their business decisions.
We are hiring Data Engineers to join the Data Engineering team to help
us build pipelines, tools, derive insights from the data we already
have, as well as add more data from external sources to improve our
platform.
Engineering at CrunchbaseThe Crunchbase engineering team is a dynamic,
fast-paced team that is committed to quickly delivering features,
evaluating their performance, and iterating towards the product vision
shared by the company.We are organized in vertical teams that include
cross-functional engineers as well as functional guildes aimed at
working tightly with the product team to deliver high standards of
code while iterating quickly on features. We value open and honest
communication and strive to build an environment where opinions and
views can be shared and considered in an effort to reach the best
decision.
Data Integrations Team Our Data Integrations team is responsible for
building and maintaining all automated solutions to get data from
various sources into our platform, as well as the frameworks and
processes to export this data. As Crunchbase grows, so does the amount
of data we process, the number of sources it comes from, and the
insights we derive from it. At its core, Crunchbase is a data company,
and data integrations is at the heart of our platform.
What You Will Do
Architect and build new dimensional data models and schema
designs to improve accessibility, efficiency, consistency, and
quality of both internal and production data
Build, monitor, and maintain analytics and production data ETL
pipelines
Provide the foundation for a data-driven culture by empowering
other engineers and the Product team to ask questions of the
dataset in an easy, reliable way
Enable data scientists to implement NLP and ML algorithms at
scale, in fault-tolerant, highly available systems
Who You Are
You have 3-4+ years of industry experience
You have a proven understanding of computer science and software
engineering fundamentals
You can code in Python
Experience with Kubernetes Kafka, Spark, data warehousing, or
Airflow a plus. If no experience, you are passionate about
learning
You may have experience building data pipelines or supporting
machine learning algorithms in production
You have excellent verbal and written communication skills
You care about agile software, cross-team collaborations, and
data-driven development and evaluation
What Crunchbase Offers
Competitive salary and equity
Generous Reimbursement policy for learning and development
activities
Daily catered lunches and plenty of snacks
Fitness reimbursement (to work off the catered lunches)
Flexible Paid Time Off (PTO)
Volunteering Paid Time Off
Incredible medical, vision and dental benefits for employees and
their families
Free One Medical Group membership for employees and their
families
401(k) and Roth plans, and free annual financial adviser
check-in
Monthly commuting stipend
Free Lyft rides anywhere in the Bay Area after late nights at
the office
Prime location in the Financial District of SF, near BART and
Muni stops
A team of creative, transparent entrepreneurs driven to
accomplish our mission
Crunchbase does not discriminate on the basis of race, creed, color,
ethnicity, national origin, religion, sex, sexual orientation, gender
expression, age, height, weight, veteran status, military obligations,
or marital status. Every day our team is honored to work with
entrepreneurs and innovators from every corner of the globe, and we
seek to build a team that reflects the diversity of our customers.
Each individual at Crunchbase brings their own perspectives, work
experiences, lifestyles, and cultures with them, and we believe that a
more diverse team builds more innovative products, provides a better
service to its customers, and helps us all grow and learn as
individuals.
#LI-MF1Apply for this job",4.4,"CrunchBase
4.4","San Francisco, CA","San Francisco, CA",51 to 200 employees,2007,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Senior Data Engineer,-1,"Job Application for Senior Data Engineer at PanjivaFirst Name *Last Name *Email *Phone *Location (City) *Resume/CV *Drop files hereAttach Dropbox Google Drive PasteCover LetterDrop files hereAttach Dropbox Google Drive PasteWhen autocomplete results are available use up and down arrows to review+ Add Another EducationLinkedIn ProfileWebsiteHow did you hear about this job?Security Clearance *Please selectNo Clearance Active Confidential Active Secret Active Top Secret Active Top Secret SCI Inactive Confidential Inactive Secret Inactive Top Secret Inactive Top Secret SCIWork AuthorizationPlease selectUnited States Citizen or Permanent Resident US Work Visa Holder No Visa: Seeking Work AuthorizationSchoolDegree High School Associate's Degree Bachelor's Degree Master's Degree Master of Business Administration (M.B.A.) Juris Doctor (J.D.) Doctor of Medicine (M.D.) Doctor of Philosophy (Ph.D.) Engineer's Degree OtherDiscipline Accounting African Studies Agriculture Anthropology Applied Health Services Architecture Art Asian Studies Biology Business Business Administration Chemistry Classical Languages Communications & Film Computer Science Dentistry Developing Nations Discipline Unknown Earth Sciences Economics Education Electronics Engineering English Studies Environmental Studies European Studies Fashion Finance Fine Arts General Studies Health Services History Human Resources Management Humanities Industrial Arts & Carpentry Information Systems International Relations Journalism Languages Latin American Studies Law Linguistics Manufacturing & Mechanics Mathematics Medicine Middle Eastern Studies Naval Science North American Studies Nuclear Technics Operations Research & Strategy Organizational Theory Philosophy Physical Education Physical Sciences Physics Political Science Psychology Public Policy Public Service Religious Studies Russian & Soviet Studies Scandinavian Studies Science Slavic Studies Social Science Social Sciences Sociology Speech Statistics & Decision Theory Urban Studies Veterinary Medicine OtherStart DateEnd DatePowered byRead our Privacy Policy{""@context"":""schema.org"",""@type"":""JobPosting"",""hiringOrganization"":{""@type"":""Organization"",""name"":""Panjiva""},""title"":""Senior Data Engineer"",""datePosted"":""2020-01-24"",""jobLocation"":{""@type"":""Place"",""address"":{""@type"":""PostalAddress"",""addressLocality"":""Cambridge, Massachusetts, United States of America"",""addressRegion"":""MA"",""addressCountry"":null,""postalCode"":null}},""description"":""\u003ch2\u003e\u003cstrong\u003eAbout Panjiva\u003c/strong\u003e\u003c/h2\u003e\n\u003cp\u003e\u003cspan style=\""font-weight: 400;\""\u003ePanjiva is a data-driven technology company that uses machine learning to provide powerful search, analysis, and visualizations of billions of shipping records from nearly every country in the world. More than 3,000 customers in over 100 countries, ranging from Fortune 500 companies and startups to government agencies and hedge funds, rely on our platform for supply chain intelligence. In global trade, better insight means better decision making and stronger connections between companies and governments across the globe.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan style=\""font-weight: 400;\""\u003eRecognizing Panjiva's cutting-edge technology, S\u0026amp;P Global acquired Panjiva in 2018. This acquisition has grown our resources, dramatically expanded our access to data, and accelerated our growth plans.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan style=\""font-weight: 400;\""\u003ePeople are Panjiva's greatest strength - join our engineering team as we revolutionize a key and fascinating part of the world economy!\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e \u003c/p\u003e\n\u003ch2\u003e\u003cstrong\u003eJob Description\u003c/strong\u003e\u003c/h2\u003e\n\u003cp\u003e\u003cspan style=\""font-weight: 400;\""\u003eAs a data engineer on our team, you will play a key role in developing our next-generation data science infrastructure and underlying core technologies. You will work with Panjiva's world-class data scientists, analysts, and engineers to create products that solve important real-world business problems in a collaborative, fast-paced, and fun environment.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan style=\""font-weight: 400;\""\u003eYou'll work closely with our data science team to develop new platforms, infrastructure, and tools that will allow for advanced machine learning and artificial intelligence applications at production scale over massive (and ever-growing) datasets. Using cutting-edge distributed parallel processing systems and technologies like Hadoop and Spark, you will be tasked with architecting and implementing systems that find ways to apply complex transformations over vast amounts of data that might typically take hours or days, on the scale of seconds or minutes.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan style=\""font-weight: 400;\""\u003eYou'll design and leverage distributed computing technologies, data schemas, APIs, and event-driven architectures to construct powerful data science pipelines that bring-to-life Panjiva's machine learning and NLP algorithms. In addition, you'll be expected to participate in augmenting our infrastructure to seamlessly integrate orders-of-magnitude-more data through constant R\u0026amp;D of the technologies, and systems we use.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan style=\""font-weight: 400;\""\u003eJoin us in building the next generation of products as we continue to deliver valuable and actionable insights to decision-makers in the $15 trillion global trade industry.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e \u003c/p\u003e\n\u003ch2\u003e\u003cstrong\u003eResponsibilities\u003c/strong\u003e\u003c/h2\u003e\n\u003cul\u003e\n\u003cli style=\""font-weight: 400;\""\u003e\u003cspan style=\""font-weight: 400;\""\u003eArchitect and implement distributed systems that perform complex transformations, processing, and analysis over very large scale datasets\u003c/span\u003e\u003c/li\u003e\n\u003cli style=\""font-weight: 400;\""\u003e\u003cspan style=\""font-weight: 400;\""\u003eWorking with our data scientists to turn large-scale messy, diverse, and often unstructured data into a source of meaningful insights for our customers\u003c/span\u003e\u003c/li\u003e\n\u003cli style=\""font-weight: 400;\""\u003e\u003cspan style=\""font-weight: 400;\""\u003eMaintaining data integrity across various data sources\u003c/span\u003e\u003c/li\u003e\n\u003cli style=\""font-weight: 400;\""\u003e\u003cspan style=\""font-weight: 400;\""\u003eOptimizing slow-running database queries and data pipelines\u003c/span\u003e\u003c/li\u003e\n\u003cli style=\""font-weight: 400;\""\u003e\u003cspan style=\""font-weight: 400;\""\u003eHelping enhance our search engine, capable of running sophisticated user queries quickly and efficiently\u003c/span\u003e\u003c/li\u003e\n\u003cli style=\""font-weight: 400;\""\u003e\u003cspan style=\""font-weight: 400;\""\u003eBuilding internal tools and backend services to enable our data scientists and product engineers to improve efficiency\u003c/span\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cspan style=\""font-weight: 400;\""\u003e \u003c/span\u003e\u003c/p\u003e\n\u003ch2\u003e\u003cstrong\u003eQualifications\u003c/strong\u003e\u003c/h2\u003e\n\u003cul\u003e\n\u003cli style=\""font-weight: 400;\""\u003e\u003cspan style=\""font-weight: 400;\""\u003eB.S., M.S., or Ph.D. in Computer Science (or a related field) or equivalent work experience\u003c/span\u003e\u003c/li\u003e\n\u003cli style=\""font-weight: 400;\""\u003e\u003cspan style=\""font-weight: 400;\""\u003e5+ years of experience in working with data-at-scale in a production environment\u003c/span\u003e\u003c/li\u003e\n\u003cli style=\""font-weight: 400;\""\u003e\u003cspan style=\""font-weight: 400;\""\u003eExperience designing and implementing large-scale, distributed systems\u003c/span\u003e\u003c/li\u003e\n\u003cli style=\""font-weight: 400;\""\u003e\u003cspan style=\""font-weight: 400;\""\u003eExperience in multi-threaded software development (or \u003c/span\u003e\u003cem\u003e\u003cspan style=\""font-weight: 400;\""\u003esome \u003c/span\u003e\u003c/em\u003e\u003cspan style=\""font-weight: 400;\""\u003eform of parallelism)\u003c/span\u003e\u003c/li\u003e\n\u003cli style=\""font-weight: 400;\""\u003e\u003cspan style=\""font-weight: 400;\""\u003eSignificant performance engineering experience (e.g., profiling slow code, understanding complicated query plans, etc.)\u003c/span\u003e\u003c/li\u003e\n\u003cli style=\""font-weight: 400;\""\u003e\u003cspan style=\""font-weight: 400;\""\u003eSolid understanding of core algorithms and data structures, including the ability to select (and",4.2,"Panjiva
4.2","Cambridge, MA","New York, NY",1 to 50 employees,2006,Company - Private,Internet,Information Technology,$1 to $5 million (USD),-1
Senior Data Engineer/Data Scientist,-1,"We are a recruiting agency that works hard to tailor the right synergy between candidate and company. We do this by looking at the career experience and goals of each candidate and clarifying the specific needs of the job with each hiring manager and team.

We are currently seeking a Senior Data Engineer/Data Scientist for an entertainment company in Burbank. The Data Engineer will lead an exciting team in developing innovative technology and delivering uniquely creative content globally. The salary for the Data Engineer starts at $90 per hour.

Please, only apply if you are able to work directly for a U.S. company for the next three years. We are not currently able to work with C2C, H1, or OPT for this position.

Duties & Responsibilities:
Build and optimize performance of Hadoop and Spark batch jobs (Spark, Kafka, Cassandra, etc.).
Construct and improve ElasticSearch performance.
Build data pipelines orchestration.
Create the design and architecture for data-lake, data-marts, data-models, and data-warehouse.
Ensure efficiency of data science workflows and advanced machine learning algorithms.
Contribute to open source solutions and communities.
Stay current on emerging tools and technologies.
Collaborate cross-functionally with other software engineers and their teams.
Establish and demonstrate technologies, solutions, and leading practices.
Balance resources, requirements, and complexity.
Qualifications:
At least, 5 years Data Engineer experience.
Bachelors in Computer Science or similar field.
Possess a passion for coding.
Knowledge of distributed systems and computation.
Experience with Scala, Java, Python, and Go-Lang.
Experience with Apache Hadoop/Spark ecosystem.
Demonstrated working knowledge of data modeling.
Stellar interpersonal and communication skills.
Required Experience:
Git, Unix/Linux, Unit, Integration, Load Testing, developing REST APIs, Ant, Maven, SBT, Gradle, and Docker containers building and deployment.
Experience, preferred:
Jenkins, GraphQL, Amazon AWS (or other cloud services), Kubernetes, Apache Spark (MLib and Graph X).
Salary for the Data Scientist:
Starts at $90/hour.
Powered by JazzHR",-1,Evolvinc,"Burbank, CA","Los Angeles, CA",1 to 50 employees,2005,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Senior Software Engineer (R,"$88K-$168K
(Glassdoor est.)","Description

SiriusXM and Pandora have joined together to create the leading audio entertainment company in the U.S. Together, we are uniquely positioned to lead a new era of audio entertainment by delivering the most compelling subscription and ad-supported audio experiences to millions of listeners -- in the car, at home and on the go. Our talent, content, technology and innovation continue to be at the forefront, and we want you to be a part of it! Check out our current openings below and at

Position Summary:
As a senior member of the Search team at Pandora/SiriusXM you are responsible for building and maintaining the service that supports Search functionality interactions across our native mobile and web applications, automotive systems and third party devices.
You work closely with Product Management and Data Science partners to implement innovative features and measure their impact. You're comfortable working in a distributed team, in a fast paced environment and have excellent written and verbal communication skills. You have a collaborative attitude and love working with others to find elegant solutions to complex problems, always keeping the end user in mind. You have a solid foundation of Java development and are comfortable building services at scale. You are familiar with cloud software deployment and monitoring tools and are enthusiastic about learning new technologies and skills. You have a backgound in Search or Recommender systems or a deep curiousity and willingness to learn.
Duties and Responsibilities:
Write high performant, well-documented code.
Excellent complex problem solving and critical thinking skills
Deploy application on prem and on cloud.
Understands the requirements mentioned in the document/stories strategize a solution.
Supervisory Responsibilities:
This role has no supervisory responsibilities.
Minimum Qualifications:
Must have a Bachelor's degree in Computers
Requirements and General Skills:
5+ years development experience with a focus on microservice development
Working knowledge of Elastic Search or other search framework
Experience deploying code to production environments
Experience with cloud computing (Google Cloud Platform, Amazon Web Services)
Experience with Spring/SpringBoot
Experience with Recommender, or Search systems.
Working knowledge of Logstash and Kibana
Working knowledge of Kafka
Experience collaborating with data scientists, exposure to machine learning algorithms and/or statistical modeling methods.
Interpersonal skills and ability to interact and work with staff at all levels.
Ability to work independently and in a team environment.
Ability to pay attention to details and be organized.
Ability to project professionalism over the phone and in person.
Ability to handle multiple tasks in a fast-paced environment.
Willingness to take initiative and to follow through on projects.
Excellent time management skills, with the ability to prioritize and multi-task, and work under shifting deadlines in a fast-paced environment.
Must have legal right to work in the U.S.
Technical Skills:
Working knowledge of Java, Elastic Search, Kibana, Logstash, Python.
Working knowledge of Clojure is a plus.
Should be familiar with Agile working methodologies.
Familiar with Team city, Jenkins, AWS.
Working knowledge of Kafka.
Good Understanding of Agile methodologies.
Thorough knowledge of MS-Office Suite (Word, Excel, PowerPoint, Access).
Our goal at SiriusXM+Pandora is to provide and maintain a work environment that fosters mutual respect, professionalism and cooperation. SiriusXM+Pandora is an equal opportunity employer that does not discriminate on the basis of actual or perceived race, creed, color, religion, national origin, ancestry, alienage or citizenship status, age, disability or handicap, sex, gender identity, marital status, familial status, veteran status, sexual orientation or any other characteristic protected by applicable federal, state or local laws.
The requirements and duties described above may be modified or waived by the Company in its sole discretion without notice.",3.5,"Pandora Media, Inc.
3.5","New York, NY","Oakland, CA",1001 to 5000 employees,2000,Company - Public,Radio,Media,$500 million to $1 billion (USD),-1
Machine Learning Engineer - Simply Biotech,-1,"Machine Learning Engineer - Simply BiotechAre you looking for a new career opportunity with an exciting biotech company?! Then we have got the right team for you! In this role, you are responsible for the duties listed below. Immediate opening for a Machine Learning Engineer in Palo Alto, CA who possess: -PhD, MS, or BS in computer science, engineering, statistics, or similar -2+ years of technical industry experience (biotech and software engineering preferred) -Must have experience with development and deployment in a production environment -Significant experience with Python -Significant experience with a deep learning framework (high preference for PyTorch & TensorFlow) Email your resumes to mdaniels@simplybiotech.com or call 858.239.2849 FULL DESCRIPTION: As a (Senior) Machine Learning Engineer, you will lead the development and deployment of advanced machine learning models that will give greater resolution into the health and molecular state of patients. You will work closely with an inter-disciplinary team of laboratory scientists, data scientists, and engineers to ensure the company meets its key milestones and objectives as well as identify additional opportunities where machine learning can bring real business value. You will also have the advantageous opportunity to collaborate on the data generation process itself. The selected candidate will further possess: -Experience with developing and deploying in a cloud platform e.g. AWS, GCP, Azure -Fundamental knowledge of probability and statistics in their application to developing and deploying machine learning models -Ability to communicate and collaborate with an inter-disciplinary team -Ability to translate business-level and scientific-level objectives to engineering objectives -Experience with clinical or biological data e.g. genomics, proteomics, imaging, EMR -Experience in NLP or image recognition applications -Experience with knowledge graphs For immediate and confidential consideration, please email your resume to mdaniels@simplybiotech.com or call 858.239.2849 More information can be found at www.SimplyBiotech.com",4.6,"TalentZok
4.6","Palo Alto, CA","San Diego, CA",51 to 200 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
"Sr. Backend Engineer, Machine Learning","$130K-$198K
(Glassdoor est.)","At Globality, we're proud to embody the core values of innovation, collaboration, and trust in both our culture and product.
We're creating ground-breaking technology utilizing a world-class, AI-powered Platform that revolutionizes how businesses buy and sell services. We are an open, inclusive, and diverse organization and our employees are at the heart of the great products we create.

We've raised over $172M and are supported by an impressive group of prominent investors, including Al Gore and SoftBank Vision Fund. Our co-founders, Joel Hyatt and Lior Delgo, are seasoned entrepreneurs who bring an extensive business-building experience to our organization. Our impressive board includes Dennis Nally (former Global Chairman of PwC) and Ron Johnson (former SVP of Apple).

Role Summary:
We seek an engineer with a passion for building machine learning and data pipeline solutions to power intelligent product features at scale.

Does this sound like you?

Are you excited about separating signal from noise in web-scale datasets?

Do you enjoy building software that improves user experience by helping users reach the right conclusions?

Does your ideal work environment involve collaborating within multi-functional teams in a dynamic startup environment?

Are you motivated by directly impacting the core technologies that power a meaningful business platform?

If so, you should join our team.

What you will be doing:
Be a lead contributor to the design and implementation of our core infrastructure and data pipeline, powering our Machine Learning and NLP products. In collaboration with our data scientists and senior engineers, you'll be improving indexing logic, tuning relevancy, and optimizing performance, towards the overall goal of delivering a delightful user experience to our end-users and internal users, across a range of ML-powered products
Wrangle messy data. Real-world data, especially as found on the web, comes in all shapes and sizes, and can often be noisy. Working alongside our NLP engineers, drive solutions for cleaning noisy text, normalizing it and ensuring high-quality data through-out our ML pipeline.
What we are looking for:
You have at least 5 years of software development experience in crafting high performance, reliable and scalable production systems
You have strong engineering experience in Python, in particular in the context of ML applications, using frameworks such as pandas, nltk, Pattern, spaCy.
You have experience working with noisy textual data, and are familiar with the various text normalization methodologies that are employed to index such data effectively
Deep understanding of core computer science fundamentals and distributed systems
Bonus: You have ample experience with Information Retrieval and Web Search systems, such as Elasticsearch, ideally cloud-based deployments such as via AWS or Elastic Cloud.
We are an equal opportunity employer and a participant in the E-Verify program. We believe diversity makes teams better and that discrimination based on race, gender, or anything else is self-defeating.",4.4,"Globality, Inc.
4.4","Menlo Park, CA","Menlo Park, CA",201 to 500 employees,2015,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
"Senior Software Engineer - Hadoop, Big Data Tools and Automation","$127K-$209K
(Glassdoor est.)","Posted: Jul 15, 2020
Weekly Hours: 40
Role Number:
200159616
Imagine what you could do here. At Apple, great ideas have a way of becoming great products, services, and customer experiences very quickly. Bring passion and dedication to your job and there's no telling what you could accomplish.

Apple’s Applied Machine Learning team has built systems for a number of large-scale data science applications. We work on many high-impact projects that serve various Apple lines of business. We use the latest in open source technology and as committers on some of these projects, we are pushing the envelope. Working with multiple lines of business, we manage many streams of Apple-scale data. We bring it all together and extract the value. We do all this with an exceptional group of software engineers, data scientists, SRE/devops engineers and managers.
Key Qualifications
Experience building tool for management of large hadoop cluster for the adminitartion and management.
Experience building tools for the capacity planning show resource consumption by users and jobs for capacity planning, showbacks and chargeback.
Experience with Kafka and streaming technologies.
Experience building large data pipelines for engrossing/egressing data with minumum resource requirements.
Expert level understanding of Hadoop based technologies - HDFS/Yarn cluster administration, Hive, Spark.
Expertise in python and java.
Expert understanding of Unix/Linux based operating system.
Excellent problem solving, critical thinking, and communication skills.
Experience deploying and managing CI/CD pipelines.
Expertise in configuration management (such as Ansible, salt) for deploying, configuring, and managing servers and systems.
The candidate should be adapt at prioritizing multiple issues in a high pressure environment.
Should be able to understand complex architectures and be comfortable working with multiple teams.
Should be highly proactive with a keen focus on improving uptime availability of our mission-critical services with automation and tooling.
Comfortable working in a fast paced environment while continuously evaluating emerging technologies
The position requires solid knowledge of secure coding practices and experience with the open source technologies.
Description
Description
We manage several large hadoop/YARN clusters running 10’s of thousands of jobs.

This role requires you an expert level understanding of hadoop/spark based technologies so that you can build right automation/tooling for the administration, capacity management and showback/chareback/resource visibility of the platform.

This also requires understanding of complete ecosystem of kafka, spark streaming and other streaming technologies, airflow to build a comprehensive end to end management and monitoring systems.

You are an independent problem-solver who is self-directed and capable of exhibiting deftness to handle multiple simultaneous competing priorities and deliver solutions in a timely manner.

Provide incident resolution for all technical production issues.

Create and maintain accurate, up-to-date documentation reflecting configuration, and responsible for writing justifications, training users in complex topics, writing status reports, documenting procedures, and interacting with other Apple staff and management.

Provide guidance to improve the stability, security, efficiency and scalability of systems.

Determine future needs for platform and investigate new products and/or features.

Strong troubleshooting ability will be used daily; will take steps on their own to isolate issues and resolve root cause through investigative analysis in environments where the candidate has little knowledge/experience/documentation.
Education & Experience
BS in computer science with 7+ years or MS plus 5+ years experience or related experience.

Experience with Kubernetes, Docker Swarm, or other container orchestration framework
Experience building and operating large scale hadoop/spark data pipeline used for machine learning in a production environment
Experience in tuning complex hive and spark queries
Expertise in debugging hadoop/spark/hive issues using Namenode, datanode, Nodemanager, spark executor logs.
Exeprience in Workflow and data pipeline orchestration (Airflow,Oozie,Jenkins etc.)
Experience in jupyter based notebook infrastructure.",4.1,"Apple
4.1","Santa Clara, CA","Cupertino, CA",10000+ employees,1976,Company - Public,Computer Hardware & Software,Information Technology,$10+ billion (USD),"Google, Microsoft, Samsung Electronics"
Senior Software Engineer in Test (SET),-1,"LeapYear's secure machine learning platform is deployed by some of the largest enterprises in the world across finance, healthcare, and technology.

Our technology ensures differential privacy, a widely recognized standard of data privacy that enables all data - including sensitive information - to be utilized for analytics, while providing mathematically proven privacy protection.

The LeapYear system is composed of a core set of components that allow private machine learning on data sets that can scale to petabytes. The core includes private algorithms for relational operations, statistical methods and machine learning. A data scientist accesses private data using a Python API. The system includes services for authentication, access control, logging, auditing and support for integration of data from a variety of data sources including SQL/NoSQL Databases, HDFS and S3. Queries are processed using Spark to support to enable fast, distributed processing of massive datasets. Administration is provided via a web-based GUI or an API.

We are looking for a Senior Software Engineer in Test (SET), who will lead the testing of LeapYear products. The role will require testing functionality, scalability, performance and availability. All tests will be automated.

For details on the specific responsibilities and requirements of this role, please see below.

Responsibilities
Work closely with the development team to develop test plans.
Define and implement automation strategies for testing the functionality of LeapYear’s products.
Define and implement an automated framework for scale, performance and availability testing.
Be accountable for the full lifecycle of your code from design to deployment.
Mentor other members of the SET team.
Develop automated systems for tracking quality metrics.

Requirements
Experience testing complex distributed systems that require scalability, reliability and flexibility.
5+ years of professional experience.
At least 3 years of experience in automation and testing.
Proficiency in a programming language such as Python, Java, C, Golang, Scala etc.
BS/MS in Computer Science/Engineering or related discipline.
Excellent oral and written communication skills.
Experience with Continuous Integration/Continuous Deployment tools(e.g. CircleCI, Travis)
Experience with cloud platforms (AWS, Azure, or GCP).
Experience with SQL/NoSQL databases.
Ability to get up to speed quickly on new technologies such as Machine Learning, Spark, differential privacy.

Preferred
Experience with big data technologies like Spark and/or Hadoop.
Experience developing for on-premise enterprise deployments.

A Few of the Perks
Culture of teaching and learning
Competitive compensation package of salary and equity
Catered lunch every day
Company outings
Build your ideal work station
Generous health insurance plan
Relocation support and visa sponsorship",4.2,"LeapYear
4.2","San Francisco, CA","San Francisco, CA",1 to 50 employees,2015,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Principal Software Engineer Manager,"$155K-$217K
(Glassdoor est.)","The Bing Ads MPS team is a world-class R&D team of passionate and talented scientists and engineers who aspire to solve challenging problems and turn innovative ideas into high-quality products and services that can help hundreds of millions of users and advertisers, and directly impact our business. Our experimentation infrastructure allows us to innovate and test new algorithms rapidly with live traffic to measure their effectiveness, and launch them in production as soon as they produce positive results, which makes our work environment productive and rewarding. We are looking for an Applied Scientist or Machine Learning Scientist to incubate technologies from end to end to make product impact. The candidate will engage in high potential projects grounded in applications to improve our ad, query and web page understanding.* Excellent Problem Solving and System Design Skills* 10+ years outstanding expertise and hands-on experience on one or more of Big Data Systems like Hadoop, Spark, Storm, Kafka OR Full stack development like Agluar, node.js and other web technologies* Experience and knowledge of managing highly motivated engineering team of 5+ engineers* BS/MS degree in CS or related areas required* Passionate, self-motivated* Effective communication skills, both verbal and written* Strong Data Structures, Algorithm fundamentalsMicrosoft is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable laws, regulations and ordinances. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. If you need assistance and/or a reasonable accommodation due to a disability during the application or the recruiting process, please send a request via the Accommodation request form.Benefits/perks listed below may vary depending on the nature of your employment with Microsoft and the country where you work.#BingAds#* Determine problems to solve based on data analysis and customer requirements* Design and build large scale low latency serving systems and data infrastructures* Lead and manage team of highly motivated and talented engineers* Drive Collaborations with other teams in Microsoft* Mentor other members of the team",4.3,"Microsoft Corporation
4.3","Bellevue, WA","Redmond, WA",10000+ employees,1975,Company - Public,Computer Hardware & Software,Information Technology,$10+ billion (USD),"Google, Amazon, Apple"
Data Scientist,"$83K-$136K
(Glassdoor est.)","Requisition ID: 48961

All Locations: Chantilly, VA (Virginia)

A trusted partner. A national resource. A leader in national security space. We are THE Aerospace Corporation. A team that takes pride in our readiness to solve some of the most complex technical challenges in existence. With challenges spanning clandestine to commercial, you’ll have the unique opportunity to work on projects that are literally evolving our nation's space and launch capabilities. We all share a common passion and aspiration – to serve a mission much bigger than ourselves. When you join our team, you’ll be part of a rare collection of thought leaders and game-changing innovators. Are you ready to launch your career?
Responsibilities
The Machine Intelligence and Exploitation Department applies data analytics, machine learning, and statistical analysis to diverse data types in order to address our customer's analytic needs. The candidate we seek will work with team members across multiple internal organizations and customers to develop innovative data-driven solutions.

Key Functions
Provide expertise in data analytics and algorithm development supporting the integration, analysis and exploitation of diverse data sources with an emphasis on remotely sensed data.
Ability to run and adapt existing machine learning, data mining and statistical algorithms for pattern recognition and anomaly detection.
Ability to create, develop, evolve, and improve machine learning, data mining, statistical, and predictive analytics algorithms for pattern recognition and anomaly detection on large diverse data sets.
Design, develop and advance new methods to extract information from diverse data sources using flexible querying methods, innovative visualization, and data aggregation/integration, data mining and analytical techniques.
Ability to understand the physical phenomenologies in the data.
Familiarity with data fusion techniques to help develop automated data aggregation applications.
Ability to create modular, hierarchical applications that assist in the automation of human activities.
Utilize technical knowledge to deliver high-quality support to multiple Federal Government customers including the oversight of other contractors.
Qualifications
Required
Degree from an accredited university in data science, statistics, applied mathematics or computer science. (Degrees in physical science or engineering are also acceptable).
A minimum of 7 years experience post Bachelor’s degree. (Time spent obtaining an advanced degree counts toward this).
Experience with remote sensing and/or signal processing.
Strong desire to gain experience in the application of machine learning, data mining, and statistical algorithms for pattern recognition, anomaly detection, and the development of predictive models.
Strong programming skills in at least one of the following languages: Python, R, Matlab, C++, and JAVA are required with Python being the preference.
Strong written and oral communication skills.
Must be able to work effectively within a diverse team of data scientists, software engineers, and intelligence analysts.
This position requires the ability to obtain and maintain a security clearance, which is issued by the U.S. government. U.S. citizenship is required to obtain a security clearance.
Strong problem-solving skills.
Strong software development skills.
Background in signal processing, image science, imagery exploitation, spectral analysis, spatial analysis, and computer vision.
Preferred
Advanced degree in data science, mathematics, statistics, computer science, physical science or engineering.
Experience in Deep Learning.
Experience in Natural Language Processing.
Knowledge of commercial and open-source statistical software packages.
Experience developing data visualizations or visual analytics applications.
Experience with a wide range of databases.
Current Top Secret clearance with SSBI.
Transcript Requirement
Transcripts are required for this position.

Additional Requisition Details

System Job Title: ENGRG SPECIALIST

Clearance Requirement: TS/SSBI

Access: SCI

Polygraph: Counter Intelligence Polygraph

Relocation Available: Yes

Employment Type: Regular

Work Schedule: Full Time

Company Statement

The Aerospace Corporation has provided independent technical and scientific research, development, and advisory services to national security space programs since 1960. We operate a federally funded research and development center (FFRDC) for the United States Air Force and the National Reconnaissance Office, and support all national security space programs. We also apply more than 50 years of experience with space systems to provide critical solutions to technologically complex systems in such areas as communications, shipping, law enforcement, and cyber, among others.

From our inception, our highly skilled technical staff has focused on ensuring the success of every mission and developing the most effective and economic space-related hardware and software in the world. Our greatest asset is the technical expertise of our people. Our state-of-the-art laboratory facilities are staffed by some of the leading scientists in the world.

Equal Opportunity Commitment

The Aerospace Corporation is an Equal Opportunity/Affirmative Action employer. We believe that a diverse workforce creates an environment in which unique ideas are developed and differing perspectives are valued, producing superior customer solutions. All qualified applicants will receive consideration for employment and will not be discriminated against on the basis of race, gender, gender identity or expression, color, religion, national origin, sexual orientation, protected veteran status, or disability status.

You can also review The Equal Employment Opportunity is the Law poster and the supplement, as well as the Pay Transparency Policy Statement.

Nearest Major Market: Washington DC
Job Segment:
Database, Scientific, Scientist, Engineer, Security Clearance, Technology, Engineering, Science, Government",3.9,"The Aerospace Corporation
3.9","El Segundo, CA","El Segundo, CA",1001 to 5000 employees,1960,Nonprofit Organization,Aerospace & Defense,Aerospace & Defense,$1 to $2 billion (USD),-1
Senior UI / Front End Engineer - Applied Machine Learning,"$110K-$240K
(Glassdoor est.)","Posted: Mar 26, 2020
Weekly Hours: 40
Role Number:
200161307
Imagine what you could do here. At Apple, great ideas have a way of becoming great products, services, and customer experiences very quickly. Bring passion and dedication to your job and there's no telling what you could accomplish.

Apple’s Applied Machine Learning team has built systems for a number of large-scale data science applications. We work on many high-impact projects that serve various Apple lines of business. We use the latest in open source technology and as committers on some of these projects, we are pushing the envelope. Working with multiple lines of business, we manage many streams of Apple-scale data. We bring it all together and extract the value. We do all this with an exceptional group of software engineers, data scientists, dev-ops engineers and managers.
Key Qualifications
Experience serving in a Lead/Senior role within a larger Front-End Engineering team
Strong understanding of JavaScript fundamentals
Experience with Single Page Application architecture
Proficient in node.js, angular, typescript. HTML5, DHTML and CSS3
Develop code and create unit tests for open source, Flux-based frameworks such as ReactJS.
Excellent communication and collaborative skills.
Experience developing and implementing UI/Front-end for high volume web applications.
Experience in Cross-browser development and troubleshooting
Proficient knowledge of Git and CI /CD pipelines
Knowledge of RESTFul services is a plus
Knowledge of Adobe Omniture is a plus
Experience building charts & visually presenting data using D3 is a plus
Description
Join Apple's AML Team, as a Search Software UI Engineer. You will work with other search engineers in the team for overall success for Search and other ML based systems. Collaborate with peers from other Engineering groups, MarCom, AppleCare and operations teams to solve complex and challenging problems with efficient and scalable delivery of Search solutions.

You are expected to be self-motivated, dedicated, and a solution-oriented individual. The main responsibilities for this position include:
Leading effort to build react based UI and taking it to production.
Should have knowledge of how dashboard and charts are created.
Should have experience and knowledge of how customer facing web pages and dynamic content is created and managed.
Work with cross functional teams to drive requirements.
Design and implement as per secure guidelines
Work with QA to identify issues and fix it.
Other aspects of the job include mentoring and providing feedback to junior developers, working with the team manager and PM in estimating scope and team capacity, responding to urgent requests from executives or business needs, and maintaining the stability and high reliability of our systems.
Education & Experience
Technical BS/MS/PHD or relevant industry experience.",4.1,"Apple
4.1","Santa Clara, CA","Cupertino, CA",10000+ employees,1976,Company - Public,Computer Hardware & Software,Information Technology,$10+ billion (USD),"Google, Microsoft, Samsung Electronics"
Senior Machine Learning Engineer,-1,"SiriusXM and Pandora have joined together to create the leading audio entertainment company in the U.S. Together, we are uniquely positioned to lead a new era of audio entertainment by delivering the most compelling subscription and ad-supported audio experiences to millions of listeners -- in the car, at home and on the go. Our talent, content, technology and innovation continue to be at the forefront, and we want you to be a part of it! Check out our current openings below and at www.siriusxm.com/careers.Position Summary:As part of the Shared Science Foundation team, you will design and build systems that solve prevalent science problems across SiriusXM and Pandora's digital products. These extensible, shared systems power personalization, content understanding, and advertising and marketing science. You will collaborate with scientists, engineers, and product managers to develop tools, platforms, and infrastructure that accelerates innovation of the entire organization. Your hybrid skill set of machine learning, software engineering, and empathetic communication uniquely positions you to architect systems with multiple stakeholders.Duties and Responsibilities:* Design and build the next-generation representation of SiriusXM and Pandora listeners' tastes and interests, incorporating music and non-music listening, favorites, contextual variation, and behavioral, advertising, and marketing signals.* Architect and build large-scale machine learning infrastructure for data exploration, prototyping, and production.* Write production code and data pipelines and conduct code reviews.* Promote and role-model best practices of data science, engineering, and communication throughout the organization.Supervisory Responsibilities:* NoneMinimum Qualifications:* 2+ years of industry experience as an applied data scientist or ML engineer.Requirements and General Skills:* Excellent written and verbal communication skills, with the ability to effectively advocate technical solutions to scientists, engineers, and product audiences.* Demonstrated ability to collaborate with and coordinate teams.* Self-motivated, growth-oriented, and driven to pursue solutions to challenging problems.* Must have legal right to work in the U.S.Technical Skills:* Production experience implementing machine learning pipelines and models at scale in Python, Java, Scala, or similar languages.* Proficiency with distributed processing and warehousing frameworks (e.g., Spark, Hadoop, Hive, Tez, etc.).* Experience with the research and development workflow/life-cycle for large-scale batch and streaming machine learning systems.* Experience architecting distributed systems and familiarity with software design patterns.* Ability to gather stakeholder requirements and evaluate technical trade-offs.Bonus Skills:* M.S. or Ph.D. in a quantitative field (CS, EE, Statistics, Physics, Math, etc.).* Passion for data-driven development, reliability, and disciplined experimentation.* Experience designing or building feature stores to integrate and version heterogeneous data types from heterogeneous data sources.* Experience with any of the following:* Cloud computing: Google Cloud Platform, Amazon Web Services, Azure* Technologies: Kafka, Airflow, Composer* ML-frameworks: TensorFlow, PyTorch, Vowpal Wabbit, scikit-learn* Knowledge of professional software engineering practices including coding standards, code reviews, source control management, build processes, testing, and operations.Our goal at SiriusXM+Pandora is to provide and maintain a work environment that fosters mutual respect, professionalism and cooperation. SiriusXM+Pandora is an equal opportunity employer that does not discriminate on the basis of actual or perceived race, creed, color, religion, national origin, ancestry, alienage or citizenship status, age, disability or handicap, sex, gender identity, marital status, familial status, veteran status, sexual orientation or any other characteristic protected by applicable federal, state or local laws.The requirements and duties described above may be modified or waived by the Company in its sole discretion without notice.",3.1,"Sirius XM
3.1","Oakland, CA","New York, NY",1001 to 5000 employees,1990,Company - Public,Radio,Media,$2 to $5 billion (USD),-1
Software Engineer (Java API),-1,"Job Description
All candidates must take a Coding Assessment.

Position Description:
This Software Engineering position is in the Connected Consumer and GDIA domains and is a highly technical position.
The position is responsible for. Delivery of Java APIs and Mobile Apps that allow our customers to move while staying connected to their vehicle.
Work as part of a product team to lead the engineering, development and coding of complex solutions that enable critical Connected Consumer and Vehicle Features.
Deliver software craftsmanship principles in the projects and be able to share the successful implementation.
Develop tools and processes to automate the delivery of new features/capabilities while elimination waste.
Experiment with new and innovative software projects that automates and improves performance of the software that enables Mobile App and Vehicle Communication.
Lead software engineers to understand platform vision, break out tasks and help them solve challenging issues.
Work hand to hand with Data Scientists to shape the future vision of our Data Science platform
Skills Required:
Basic Qualifications: Bachelor""s degree in Information Technology or a related field of study.
7+ years of object oriented development experience in API, Cloud, Mobile App or Machine Learning Technologies.
7+ years of experience in designing and developing scalable features
Preferred Qualifications:
Excellent software engineering knowledge; OO Design Principles.
eXtreme Programming (XP) disciplines including paired programming and Test-First/Test Driven Development (TDD).
Experience with Spring Cloud and deploying to cloud platforms, preferably Pivotal Cloud Foundry or Cloud Foundry.
Experience with Android and deploying to the Google Play Store.
Highly effective in working with other technical specialists, Product Managers, UI/UX Designers and Product Owners.
Delivered products that include web front-end development; JavaScript, client-side MVC frameworks like Angular, React, etc. Capable in Continuous Integration/Continuous Delivery tools and pipelines such as Jenkins, Maven, Gradle, etc. Understanding or desire to learn BI end to end technology stack (Tools such as Kubeflow, Kubernetes, SeldonCore, H2O, Data Robot, Anaconda, OpenScale, pytorch, tensorflow, xgboost etc)
Education Required:
B.S. Information Systems, Computer Science or equivalent work experience in the requested field",5.0,"BlueStone Staffing Solutions
5.0","Taylor, MI","Palatine, IL",51 to 200 employees,2002,Company - Private,IT Services,Information Technology,$10 to $25 million (USD),-1
REMOTE Senior Data Engineer,-1,"REMOTE Senior Data Engineer
We are one of the fastest-growing medical device companies in the world! We are publicly traded, have a global presence, but still operate like a startup. We have an agile, fast-paced team and are looking for Data Engineers that thrive in that kind of environment.

Our Data Engineering team is growing and we have urgent openings for Mid-to-Senior level Data Engineers to join our team!

100% Remote.

If this sounds like a good fit, please apply today!
What You Will Be Doing
- Build enterprise-level ETL pipelines
- Develop real-time streaming pipelines and queue-based event processing systems
- Work closely with machine learning and data scientists to scale model training and explore new data sources and model features
What You Need for this Position
Must have:
- 3+ years of experience as a Data Engineer or in a similar role
- Experience with data modeling, data warehousing, and building ETL pipelines
- Software Engineering background
- Python
- Spark
- AWS

Nice to haves:
- Kafka
- Pandas
- Airflow
- Snowflake
What's In It for You
Base Salary: $140,000 - $185,000
- Stock options
- Bonus
- Quarterly flights to our headquarters
- Health, Dental, and Vision
- 401K
- Unlimited PTO
- Remote
So, if you are a Senior Data Engineer with experience, please apply today!
-
Applicants must be authorized to work in the U.S.


CyberCoders, Inc is proud to be an Equal Opportunity Employer

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, protected veteran status, or any other characteristic protected by law.

Your Right to Work In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification document form upon hire.

CyberCoders will consider for Employment in the City of Los Angeles qualified Applicants with Criminal Histories in a manner consistent with the requirements of the Los Angeles Fair Chance Initiative for Hiring (Ban the Box) Ordinance.",4.2,"CyberCoders
4.2","Los Angeles, CA","Irvine, CA",201 to 500 employees,1999,Subsidiary or Business Segment,Staffing & Outsourcing,Business Services,$100 to $500 million (USD),-1
"Software Engineer, Data Platform / Python / Spark / AWS / Machine Learning",-1,"Software Engineer – Data Platform

Job Description:

A Software Engineer – Data Platform who is an expert at leveraging technology to scale backend systems with large throughputs of financial data and complex computations. They are on the cutting edge of Big Data technology and are interested in solving complex problems around performance speed-ups, code efficiency and large-scale database management.

Role and Responsibilities

· Architect data infrastructure and code bases

· Implement best-of-breed database technologies

· Optimize systems to quickly process data and evaluate models

· Design processes for scraping and storing large amounts of web data

· Develop and maintain out platform for Data Scientists at the firm

· Hire and groom new Data Engineers to execute on the firm’s engineering strategies

Ideal Candidate

· 2+ years of experience at a technology company as a Data Engineer, or Backend Engineer focused on data systems and architecture

· Excellent programming skills in Python 2 & 3 including Pandas, Numpy and Scipy

· Knowledge of Cython, C, and JIT compilation preferred

· Deep understanding of both relational databases (MySQL) and NOSQL databases (MongoDB)

· Expert at working with Amazon AWS (S3, EC2) or other Infrastructure as a Service

· Experience with creating and/or maintain code and database backends

· Strong web scraping skills and some experience implementing machine learning techniques

· Self-driven person with excellent verbal and written communication skills

· Plus: Background in distributed computing frameworks (Spark)

· Plus: Graduate degree in STEM field

· Plus: Knowledge of advanced data science techniques and statistical modeling concepts

Company Background:

We are transforming the private equity industry akin to how hedge fund quants transformed investing in the public markets.

We are the first investment and operating firm founded on Predictive Unit Economics.

Predictive Unit Economics forecasts business drivers – how customer purchasing behavior, customer acquisition costs, and operating levers change over time.

Leveraging 25 years of academic research, we use proprietary statistical analyses and models to precisely value and operationally optimize businesses.

Please send your resume to Jerald@motektech.com",3.1,"MoTek Technologies
3.1",Remote,"San Jose, CA",1 to 50 employees,2009,Company - Private,IT Services,Information Technology,$1 to $5 million (USD),-1
Data Engineer,-1,"About Envelop

Envelop Risk is a rapidly-growing underwriting agency combining world leaders in (re)insurance underwriting and artificial intelligence-based simulation modelling. We underwrite cyber reinsurance contracts and are building cyber insurance products that will be distributed globally. We are seeking technical staff for our global technology hub in central Bristol.

We offer a flexible, equal-opportunity workplace with an engaged and talented team delivering high-quality projects on the cutting edge of technology. Occasional international travel for client workshops and technical networking may be required.

About the Role

Envelop is seeking talented data engineers with a background in cloud-hosted data processing pipelines. The role will require close collaboration with Envelop’s passionate team of data scientists, software engineers, and underwriters, shaping data analytics solutions to meet client needs.

Insurance and cyber security experience are not required, but would be looked upon favourably.

Responsibilities
Designing, implementing, and managing elements of our cloud-hosted data analytics platform
Working with our data science team to assist in more complex data ingest tasks
Managing systems that can support a range of data sets
Developing and evaluating tools and platforms to support our machine learning models
Continually evaluating and improving systems in production
Keeping up to date with the latest tools, methods, & technologies
Key skills
Good knowledge of using Python for data processing (Pandas, SQLAlchemy, etc)
Fluency in SQL
Exposure to working with large, complex, and messy data sets
Working in an agile software development environment
Desirable experience
PostgreSQL
Data workflow tools such as Apache Airflow, Luigi, etc
Non-relational databases (e.g. BigTable, Redis, CouchDB, RethinkDB, Elasticsearch, etc)
Google Cloud Platform
Qualifications
Bachelor of Science or higher in a technical degree, with specializations related to computer science preferred
At least one year’s relevant industry experience, including internships, part-time positions, and graduate level education
We are an equal opportunity employer. We are totally opposed to discrimination in any form on the grounds of race, sex, disability or religion and it is our policy to provide equal employment opportunities for all employees regardless of race, sex, colour, nationality, national or ethnic origin, sexual orientation, marital status, age or disability. We perform police background checks, but will not exclude any candidate arrested for non-violent climate strike protest.

NO AGENCIES.",-1,Envelop Risk Analytics,"Bristol, CT","London, United Kingdom",1 to 50 employees,-1,Unknown,-1,-1,Unknown / Non-Applicable,-1
"Frontend Engineer, Amazon SageMaker","$125K-$154K
(Glassdoor est.)","Interested in Machine Learning? As the SDE on the SageMaker UI team, youll get to work on:

1. The SageMaker Management Console (https://console.aws.amazon.com/sagemaker )
This is one of AWS' largest consoles, and we're not slowing down! The baseline requirement is to keeps parity with SageMaker's rapidly expanding HTTP API's, but we'll push to also develop unique experiences for SageMaker metadata that are only possible in a browser or mobile device. You own our webservers and the bytes they vend, including the design, testing, continuous deployment, operations, usage analytics, and customer support.

2. Custom UI/widgets for AWS ML's Notebook authoring and data scientist IDE experience
From a browser, we're making a highly scalable and collaborative data science workbench so a data scientist, developer, or student can launch a wholly configured and sharable workspace in the cloud.

Key Responsibilities:
· Work closely with senior engineers, UX designers, and product managers to develop friendly UI experiences.
· Work closely with engineers to architect and develop the best technical design.
· Develop/maintain operational rigor for the frontend of a fast-growing AWS service.
· Develop the engineers of an existing two pizza scrum team.
· Collaborate with other SageMaker SDE's for features that cut across SageMaker.
· Engage with customers and other AWS partners.
· Help with hiring.
You'll be well supported with by a group with deep technical chops, including multiple senior and principal engineers.

What is SageMaker?
Amazon SageMaker (https://aws.amazon.com/sagemaker/) is a fully-managed Machine Learning platform that makes it easy to build ML models, manage them, and integrate them with custom applications for batch or online predictions. SageMaker takes away the heavy-lifting normally associated with large-scale Machine Learning implementations so that developers and scientists can focus on the truly creative work of modeling and solving the business problem at hand.




Basic Qualifications

· Bachelors Degree in Computer Science or related field.
· Equivalent experience to a Bachelor's degree based on 3 years of work experience for every 1 year of education
· 2+ years professional experience in software development.
· Experience with modern programming languages (Java, C#, Python) and open-source technologies.
· Experience with web/mobile technologies (e.g., JavaScript/TypeScript, NodeJS, React, WebPack, HTTP mechanics/performance).

Preferred Qualifications

· Experience building tools for data scientists or developers.
· Attuned design sense so can collaborate with UX designers and hold a high bar with backend SDE's.
· Experience with with CI/CD in a frontend context.
· Experience establishing and leveraging web analytics.
· Machine learning knowledge and experience.
· Knowledge of professional software engineering practices & best practices for the full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations.
· Ability to take a project from scoping requirements through actual launch of the project.
· Experience in communicating with users, other technical teams, and management to collect requirements, describe software product features, and technical designs.
· Deep hands-on technical expertise in full-stack development.



Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.",3.9,"Amazon
3.9","East Palo Alto, CA","Seattle, WA",10000+ employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),"Google, Microsoft, Walmart"
Senior Machine Learning Engineer - Data Science,"$97K-$166K
(Glassdoor est.)","Sr Data Engineer - GE07BE

You are a driven and motivated problem solver ready to pursue meaningful work. You strive to make an impact every day & not only at work, but in your personal life and community too. If that sounds like you, then you've landed in the right place.

Senior Machine Learning Engineer

The mission for the Data Science as a Service (DSaaS) core team is to partner with Segment Data Science teams and IT organizations across The Harford to enable deployment of Data Science assets (data, model, business rules) into business workflows in batch and/or real-time mode. The DSaaS team is responsible for creating playbooks and modular code to enable adoption of best practices within the Data Science organization. Learning from recent deployments using existing architectural patterns, the goal is to evolve the playbook to support the cloud adoption on the AWS platform. The team consults on use cases to provide a high level view of cost, time and effort associated with batch vs real-time implementations. The team is responsible for guiding the Data Science practice to allow for faster, cheaper, consistent, and reliable deployments while enabling transparency and reproducibility of modeling assets.

The Senior Machine Learning Engineer is responsible for hands-on deployments of data science artifacts into business workflows and works closely with the Data Scientists to understand the inputs and outputs of the models. The Senior Machine Learning Engineer will establish logging, error handling, and error recovery criteria to support model failures in production deployments. The engineer will also establish the testing criteria for validating the model deployments in collaboration with the front end engineering teams. The engineer must have an understanding of model deployment pipelines incorporating data from internal systems and third party sources. Expertise in Linux, SQL, Hadoop, and Spark is essential for this role. The engineer should be able to write Python code using object oriented software engineering principles and delivering modularized, reusable code. Understanding of CI/CD tools to automate pipelines and code delivery is preferred.

Responsibilities
Understand sources of data within The Hartford, and work with SME’s to describe and understand data lineage and suitability for a use case.
Create summary statistics/reports from data warehouses, marts, and operational data stores to establish testing criteria and create model training and validation data sets.
Produce code artifacts and documentation for reproducibility and hand-off to other data science teams.
Contribute to the design, implementation, and evaluation of ML models in production in agile framework. Execute testing (integration, performance, regression).
Prototype new approaches and productionize model code to be deployed to business applications
Adhere to requirements for scale, performance, and availability
Support implementation and testing of assets into production work and manage and estimate work for junior engineers to deliver the requirements for each project.
Describe technical work to non-technical audiences.
Establish best practices for code management, issue management, data and storage management.
Perform code review and mentor engineers on team, set timelines and delivery scope and develop success criteria for project increment delivery.
Interact with engineers, architects, product owners, and asset owners to propose a technical solution and provide work estimates to deliver the software. Call out risks and issues and establish escalation criteria for product based on final solution.
Provide L3 support for production assets in conjunction with IT production support teams, Data Scientists, and the model Product Owner.
Basic knowledge of modeling tools and data science platforms is preferred.
Ability to provide input as consultant on projects as a technical expert.
Ability to identify and investigate potential data errors during model development or deployment phases.
Ability to respond to change, interested in continuous learning, adopting new technologies to enable data science asset deployment into production.
Understand tiered application architectures, understand and implement API based predictive and scoring services
Establish production support documentation and process with on-shore and off-shore teams.
Configure deployments in containerized environments.
Experience & Skills
2+ years of experience in implementing machine learning algorithms (regression, dimensionality reduction, recommendation systems, outlier detection, and predictive models)
Experience in leading projects from incubation to large scale production deployments
5+ years’ experience in object oriented programming and design patterns.
BA, BS, MS, PHD in Computer Science and Engineering
Experience deploying on the AWS platform, certification is preferred but not required.
Candidates must have the technical skills to transform, manipulate and store data, the analytical skills to relate the data to the business processes that generates it and the communication skills to disseminate information regarding the availability, quality, and other characteristics of the data to a diverse audience.
3+ years of writing object oriented code in in Python
Determine business solutions and translate into actionable steps for self and junior engineers on the team.
Demonstrate a passion for learning new skills and creating best practices and standards within the organization.
Results oriented with the ability to multi-task and adjust priorities when necessary
Equal Opportunity Employer/Females/Minorities/Veterans/Disability/Sexual Orientation/Gender Identity or Expression/Religion/Age


Equal Opportunity Employer/Females/Minorities/Veterans/Disability/Sexual Orientation/Gender Identity or Expression/Religion/Age",3.9,"The Hartford
3.9","Hartford, CT","Hartford, CT",10000+ employees,1810,Company - Public,Insurance Carriers,Insurance,$10+ billion (USD),-1
Software Development Engineer - Data and Machine Learning,-1,"Merch by Amazon is a rapidly expanding Amazon business that provides a make-on-demand service for creating, publishing, promoting, and selling graphic merchandise such as t-shirts, hoodies, PopSockets, and more. Content creators upload designs and we list, sell, print, and ship these items to Amazon customers. Our customers get great graphic products, content creators get a generous royalty.

Our Data Science team is looking for a talented, creative and passionate Software Development Engineer to help us leverage data to benefit our designers, brands, and customers. Our projects include orchestrating hundreds of data sources, using machine learning to evaluate our products, and optimizing product placement and promotion to ensure that our customers can find the most relevant products at the right time. You will work alongside Scientists and Data Engineers and will take the lead on designing and implementing infrastructure for machine learning deployment and data orchestration. You will also directly apply the latest machine learning methodologies to develop and deploy machine learning models.

Merch by Amazon - it's not just a job, it's a wardrobe. If you're looking for a chance to build data-driven products with a team of top-notch engineers and scientists, for a new business that promises to shake things up on behalf of all sorts of customers; if you're an expert software practitioner, with a gritty, start-up mentality, and want to build quick, release, learn from data, and then build some more; if you have an interest in Machine Learning, and how to build algorithms from Amazon-scale data to optimize a system; if you wear t-shirts, or at least appreciate customers who do - well we might have a job for you.Basic Qualifications
Bachelor's degree in Computer Science, or equivalent
3+ years' experience developing distributed services, deployed machine learning systems, and/or high-volume data processing workflows
Knowledge of Computer Science fundamentals in data structures, algorithm design, problem solving and complexity analysis
Strong sense of ownership, customer obsession, and drive.
Able to work in a diverse team
Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.",-1,Amazon Corporate LLC,"Seattle, WA",-1,-1,-1,-1,-1,-1,-1,-1
Big Data Engineer (Atlanta),"$47K-$90K
(Glassdoor est.)","Tiger Analytics is a fast-growing advanced analytics consulting firm. Our consultants bring deep expertise in Data Science, Machine Learning and AI. We are the trusted analytics partner for several Fortune 100 companies, enabling them to generate business value from data. Our business value and leadership has been recognized by various market research firms, including Forrester and Gartner. We are looking for top-notch talent as we continue to build the best analytics global consulting team in the world.

This role will be responsible for Architecture, Designing and implementing Advanced Analytics capabilities at enterprise level. These capabilities include Batch and Streaming Analytics, Machine learning models, Natural Language processing and Natural language generation and other emerging technologies in the field of Advanced Analytics. We are looking for Data Engineer supports the Data and Analytics organization by designing, optimizing, and developing data pipelines to support machine learning and AI models. You will work with a cross-functional team of Data Scientists and Software Developers on feature engineering and scoring pipelines, assemble large data sets that meet business requirements. You will also develop feature engineering and scoring pipelines using Sparks SQL and workflow schedulers, technology stack: BitBucket, Jira, Hadoop/Spark and Openshift/Kubernetes. The Data Engineer will work closely with data scientists to ensure that feature engineering pipelines meet their needs, and provides guidance for writing Spark jobs to ensure that data science code is optimized for production.

Requirements
Bachelor’s degree in Mathematics, Physics, Statistics, Engineering or a quantitative related field
4 years of experience using “big data” technologies
2+ years of experience in design and implementing AWS Cloud Solutions at enterprise level
Experience with functional or object-oriented languages such as Python, C++, REST, Scala
Advanced working knowledge of SQL and relational databases
Experience with Airflow, Argo, Luigi, or similar orchestration tool
Experience performing root cause analysis on Spark jobs to identify areas for improvement
Experience with No-SQL databases such as HBase, Cassandra, or Redis.
Experience with streaming technologies such as Kafka, Flink, or Spark Streaming
Experience with DevOps principals and CI/CD; and Containers and Kubernetes
Benefits

Significant career development opportunities exist as the company grows. The position offers a unique opportunity to be part of a small, challenging, and entrepreneurial environment, with a high degree of individual responsibility.",4.6,"Tiger Analytics
4.6","Atlanta, GA","Santa Clara, CA",201 to 500 employees,2011,Company - Private,Consulting,Business Services,$10 to $25 million (USD),"Mu Sigma, LatentView Analytics, Fractal"
Senior Data Engineer - Remote,-1,"SemanticBits is a leading company specializing in the design and development of digital health services, and the work we do is just as unique as the culture we’ve created. We develop cutting-edge solutions to complex problems for commercial, academic, and government organizations. The systems we develop are used in finding cures for deadly diseases, improving the quality of healthcare delivered to millions of people, and revolutionizing the healthcare industry on a nationwide scale. There is a meaningful connection between our work and the real people who benefit from it; and, as such, we create an environment in which new ideas and innovative strategies are encouraged. We are an established company with the mindset of a startup and we feel confident that we offer an employment experience unlike any other and that we set our employees up for professional success every day.

SemanticBits is looking for a talented Data Engineer who is eager to apply computer science, software engineering, databases, and distributed/parallel processing frameworks to prepare big data for the use of data analysts and data scientists. You will deliver data acquisition, transformations, cleansing, conversion, compression, and loading of data into data and analytics models. You will work in partnership with data scientists and analysts to understand use cases, data needs, and outcome objectives. You are a practitioner of advanced data modeling and optimization of data and analytics solutions at scale. Expert in data management, data access (big data, data marts, etc.), programming, and data modeling; and familiar with analytic algorithms and applications (like machine learning). This position is open to a mid-level to principal professional depending on experience.
Responsibilities
Strong knowledge of computer science fundamentals: object-oriented design and programming, data structures, algorithms, databases (SQL and relational design), networking
Demonstrable experience engineering scalable data processing pipelines.
Demonstrable expertise with Python, Scala, Spark, and wrangling of various data formats - Parquet, CSV, XML, JSON.
Experience with the following technologies is highly desirable: Redshift (w/Spectrum), Hadoop, Apache NiFi, Airflow, Apache Kafka, Apache Superset, Flask, Node.js, Express, AWS EMR, Tableau, Looker, Dremio
Required Qualifications:
Experience with Agile methodology, using test-driven development.
Excellent command of written and spoken EnglishSelf-driven problem solver
Candidate must reside in the United States
Bachelor's degree in technological or related field and a minimum of 5 years of relevant experience or a Master’s degree with a minimum of 3 years experience
Flexible and willing to accept a change in priorities as necessary
Nice to have:
Experience working in the healthcare industry
Federal Government contracting work experience
Prior experience working remotely full-time
Physical and emotional requirements for the job:
This position is to be performed remotely from an individual’s home office and involves sedentary work. Employees in this role can be expected to exert up to 10 pounds of force on occasion in order to lift, carry, push, pull or otherwise move standard electronic equipment. Employees are expected to make decisions in a timely manner and display emotional intelligence during occasional stressful situations.
Benefits
Competitive base salary
Three weeks of PTO
Ten paid holiday days
Comprehensive health benefits (medical with HSA option, dental, and vision)
401k retirement plan with matching benefit
100% paid short-term and long-term disability
100% paid life insurance
Flexible Spending Accounts (FSA)
Casual working environment
Flexible working hours

SemanticBits, LLC is an equal opportunity, affirmative action employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability, or any other characteristic protected by law. We are also a veteran-friendly employer.

If you are an individual with a disability and require a reasonable accommodation to complete any part of the application process, or are limited in the ability or unable to access or use this online application process and need an alternative method for applying, you may contact 703-787-9656 x257 or HR@semanticbits.com for assistance.",4.6,"SemanticBits
4.6","Herndon, VA","Herndon, VA",51 to 200 employees,2005,Company - Private,Enterprise Software & Network Solutions,Information Technology,$5 to $10 million (USD),-1
Supply Chain Data Engineer,-1,"What You'll Do


Do you love working with data? Are you passionate about turning complex data into information, information into insight, and insight into business decisions? Then the Cisco System Data and Analytics team may be an exceptional opportunity for you. We are looking for a highly motivated Data Engineer who has a solid background in Database tools like Snowflake, Google Cloud Platform, Oracle, Teradata and SAP Hana with hands-on coding in SQL/ R/ Python and SAS.

In this role, you will develop Data architecture, Data Foundation and Self-Service capability for Global Planning team within Cisco Supply Chain. You will help develop Prototypes and MVPs for Predictive and Prescriptive Analytics using Database, Visualization tools working closely with Data Analysts and Data Scientists. You will work with business owners and solution leads to understand business requirements and drive Data Architecture Forum with IT to Digitize the capability.

Responsibilities:
Work with large, complex data to analyze and interpret trajectories or patterns.
Build Analytical tools using the data pipeline to provide actionable insight.
Collaborate with Multi-functional team to enable End to End Solution
Work with IT to develop Data Sources and Self Service capability
Own and maintain data quality, data security and tool performance.
Make recommendations to Business on Opportunity for Cost reduction, Customer Excellence and Forecasting Outcomes with effective presentations of findings at multiple levels of partners through visual displays of quantitative information.
Initiate project to improve process and tools
Who You'll Work With
You will work with business partners, IT, solution manager and product owners to define problems, scope projects, and deliver intelligent data solutions.
You will have the opportunity to work with some of the newest technologies, work on the most transformative projects, and join a select Data Science team passionate about data-centric decisions, applying technology and continuous learning.
Requirements:


Minimum Qualifications:
Bachelor degree or Equivalent in Computer Science or Information science
Master degree in Data Analytics/ Science is a plus.
7+ years of relevant work experience in data analysis or related field. (e.g., as a Data Engineer, Data Architect, Data Analyst).
Hands on Experience with software (e.g., R, Python, SAS) and database languages (e.g., SQL).
Preferred qualifications:

Supply chain experience
Experience working with Relational Database like SQL, Snowflake, GCP, Oracle, Teradata, SAP Hana and Proficient in writing complex SQL queries for integration with Application.
Experience with NoSQL technologies, specifically Document (MongoDB) and Graph (Neo4j) types are desireable.
Experience in articulating business problems and answering using mathematical techniques using available data.
Demonstrated skills in selecting the right Architecture given a data analysis problem.
Effective written and verbal communication skills.
Demonstrated leadership and self-direction.
Experience in visualization using Tableau or similar products
Why Cisco


WE ARE CISCO

#WeAreCisco, where each person is unique, but we bring our talents to work as a team and make a difference. Here’s how we do it.

We embrace digital, and help our customers implement change in their digital businesses. Some may think we’re “old” (30 years strong!) and only about hardware, but we’re also a software company. And a security company. A blockchain company. An AI/Machine Learning company. We even invented an intuitive network that adapts, predicts, learns and protects. No other company can do what we do – you can’t put us in a box!

But “Digital Transformation” is an empty buzz phrase without a culture that allows for innovation, creativity, and yes, even failure (if you learn from it.)

Day to day, we focus on the give and take. We give our best, we give our egos a break and we give of ourselves (because giving back is built into our DNA.) We take accountability, we take ambitious steps, and we take difference to heart. Because without diversity of thought and a dedication to equality for all, there is no moving forward.

So, you have colorful hair? Don’t care. Tattoos? Show off your ink. Like polka dots? That’s cool.",4.1,"Cisco Systems - Engineering - Software
4.1","Research Triangle Park, NC","San Jose, CA",10000+ employees,1984,Company - Private,Computer Hardware & Software,Information Technology,$10+ billion (USD),"Alcatel-Lucent, Juniper Networks"
Sr. Data Engineer - Elasticsearch,-1,"WHO WE ARE

Signal Sciences is the fastest growing web application security company in the world. Our award-winning next-gen WAF and RASP solution protects 40,000+ applications and APIs with over 2 trillion production requests per month. Signal Sciences' patented architecture allows our customers to embrace cloud and DevOps while bringing actionable security visibility to development, DevOps, and security teams.

We work with some of the world's most recognizable companies, like Datadog, DoorDash, Under Armour, Starbucks, Aflac, and many more across industries. We make web applications more secure. Simple as that. We do it by providing an unparalleled platform that teams actually want to use. It's flexible, exceptionally elastic, collaborativeand protects business initiatives like DevOps and cloud adoption without disrupting current workflows and processes already in place.

SUMMARY

We are looking for a Senior Data Engineer who will be architecting a highly scalable data integration and transformation platform processing a high volume of data under defined SLA. You will be creating and building the platform that includes ingestion and transformation of data, data governance, machine learning, analytics, and consumer insights.

Our tech stack includes Elasticsearch, Logstash, Kibana, ElastiCache/Redis, MongoDB Atlas, AWS S3, Datadog, Go, RPC

RESPONSIBILITIES
Developing sequencing data pipelines and/or data science platform
Responsible for building and managing end-to-end data pipelines and operations from ingestion and integration through delivery for the data products
Build cross-functional relationships with Business Stakeholders, Architects, Data Scientists, Product Managers and IT to understand data needs and deliver on those needs
Drive the design, building, and launching of new data models and data pipelines in production
Manage the development of data resources and support new product launches
Lead discussion of product-oriented analysis in meetings with clients and partners; comfortable speaking to executives
Primary data liaison for stakeholders to drive transformation and to democratize use of data
Consolidate the fragmented data across the company and provide simplified access to data for the stakeholders, internal users as well as external partners
Support compliance and auditing through a single gateway for data exchange
Stay abreast of technology development in retail and other industries
Act as a sounding board on testing, experimentation, target audience profiling and consumer insights that analyze the relationship between customers, products, partners, conversions, engagement and revenue, and drivers
Work with multiple complex and disparate datasets to enable data delivery through various means and APIs to evaluate performance and amalgamate information to derive strategic insights and recommendations
Establish the core data foundation and common data lake to enable data-driven decisions
Support delivery of scalable data products
QUALITIES / EXPERIENCE WE'RE SEEKING
Software development experience
Exceptional skills in at least one high-level programming language (Java, Scala, Go, Python or equivalent)
ETL and ELT pipelines
Data processing and job orchestration
Implementing analytics pipelines to assess machine learning model results
Setting up data and cloud environments to make data science more efficient
Quickly learning new tools
Strong understanding of ELK Stack
Database experience including MongoDB
Experience with Container technology and AWS services including S3, Amazon ECS
Excellent communication skills to collaborate with cross-functional partners and independently drive projects and decisions
WHY YOU SHOULD JOIN SIGNAL SCIENCES

We're not just rethinking what's possible with web application securitywe're revolutionizing it. At Signal Sciences, we engineer big ideas with an eye on the future, building sustainable and wide-reaching solutions that not only serve teams' immediate needs but also instinctively evolve along with them. We believe in simple, effective actions. We value teamwork.

Signal Sciences is disrupting the web security industry and was recently named one of the Next Billion-Dollar Startups by Forbes. As a team member, you'll enjoy 100% employer-sponsored medical, dental, and vision benefits, 401K retirement plan, and a flexible work environment. Most of all, you will have the opportunity to make a positive impact on improving security in the world's #1 most vulnerable part of technology infrastructure (the web) with the new industry leader in web application security. Join us and find out why we were named Best Place to Work in 2019 by LA Business Journal, and Best Work-Life Balance in 2019 by Comparably.",4.1,"Signal Sciences
4.1",Remote,"Culver City, CA",51 to 200 employees,2014,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Nuuly: Machine Learning Engineer,-1,"Urban Outfitters, Inc. (“URBN”) is a portfolio of global consumer brands which offers a variety of lifestyle merchandise and consumer products through its brands Urban Outfitters, Anthropologie, Free People, BHLDN, Terrain and the Vetri Family. Urban Outfitters, Inc., is both a Fortune 1000 and S&P 500 ranked company with $3.4 Billion in revenue.

Reports to: Senior Data Science Manager, Nuuly

What is Nuuly:

Nuuly is the newest sibling to Urban Outfitters, Anthropologie, and Free People, and focuses on circular fashion by offering a subscription rental experience for women’s apparel. You'll be part of a close-knit and collaborative environment at Nuuly. We pride ourselves on a relaxed, inclusive, and innovative culture. Our parent company, Urban Outfitters, Inc. (NASDAQ: URBN, www.urbn.com) is a specialty retailer, offering lifestyle merchandise to highly defined customer niches and a Fortune 1000 company with $3.4 Billion in revenue.

What is Nuuly Data Science:

The Data Science team is responsible for the Data Science, Machine Learning, and Analytics functions at Nuuly. Our expertise spans project management, machine learning, software engineering, data engineering, and analytics. Unlike most Data Science organizations, our team is a full-service Machine Learning solution provider, taking projects from ideation through deployment of production services. We work closely with the Engineering organization on a very wide range of projects including an in-house on-site personalization system, a dynamic pricing capability, and a warehouse optimization system for our fulfilment center in Bristol, PA.

What You’ll Do

Nuuly Engineering has built a state-of-the-art Kafka-based streaming data platform which provides ML systems unfettered access to data in real-time. As a Machine Learning Engineer, you will be responsible for architecting and building ML model training and deployment pipelines into the Nuuly streaming platform. You will work closely with data scientists, data engineers, and services engineers on:
Experimentation: Perform exploratory proof-of-concept studies to evaluate potential deployment architectures and to evaluate new technologies.
Design: Work with the team to design architectures for offline training and real-time deployment of machine learning models that meet feature requirements. Requirements that often drive architectural decisions include ML model format and training language, inference latency, training/inference cost, retraining frequency, and many others.
Implementation: Implement and maintain the ML architecture, including data pipelines and applications that enable training and inference of ML models in production.
Deployment: Implement and maintain automated monitoring of deployed models to assess their performance, uptime, etc.
Model Building (optional): In addition to the above, if your interest and experience includes building ML models, this role may involve work in building models.
Qualifications:
Strong coding skills and software development experience. Proficiency in Python is required; Additionally, experience with a JVM language is preferred.
Experience deploying machine learning models in production
Familiarity with machine learning approaches and terminology. Understanding of the practical aspects of ML, e.g. train/dev/test sets, precision and recall, overfitting, hyperparameter tuning, etc.
Preferred Qualifications:
Streaming data tools (Kafka, Kinesis, Pub/Sub, etc.)
Datastores (relational databases, wide column stores, document stores, etc.)
Distributed computing systems (Hadoop, Spark, etc.)
ML tools (TensorFlow, pyTorch, scikit learn, Jupyter Notebooks, etc.)
Data or ML orchestration frameworks (Kubeflow, MLflow, Airflow, etc.)
1+ years’ experience with Cloud platforms (Google Cloud Platform, Amazon Web Services, Microsoft Azure, etc.)
Cloud infrastructure (Virtual Machines, Cloud Storage, IAM, etc.)
Experience with Docker, Kubernetes, or other containerized systems",-1,Nuuly,"Harrisburg, PA",-1,-1,-1,-1,-1,-1,-1,-1
Machine Learning Engineer (Imaging),"$80K-$138K
(Glassdoor est.)","Position Summary

Samsung Austin Semiconductor is one of the most advanced semiconductor manufacturing facilities in the world with more than 3,000 employees and 2.45 million square feet of floor space. Samsung Austin Semiconductor has broad semiconductor process technology offerings serving customers in various application areas including mobile, consumer, networking/high performance computing, Internet of Things, RF and automotive. Since 1996, SAS has invested approximately $17 billion in its Austin, TX campus, making it one of the largest direct foreign investments in United States history. Samsung Austin Semiconductor is a US-based subsidiary of Samsung Electronics Co., Ltd. The Austin facility is one of the few semiconductor plants the company has outside South Korea. Visit www.samsung.com/us/sas.

SAS is focused on being the World’s Best Foundry product supplier.

Role and Responsibilities
Our company creates some of the world’s most high-tech semiconductor manufacturing line for CPUs, GPUs, and IoT sensors.
We are currently in search of a Machine Learning developer to find and optimize signals from data from various resources, transform data, implement new features, and design machine learning models for business value.
Looking for a Machine Learning engineer with a passion for data, and enjoys being a part of a small high performing team developing and maintaining in-house models.
Be a member of the Defect Engineering Systems group which provides data summarization across many key dashboards.
Helps by directing the focus of the factory and continuously improving time to detection, accuracy, and throughput.
Working with key members of the organization to obtain stronger predictive data.
Feature Engineering to improve model performance.
Attend team meetings and offer solutions to challenging problems.
Collaborate with peer data scientists across the organization on best methods for data modeling.
Other duties as needed.
Experience building and extending machine learning models.
Experience with open source frameworks (Tensorflow, PyTorch).
Comfortable working with command line interfaces (Ubuntu experience a plus).
Ability to summarize results to a broad range of audiences.
Ability to learn quickly and keep deadlines while applying good design principals.
Experience with CNNs, Auto-Encoders, Manifold Learning, and Recommendation Systems.
Ability to use VM container software (Docker / Kubernetes).
Familiar with Atlassian software (BitBucket, Confluence, Jira).
Semiconductor process knowledge (specifically defect domain knowledge: detection, classification, determining impact) is a plus.
Enjoy solving challenging problems and eager to learn new technologies.
Working with a small highly motivated team to develop and implement new ideas.
Work days and hours: M-F, 8am to 5pm/1st shift
Skills and Qualifications
B.S or M.S Engineering Degree.
3- 7 years of Data Science/Machine Learning experience is a must
Proficient with Python, SQL, and data manipulation is required.
Prefer experience with Tensorflow image processing and modeling
Excellent communication, interpersonal, initiation, & troubleshooting skills.
Fundamental understanding of analytic techniques is a plus.
Fast learner with the ability to develop and maintain.
* Please visit Samsung membership to see Privacy Policy, which defaults according to your location. You can change Country/Language at the bottom of the page. If you are European Economic Resident, please click here.

* Samsung Electronics America, Inc. and its subsidiaries are committed to employing a diverse workforce, and provide Equal Employment Opportunity for all individuals regardless of race, color, religion, gender, age, national origin, marital status, sexual orientation, gender identity, status as a protected veteran, genetic information, status as a qualified individual with a disability, or any other characteristic protected by law.",2.9,"Samsung Austin Semiconductor
2.9","Austin, TX","Austin, TX",1001 to 5000 employees,1996,Subsidiary or Business Segment,Electrical & Electronic Manufacturing,Manufacturing,Unknown / Non-Applicable,"GLOBALFOUNDRIES, Intel Corporation, TSMC"
Operation Productivity Engineer,-1,"Operation Productivity Engineer New Iron is leading the search for an Operation Productivity Engineer Senior Application Specialist. This position is a remote contract-to-hire for a global company. Priority will be given to candidates who can work well independently in a global work environment, are strong communicators and who are passionate about supporting our industrial clients. This is a compelling greenfield opportunity to bring unique and differentiated value to pharma manufacturing. Our clientrsquos mission is to increase productivity while dramatically reducing the cost of pharmaceutical manufacturing. The ideal candidate will have operations research expertise as well as experience with informatics systems commonly found in the Pharma and Biopharma Industries. Candidates must have excellent process knowledge and experience and be able to convey a technical message to a business audience. You will support clients to improve their manufacturing processes through effective planning and scheduling using optimization and simulation. Candidates must have hands-on experience with planning and scheduling in the Pharma and Biopharma Industries. If you are self-directed and comfortable supporting the needs of multiple teams and products, we'd love to help you find your next career move! Job Responsibilities May Include Working closely with internal sales and engineering teams as well as with external process engineers and manufacturing scientists Performing a range of pre and post sales activities support a technical sales strategy for a new client communicate the value of software products vis-a-vis industry challenge software installs process model design workflow design data manipulation data source identification and characterization Technical teaching and consulting Coordinating with various teams to validate and deploy models to improve business processes Evaluate process and equipment data to determine the ideal modeling approach for improved performance and increased equipment availability (candidate must be able to define good and bad data quality). Leverage optimization approaches in combination with discrete-event based simulation to develop data-driven applications that support key business and operations processes Up to 50 domesticinternational travel post COVID Candidates Should Have the Following Experience 3+ years of experience in the pharmabiopharma industry 5+ years as a process engineer working with chemical or similar processes Demonstrated ability in supply chain planning and production scheduling A proven ability to interact with clients, and explain technical details in laymenrsquos terms. Database experience (PI System, Oracle, SQL, or similar) Data communication, interfacing (OPC DAHDAUA, relational database calls, etc.) Data visualization experience MES experience - e.g., (Syncade or Werum), ELN, LIMS, SCADA, PLC, DCS, BES, PI Historian, AspenTech IP21, GE Proficy, etc. Experience with factory interfaces including OPC, ODBC, OSI PI Strong written and verbal communication skills Nice to have Experience with programming languages such as Python, Java, C, C++ Processing (importing, cleaning, filtering) large data sets Developing andor applying optimization and operations research methodologies Experience with optimization tools and frameworks (Pyomo, GAMS, Gurobi, etc.) Experience with discrete-event based simulation Developing andor applying data modeling and machine learning methodologies Experience with statistical and mathematical modeling environments (R, Python, MATLAB, etc.) Bachelor degree in Engineering, Industrial Engineering or related field This is a remote contract-to-hire role for a client based in the US. Principals only. Recruiters please do not contact this job poster.",5.0,"New Iron Group, Inc.
5.0",United States,"Austin, TX",1 to 50 employees,2003,Contract,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Principal Data Scientist,"$135K-$211K
(Glassdoor est.)","At the heart of Defining Possible is our commitment to missions. In rapidly changing global security environments, Northrop Grumman brings informed insights and software-secure technology to enable strategic planning. We're looking for innovators who can help us keep building on our wide portfolio of secure, affordable, integrated, and multi-domain systems and technologies that fuel those missions. By joining in our shared mission, we'll support yours of expanding your personal network and developing skills, whether you are new to the field or an industry thought-leader. At Northrop Grumman, you'll have the resources, support, and team to do some of the best work of your career.

The Engineering & Sciences (E&S) organization pushes the boundaries of innovation, redefines engineering capabilities, and drives advances in various sciences. Our team is chartered with providing the skills, innovative technologies to develop, design, produce and sustain optimized product lines across the sector while providing a decisive advantage to the warfighter. Come be a part of our mission!

Join a program that has been around for 16 years and under contract to go at least another 9 years. The team is currently completely revamping the architecture and bringing it up to date utilizing modern constructs and tools. You will work closely with our customers and their contractor team to lead an ongoing effort to optimize complex cyber systems. Daily you will face complex technical problems involving telecommunications, network engineering, and large data sets requiring strong statistical and data visualization skills. Solving complex technical problems, including the ability to conduct independent research and develop prototype analytical algorithms is needed. You will be analyzing performance of modern internet applications such as streaming video, VoIP or other internet transmission protocols and providing recommendations for system performance improvements. You will utilize your verbal and written skills to communicate to fellow team members and our customer. New areas of interest include Model Based System Engineering, Machine Learning and Artificial Intelligence.

Northrop Grumman Mission Systems (NGMS) is looking for you to join our team as a Principal Data Scientist based out of San Jose, CA.

A current active Top Secret Clearance is required. Applicants without a clearance may be considered with the understanding that employment will not begin until a TS/SCI clearance is obtained.

CIMS

Qualifications:

Basic Qualifications: Systems Engineer
Bachelor's Degree in a STEM discipline (Science, Technology, Engineering, or Math) with 4 years relevant work experience; or a Master's degree in a STEM discipline with 2 years relevant work experience; or a PhD in a STEM discipline with 0 years' experience.
US Citizenship is required with the ability to obtain and maintain a Top Secret/SCI level Clearance.
Knowledgeable with at least one software or scripting language (C, C++, PERL, Python, Java, etc.), Python preferred.
Preferred Qualifications:
Current Top Secret/SCI clearance with CI poly.
Experience developing software solutions on the Unix OS platform.
Experience working with Big Data.
Experience developing and executing test plans.
Graduate Degree in Electrical Engineering, Computer Science, Physics, Mathematics.
Knowledge of Machine Learning/Artificial Intelligence.
Background in a telecommunications and/or network management.
Experience with software and hardware interface development.
Experience with system software development/configuration/ management.
Software integration experience.
Understanding network performance profiling and optimization.
Experience developing software solutions on the Unix OS platform.
Experience utilizing Data analytics tools.
Experience working with Big Data.
Understanding of IP protocols
What We Can Offer You:

Northrop Grumman provides a comprehensive benefits package and a work environment that encourages your growth and supports the mutual success of our people and our company. Northrop Grumman benefits give you the flexibility and control to choose the benefits that make the most sense for you and your family. Your benefits will include the following:

Health Plan

Savings Plan

Paid Time Off

Education Assistance

Training and Development

Flexible Work Arrangements

https://benefits.northropgrumman.com/us/en2/BenefitsOverview/Pages/default.aspx

Additional Northrop Grumman Information:

Northrop Grumman has approximately 85,000 employees in all 50 states and in more than 25 countries, we strive to attract and retain the best employees by providing an inclusive work environment wherein employees are receptive to diverse ideas, perspectives and talents to help solve our toughest customer challenges: to develop and maintain some of the most technically sophisticated products, programs and services in the world.

Our Values. The women and men of Northrop Grumman Corporation are guided by Our Values. They describe our company as we want it to be. We want our decisions and actions to demonstrate these Values. We believe that putting Our Values into practice creates long-term benefits for shareholders, customers, employees, suppliers, and the communities we serve.

Our Responsibility. At Northrop Grumman, we are committed to maintaining the highest of ethical standards, embracing diversity and inclusion, protecting the environment, and striving to be an ideal corporate citizen in the community and in the world.

Northrop Grumman is committed to hiring and retaining a diverse workforce. We are proud to be an Equal Opportunity/Affirmative Action Employer, making decisions without regard to race, color, religion, creed, sex, sexual orientation, gender identity, marital status, national origin, age, veteran status, disability, or any other protected class. For our complete EEO/AA and Pay Transparency statement, please visit www.northropgrumman.com/EEO. U.S. Citizenship is required for most positions.",3.8,"Northrop Grumman
3.8","San Jose, CA","Falls Church, VA",10000+ employees,1939,Company - Public,Aerospace & Defense,Aerospace & Defense,$10+ billion (USD),-1
"Senior Software Engineer, Data Platform","$104K-$204K
(Glassdoor est.)","Company Description

As an Etsy employee, you can do the work you love, be yourself, and make an impact in the lives of millions. Our commitments to diversity and inclusion, team culture and the spaces where we work all reflect our mission to keep commerce human.

Job Description

As a member of our Data Platform team, you'll help us build tools and infrastructure for collecting and processing data in batch and streaming pipelines. Your work will enable other developers and data scientists to write custom data pipelines that power data science, machine learning, and product development.

You should have experience building and supporting at scale data processing platforms, and collaborating with other teams that use them. Experience building applications using one of the major cloud providers is a bonus but not required. We value curiosity, passion, responsibility and generosity of spirit.

We primarily write in Python, Java, and Scala and use technologies like Hadoop, Kafka, Airflow, Kubernetes, Avro, and GCP services like Dataproc, Dataflow, and BigQuery.

This is a full time role. Our team is headquartered in Brooklyn, but we support remote work and accept remote applicants.

Qualifications

ABOUT THE ROLE
We build highly-performant systems that are maintainable and easy to understand by selecting and integrating with the best of current technologies.
Our team is responsible for developing and monitoring our batch and streaming environments and improving or fixing them over time.
We also write ETL code and advise other teams on how to improve theirs.
We build a lot of tools and libraries in Java, Scala, or Python.
ABOUT YOU
Understand that being an effective software engineer is about communicating with people as much as it is about writing code.
Are willing to work with and improve code you did not originally write.
Are generous with your time and experience, and can mentor and learn from other engineers.
Can tackle unconstrained problems and know when to seek help.
Have familiarity with a few of the following: advantages and limitations of distributed systems, writing ETL pipelines, building and monitoring cloud services, and using or maintaining batch data processing environments like Hadoop or Spark in Dataproc, and stream processing systems like Kafka Streams, Spark, or Dataflow
Additional Information

At Etsy, we believe that a diverse, equitable and inclusive workplace makes us a more relevant, more competitive, and more resilient company. We welcome people from all backgrounds, ethnicities, cultures, and experiences. Etsy is an equal opportunity employer. We do not discriminate on the basis of race, color, ancestry, religion, national origin, sexual orientation, age, citizenship, marital or family status, disability, gender identity or expression, veteran status, or any other legally protected status. We will ensure that individuals with disabilities are provided a reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. While Etsy supports visa sponsorship, sponsorship opportunities may be limited to certain roles and skillsets.",3.6,"Etsy
3.6","Brooklyn, NY","Brooklyn, NY",501 to 1000 employees,2005,Company - Public,Other Retail Stores,Retail,$100 to $500 million (USD),"Airbnb, Warby Parker, Kickstarter"
Senior Data Scientist / Software Engineer,-1,"Job Description

Data Science is an emerging field within cyber security. This division, given its deep expertise and comprehensive view on the advanced threat landscape, is uniquely positioned to enable data scientists to have major impact within our industry, company, and across our customer base. Detecting security breaches using machine learning and data analytics is an unsolved problem (this is not handwriting recognition folks) and has huge potential.

If you are someone who wants to be on the cutting edge of a high-profile industry, who wants to make an impact by pushing both fields of data science and cyber security forward, you may be the perfect candidate to help us on our mission.

Job Responsibilities
Develop, and manage data systems to ingest and process data at massive scale
Identify data sources both internally and externally that we can use to find evil.
Contribute towards the architecture and design of software solutions for long-term storage and retrieval.
Identify and implement data exploration technologies. Create dashboards and implement analytical tools for exploration
Work with data scientists to productize ML models and assist product teams with ML model releases into end products.
Collect requirements, design, and build backend components and tools to run ML models, assess ML model efficacy, manage large scale datasets, and generate features for ML models
Contribute to the evolution of coding and design practices within the organization.
Review code base commits and contribute to the growth of team members.
Job Qualifications

Core Requirements
Ability to work in an iterative, agile development environment.
Experience implementing ETL processes and building data pipelines
Experience developing reliable distributed systems.
Experience in Data modeling and schema design
Strong knowledge of a variety of operating systems, networking fundamentals, software design and programming best practices.
Experience with use of a wide array of algorithms and data structures.
Deep understanding and experience of going through the entire life cycle of building software platforms and products
Deep knowledge of various AWS services and associated tools
Strong experience developing in Python 3
Experience developing in at least 1 of the following: C, Go or Java
Experience with RDBMS, such as PostgreSQL or MySQL, as well as NoSQL
Experience with Kubernetes and Docker.
Experience deploying products in AWS
Additional Qualification:
Ability to pick up, work with and explore new analytical tools
Strong experience with DevOps practices and common tooling
Strong communication skills.
Ability to work with loosely defined requirements.",3.4,"DISYS
3.4","Raleigh, NC","Mc Lean, VA",1001 to 5000 employees,1994,Company - Private,IT Services,Information Technology,$100 to $500 million (USD),-1
Principal Software Engineer - Personalization,"$105K-$200K
(Glassdoor est.)","Our Opportunity:

We are hiring a Principal Engineer for our Personalization team in Boston, MA. In this position, you will help us build scalable, robust software systems that use machine learning and deep learning models to drive Personalization at Chewy. You are a seasoned software engineer with a background in building large-scale distributed systems. You are passionate about working with large amounts of data and putting it use to improve customer experience.

What You'll Do:
You will work with a team of highly skilled engineers and scientists, who are developing the next generation personalization systems.You will be a technical lead for the team on our cross-functional projects
You have expert understanding of the systems, their dependencies and shortcomings
You hold a high bar for the quality of architecture and design of systems. Keep it simple too
You have expert knowledge full-stack
You bring engineering excellence mindset to the team and drive focus scalability, performance across systems
You are knowledgeable in design patterns and other artifact and use them to solve design problems
Actively mentor engineers and support resolving advanced technical issues
Through deep knowledge and experience drive influence across organization
What You'll Need:
Bachelor's degree and/or Master's degree in Computer Science or equivalent
10+years of software engineering experience with Java or C#
10+ years of experience working on large enterprise-scale projects
Expert knowledge application of CS fundamentals in OO Design, data structures, algorithms and problem solving
Experience working with AWS or similar cloud environments
Understanding of emerging technologies and their applicability
Position may require travel
Bonus:
PhD in Computer Science or related field
Experience working with ML, Spark, Hadoop etc
Experience building high-performance computational systems
If you have a disability under the Americans with Disabilities Act or similar law, or you require a religious accommodation, and you wish to discuss potential accommodations related to applying for employment at our company, please contact HR@Chewy.com.

To access Chewy's Privacy Policy, which contains information regarding information collected from job applicants and how we use it, please click here: Chewy Privacy Policy (https://www.chewy.com/app/content/privacy).",2.8,"Chewy
2.8","Boston, MA","Dania Beach, FL",10000+ employees,2011,Company - Public,Pet & Pet Supplies Stores,Retail,Unknown / Non-Applicable,-1
Senior Software Engineer - Big Data,-1,"SomaDetect is looking for a qualified Senior Software Engineer to design reliable and scalable data management solutions for our AI modelling needs. You will be responsible for developing, testing, improving and maintaining new and existing big data management solutions on both cloud and on-premises infrastructure to help our Artificial Intelligence Team build models and algorithms.

You will work closely with AI Scientists to ensure our system is working consistently. You will also collaborate with other members of the Product Development Team to provide technical support and identify new requirements. Communication and organization skills are keys to this position, along with a problem-solution attitude.

Responsibilities
Architect reliable and scalable big data solutions.
Implement, optimize and maintain big data solutions and systems.
Troubleshoot issues with existing data solutions.
Participate in user requirements gathering and identify new features.
Create unit and integration tests for new components and services.
Document usage and architecture of new services and applications.
Research and suggest new big data management products, services and protocols
Requirements
You have an in-depth understanding of big data management.
You have at least 5 years of experience with Python backend programming or other equivalent backend frameworks and languages such as Java, Ruby, .NET, NodeJS, Go, Rust or C++;
You have hands-on experience with NoSQL and SQL databases.
You have at least 5 years of experience building and securing REST APIs;
You have scaled big data solutions to 100s of Terabytes of data.
You have experience configuring and maintaining high availability data server architectures
You have solid knowledge and experience with containerization technologies like Docker;
You have a good understanding of networking and cloud security;
You have experience developing front-end code with HTML and JavaScript.
You have experience with agile planning tools like Jira or equivalent;
You have knowledge of image processing techniques.
You possess a university or college degree in Computer Science or Software Engineering;
You have a passion for technology and technology trends and you are eager to learn more;
You have exceptional critical thinking and analytical skills;
You have strong communication and documentation skills with the ability to communicate complex concepts to a broad range of individuals.
Assets:
Experience optimizing the use of NVIDIA Machine Learning hardware architectures like DGX.
Practical experience with machine learning libraries such as Keras & TensorFlow or equivalent;
Experience with deep learning architectures such as CNN.
Experience running machine learning applications on the cloud;
Experience building CI/CD pipelines in Bitbucket, GitLab or equivalent;
Experience with MLOps;
Experience with modern JavaScript frameworks like Vue, Angular, React or others.
Experience with Infrastructure as Code tools like CloudFormation, Terraform or others;
Knowledge of container orchestration tools like ECS or Kubernetes;
Experience with Django Python framework or Flask;
About SomaDetect

SomaDetect is a precision dairy technology, milk quality and dairy data company with offices in Fredericton, NB, Buffalo, NY and Thorold, ON. Founded in Fredericton, New Brunswick in 2016, SomaDetect has designed and produced an in-line sensor that measures critical indicators of dairy-quality from every cow at every milking. Our technology uses no consumables, chemicals, or cartridges, and with no lost milk. For more information, visit www.somadetect.com",-1,SomaDetect,Remote,"Fredericton, Canada",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Machine Learning Engineer,-1,"CodaMetrix is a well-capitalized, early-stage company focused on solving some of the more interesting yet challenging problems in clinical and healthcare administrative areas. The company was formed by the Massachusetts General Brigham (MGB) to help commercialize and build upon internally developed, and highly utilized AI-driven solutions.

CodaMetrix is led by proven entrepreneurs, technology, and healthcare veterans, whose vision is to create a highly desirable atmosphere for technical talent to flourish and develop innovative, significant, reliable, and broadly utilized solutions.

As an early-stage company, specific responsibilities will evolve, and significant job expansion and promotion opportunities are available.

*Job Description
At CodaMetrix, the machine learning and AI team is responsible for the invention, analysis, and deployment of new machine learning techniques using healthcare data to improve administrative and clinical medicine.

We are looking for an experienced engineer to join our machine learning team and help with translating proof-of-concept ideas to product grade solutions. The Machine Learning Engineer will work closely with data scientists, product owners, and backend engineers to gather requirements and understand performance criteria to deliver solutions that bring our AI-driven robust and scalable products to market. The Machine Learning Engineer reports to the Senior Director of Machine Learning and AI.

Responsibilities
Establish processes for data and modeling lifecycle through managing the transitions from proof-of-concept to production.
Promote for best practice software development principles.
Implement and test machine learning and deep learning techniques at scale.
Analyze the quality and calibration of predictive models.
Collaborate with machine learning, engineering, and product development teams, for deployment of new machine learning techniques and follow deployments, tracking issues, and successes.
Interface with medical coders, administrators, and physicians to understand the strengths and weaknesses of existing products and to help develop new machine learning-empowered products.
Requirements
Minimum of a bachelor's degree in software engineering, computer science or a related technical field with significant course or project work in machine learning, artificial intelligence, or data science. A masters degree with significant course or project work in a machine learning related field is a plus.
Minimum of two years experience in professional software development.
Fluent with software development best practices, including version control, documentation, testing and CI/CD.
Extensive experience with machine learning approaches and an understanding of the analysis and testing processes of machine learning algorithms.
Must have experience with AWS, particularly SageMaker, cloud storage (S3, Redshift) and computing (EC2, EMR)
Experience with SQL and NoSQL Databases, particularly Elastic Search and production database systems (e.g. Postgres) and technologies
Proficiency in one or more programming languages such as Python and/or Java.
Beneficial Experience
Familiarity with Natural Language Processing approaches.
Familiarity with deep learning approaches such as CNN, RNN and Reinforcement learning.
Some knowledge of US healthcare systems.
Location: Boston, MA with the ability to work remotely.

Job Type: Regular, full-time.

Compensation: Highly competitive and commensurate with the level of experience.

EEO Statement

CodaMetrix is an Equal Employment Opportunity Employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, gender, national origin, age, disability status, protected veteran status, or any other characteristic protected by law.

Our company, as well as our products, are made better because we embrace diverse skills, perspectives, and ideas.
Job Type: Full-time

Benefits:
401(k)
Dental Insurance
Flexible Schedule
Health Insurance
Paid Time Off
Parental Leave
Referral Program
Vision Insurance
Schedule:
Monday to Friday
Experience:
developing product grade software: 1 year (Required)
AWS SageMaker: 1 year (Preferred)
Software Development: 4 years (Required)
AWS or cloud services: 1 year (Required)
Education:
Master's (Preferred)
Work authorization:
United States (Preferred)
Application Question:
What are the uses of APIs in cloud services?
Work Location:
One location
This Company Describes Its Culture as:
Detail-oriented -- quality and precision-focused
Innovative -- innovative and risk-taking
Team-oriented -- cooperative and collaborative
Company's website:
www.codametrix.com
Benefit Conditions:
Only full-time employees eligible
Work Remotely:
Temporarily due to COVID-19",-1,CodaMetrix,"Boston, MA","Boston, MA",1 to 50 employees,-1,Company - Public,-1,-1,Unknown / Non-Applicable,-1
Sr. Software Engineer - Infrastructure,-1,"LeapYear's secure machine learning platform is deployed by some of the largest enterprises in the world across finance, healthcare, and technology.

Our technology ensures differential privacy, a widely recognized standard of data privacy that enables all data - including sensitive information - to be utilized for analytics, while providing mathematically proven privacy protection.

The LeapYear system is composed of a core set of components that allow private machine learning on data sets that can scale to petabytes. The system includes private algorithms for relational operations, statistical methods and machine learning. A data scientist accesses private data using a Python API. Administration is provided via a web-based GUI or an API.

LeapYear's Infrastructure team builds the tools that build our software and scales our test infrastructure such that all developers can contribute to automated test suites. For deployments of LeapYear, Infrastructure engineers write sophisticated, parameterized installers for enterprise environments, and automate deployment into cloud environments.

We are looking for versatile problem solvers that are interested in developer productivity, automation, and cloud infrastructure.
Responsibilities
Build the network and scale our existing systems using Infrastructure as Code
Partner with product management to define problems and identify iterative solutions
Balance immediate business objectives against a long-term architectural vision
Contribute to an engineering-wide culture of code quality and shared responsibility for testing
Contribute to other engineer's personal development by sharing knowledge, mentoring, and coaching
Requirements
7+ years of general software programming experience, including regular use of major scripting languages (Python, Bash, Ruby, Java)
5+ years of experience building network infrastructure, preferably with Infrastructure as Code tools
2+ years of experience using Infrastructure as Code tools such as Terraform, AWS CloudFormation, Ansible, and Packer
2+ years of experience building infrastructure with containers and using tools such as Kubernetes, Docker Compose or Docker
Enterprise experience with Linux systems administration, command line tools, and various distributions of Linux (Red Hat, Centos, Ubuntu, etc).
Experience with Continuous Integration/Continuous Deployment tools such as CircleCi, Jenkins or Spinnaker (CircleCI preferred)
Experience with services provided by AWS, GCP, VMware and Azure (AWS and GCP preferred)
Preferred
Experience with administering and running Hadoop and Spark clusters
Experience working in a startup environment
Experience with security best practices in Linux system administration and cloud infrastructure
Experience using secret management tools such as Vault or AWS/GCP secret manager
Experience testing the results of statistical analysis, preferably machine learning
Experience with Maven, Bazel, Gradle, or other modern build systems
Acquainted with and interested in functional programming (Haskell, OCaml, Clojure, Erlang, Scala)
A Few of the Perks
Culture of teaching and learning
Competitive compensation package of salary and equity
Catered lunch every day
Company outings
Build your ideal work station
Generous health insurance plan
Relocation support and visa sponsorship",4.2,"LeapYear
4.2","San Francisco, CA","San Francisco, CA",1 to 50 employees,2015,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Software Engineer II - CTJ with Security Clearance,"$95K-$138K
(Glassdoor est.)","Are you interested in working for one of the most exciting products at Microsoft to help advance Microsoft's AI Platform? Are you excited about being part of a product group working with Microsoft researchers, data scientists and AI engineering teams to ensure success as they move forward with cloud computing in Azure? If so, then look no further than the AI Platform team. AI Platform is responsible for the Azure Machine Learning (Azure ML) and Cognitive Services products. Azure ML is building the machine learning development platform that makes it easy for all data scientists and AI developers to create and deploy robust and highly scalable ML and AI solutions in the cloud using the best of the open source ecosystem and innovation from inside the company along with the latest breakthroughs in research. Artificial intelligence (AI) is dramatically transforming people's work and life now, and Cognitive Services bring AI within reach of every developer-without requiring machine-learning expertise. All it takes is an API call to embed the ability to see, hear, speak, search, understand, and accelerate decision-making into your apps. We are hiring engineers who are passionate about building scalable, distributed, highly available, and secure cloud services for Microsoft AI Platform. We value creativity and a desire to learn new technologies, agility and accountability. Join our team and help us build the best AI Platform for the world! Responsibilities As a member of our team, you will participate in developing innovative solutions across AI Platform. Responsibilities include the following. * Write concise and clean code with unit tests * Build scalable, high-performance services that are highly reliable * Design and implement new features as well as add functionality to existing systems * Investigate pre-production and production issues, implement and deploy fixes * Participate in an on-call rotation (typically 24/7 for one week every 6-8 weeks) * Being enthusiastic, self-motivated, and a great collaborator * Being passionate about making customers successful Qualifications Qualifications: * A minimum of a Bachelor's degree in Computer Science or Engineering, or a related field, or equivalent alternative education, skills, and/or practical experience is required. * 5 years of software development experience in C#, Java, Scala, C++, Go, Python or similar languages. * Solid Computer Science fundamentals, fluent in multi-threaded programming, experience/inclination for architecting at scale * Demonstrated technical design, problem solving, coding and debugging skills * Experience with distributed systems design and implementation, especially microservices architecture, and Kubernetes, Linux, and related technologies is a plus * Good written and oral communication skills Security Clearance Requirements: * Citizenship Verification: This position requires verification of US Citizenship to meet federal government security requirements * Candidates must have an active TS and be willing to upgrade to TS/SCI (with polygraph) or have an active TS/SCI and be willing to upgrade to TS/SCI (with polygraph). This role will require candidates to maintain the TS/SCI (with polygraph) clearance. * Microsoft Cloud Background Check: This position will be required to pass the Microsoft Cloud background check upon hire/transfer and every two years thereafter Ability to meet Microsoft, customer and/or government security screening requirements are required for this role. These requirements include, but are not limited to the following specialized security screenings: Microsoft Cloud Background Check: This position will be required to pass the Microsoft Cloud background check upon hire/transfer and every two years thereafter. #AIPLATFORM# #AIPLATREF# Microsoft is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable laws, regulations and ordinances. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. If you need assistance and/or a reasonable accommodation due to a disability during the application or the recruiting process, please send a request via the Accommodation request form . Benefits/perks listed below may vary depending on the nature of your employment with Microsoft and the country where you work.",4.3,"Microsoft Corporation
4.3","Elkridge, MD","Redmond, WA",10000+ employees,1975,Company - Public,Computer Hardware & Software,Information Technology,$10+ billion (USD),"Google, Amazon, Apple"
Sr. Software Engineer - AI Infrastructure and Parallel Computing,"$131K-$149K
(Glassdoor est.)","Sr. Software Engineer AI Infrastructure and Parallel Computing


Location: Campbell, CA

Start Date: Immediate

STAR Labs

STAR Labs (Samsung Technology & Advanced Research Labs) is headed by Pranav Mistry with a mission to undertake independent initiatives to create end-to-end new businesses and expand growth areas for Samsung. At STAR Labs, we are building new immersive and intelligent services that is making science fiction a reality. STAR Labs consists of best of the best from domains such as computer science, business strategy, engineering, design; and diverse set of experiences from places like MIT, Stanford, Oxford, CMU, Nasa, Google, Microsoft and many more. NEON is a venture from STAR Labs (http://neon.life)

The team builds upon their outstanding track record of creating products that have real-world impact at global scale. We are rapidly expanding and is looking for the best to join and help us build foundation for our next magical technology stack. We value our differences and are excited to learn what you can add to STAR Labs.

Requirements
Collaborate within the team across product, design, product, infrastructure, strategy and engineering.
Mentor, learn and share knowledge with others along the way.
Have impact and have fun
Working outside your comfort zone
Skills
MS of PhD from leading university in Computer Science and/or 4+ years of relevant industry experience
Minimum 3 years of experience developing C/C++ software, including modern C/C++ (C++11/14) and multithreading, resource management and compute graph optimization
Understanding of modern GPU architectures for parallel computing
Experience with at least one of the following: imaging software, CUDA/OpenCL, SIMD, multithreading, computer vision
Apply your software architecture skills to design consistent C/C++/Python API's, write code running on CPU and/or GPU, and advocate for best coding practices amongst the group
Partner with the vision & machine learning scientists to develop robust, performant software pipelines
Experience with any of the deep learning frameworks: Tensorflow, PyTorch, Caffe, Keras and others.
Experience working with multi-node/distributed training, data loading and image/video processing
Previous experience of scaling up and optimizing HPC, computer vision or deep learning training pipelines to terabyte scale datasets is a huge plus.
Samsung is an EEO/Veterans/Disabled/LGBT employer. We welcome and encourage diversity as we strive to create an inclusive workplace",3.5,"Samsung Research America
3.5","Campbell, CA","Mountain View, CA",1001 to 5000 employees,1988,Subsidiary or Business Segment,Computer Hardware & Software,Information Technology,$50 to $100 million (USD),"Sony, LG Electronics, Nokia"
Data Engineer,-1,"About VidMob:

VidMob is an award-winning Marketing Creative Platform that provides an end-to-end technology solution for all a brand's creative needs. It is an integrated platform combining first-of-a-kind creative analytics with best-in-class creative production to understand and improve marketing effectiveness.

Culture fit is key to success at VidMob. We seek candidates that are curious, collaborative and committed to excellence. We take every hire seriously and only choose seriously talented team members. We care deeply about our employees and are dedicated to making VidMob an exceptional company to work for. VidMob is proud to offer comprehensive health plans paid for by the company, enhanced Maternity/Paternity Programs and unlimited vacation plans. We also provide employees with access to 401K plans, healthy food and snacks, and pre-taxed transit.

VidMob is an Equal Opportunity Employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics.

Who We're Seeing

We are looking for a Data Engineer with the passion and technical skills to make data come to life. The ideal candidate must blend expertise in data with hands-on experience in engineering. You should strive to design and build large-scale, high-performance data systems through your insights into data and how to manage it at scale. If faced with roadblocks, you continue to reach higher to make greatness happen. You believe in not only serving customers but also empowering them by providing knowledge and tools.

What You'll Do

Play a pivotal role in growing our data initiatives, supporting both data insights and software engineering teams. Rapidly process data on an immense scale. Create reports that drive business outcomes and optimizations. Balance granularity and business value with resource cost and efficiency. Develop the maturity of VidMob's platform by reducing latency and error rates. Maintain speed, availability, and reliability as our client base grows.

Responsibilities
Work with data insights teams to define and extract data sets for use in analysis and machine learning
Work with software engineering and data science teams to design, build, and manage our application DB, machine learning components, and our data infrastructure
Maintain, extend, and automate reporting infrastructure
Manage the design and architecture of our data warehouse
Create software tools to automate and manage ETL processes and dependencies
Minimum Qualifications
B.S. in computer science or equivalent experience
Advanced working knowledge of SQL and relational databases, MySQL preferred
Understanding of statistics and data modeling methodologies
Experience collaborating with Data Scientists and Data Analysts
Ability to create fast solutions to problems introduced in a changing environment with iteration towards optimal solutions
Experience with data-related AWS services such as RDS, Redshift, and Kinesis
Experience with programming or scripting language, preferably Python, Java, or Scala

Details

Location: Pittsfield, MA

Compensation: Competitive salary and equity (based on experience).

Benefits:
Health Care Plan (Medical, Dental & Vision)
Unlimited Paid Time Off (Vacation, Sick & Public Holidays)
Family Leave (Maternity, Paternity)
Training & Development
Stock Option Plan
401k Plan",5.0,"VidMob
5.0","Pittsfield, MA","New York, NY",51 to 200 employees,2015,Company - Private,Audiovisual,"Arts, Entertainment & Recreation",Unknown / Non-Applicable,-1
Senior Manager AI Software Engineering - AI & Data Platform,"$115K-$217K
(Glassdoor est.)","We are EA

And we make games how cool is that? In fact, we entertain millions of people across the globe with the most amazing and immersive interactive software in the industry. But making games is not easy. Thats why we employ the most creative, passionate people in the industry.

The Challenge Ahead:

The EA Digital Platform Data & AI Group provides unified AI resources across all franchises within Electronic Arts. Our group develops AI and data-driven solutions to game team problems, and common AI infrastructure for use in every facet of the company. From data modeling to agent building, we use a modern, cloud-based tech stack with outstanding tools to provide solutions and platforms empowering the future of game development, marketing, sales, and player experience.

Reporting to a Director of AI Engineering/Principle you will lead the efforts of a small team of engineers in the development of the EA AI platform.

What does an AI Engineer at EA do?
You will create scalable solutions for business problems in the gaming domain
You will develop core AI infrastructure components to ease the use of AI and machine learning techniques for building games, play games, and operate games
You will work side-by-side with AI Scientists to develop and evaluate new models for predictive learning applications like recommendations or bad-actor detection.
You will work with the core development teams to deploy models as part of production systems
You will establish scalable, efficient, automated processes for large-scale data analyses, model development, model validation and model implementation.
Our next AI Engineer at EA has:
Masters minimum or Ph.D in Computer Science, or related fields (focus in AI or ML)
1+ years experience leading a platform engineering team
5+ years of software development experience, writing clean reusable code, test-driven development, and integration
3+ years of hands on experience with AI/ML technology
Experience handling large volumes of data
Programming skills (object-oriented and functional paradigms)
Experience with large-scale distributed programming paradigms
Experience with analytic tools such as Spark, Tensorflow, or similar
Experience with SQL and MPP databases
Experience with cloud service providers (AWS, Google Cloud, Azure)
Experience with system deployment and orchestration technologies such as Docker and Kubernetes
Job Requirements: Masters degree or foreign degree equivalent in Computer Science, Electrical

Engineering, or related field and five years of experience in the job offered or software engineering

related occupation, or Ph.D degree or foreign degree equivalent in Computer Science, Electrical

Engineering, or related field and one year of experience in the job offered or software engineering related

occupation.

Whats in it for you? Glad you asked!

We love to brag about our great perks like comprehensive health and benefit packages, tuition reimbursement, and 401k with company match and, of course, free video games. And since we realize it takes outstanding people to make excellent games, we offer great compensation packages and a culture that appreciates creativity and individuality.

#LI-NS1",3.9,"Electronic Arts
3.9","Redwood City, CA","Redwood City, CA",5001 to 10000 employees,1982,Company - Public,Video Games,Media,$2 to $5 billion (USD),"Riot Games, Google, Activision Blizzard"
Senior Software Engineer,"$88K-$168K
(Glassdoor est.)","Description

SiriusXM and Pandora have joined together to create the leading audio entertainment company in the U.S. Together, we are uniquely positioned to lead a new era of audio entertainment by delivering the most compelling subscription and ad-supported audio experiences to millions of listeners in the car, at home and on the go. Our talent, content, technology and innovation continue to be at the forefront, and we want you to be a part of it! Check out our current openings below and at

Position Summary:
As a senior member of the Search team at Pandora/SiriusXM you are responsible for building and maintaining the service that supports Search functionality interactions across our native mobile and web applications, automotive systems and third party devices.
You work closely with Product Management and Data Science partners to implement innovative features and measure their impact. You're comfortable working in a distributed team, in a fast paced environment and have excellent written and verbal communication skills. You have a collaborative attitude and love working with others to find elegant solutions to complex problems, always keeping the end user in mind. You have a solid foundation of Java development and are comfortable building services at scale. You are familiar with cloud software deployment and monitoring tools and are enthusiastic about learning new technologies and skills. You have a backgound in Search or Recommender systems or a deep curiousity and willingness to learn.
Duties and Responsibilities:
Write high performant, well-documented code.
Excellent complex problem solving and critical thinking skills
Deploy application on prem and on cloud.
Understands the requirements mentioned in the document/stories strategize a solution.
Supervisory Responsibilities:
This role has no supervisory responsibilities.
Minimum Qualifications:
Must have a Bachelor's degree in Computers
Requirements and General Skills:
5+ years development experience with a focus on microservice development
Working knowledge of Elastic Search or other search framework
Experience deploying code to production environments
Experience with cloud computing (Google Cloud Platform, Amazon Web Services)
Experience with Spring/SpringBoot
Experience with Recommender, or Search systems.
Working knowledge of Logstash and Kibana
Working knowledge of Kafka
Experience collaborating with data scientists, exposure to machine learning algorithms and/or statistical modeling methods.
Interpersonal skills and ability to interact and work with staff at all levels.
Ability to work independently and in a team environment.
Ability to pay attention to details and be organized.
Ability to project professionalism over the phone and in person.
Ability to handle multiple tasks in a fast-paced environment.
Willingness to take initiative and to follow through on projects.
Excellent time management skills, with the ability to prioritize and multi-task, and work under shifting deadlines in a fast-paced environment.
Must have legal right to work in the U.S.
Technical Skills:
Working knowledge of Java, Elastic Search, Kibana, Logstash, Python.
Working knowledge of Clojure is a plus.
Should be familiar with Agile working methodologies.
Familiar with Team city, Jenkins, AWS.
Working knowledge of Kafka.
Good Understanding of Agile methodologies.
Thorough knowledge of MS-Office Suite (Word, Excel, PowerPoint, Access).
Our goal at SiriusXM+Pandora is to provide and maintain a work environment that fosters mutual respect, professionalism and cooperation. SiriusXM+Pandora is an equal opportunity employer that does not discriminate on the basis of actual or perceived race, creed, color, religion, national origin, ancestry, alienage or citizenship status, age, disability or handicap, sex, gender identity, marital status, familial status, veteran status, sexual orientation or any other characteristic protected by applicable federal, state or local laws.
The requirements and duties described above may be modified or waived by the Company in its sole discretion without notice.",3.5,"Pandora Media, Inc.
3.5","New York, NY","Oakland, CA",1001 to 5000 employees,2000,Company - Public,Radio,Media,$500 million to $1 billion (USD),-1
Software Engineer - Data Platform,"$84K-$110K
(Glassdoor est.)","Software Engineer - Data Platform

Charlotte, NC

Position Summary: The Engineering team is seeking a business intelligence expert with a skills emphasis on data management, data warehousing, and developing framework for data platform. The team works closely with Product Managers, Executives, Data scientists, Report developers and other key parts of the business to understand their data requirements and build appropriate systems and platform that meet or exceed those specific business functions. You must be willing to get into the details and do, but also be able to step back and help us plan the strategic direction of our data management and reporting practices.

Essential Duties and Responsibilities (other duties may be assigned):
Architect and build to enhance an ever-expanding data platform supporting business process needs for internal and external integration via self-serve computing, reporting solutions, and interactive querying
Define, build, test, document and audit data platform artifacts including data models, data flow processes, integrations, etc
Able to work cross-functionally across multiple departments in a fast-paced environment
Identifies opportunities to adopt innovative technologies that fuels HCSs vision
Strong analytical and problem-solving skills with attention to detail
Work with the latest and greatest technologies in the Microsoft cloud stack including SQL Server, MS Azure, Data Lake, ADF, SSAS, SSIS etc
Qualifications:
Working knowledge of ETL development, data transformation, data modeling and data warehouse best practices
Detailed knowledge of Relational and Multi-Dimensional databases
Knowledge of database concepts, and experience with RDBMS and No-SQL solutions
The successful candidate will have strong programming skills, especially in SQL, data modeling and related data warehouse concepts
Experience with at least one scripting language or OO programming language
Working knowledge of software development life-cycle
Education/Experience:
4-year / bachelors degree in computer science or equivalent field from an accredited college or university
2+ years of relevant work experience
Experience working with cloud technologies such as Azure or AWS
Ability to write, analyze, and debug SQL queries
Experience with Data Warehouse design, ETL (Extraction, Transformation & Load), architecting efficient software designs for DW platform
Knowledge of database modeling and design in a Data warehousing context
Experience with development of test automation solutions
Ideal candidates will have a deep understanding of technical and functional designs for Databases, Data Warehousing, Reporting, and Data Mining areas
.Net or Java experience a plus
Familiarity or experience with Hadoop or Machine Learning is a plus",4.8,"Health Credit Services
4.8","Charlotte, NC","Charlotte, NC",51 to 200 employees,2015,Company - Private,Lending,Finance,Unknown / Non-Applicable,-1
Staff Machine Learning Engineer,"$138K-$235K
(Glassdoor est.)","ServiceNow is changing the way people work. With a service-orientation toward the activities, tasks and processes that make up day-to-day work life, we help the modern enterprise operate faster and be more scalable than ever before.

If you thought you knew about ServiceNow and what we do, take a look again! Our products lines are diverse and robust. The Enterprise Cloud is dynamic, scalable to billions of transactions weekly, and global in scope and size.

As a part of the core Platform as a Service offering, the Intelligent Automation Development team is building the core machine learning/AI/predictive analytics technology that will power revenue generating business use-cases using customer data to predict desired outcomes automatically; hence delivering significant increase in productivity of business processes of ServiceNow customers. The team focuses on operationalizing machine learning and predictive analytics use cases for all ServiceNow business applications.

We employ only the brightest, innovative and most intuitive data scientists on the planet. We have offices in San Diego, San Francisco, Santa Clara and Hyderabad and work as a distributed team. Come join the Intelligent Automation team and make your mark in the most challenging problem area - helping customers derive the insights from their own data on ServiceNow platform.

What you get to do in this role:

Specifically, you will
Work on various ServiceNow client data sets and focus on solving applied problems in classic ML solutions such as Classification, Similarity, Clustering, Natural Language Understanding, Text Mining, Anomaly Detection, Forecasting, etc., by leveraging statistical/mathematical concepts and core machine learning/AI tools and techniques
Opportunity to learn, work and contribute to the innovative and enterprise grade ServiceNow’s Machine Learning and Artificial Intelligence engine as part of the overall Platform-as-a-Service offering
Understand the business needs of Platform BU's customers
Translate the business needs into data requirements
Design and experiment (proof of concept), code, execute and iterate to retrieve business value/knowledge discovery from client’s data
Define and document success criteria/measures for the POC to prove the feasibility of the design experiment
Communicate and collaborate with appropriate teams and important stakeholders from the business units on the complete lifecycle of the experiment
Retrieve, clean/sanitize/normalize client’s data available in multiple data sources in ServiceNow instance
Choose an appropriate Statistical/ML/AI model, engineer the features and define appropriate model evaluation metrics
Plan to generalize, scale and integrate the model at the platform level making it available as a core feature/functionality to all ServiceNow client base
Monitor, support, fix bugs, iterate and improve model performance to a desired level over a definitive time period
Completely own the quality and metrics (response times, scalability, etc.) of the deployed model
Develop innovative patentable ideas that ensures the competitiveness of this product within the domain of similar work being done in the industry
Lead and deliver key asks from internal constituents by example
Advance the natural language capabilities of the ServiceNow platform
To be successful in this role, we need someone who has:
10+ years of research experience with 5+ years of core Machine Learning Engineering/AI experience
5+ years of java programming experience
Advanced degree in the field of data science/computer science/mathematics/statistics will be a definite plus
Working experience in Machine Learning based solutions such as classification, similarity, clustering is highly preferred
Deep understanding of Statistics/Linear Algebra/Calculus and various optimization algorithms is a must
Hands-on experience on various supervised/semi-supervised/unsupervised ML/AI algorithms like SVM, Random Forests, Clustering, Linear/Logistic Regression, Classification, PCA, Time Series Forecasting, Deep Neural Nets and Sequential speech/language models
Strong leadership and influencing skills with an ability to crisply communicate/articulate model performance/experience results to Key stakeholder’s and wider audience with appropriate visualization techniques
Ardent data enthusiast with experience and interest in engaging with data science communities like Kaggle and various online forums
Ability to translate business needs into data requirements Experience working in Agile/Scrum environment is desired
Experienced in various forms of decision sciences and optimization software development
Exceptional debugging, testing, and problem-solving skills
Self-starter, with quick learning curve
Strong written and verbal communication skills and an ability and interest to mentor other junior data scientists.
Working experience within product development teams is a must
Must have demonstrated work experience through multiple life cycles of a product within a single company
Must have demonstrated capabilities to create patentable ideas.
We provide competitive compensation, generous benefits and a professional atmosphere. This is a very collaborative and inclusive work environment where individuals strong on aptitude and attitude will have an opportunity to grow their professional careers through working with some of the most advanced technology and talented developers in the business.

This position is based in Santa Clara,CA.",3.7,"ServiceNow
3.7","Santa Clara, CA","Santa Clara, CA",10000+ employees,2004,Company - Public,Enterprise Software & Network Solutions,Information Technology,$2 to $5 billion (USD),"BMC Software, CA Technologies, Salesforce"
Data Engineer,"$65K-$124K
(Glassdoor est.)","Alignment Healthcare is a data and technology driven healthcare company focused partnering with health systems, health plans and provider groups to provide care delivery that is preventive, convenient, coordinated, and that results in improved clinical outcomes for seniors.

We are experiencing rapid growth (backed by top private equity firms), our Data Services and BI team is looking for the best and brightest leaders. Data drives the way we make decisions. We love our customers and understanding them better makes it possible to provide the best clinical outcome and care experience.

This position will play a key role in building and operating a cloud-based data platform and its pipelines using big data technologies.

As a Data Engineer, you will develop a new data engineering platform that leverage a new cloud architecture and will extend or migrate our existing data pipelines to this architecture as needed. You will also be assisting with integrating the SQL data warehouse platform as our primary processing platform to create the curated enterprise data model for the company to leverage. You will be part of a team building the next generation data platform and to drive the adoption of new technologies and new practices in existing implementations. You will be responsible for designing and implementing the complex ETL pipelines in cloud data platform and other solutions to support the rapidly growing and dynamic business demand for data, and use it to deliver the data as service which will have an immediate influence on day-to-day decision making.
Interfacing with business customers, gathering requirements and developing new datasets in data platform
Building and migrating the complex ETL pipelines from on premise system to cloud and Spark to make the system grow elastically
Identifying the data quality issues to address them immediately to provide great user experience
Extracting and combining data from various heterogeneous data sources
Designing, implementing and supporting a platform that can provide ad-hoc access to large datasets
Modelling data and metadata to support machine learning and AI
Basic Qualifications:
Bachelors or Masters in Computer Science, Engineering, Mathematics, Statistics, or related field
3+ years relevant experience in cloud based data engineering.
Demonstrated ability in data modeling, ETL development, and data warehousing.
Data Warehousing Experience with SQL Server, Oracle, Redshift, Teradata, etc.
Experience with Big Data Technologies (NoSQL databases, Hadoop, Hive, Hbase, Pig, Spark, Elasticsearch etc.)
Experience in using Python, Java and/or other data engineering languages
Knowledge and experience of SQL Sever and SSIS.
Excellent communication, analytical and collaborative problem-solving skills
Preferred Qualifications:
Healthcare domain and data experience
Healthcare EDI experience is a plus
Industry experience as a Data Engineer or related specialty (e.g., Software Engineer, Business Intelligence Engineer, Data Scientist) with a track record of manipulating, processing, and extracting value from large datasets.
Experience building/operating highly available, distributed systems of data extraction, ingestion, and processing of large data sets
Experience building data products incrementally and integrating and managing datasets from multiple sources
Experience leading large-scale data warehousing and analytics projects, including using Azure or AWS technologies – SQL Server, Redshift, S3, EC2, Data-pipeline, Data Lake, Data Factory and other big data technologies
Experience providing technical leadership and mentor other engineers for the best practices on the data engineering space
Linux/UNIX including to process large data sets.
Experience with Azure, AWS or GCP is a plus
Microsoft Azure Certification is a plus
Demonstrable track record dealing well with ambiguity, prioritizing needs, and delivering results in an agile, dynamic startup environment
Problem solving skills and Ability to meet deadlines are a must
Microsoft Azure Certification is a plus
Essential Physical Functions:

The physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform

the essential functions.
While performing the duties of this job, the employee is regularly required to talk or hear. The employee regularly is required to stand, walk, sit, use hand to finger, handle or feel objects, tools, or controls; and reach with hands and arms.
The employee frequently lifts and/or moves up to 10 pounds. Specific vision abilities required by this job include close vision and the ability to adjust focus.
Alignment Healthcare, LLC is proud to practice Equal Employment Opportunity and Affirmative Action. We are looking for diversity in qualified candidates for employment: Minority/Female/Disable/Protected Veteran.
If you require any reasonable accommodation under the Americans with Disabilities Act (ADA) in completing the online application, interviewing, completing any pre-employment testing or otherwise participating in the employee selection process, please contact careers@ahcusa.com.
(function() { var ac = document.createElement('script'); ac.type = 'text/javascript'; ac.src = ('https:' == document.location.protocol ? 'https://' : 'http://') + 'click.appcast.io/pixels/grpeople1-1573.js?ent=8&t=' + new Date().getTime(); var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ac, s); })();",3.5,"Alignment Healthcare
3.5","Orange, CA","Orange, CA",501 to 1000 employees,2013,Company - Private,Health Care Services & Hospitals,Health Care,Unknown / Non-Applicable,-1
Principal Software Applications & Infrastructure Engineer,"$133K-$233K
(Glassdoor est.)","SharkNinja is a relentless innovator with 550+ patents in consumer technologies. We obsess about consumer satisfaction. We build up our company by building up our people. We seize opportunities—individually and collectively—to be competitive with our products and attract the most talented people in the world.

SharkNinja Robotics Organization is a unique group of Roboticists, Software, Hardware Engineers, Analysts and Data Scientists who work on cutting edge technologies in IoT, Cloud, Artificial Intelligence, Machine Learning to create delightful consumer products. Through an unrelenting focus on solving for consumer’s pain points, we have built a loyal and passionate following that continues to garner us 5‑star ratings on our products.
The Principal Software Applications & Infrastructure Engineer will provide technical leadership to develop processes, build, and scale our mobile applications, release infrastructure and tools used to deploy software (Application, Firmware and Cloud) to our customers (through the mobile apps) and their devices (Robots/IoT). This is a hybrid role leading the mobile application development team and building out the software infrastructure to scale the output of the team through automation.
Responsibilities:
Work with development partners, SQA, UX Design, and Product management to build mobile applications for IoT devices and Robots.
Support the entire application lifecycle (concept, design, test, release and support)
Lead the team to pay down the technical debt while also creating new features
Develop, Support and Maintain CI (and ultimately CD) tools and systems.
Institute a test-first mentality without sacrificing velocity
Participate in code and security reviews
Design and implement a release status dashboard for executive reviews.
Automate builds for our target platforms (Mac, Windows, Linux, iOS, Android, and AWS)
Deliver reliable releases through methodical release planning and flawless execution.
Automate as many tasks as possible, support and further integrate automated tests with Quality metrics and conditional deployments.
Participate in Code reviews and help perform remote device upgrades.
Qualifications:
BS in CS/EE or equivalent with 10+ years of experience in S/W development and release management role
Min. of 4 years of experience in a release role in a highly scalable secure production
Min. of 4 years of mobile app development experience on iOS or Android platforms
Strong leadership and persuasive communication skills.
Must have experience working in an AGILE fast paced start up like environment.
Expert level skills in Scripting Languages - Python, PowerShell, Bash and one or two programming languages C/C++/Objective-C/Java.
Experience in an environment preferably dealing with millions of connected devices
Expert level knowledge of scalable deployments using Linux, Windows, Mac, iOS, Android, AWS based solutions.
Strong familiarity with Automation technologies, source control tools like Bitbucket/Git, Makefiles and Jenkins.
At SharkNinja, our purpose is to positively impact people’s lives every day in every home around the world. We work very hard to provide our consumers with high quality, exciting 5-star products that make life easier. We thrive on passion and innovation, and are looking for great people, with great ideas, who want to create the next big thing. We take a team approach to our projects, where everyone has a voice. We want individuals to push limits, look outside the box and think the unthinkable. With the explosive growth we have been experiencing, we’re looking for motivated individuals to join us on our exciting journey. People need to think big, move fast and want to make a significant impact. Are you ready?",3.1,"SharkNinja
3.1","Needham, MA","Needham, MA",1001 to 5000 employees,1993,Company - Private,Consumer Products Manufacturing,Manufacturing,$1 to $2 billion (USD),"Dyson, Keurig Green Mountain"
Data Scientist (Java),-1,"About Us:
We are able to operate at a low cost while delivering advanced capabilities to our clients by building and operating highly automated systems in all aspects of its business. We offer award-winning desktop, mobile and web applications which provide our clients with the tools they need to be successful. The company was founded by a software engineer to rewrite the rules of trading by automating anything and everything. Software development is the lifeblood of our firm, and it shows. Our engineers work with latest technology, command respect in the firm, and have competitive compensation packages.

We are looking for a Data Scientist. The successful candidate will execute analytical tasks on large data sets to support decision makers and provide insight and reports about our platforms. The data scientist role will use data to help us better understand who our clients are, how they engage with our products and services and how we can better serve them by identifying interesting and useful trends in our data. You will make an impact by using your passion for data and analysis to generate actionable insights that we will use to improve the experience for our clients.

* Must be able to work full-time at job location. We will not offer remote or contract work.

Responsibilities:
Collect and analyze various telemetry and behavioral data
Produce daily metrics and reports
Clean and prepare data for Machine Learning and A.I.
Assist with designing and running A/B tests
Automate frequently used reporting and data analysis workflows
Work closely with software engineers and architects to extract, transform and standardize data for optimal use for analytic tools

Qualifications
Bachelors in Computer Science, Mathematics, Statistics or related fields; Masters strongly preferred
2+ years' experience in a data science or data analysis role
2+ years of Java coding experience
2+ years mining and analyzing data sets to extract meaningful trends, producing meaningful and actionable reports
Experience using statistical programming languages, machine learning and other toolkits and techniques for analyzing large, complex datasets
Technical proficiency with transforming structured and unstructured data sets
Strong analytical skills, attention to detail and accuracy
Expert problem solving skills and creative thinking ability

We offer:
Excellent Medical , fully paid by company
Comprehensive Dental and Vision
Discretionary performance bonus
Flex Spending Account
Commuter Reimbursement Account
Matching 401K
Stock Incentive Plan
Vacation
Life Insurance
Lunch Paid by company

Company Overview
We are a low-cost provider of trade execution and clearing services for active traders, institutional investors, financial advisors and introducing brokers. Our premier technology provides electronic access to stocks, options, futures, forex, bonds, and funds worldwide from a single Integrated Investment account. We are one of the largest online brokers by trade volume and is consistently ranked at the top of its field.

Our employees are part of a dynamic, multinational, fast-paced, results-oriented team working to provide our customers with state-of-the-art trading technology, superior execution capabilities, worldwide electronic access, and sophisticated risk management tools.

Our headquarters are in Greenwich, CT, USA. We have offices in the United States, Canada, the United Kingdom, Switzerland, Hungary, Estonia, Russia, India, Hong Kong, China, Japan and Australia. We are a member of NYSE, FINRA, and SIPC. We are regulated by securities and commodities agencies around the world.",4.9,"ubergig
4.9","New York, NY","New York, NY",1 to 50 employees,2009,Company - Private,Building & Personnel Services,Business Services,$5 to $10 million (USD),-1
Senior Machine Learning Engineer,-1,"About Labelbox

Labelbox is building infrastructure for data science teams to manage training data for neural networks. It's easy to take for granted the existence of collaborative tools for tasks like writing and debugging code; the machine learning world has no standard tooling for labeling data, storing it, debugging models and continually improving their accuracy. Enter Labelbox. Our vision is to become the go-to software platform for data scientists to collaboratively manage their data and train neural networks, all in a tight feedback loop.

Labelbox is experiencing massive growth, and we are looking to expand our engineering team to meet the demands of our burgeoning customer base which includes companies like American Family Insurance, Lytx, Airbus, Genius Sports, Keeptruckin and others. Labelbox is venture backed by Andreessen Horowitz, Gradient Ventures (Google’s AI-focused venture fund), Kleiner Perkins and First Round Capital and has been featured in Tech Crunch, Web Summit and Forbes.

Qualifications
• Masters or PhD in CS preferred or equivalent experience
• Expert in deep learning and computer vision
• Excellent developer with experience building production-scale data pipelines and web applications in Python
• Intimate experience with deep learning frameworks (TensorFlow, Pytorch, Caffe, Keras)
• Previously built and shipped ML products

Bonus Qualifications
• PhD in Computer Science with focus on Computer Vision
• Comfortable with speaking at tech / industry conferences.

Responsibilities
• Build, implement, deploy computer vision algorithms that significantly speed up labeling
• Deliver product innovation in how teams using Labelbox are able to improve the accuracy of their model

We believe that AI has the power to transform every aspect of our lives -- from healthcare to agriculture. The exponential impact of artificial intelligence will mean that mammograms can happen quickly and cheaply irrespective of the limited number of radiologists in the world and that farmers will know the instant disease hits their crops without needing to be there in person.

We’re building a platform to accelerate the development of this future. Rather than requiring companies to create their own expensive and incomplete homegrown tools, we’ve created a training data platform that acts as a central hub for humans to interface with AI. When humans have better ways to input and manage data, machines have better ways to learn.

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.",4.0,"Labelbox
4.0","San Francisco, CA","San Francisco, CA",1 to 50 employees,2018,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Signal Processing and Machine Learning Engineer - ATAS,-1,"ID: 495711
Type: Researchers
Location: Smyrna, GA
Categories: Acoustics, Algorithm Development, Artificial Intelligence, Data Analytics/Science, Health Informatics, Machine Learning, Modeling/Simulation, Signal Processing
Job Description


The Aerospace Transportation and Advanced Systems Laboratory (ATAS), Aerospace and Acoustics Technologies Division (AATD) is searching for a Signal Processing and Machine Learning engineer who can think outside of the box and is looking for a dynamic and challenging work environment. The candidate will support multiple opportunities in the Biosensing and Signal Analytics Branch (BSAB), as it relates to physiological sensing, biomedical signal processing, and machine learning, communications, tactical sensing, and related tactical applications. The role of this position is to apply technical skills to support the development of software and hardware in support of ongoing projects and support the development of new research opportunities.

Job Duties


The ideal candidate will display skills and an educational background in electrical engineering and in one or more of the following areas: signal processing, statistical signal processing, machine learning, data processing, array processing, and beamforming, acoustics, and related topics. The desired candidate should be familiar with the application of digital signal processing and machine learning to data analysis and exploration and algorithm development using modern programming techniques. Moreover, candidates should also possess familiarity with data measurement techniques, data acquisition systems and transducers, have familiarity with a laboratory environment, have excellent communication skills and be familiar with the peer-review publishing and review process.

Travel Requirements


10% - 25% travel

Education & Length of Experience


Research Engineer/Scientist I
A Bachelor's degree in Electrical and Computer Engineering, Electronic Engineering, Computer Science, Mechanical Engineering, Aerospace Engineering, or a related field of study.
Research Engineer/Scientist II
A Master’s degree in Electrical and Computer Engineering, Electronic Engineering, Computer Science, Mechanical Engineering, Aerospace Engineering, or a related field of study and three (3) years of relevant full-time experience after completion of that degree,
A Master’s degree in Electrical and Computer Engineering, Electronic Engineering, Computer Science, Mechanical Engineering, Aerospace Engineering, or a related field of study and five (5) years of relevant full-time experience after completion of a Bachelor’s degree, or
A Doctoral degree in Electrical and Computer Engineering, Electronic Engineering, Computer Science, Mechanical Engineering, Aerospace Engineering, or a related field of study.
Required Minimum Qualifications
Candidates currently enrolled in an accredited Bachelor's degree program relevant to this position will be considered. Candidate must have a graduation date of no later than December 2020
Experience in signal processing and machine learning algorithms utilized for applications
Programming experience in Matlab, Python, C, and C++
Experience with Linux and Windows and open-source software tools
Knowledgeable in version control software such as GIT
Experience with the acquisition and analysis of measured data
Good verbal and written communication skills
Self-starter and ability to work in a team environment
Preferred Qualifications
A Master or Ph.D. in Electrical Engineering or related fields
Active Secret Clearance
Record of publications and technical seminar presentations
Experience in applied ML to time series analysis and development of predictive models
Knowledge of array signal processing with emphasis on acoustic applications and infrasound
Experience in time-frequency analysis and wavelets
Experience with one or more of the following Matlab Toolboxes: Signal Processing, Statistics and Machine Learning, Phased Array, Wavelets
Experience managing research projects, making technical presentations, and report writing
U.S. Citizenship Requirements


Due to our research contracts with the US federal government, candidates for this position are required to be US Citizens.

Clearance Type Required


Ability to obtain Secret Clearance upon hire

Diversity & Inclusion


Diversity & Inclusion (D&I) at Georgia Tech Research Institute aims to enhance the Institute’s mission of solving the world’s most complex technical problems by creating a workforce with a shared appreciation for diversity, raising awareness around inclusiveness, and fostering a sense of belonging and appreciation for all members of our community.

Equal Employment Opportunity


Georgia Tech Research Institute is an Equal Opportunity Employer of individuals with disabilities and protected veterans and actively seeks diversity among its employees. Equal Employment Opportunity is the Law.

Posted: 06/15/2020
Closes: 09/15/2020",3.6,"Georgia Tech Research Institute
3.6","Smyrna, GA","Atlanta, GA",1001 to 5000 employees,1943,Subsidiary or Business Segment,Research & Development,Business Services,$100 to $500 million (USD),"MIT Lincoln Laboratory, Johns Hopkins University Applied Physics Laboratory"
"Big Data Engineer, Sr Principal","$127K-$214K
(Glassdoor est.)","Description
Position Description:

The Vanguard 2.2.1 contract currently has an opening for a Data
Architect/Scientist to support the Department of State (DoS) Bureau of
Information Resource Management (IRM) Artificial Intelligence and Emerging
Technologies Directorate. This program develops leading-edge technologies and
delivers innovative solutions to the DoS. SAIC is seeking a highly qualified
Data Architect/Scientist to support the various initiatives; Artificial
Intelligence, Machine Learning, consolidation and centralized data lake for
various Splunk platforms, IaaS, PaaS, and SaaS initiatives within the Amazon,
Google, and Microsoft cloud environments. The preferred candidate will develop
solutions utilizing quantitative analysis, predictive analytics, data modeling,
data lake design, and machine learning in support of the DoS mission.
REQUIRED SKILLS:
Experience in applying
Database Design, Data Lake, and Data Mining principles within virtual, cloud,
and hybrid cloud environments.
Familiar with Big Data
Architecture (Hadoop, Cloudera, Spark), distributed system, data warehousing
(example: Apache Hive), and Data Lakes
Experience with
Infrastructure as a Service, Platform as a Service and Software as a Service
within at least one of the 3 major cloud providers (Amazon, Google, or
Microsoft)
Strong Technical Skills in
MS SQL, MySQL, PostgreSQL, or MongoDB
Programming languages -
XML, JavaScript, Python
Strong development,
debugging, testing and troubleshooting skills.
Experience with Splunk
and Tableau
Experience with data
modeling, predictive analytics, quantitative analysis, data lake design,
machine learning
Experience with database
security hardening processes in a Government environment
Experience with shell
scripting
Experience with Agile,
Scrum, DevOps process
Proficient working within
Windows and Linux Operating Systems
DESIRED SKILLS:
Team oriented approach
and capable of working independently
Mission/customer driven
solution architect
Ability to integrate
customer vision/mission with emerging technologies
Excellent oral and
written communication skills
Excellent analytical and
troubleshooting skills
Qualifications

TYPICAL EDUCATION AND EXPERIENCE: Bachelors and eight (8) years or more experience; Masters and five (5) years or more experience",3.7,"SAIC
3.7","Springfield, VA","Reston, VA",10000+ employees,2013,Company - Public,Enterprise Software & Network Solutions,Information Technology,$5 to $10 million (USD),"Booz Allen Hamilton, CACI International"
Algo Software Engineer (C++/Python),"$141K-$180K
(Glassdoor est.)","At HRT, we program computers to intelligently trade on the stock market. We make the world's markets more financially efficient using smart algorithms. To get the job done, we hire some of the smartest computer scientists in the world to develop both our low latency trading platform and our massive distributed research platform.

Algo Software Engineers (AE) are programmers that are embedded in HRT's trading teams and work hand-in-hand with Algo Strategy Developers (AD). Whereas ADs tend to use their math skills to make smarter strategies, AEs focus on the software that powers trading and research. Because of this close collaboration, AEs tend to be the type of engineers that thrive on constant interaction and discussion. Hearing how their most recently deployed system allowed for whole new types of research would make their week. AEs are the type of engineers that don't mind juggling a few projects at once and have a varied portfolio of project types, from long-term ambitious new systems to fire-fighting live issues.

Our environment is particularly well suited to driven, self-motivated programmers. For one, the company's Partners are all programmers. Team Leads spend a majority of their time doing technical work. Algo teams run on a very bottom-up approach that encourages everyone on the teams to come up with ideas and dictate the direction of each team together. Finally, there is very little emphasis placed on project management process (almost no meetings and no project managers) and there is a lot of emphasis placed on engineering process such as automated testing, design/code reviews, and technical training.

We are a Linux/Unix shop with a codebase written primarily in C++ and Python. If you are not a C++ or Python or Linux expert, that's probably OK. We really care more about your technical fundamentals, practical experience and that intense desire to make things better for other people. That being said, we want someone who is familiar with a non-scripting language such as C++ or Java.

Here are a few examples of programmers who are currently AEs at HRT:
When he's not solving riddles and dancing salsa, David's writing distributed computing APIs. He regularly solves bugs like ""one out of a million jobs are dying on only these machines and only on Tuesdays"". He likes bridging the gap between Algo Strategy Developers and Systems Engineers to explore how to use distributed computing to run research. He really enjoys coming up with ways to make millions of jobs more efficient.
Kai came to HRT after 3.5 years of programming C++ at a company that provides large amounts of data to the finance industry. He plays several musical instruments and has tasted thousands of wines, yet he finds his work to be an even more rewarding experience. He builds tools to discover opportunities and aid live trading. He is excited about automating strategies and implementing ideas from his teammates, in addition to applying his technical skills to the world of trading.
Aaron started programming at age 5 and previously ran the research team at a music software company, bringing over 7 years of experience to HRT. He cooks and practices partner acrobatics in his free time. He gets joy from his teammates' happiness when their research runs twice as fast, from building them tools that help them visualize their strategies, and from keeping code organized and maintainable. He's gotten coworkers from other teams involved in latency improvements to his group's live trading. He enjoys the collaborative environment and learning from his coworkers.
Culture:
Hudson River Trading (HRT) brings a scientific approach to trading financial products. We have built one of the world's most sophisticated computing environments for research and development. Our researchers are at the forefront of innovation in the world of algorithmic trading.

At HRT we come from all sorts of backgrounds: mathematics, computer science, statistics, physics, and engineering. We're a community of self-starters who are motivated by the excitement of being at the cutting edge of automated trading. Our culture celebrates great ideas whether they come from HRT veterans or new hires. At HRT we're friends and colleagues, whether we are sharing a meal, playing the latest board game, or writing elegant code. We embrace a culture of togetherness that extends far beyond the walls of our office.

Seem like something you might be interested in? Our goal is to find the best people and bring them together to do great work in a place where everyone is valued. HRT is proud of our diverse staff; we have offices all over the globe and benefit from our varied and unique perspectives. HRT is an equal opportunity employer; so whoever you are we'd love to get to know you.",5.0,"Hudson River Trading
5.0","New York, NY","New York, NY",201 to 500 employees,2002,Company - Private,Financial Analytics & Research,Finance,Unknown / Non-Applicable,-1
"Sr Software Development Engineer - Machine Learning, Alexa AI","$142K-$221K
(Glassdoor est.)","The main responsibilities for this position include:
· Develop scalable architecture for conversational dialogue platform with continuous learning capabilities
· Build technical strategy for integrating business policies with machine learned models to best fulfill a customers intent, crossing multiple skills and service providers
· Develop approaches for fast inference for conversational models to reduce user perceived latency
· Audit and influence the design for storing and accessing context collected from heterogeneous sources first-party domain verticals, third-party skills, explicit & implicit user preferences
· Develop multi-turn dialog strategies inclusive of representations for how developers can easily integrate their services/capabilities into Alexa with minimal code authoring
· Develop offline and online machine learning modeling architecture for fast, scalable supervised, semi-supervised, and unsupervised learning from heterogeneous data sources live interaction data, catalogs, knowledge bases, etc.
· Contribute to the architecture for running large-scale end-to-end A/B testing for a complex AI system like Alexa that has multiple ML-based stochastic decision-making steps before giving a response to the user.
Strong candidates will have the following experience:
• Deep technical experience with real-world Spoken Language Systems and/or Web Search
• Industry luminary who can attract top science and engineering talent
Ability to work with multi-disciplinary, geographically distributed team of machine learning scientists, software developers, product managers, data specialists, etc.


Basic Qualifications

· 3+ years of programming experience with at least one modern language such as Java, C++, or C# including object-oriented design
· 2+ years of experience contributing to the architecture and design (architecture, design patterns, reliability and scaling) of new and current systems
· 4+ years of professional software development experience
· 10+ years of industry experience developing scalable architecture
· Bachelors/MS/PhD in Computer Science or other Engineering, Math or Science Disciplines or equivalent years of experience


Preferred Qualifications

· Proven track record of scalable engineering systems in real-world applications /products
· Excellent written and verbal communication skills with the ability to present complex information in a clear and concise manner to a variety of audiences
· Ability to think strategically and create long-term roadmap",3.9,"Amazon
3.9","Sunnyvale, CA","Seattle, WA",10000+ employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),"Google, Microsoft, Walmart"
Research Engineer - Deep Learning,-1,"Job Description
Research Engineer in Deep Learning and Computer Vision

Company Introduction:

CuraCloud is a rapidly growing healthcare AI startup company founded in 2015 in Seattle, WA. Our mission is to empower healthcare with AI technology by creating custom AI-driven quality and productivity innovations.

We are dedicated to provide healthcare clinicians and researchers with deep learning based tools and software solutions, increasing the efficiency of healthcare delivery and allowing healthcare providers to gain unprecedented insights into diagnostics, care processes, treatment variability, and patient outcomes. We are working with radiology practices, hospital networks, university-based researchers, and IT services providers around the world to make a positive impact on healthcare.

Job Location

Seattle, WA, USA

Job Overview

We are looking for talented research engineers with deep learning expertise to build our medical image analysis products. As part of our core research and development team, you will:
Design and develop cutting-edge deep learning algorithms applicable to one or more of: medical image data analysis, computer vision, NLP
Directly participate throughout the entire design process
Design and perform experiments to continually refine and enhance our deep learning technology solutions
Work closely with Research Scientist team members to write papers and patents
Qualifications
MS in Computer Science, Electrical Engineering, Statistics, Biomedical Engineering or related discipline required
Two or more years' research and internship experience in Computer Vision, Machine Learning and Image Understanding
Proficient in Deep Learning Libraries (e.g. TensorFLow, Pytorch),
Strong verbal and written communication skills
Strong presentation skills
Ability to work independently and as part of a team to meet project goals
Ability to quickly learn new skills and knowledge in a fast-pace work environment
Desired:
Experience in C++ is a plus
CuraCloud Corporation is an equal opportunity employer and all qualified applicants will receive consideration for employment. We will provide competitive salaries and benefits.

If interested, please send your full-length CV to: join@curacloudcorp.com

Powered by JazzHR

8Zbs89WN52",4.1,"CuraCloud Corporation
4.1","Seattle, WA","Seattle, WA (US), WA",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
"Sr Software Development Engineer - Machine Learning, Alexa AI","$142K-$221K
(Glassdoor est.)","The main responsibilities for this position include:
· Develop scalable architecture for conversational dialogue platform with continuous learning capabilities
· Build technical strategy for integrating business policies with machine learned models to best fulfill a customers intent, crossing multiple skills and service providers
· Develop approaches for fast inference for conversational models to reduce user perceived latency
· Audit and influence the design for storing and accessing context collected from heterogeneous sources first-party domain verticals, third-party skills, explicit & implicit user preferences
· Develop multi-turn dialog strategies inclusive of representations for how developers can easily integrate their services/capabilities into Alexa with minimal code authoring
· Develop offline and online machine learning modeling architecture for fast, scalable supervised, semi-supervised, and unsupervised learning from heterogeneous data sources live interaction data, catalogs, knowledge bases, etc.
· Contribute to the architecture for running large-scale end-to-end A/B testing for a complex AI system like Alexa that has multiple ML-based stochastic decision-making steps before giving a response to the user.
Strong candidates will have the following experience:
• Deep technical experience with real-world Spoken Language Systems and/or Web Search
• Industry luminary who can attract top science and engineering talent
Ability to work with multi-disciplinary, geographically distributed team of machine learning scientists, software developers, product managers, data specialists, etc.


Basic Qualifications

· 3+ years of programming experience with at least one modern language such as Java, C++, or C# including object-oriented design
· 2+ years of experience contributing to the architecture and design (architecture, design patterns, reliability and scaling) of new and current systems
· 4+ years of professional software development experience
· 10+ years of industry experience developing scalable architecture
· Bachelors/MS/PhD in Computer Science or other Engineering, Math or Science Disciplines or equivalent years of experience


Preferred Qualifications

· Proven track record of scalable engineering systems in real-world applications /products
· Excellent written and verbal communication skills with the ability to present complex information in a clear and concise manner to a variety of audiences
· Ability to think strategically and create long-term roadmap",3.9,"Amazon
3.9","Sunnyvale, CA","Seattle, WA",10000+ employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),"Google, Microsoft, Walmart"
Algo Software Engineer (C++/Python),"$141K-$180K
(Glassdoor est.)","At HRT, we program computers to intelligently trade on the stock market. We make the world's markets more financially efficient using smart algorithms. To get the job done, we hire some of the smartest computer scientists in the world to develop both our low latency trading platform and our massive distributed research platform.

Algo Software Engineers (AE) are programmers that are embedded in HRT's trading teams and work hand-in-hand with Algo Strategy Developers (AD). Whereas ADs tend to use their math skills to make smarter strategies, AEs focus on the software that powers trading and research. Because of this close collaboration, AEs tend to be the type of engineers that thrive on constant interaction and discussion. Hearing how their most recently deployed system allowed for whole new types of research would make their week. AEs are the type of engineers that don't mind juggling a few projects at once and have a varied portfolio of project types, from long-term ambitious new systems to fire-fighting live issues.

Our environment is particularly well suited to driven, self-motivated programmers. For one, the company's Partners are all programmers. Team Leads spend a majority of their time doing technical work. Algo teams run on a very bottom-up approach that encourages everyone on the teams to come up with ideas and dictate the direction of each team together. Finally, there is very little emphasis placed on project management process (almost no meetings and no project managers) and there is a lot of emphasis placed on engineering process such as automated testing, design/code reviews, and technical training.

We are a Linux/Unix shop with a codebase written primarily in C++ and Python. If you are not a C++ or Python or Linux expert, that's probably OK. We really care more about your technical fundamentals, practical experience and that intense desire to make things better for other people. That being said, we want someone who is familiar with a non-scripting language such as C++ or Java.

Here are a few examples of programmers who are currently AEs at HRT:
When he's not solving riddles and dancing salsa, David's writing distributed computing APIs. He regularly solves bugs like ""one out of a million jobs are dying on only these machines and only on Tuesdays"". He likes bridging the gap between Algo Strategy Developers and Systems Engineers to explore how to use distributed computing to run research. He really enjoys coming up with ways to make millions of jobs more efficient.
Kai came to HRT after 3.5 years of programming C++ at a company that provides large amounts of data to the finance industry. He plays several musical instruments and has tasted thousands of wines, yet he finds his work to be an even more rewarding experience. He builds tools to discover opportunities and aid live trading. He is excited about automating strategies and implementing ideas from his teammates, in addition to applying his technical skills to the world of trading.
Aaron started programming at age 5 and previously ran the research team at a music software company, bringing over 7 years of experience to HRT. He cooks and practices partner acrobatics in his free time. He gets joy from his teammates' happiness when their research runs twice as fast, from building them tools that help them visualize their strategies, and from keeping code organized and maintainable. He's gotten coworkers from other teams involved in latency improvements to his group's live trading. He enjoys the collaborative environment and learning from his coworkers.
Culture:
Hudson River Trading (HRT) brings a scientific approach to trading financial products. We have built one of the world's most sophisticated computing environments for research and development. Our researchers are at the forefront of innovation in the world of algorithmic trading.

At HRT we come from all sorts of backgrounds: mathematics, computer science, statistics, physics, and engineering. We're a community of self-starters who are motivated by the excitement of being at the cutting edge of automated trading. Our culture celebrates great ideas whether they come from HRT veterans or new hires. At HRT we're friends and colleagues, whether we are sharing a meal, playing the latest board game, or writing elegant code. We embrace a culture of togetherness that extends far beyond the walls of our office.

Seem like something you might be interested in? Our goal is to find the best people and bring them together to do great work in a place where everyone is valued. HRT is proud of our diverse staff; we have offices all over the globe and benefit from our varied and unique perspectives. HRT is an equal opportunity employer; so whoever you are we'd love to get to know you.",5.0,"Hudson River Trading
5.0","New York, NY","New York, NY",201 to 500 employees,2002,Company - Private,Financial Analytics & Research,Finance,Unknown / Non-Applicable,-1
"Software Engineer, Lead: Big Data for Machine Learning Product Platform","$88K-$171K
(Glassdoor est.)","As an experienced member of our Software Engineering Group we look first and foremost for people who are passionate around solving business problems through innovation & engineering practices. You will be required to apply your depth of knowledge and expertise to all aspects of the software development lifecycle, as well as partner continuously with your many stakeholders on a daily basis to stay focused on common goals. We embrace a culture of experimentation and constantly strive for improvement and learning. You'll work in a collaborative, trusting, thought-provoking environment-one that encourages diversity of thought and creative solutions that are in the best interests of our customers globally.* BS/BA degree or equivalent experience* Solid experience in building data-intensive systems with good understanding of performance tradeoffs* Experience in Test Driven Development and Agile Software Development with CI/CD* Ability to work in large, collaborative teams to achieve organizational goals, and passionate about building an innovative culture* Proficiency in at least 2 of the modern programming languages: Java, Scala, Python, C++* Advanced experience in Big Data Technology with Hadoop, Spark, Flink* Mindset to work with highly sensitive data and appropriate controls framework.* Experience with data management, manipulating large data sets through statistical software and data warehousing environments processing large volume of transactions.* Ability to work in large, collaborative teams to achieve organizational goals, and passionate about building an innovative culture* Collaborate with product owners, data scientists, engineers, end users, and other stakeholders to build data product platformHighly Desirable Skills:Kafka, GraphQL API, Panda, Jupyter, Gaia, AWSCIB (Corporate & Investment Bank)Our Corporate & Investment Bank relies on innovators like you to build and maintain the technology that helps us safely service the world's important corporations, governments and institutions. You'll develop solutions for a bank entrusted with holding $18 trillion of assets and $393 billion in deposits. The Corporate & Investment Bank provides strategic advice, raises capital, manages risk, and extends liquidity in markets spanning over 100 countries around the world.When you work at JPMorgan Chase & Co., you're not just working at a global financial institution. You're an integral part of one of the world's biggest tech organizations. In our global technology centers, our team of 50,000 technologists design, build and deploy everything from enterprise technology initiatives to big data and mobile solutions, as well as innovations in electronic payments, cybersecurity, machine learning, and cloud development. Our $11B annual investment in technology enables us to hire people to create innovative solutions that are transforming the financial services industry.At JPMorgan Chase & Co. we value the unique skills of every employee, and we're building a technology organization that thrives on diversity. We encourage professional growth and career development, and offer competitive benefits and compensation. If you're looking to build your career as part of a global technology team tackling big challenges that impact the lives of people and companies all around the world, we want to meet you.",3.9,"JPMorgan Chase & Co.
3.9","New York, NY","New York, NY",10000+ employees,1799,Company - Public,Investment Banking & Asset Management,Finance,$10+ billion (USD),-1
Software Development Engineer - Alexa AI,"$119K-$149K
(Glassdoor est.)","Alexa is the groundbreaking cloud-based intelligent agent that powers Echo and other devices designed around your voice. Our mission is to push the envelope in Artificial Intelligence (AI), Natural Language Understanding (NLU), Machine Learning (ML), Dialog Management, Automatic Speech Recognition (ASR), and Audio Signal Processing, in order to provide the best-possible experience for our customers. Were looking for a Software Development Engineer to help build industry-leading conversational technologies that customers love.


As a Software Development Engineer for the Alexa team, you will be responsible for translating business and functional requirements into concrete deliverables with the design, development, testing, and deployment of highly scalable distributed services. You will also partner with scientists and platform engineers to help invent, implement, and connect sophisticated algorithms to our cloud based engines. A successful candidate should have knowledge of research domains including AI, NLU, ML, and Dialog Management. They should also be very agile in developing flexible software with respect to scientific, experimentation methods and usage patterns. Additional responsibilities include:

· Developing and maintaining core system features
· Helping define product features, drive the system architecture, and spearhead the best practices that enable a quality product
· Working with scientists and other engineers to investigate design approaches, prototype new technology, and evaluate technical feasibility
· Operate in an Agile/Scrum environment to deliver high quality software against aggressive schedules s


Basic Qualifications

· 2+ years of non-internship professional software development experience
· Programming experience with at least one modern language such as Java, C++, or C# including object-oriented design
· 1+ years of experience contributing to the architecture and design (architecture, design patterns, reliability and scaling) of new and current systems.

· Bachelor's degree in Electrical Engineering, Computer Sciences, Mathematics, or related technical field
·
· Knowledge of programming languages such as C/C++, Java, Perl or Python and open-source technologies (Apache, Hadoop)
·
· Experience with OO design and common design pattern
·
· Knowledge with data structures, algorithm design, problem solving, and complexity analysis
·
· Experience defining system architectures and exploring technical feasibility trade-offs



Preferred Qualifications


· Master's in Electrical Engineering, Computer Sciences, Mathematics, or related technical field
·
· Experience developing cloud software services and an understanding of design for scalability, performance and reliability
·
· Experience optimizing for short term execution while planning for long term technical capabilities
·
· Ability to prototype and evaluate applications and interaction methodologies
·
· Ability to produce code that is fault-tolerant, efficient, and maintainable
·
· Academic and/or industry experience with standard AI and ML techniques, NLU, and scientific thinking
·
· Experience working effectively with science, data processing, and software engineering teams
·
· Ability and willingness to multi-task and learn new technologies quickly
·
· Written and verbal technical communication skills with an ability to present complex technical information in a clear and concise manner to a variety of audiences



Amazon is an Equal Opportunity Employer Minority / Women / Disability / Veteran / Gender Identity / Sexual Orientation / Age",3.9,"Amazon
3.9","Sunnyvale, CA","Seattle, WA",10000+ employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),"Google, Microsoft, Walmart"
Principal Data Scientist,"$107K-$171K
(Glassdoor est.)","Please note, this is a proactive search for a role that has been vetted by our leadership team for future hiring.  The recruiting team and hiring managers remain active in discussions with interested, qualified individuals and are committed to being transparent on timelines throughout the process. Thank you.

Who We Are:


Vistaprint’s Data and Analytics (DnA) organization is working to make our company one of the world’s most well-known and successful data-driven companies. The cross-functional team includes product owners, analysts, technologists, data engineers and more – all focused on providing Vistaprint with information and tools we can use to deliver jaw-dropping customer value. DnA team members are empowered to learn new skills, communicate openly and be active problem-solvers.

About Our Team:


As the Principal Data Scientist, you will be a “go-to” domain specialist in data science and machine learning. You will lead the charge on innovative work, mentoring more junior data scientists, and guiding the organization on methodology and the best ways to work. You will also guide high-profile projects - not just delivering solutions, but finding opportunities and owning the work. Your statistical, computer science and business domain expertise will have a significant influence on our business.

You will join a core team of Data Scientists, working with Marketers, Analysts, Engineers and Product Owners to forge new paths and redefine how data is utilized to deliver value!

What You Will Do:
Engage with partners to advise on analytical project requirements, discuss methodologies and collaborate on work you're doing.
Learn, practice, and lead others to use new tools in an inspiring technical environment that combines both coding skills, web technologies and real-time data.
Analyze pre-existing models and algorithms; suggest how to improve the efficiency and effectiveness, to drive value to the organization
Deliver a range of custom Data Science projects that may include Recommendation Systems, Price Optimization; Time Series Modeling; Customer Lifetime Value Customer, Propensity Modeling); Image Recognition; The list goes on.
Be a thought leader within the Data Science team, knowing the latest trends and technologies
Your Qualifications:


PhD in Statistics, Mathematics, Operational Research or similar field
Extensive machine learning and modeling experience, and have delivered multiple projects as a lead scientist or in a similar capacity
Strong programming skills in Python and R
Hands-on experience using “big data technologies”
Experience using standard libraries (scikit-learn, MLlib, TensorFlow, MXNet, PyMC3)
Experience of software engineering techniques including version control, continuous integration, unit testing.
Proven ability to independently communicate technical and statistical concepts to non-practitioners within the business, and influence the application.
Experience of designing and building DS products for ecommerce like recommendation systems, forecasts, Customer Lifetime Value Models, etc.
Nice to Have:


Spark, Java, Scala
Bayesian Statistics
Agile working methodology


Why You’ll Love Working Here:


At Vistaprint, we put great importance into the wellbeing of our employees, which is why we offer perks that ensure a phenomenal work/life balance. Perks include flexible schedules, work from home capabilities, and very generous time off, including our unique sabbatical-like program, “Vistabreak”, to name a few! Here in Waltham, we offer a modern and collaborative office environment with a free on-site gym, fully stocked kitchens, and cold brew on tap.

About Us:


As an e-commerce powerhouse, Vistaprint is a dynamic organization that maintains an exciting, entrepreneurial culture. With founder Robert Keane’s return as CEO, we’ve renewed our focus on empowering and helping small businesses. To do this, we create customer value (and delight) through accessible, cutting-edge technology. We thrive on providing opportunities for exploration, collaboration, innovation and growth – for both our customers and our team.

Equal Opportunity Employer:


Vistaprint, a Cimpress company, is an Equal Employment Opportunity Employer. All qualified candidates will receive consideration for employment without regard to race, color, sex, national or ethnic origin, nationality, age, religion, citizenship, disability, medical condition, sexual orientation, gender identity, gender presentation, legal or preferred name, marital status, pregnancy, family structure, veteran status or any other basis protected by human rights laws or regulations. This list is not exhaustive and, in fact, in many cases, we strive to do more than the law requires.

#LI-KM1

Nearest Major Market: Waltham
Nearest Secondary Market: Boston
Job Segment:
Database, Scientific, Scientist, Engineer, Computer Science, Technology, Engineering, Science",3.5,"Vistaprint
3.5","Waltham, MA","Venlo, Netherlands",5001 to 10000 employees,1995,Company - Public,Other Retail Stores,Retail,$1 to $2 billion (USD),"Tripadvisor, Wayfair, Amazon"
Frontend Software Engineer - UI/UX Development and Design,-1,"Are you a Frontend Software Engineer who loves to create beautiful software design in an engaging environment?. We are looking for exceptional web developers with strong software engineering chops and solid UI/UX design skills to join our front-end development team.

You will design and develop innovative user interfaces and information visualizations for a growing web application to help our end users make sense of their challenging problems. This position is unique among front-end development positions in that you will be responsible for building and maintaining a front-end codebase that is used across many products at the company. This requires a keen focus on keeping the interface intuitive while still enabling all of the powerful data analysis tools necessary to slice and dice a problem.

You will work with our superlative team that includes Systems Engineers, Mathematicians, Computer Scientists, UI/UX Designers, and Developers. Solving fun and challenging problems is in our DNA - at CCRi, we only take on interesting projects.

Requirements

Are dedicated to designing and building superb user interfaces

· Have strong experience with JavaScript, HTML, and CSS

· Have experience developing and iterating on mockups, translating these to style and code

· Have excellent debugging and problem-solving skills

· Have a strong visual design sense and appreciation for developing a stellar user experience

· Enjoy researching and testing the latest and greatest technologies

· Have the ability to multitask, prioritize, and respond quickly in a fast-paced environment

· Learn quickly and want to share knowledge

· Enjoy working in an exciting, dynamic environment with a great team of intelligent co-workers

· Bachelor’s Degree in a technical field with at least 3 additional years of related professional experience

· US citizenship required

Bonus points if you also:

· Use Angular, or have experience with other JS frameworks

· Have experience writing in TypeScript

· Have experience with css pre-processors (Stylus, LESS, SASS, etc)

· Use data visualization tools/toolkits such as d3 or similar libraries

· Have experience developing map based applications using OpenLayers, Leaflet, Google Maps, etc.

· Are familiar with all aspects of software development, including client/server programming

· Have the ability to drive and review APIs for back-end functionality

· Are interested in data mining, analytics, and/or machine learning

We’re looking for candidates with solid technical foundations and a desire to continue learning. Preference given to candidates with an active security clearance.

In compliance with federal law, all persons hired will be required to verify identity and status as a US citizen, and to complete the required employment eligibility verification document form upon hire. Failure to do so can and will result in dismissal.

Benefits
Intellectually Challenging Work and Learning Opportunities· Health Insurance· Short Term Disability Insurance· Generously Defined Benefit Retirement· Extremely Flexible Vacation Policy· Relocation
Want to know more about CCRi? https://www.youtube.com/watch?v=xjIqoDmAg4I
The job description above is not intended to be comprehensive list. Responsibilities, activities, duties, and/or tasks may change or be assigned at any time.

CCRi is committed to a diverse and inclusive workforce because we know that our differences benefit our employees, our customers, and our community. We are proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, color, religion, age, sex, sexual orientation, gender identity, national origin, status as a an individual with a disability, status as a protected veteran, or any other applicable legally protected characteristics.",4.5,"CCRi
4.5","Charlottesville, VA","Charlottesville, VA",51 to 200 employees,1989,Company - Private,Aerospace & Defense,Aerospace & Defense,$10 to $25 million (USD),-1
Data Engineer,-1,"RESPONSIBILITIES:

Kforce has a client that is in search of a Data Engineer to join their team in Milwaukee, WI. In this role, you will work in an agile environment.

Responsibilities:
Design, develop, optimize, and maintain data architecture and pipelines that adhere to ETL principles and business goals
Solve complex data problems to deliver insights that helps our business to achieve their goals
Create data products for analytics and data scientist team members to improve their productivity
Advise, consult, mentor and coach other data and analytic professionals on data standards and practices
Lead the evaluation, implementation and deployment of emerging tools and process for analytic data engineering in order to improve our productivity as a team
REQUIREMENTS:
5 years of experience working in data engineering or architecture role; 7+ years preferred
Expertise in SQL and data analysis
Experience developing and maintaining data warehouses in big data solutions
Experience developing data models at enterprise level
Experience working in Azure
Experience developing data models at an enterprise level, ETL and be familiar with Power BI and Azure stack
Worked with BI tools such as Tableau, Power BI, Looker, Shiny
Conceptual knowledge of data and analytics, such as dimensional modeling, ETL, reporting tools, data governance, data warehousing, structured and unstructured data
Exposure to machine learning, data science, computer vision, artificial intelligence, statistics, and/or applied mathematics
Passionate about Agile software processes, data-driven development, reliability, and experimentation
Kforce is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.",4.1,"Kforce
4.1","Milwaukee, WI","Tampa, FL",10000+ employees,1966,Company - Public,Staffing & Outsourcing,Business Services,$1 to $2 billion (USD),-1
Data Scientist (PHD Required),-1,"Candidate should have experience with Computer Vision and Deep Learning

Must have:

PHD. in computer science or data science

2 years professional experience as software development engineer, data scientist, or machine learning engineer

Proficient in Python, with solid background in data structures and algorithms

Professional experience with computer vision knowledge of image classification, object detection; resnet, yolo, etc., in Pytorch

Other skills needed:

Experience with AWS sagemaker, github

Hungry desires to get things done while honoring people, and seeks better ways to do the job

Humble is open to being coached, has high EQ and is self-aware

Powered by JazzHR",4.6,"Serigor Inc.
4.6","San Francisco, CA","Baltimore, MD",1 to 50 employees,-1,Company - Private,IT Services,Information Technology,Less than $1 million (USD),-1
Software Engineer,-1,"IMMEDIATE OPENING !!

***An active Top Secret/SCI Full Scope Poly security clearance is mandatory for this position***

MOJA is seeking a Software Engineer to support our Customers’s warehouse management application.

In this position you will provide application development support. You will be part of a team with full stack multitasking capabilities working with our talented group of Developers, PMs, and Designers. You will apply IT acumen to engineer, design, and build the 2.0 System.

You will provide development engineering, and programming support to projects and infrastructure support activities, as well as designing and developing enterprise applications in a web environment. This includes analyzing user needs and developing, creating, and modifying general computer applications/software or specialized utility programs and solutions to match. You will design software or customize software for our client's use with the aim of optimizing operational efficiency. You will manage websites, including designing, developing, deploying, and maintaining activities, as well as performing testing and quality assurance of websites and web applications. You will analyze and design databases within an application area, working individually or coordinating database development with our customer as part of the larger sponsor team. To do this, you will need to maintain a strong awareness of technical trends in information technology, and develop and maintain a strong awareness of on-going IT projects and business unit requirements. You will need to be able to apply the project management model (Agile) for a given development effort; and provide analysis, design, development, deployment, and lifecycle support for innovative hardware systems and applications. Your work will involve being able to develop end-to-end cost analysis for projects, ensuring systems being developed comply with the enterprise technical architecture, and leading teams consisting of contractor personnel. You will manage and track user stories through the customer’s JIRA site, help project and program teams prepare for IT Project Management Program control gates, and keep senior management apprised of project or program status.

REQUIRED SKILLS:
Experience working with Amazon Web Services environments, including S3, EMR, SQS, and SNS, to design, develop, deploy, maintain, and monitor web applications within AWS infrastructures.
Experience providing technical direction to software and data science teams.
Experience collaborating with staff, IT customers, and other technical and non-technical staff and contractors at all levels.
Experience with Apache Spark.
Experience with PostgreSQL.
Experience working with RDS databases.
Experience developing complex data transformation flows using graphical ETL tools.
Experience engineering large scale data-acquisition, cleansing, transforming, and processing of structured and unstructured data.
Experience translating product requirements into system solutions that take into account technical, schedule, cost, security, and policy constraints.
Experience working in an agile environment and leading agile projects.
Experience providing technical direction to project teams of developers and data scientists who build web-based dashboards and reports.
DESIRED SKILLS
Experience engineering natural language processing and machine learning techniques into automated workflows. (Example techniques include clustering, ontologies and topic modeling, entity extraction Latent Semantic Indexing, and collaborative filtering.)
Experience working with data science tools technologies, particularly Python.
Experience developing non-traditional or innovative means of applying technical solutions to difficult analytic problems.
Experience working and applying creativity in a fast paced environment.
Experience with coordination and facilitation of meetings and technical discussions of requirements; tracking project status, plans, action items and drafting meeting minutes.
Experience with AWS Data Pipeline.
Experience with Kinesis.
Experience with Apache NiFi and Apache Kafka.
Experience developing in Java, Scala and Python.
Experience with Presto, Hive, Hadoop, and Cloudera.
Experience programming web applications in HTML, CSS, and JavaScript using jQuery.
Experience with Solr, Elasticsearch, or similar tool.
Experience with developing REST APIs and interfacing with REST APIs using AJAX.
*Referral Bonus Eligible**
MOJA is an information technology and intelligence analysis company based in Northern Virginia that has been providing information management solutions since it’s conception in 1995. We specialize in system integration, application development, network management, and intelligence analysis in support of the intelligence community and national level decision-makers. MOJA is a proud Certified Veteran Owned, Minority Owned company.

Have Questions? Not ready to apply, but want to submit your resume? You can email us directly: hr@moja.net or call us at (703) 369-4339.

MOJA benefits include: Health/Vision/Dental, Life/Disability, AFLAC & 401k.
MOJA is a proud Certified Veteran Owned, Minority Owned company and an equal opportunity employer.
MOJA is an e-verify employer.
Visit our website: www.moja.net",5.0,"MOJA
5.0","Springfield, VA","Manassas, VA",1 to 50 employees,-1,Company - Private,Aerospace & Defense,Aerospace & Defense,$1 to $5 million (USD),-1
Future Opportunity: (Senior) Machine Learning Engineer,-1,"Please note - this posting is for future opportunities and we will contact you should an opportunity arise that may be a good match.The OpportunityMachine learning lies at the core of insitro's approach to rethinking drug development. As a machine learning engineer, you will lead the development of cutting edge machine learning methods that solve key problems in the drug development process. You will work closely with a cross-functional team of life scientists, bioengineers, and data scientists to identify areas where machine learning can make a difference, to conceptualize and develop biological datasets using cutting edge, high throughput platforms, and to analyze these data sets using the best machine learning methods, applied at scale. You will need to come up with novel methods that use a broad spectrum of machine learning approaches, including techniques at the forefront of the field. We aim to develop large data sets, and apply cutting edge machine learning methods; hence, you will need to develop and deploy machine learning methods at scale. You will work as part of a team to rigorously analyze our data, pull out key insights, and make accurate predictions that will let us quickly develop drugs that have high efficacy and low toxicity. You will be joining as the founding team of a biotech startup that has long-term stability due to significant funding, but yet is very much in formation. A lot can change in this early and exciting phase, providing many opportunities for significant impact. You will work closely with a very talented team, learn a broad range of skills, and help shape insitro's culture, strategic direction, and outcomes. Join us, and help make a difference to patients!About You* BS, MS, or Ph.D. in computer science, statistics, mathematics, physics, engineering, or equivalent practical experience* Expertise in one or more general-purpose programming languages (such as Python, C/C++, or Scala)* Demonstrated ability to write high-quality, production-ready code (readable, well-tested, with well-designed APIs)* 4+ years of real-world work experience in software development for high-end machine learning algorithms* Significant experience with at least one high-end ML development environment (Tensorflow, Pytorch, Caffe, etc.)* Demonstrated ability to develop novel machine learning methods that go beyond putting together of existing code, and to apply problem-solving skills to complex issues* Ability to communicate effectively and collaborate with people of diverse backgrounds and job functions* Passion for making a difference in the worldNice to Have* Experience with biological data (DNA sequences, RNAseq, proteomics, microscopy images, etc.)* Experience with scalable machine learning, including the application to large datasets (100TB+)* Proficiency in Linux environment (including shell scripting), experience with database languages (e.g., SQL, No-SQL) and experience with version control practices and tools (Git, Perforce, etc.)* Familiarity with cloud computing services (AWS or GCP)Experience in these areas is highly valued but not required* Imaging and high content microscopy* Statistical Genetics* Functional genomics and epigenomics* Proteomics and small molecules modeling* Large-scale deep learning model trainingBenefits at insitro* Excellent medical, dental, and vision coverage* Open vacation policy* Team lunches (catered daily)* Commuter benefits* Paid parental leave",-1,Insitro,"South San Francisco, CA","San Francisco, CA",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Staff Software Engineer - Data Platform,"$87K-$173K
(Glassdoor est.)","At the intersection of technology, science, business and sports, Strivr offers an end-to-end, VR-based immersive learning platform that changes the way people around the world train, learn, and perform. With a mission to elevate performance through immersive experience, we are redefining an industry in real time and shaping the future of learning.

Strivr was founded in 2015 out of Stanford University’s Virtual Human Interaction Lab, using the football field as our proving ground. Since then, we have quickly expanded from the athlete to the enterprise, partnering with leading Fortune 500 companies including Walmart, Verizon, and Fidelity to innovate and elevate employee development.

At Strivr, our engineering teams develop immersive experience software and a cloud-based software platform that powers the creation, management, and experience of immersive learning with a unique level of insights and predictive analytics. The platform is scalable, secure, and compliant which is critical to making our customers and users successful on our platform. The engineering team is distributed and located in offices in Seattle and Palo Alto. In addition to the five company values of teamwork, grit, transparency, impact, and passion, we index on strong communication skills, a growth mindset, responsibility and ownership, and a collaborative and respectful work culture.

We capture and analyze device, usage, sentiment, and assessment data, attention and engagement data based on spatial (gaze, hand) and voice data over tens of millions of in-headset immersive learning and training sessions. We are developing a streaming analytics platform that will allow us to process, join, aggregate, reform, and query data across these very large structured and unstructured datasets to produce immersive analytics with deep insights on learning sessions. Consumers include customers and external users for insights on their learning and training performance, and internal users like Data Scientists and Analysts who need access to raw and processed data from pipelines using notebooks and machine learning frameworks to develop, experiment with, and train learning models.

We are hiring software engineers who are passionate about data engineering and analytics, and developing secure, scalable, and reliable data pipelines and platforms. As an engineer working on the Strivr’s data platform, you will have the opportunity to own the full cycle development of distributed services, data pipelines, and infrastructure that needs to scale to process petabytes of data and deliver insights and immersive analytics to hundreds of thousands of users and devices, all in real-time access. You will be expected to prioritize scalability, reliability, and security in your designs and implementation. You will work cross-functionally with other engineering teams, Product Managers and Data Scientists to deliver end-to-end user-facing functionality and experience.

Your responsibilities:
Systems architecture, design, implementation, and support of the following platform areas and capabilities:
Real-time and batch processing pipelines to process data into logical data sets in data lakes and analytical databases
Business and semantic layer services to transform data into reports, insights, and immersive analytics
APIs for querying raw and processed data for consumption by user-facing visualizations and dashboards in web applications
Tooling and infrastructure for machine learning frameworks, notebooks, and pipelines for querying raw and processed data for training and experimentation
Tooling and infrastructure for data validation in the different phases of the pipeline and in the data stores
Tooling and infrastructure to implement and enforce security and compliance policies for data protection and governance
Write secure, reliable, and performant code and add monitoring for everything you develop
Be data-driven, use instrumentation and monitoring to make improvements to the platform, functional or for-performance, or otherwise
Be a visible technical leader in the organization. Influence engineers by advocating for and practicing a culture of engineering excellence. Mentor and coach lesser experienced engineers to make a positive impact on their career development
Minimum Qualifications:
5+ years of software engineering experience, specifically with development of data pipelines and platforms, and a solid background in software development with one or more of C#, Java, Go
Experience with development and operationalization of large-scale data pipelines and distributed services for structured and unstructured data using streaming frameworks and systems like Kafka, Beam, Spark
Strong database fundamentals including SQL and operational experience with relational (like Postgres) and non-relational databases (like Druid, BigQuery, Elastic)
Experience with development of a data platform with tools and infrastructure for machine learning, training models, and experimentation
Strong written and verbal communication skills, both technical and non-technical
Ability to apply concepts from computer science, data-structures, and algorithms in order to solve problems in a pragmatic and efficient way
Passion for writing secure, readable, modular, and maintainable code and a drive for shipping high quality software with an emphasis on testing, data validation, monitoring, and SLOs to ensure data accuracy with high availability
Bachelors in Computer Science or related field, or equivalent experience
Preferred Qualifications:
Experience developing secure and scalable API services based on GraphQL or REST for web applications
Experience developing on public cloud platforms (Google Cloud, AWS, or Azure) including experience with orchestration using Kubernetes and Docker
Experience with one or more of the following: Natural Language Processing, text understanding, classification, pattern recognition, or similar",4.5,"Strivr
4.5","Palo Alto, CA","Palo Alto, CA",51 to 200 employees,2015,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Scientist,-1,"About Infinitive:

At Infinitive, we do mission-critical work for great companies. We specialize in digital marketing and digital advertising solutions, customer data & analytics, digital & business transformation, and Technology solutions. Our Technology solutions focus on Managed Cloud Services, Cloud Enablement, Digital Operations, Application Development, DevOps, Product Development, Cloud Security, Data Science and Analytics, AI/ML, IoT, and everything in between.

Our experts are results-obsessed, focused and flexible, highly engaged and hugely experienced having sat in our clients seats. Those qualities are what make us different than old-school consulting shops. And surely, they are why clients and partners describe us as the gold standard in client experience.

Infinitive has been named a Best Small Firms to Work For by Consulting Magazine seven times, a Washington Post Top Workplace three times, a Washington Business Journal Best Places to Work twice, and is a seven time winner of Virginia Business Best Places to Work.

About this Role:

Infinitive is growing its team in the Northern Virginia area and is currently seeking a Data Scientist to join our growing Technology practice. This person will utilize their experience in analytics, IoT, machine learning, and artificial intelligence advances to create value from structured and unstructured data. The ideal candidate has experience designing novel data analytic methods and workflows, including full data pipelines from raw data through analysis results. They must also have exposure to a variety of data mining/data analysis methods, data tools, building and implementing models, using/creating algorithms, and creating/running simulations.

We are looking for candidates who are accountable, passionate, assertive, proactive, open & honest, results oriented, and adaptable. Each project engagement represents a new challenge that will give you exposure to new clients, business issues, technologies, and people and will involve a range of responsibilities to include:
Developing in Java, Python, R, or other high-level languages.
Managing disparate data sources with varying data structures of content and preparing these for data science and machine learning applications.
Working with distributed scalable Big Data storage, processing, and computation, including AWS EMR, Spark, etc.
Implementation knowledge of, or desire to learn AWS / Azure data science capabilities.
Developing solutions and integrating and extending free and Open-source software (FOSS) or COTS products.
Conduct MapReduce programming with Apache Hadoop, the Hadoop Distributed File System (HDFS), and processing large data stores.
Knowledge of SQL and query languages.
Utilize real-time, large-scale data processing engine, including Apache Spark.
Lead and create Data Science and Analytics methodologies and frameworks for implementation.
Ability to build and develop Data Science demonstrations for clients
Qualifications:
3+ years of development experience (Java, Python, R)
2+ years of experience with distributed scalable Big Data storage, including AWS EMR, Spark, etc.
Desire to become AWS / Azure Certified architect / engineer.
Interest in being involved internally and growing a small business (entrepreneurial spirit)
Ability to travel (up to 20%) and to work independently
Ability to commute to client site
Experience using Agile software development methods in a DevOps environment.
Excellent leadership, peer management, and communication skills
Management consulting experience (preferred)
Bachelor's degree
Applicants for employment in the U.S. must possess work authorization which does not require sponsorship by the employer for a visa.

Infinitive is an Equal Opportunity Employer.

Powered by JazzHR",3.4,"Infinitive Inc
3.4","McLean, VA","Cedar Rapids, IA",201 to 500 employees,1997,Company - Private,Enterprise Software & Network Solutions,Information Technology,$10 to $25 million (USD),-1
R&D Software Expert Engineer,"$61K-$123K
(Glassdoor est.)","Keysight is the world's leading electronic measurement company, helping scientists and engineers address their toughest technical challenges with confidence through innovations in wireless, modular, and software solutions. Our employees leverage their insight and passion to deliver measurement solutions in wireless communications, aerospace and defense, and semiconductor markets with world-class platforms, software and consistent measurement science.

This job will be part of the Communications Solutions Group, which is responsible for Keysight's portfolio in the Wireless Data Ecosystem, including wireless devices, operators, internet infrastructure, and Aerospace & Defense. Our software-centric solutions accelerate our customers' time to market and reduce their costs - giving them a competitive advantage in today's and tomorrow's technology waves.
Job Listing Detail
Keysight Technologies has been unlocking electronic measurement insights for 75 years. We are the world's leading electronic measurement company Keysight employees serve customers in more than 100 countries, delivering solutions in wireless communications, aerospace and defense and semiconductor markets with world class platforms, software and measurement solutions. This job will be part of Communications and Solutions Group (CSG) Organization, which is responsible for delivering world leading solutions to the market. This position is focused on new product development for Keysight’s 5G/6G products and is based out of our R&D office in Santa Rosa, CA.
Job Description
This is one of those rare opportunities to continuously challenge your own creativity and design skills by developing solutions for the fast moving, emerging standards for the 5G/6G ecosystem. You will join a highly talented and motivated team of software and hardware engineers creating cutting edge technology test products for 5G/6G customer base. Will get to work on multiple operating systems, the latest generation of FPGAs, and powerful server class machines. You will have the opportunity to lead, learn and contribute to new and emerging technologies in fast paced projects to work closely with customers.
Job Qualifications
BS (MS Preferred) with degree in CSE, EE, CS or related discipline
5+ years of embedded Software development
Strong experience building software using C++, C# and C
Experience with designing modular software for multiple target environments (Windows, Linux, Bare metal)
Hands-on development experience with embedded systems
Fluency in various standard tools, e.g. scripting languages, IDEs, source control, and bug tracking systems
Extremely strong verbal communications skills and a desire for strong team collaboration
A passion for building things, including working in a fast-paced environment with hands-on design and development cycles
Over and above, a deep commitment to your own quality work and a strong desire to help the entire team to succeed
Additional Preferred Qualifications
7+ years of Experience with RF and Digital communication concepts (modulation, demodulation, mixing, etc.)
Academic knowledge or equivalent experience with wireless communications, especially 3GPP standards such as 4G, 5G
Experience with building real-time embedded system software and Linux application development
Experience with reading schematics and datasheets
Ability to debug circuits that interface with embedded software – spanning from the debugger down to the oscilloscope level
Experience using Visual Studio Team and developing embedded applications running a Windows operating system
Job Function
R&D
Shift:

Day Job
Schedule:

Full Time (F)
Travel Required:
Duration (Temp Positions Only):

Not Applicable

Careers Privacy Statement

***Keysight is an Equal Opportunity Employer.***

Keysight Technologies Inc. is an equal opportunity employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability or any other protected categories under all applicable laws.

Candidates can be considered to work from the following locations:

Americas : United States : California : Santa Rosa

Job ID : 36669",4.1,"Keysight Technologies
4.1","Santa Rosa, CA","Santa Rosa, CA",10000+ employees,2014,Company - Public,Electrical & Electronic Manufacturing,Manufacturing,$2 to $5 billion (USD),-1
Data Engineer,"$84K-$154K
(Glassdoor est.)","We're looking for a Data Engineer to join Procore's Information Technology Engineering team to help evolve our data-driven culture and become a world-class data organization. In this role, you'll help us gain a data advantage by leveraging our data assets and designing the foundation for which our advantage is constructed.

As a successful Data Engineer, you have a strong background in cloud infrastructure, particularly AWS and Google Cloud Platform. You strive to excel at everything you do while being able to prioritize between the must-haves and nice-to-haves. If you're intrinsically motivated and ready to roll up your sleeves and dive in—we'd love to hear from you!

This position will report into our Director, IT Engineering and has the option to be based in our Austin, TX offices located at the heart of downtown. We're looking for candidates to join us immediately.

What you'll do:
Create ETL (Extract, Transform & Load) pipelines to deliver sanctioned data to stakeholders, while maintaining high accuracy and reliability
Tune and monitor data infrastructure Performance to support a growing organization
Brainstorm data product ideas and partner closely with Data Scientists, Product Management and Operations teams to develop, test, deploy, and operate high-quality software
Develop data infrastructure that ingests and transform data from different sources and customers at scale.
Partner end-to-end with Business Managers, Product Managers, and Data Scientists to understand customer requirements and design prototypes and bring ideas to production
Work with internal business leaders to ingest data to enrich their data modeling and work products.
Participate in conversations with teams about business-impacting topics and brainstorm innovative ways to transform data into information and knowledge that drives revenue and reduces cost
What we are looking for:
BS or MS in Computer Science or equivalent
5+ years of data warehousing or data engineering experience with a distinguished track record on technically demanding projects
Deep knowledge of SQL databases (preferably PostgreSQL)
Comfort working with cloud-managed data warehouse technologies (Amazon Redshift, Google BigQuery, Snowflake)
Strong experience working with Python, particularly for ETL or Data Science related tasks
Experience working in a data lake architecture, separating compute from storage
Passion for creating new products and services, including being comfortable with the ambiguity associated with designing new products
Experience working with REST APIs to ingest and enrich data sets
Experience with Apache Airflow for workflow management is preferred
Comfort using Hadoop related technologies(Spark, Hive, Presto, etc.) is preferred
Data Science/Machine Learning background is preferred
Familiarity with the construction industry is preferred
About Us
Procore Technologies is building the software that builds the world. We provide cloud-based construction management software that helps clients more efficiently build skyscrapers, hospitals, housing complexes, and more. Our headquarters is located on the bluffs above the Pacific Ocean in Carpinteria, CA, with growing offices worldwide. Check us out on Glassdoor to see what others are saying about working at Procore!

We are an equal opportunity employer and welcome builders of all backgrounds. We thrive in a diverse, dynamic and inclusive environment. We do not tolerate discrimination against employees on the basis of age, color, disability, gender, gender identity or expression, marital status, national origin, political affiliation, race, religion, sexual orientation, veteran status, or any other classification protected by law.

Perks & Benefits
You are a person with dreams, goals, and ambitions—both personally and professionally. That's why we believe in providing benefits that not only match our Procore values (Openness, Optimism, and Ownership) but enhance the lives of our team members. Here are just a few of our benefit offerings: competitive health care plans, unlimited paid time off (Procore Values Time), employee enrichment and development programs, and volunteer days.",4.2,"Procore Technologies
4.2","Austin, TX","Carpinteria, CA",1001 to 5000 employees,2002,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Software Engineer (Device Drivers),-1,"Latest data points from customer meeting: Please look at profiles with the below skillset.
The programming experience on language remains same (Python , C/C ++ etc.)
The device driver development is specifically for remote devices / instruments
This is also referred as application drivers or remote instrument control
Ability to write simulator in absence of such instruments for unit testing etc.
Ability to understand instrument connectivity.
If we look for IoT + lifescience experience we will get good candidates.

Client is looking for a Device Driver Software Engineer to join our team in San Diego. You will be part of the Software team to develop, test, refine and expand our robotic work cell capabilities, and learn about the varied challenges of making and maintaining a truly general-purpose robotic system.

Â

Expectations:
Proficient in automation, working with devices and components, and integrating new hardware and software
A person with hands on experience, great attitude and ready to work with robots and automated equipment
Familiar with SDLC processes
Experience working with different programming paradigmsÂ
Proficient in one of the following programming languages: Java, Scala, or Python
General understanding of operating systems
A problem-solver with strong analytical skills
Organized with excellent communication skills
Comfortable in a fast-paced and autonomous environment
A team player who can work in a versatile and diverse environment
You Might Have:

Experience with Jenkins, Git, and other software tools and technologies.
MS (or BS with equivalent experience) in an engineering discipline with 5+ years of hands on system integration or automation design and implementation experience.
Experience debugging mechanisms, controls, software or electrical hardware.
A bonus but not necessary:
Knowledge of basic scientific principles in biology and chemistry and/or experience working closely with scientists to automate biological or chemical processes.
Expert ability to create, validate and maintain liquid handling processes on laboratory robotic workstations.
Experience with various lab automation equipment hardware and software.
DFM experience and an understanding of FMEA.
Experience with mechanical machine tools or test equipment, and fabrication or test/debug experience.
Experience interfacing with hardware and software vendors
Â",3.9,"Themesoft Inc
3.9","San Diego, CA","Plano, TX",51 to 200 employees,2004,Company - Private,IT Services,Information Technology,$50 to $100 million (USD),-1
Data Engineer,-1,"Hello,
Â
Data Engineer
Durham, NC
12+months
Â
7+ years of software development with two recent years of Scala development.
3+ years of using Spark
Experience developing web servicesÂand connecting to APIs. Preference will be given to candidates who have developed in a micro-service architecture.

Scala Data Science Developer â the role
As a member of a fast-growing team, within a growing area of the business, this role presents exciting opportunities for career progression.Â
Working with an enormous breadth of data, you will be able to design and develop data science applications on the latest big data platforms.Â
As a member of the team of data science software engineers and data scientists, you will have the opportunity and support to develop truly innovative solutions in support of the business.
Collaborating with data scientists, data engineers, and other developers to develop data science applications and services to support CRO business, including optimizing the design and execution of clinical trials, and improving risk management.
Collaborating on projects from concept to completion.
Designing and developing microservices to enable integration with legacy applications.
Comprehensive testing of your own code.
Documenting the application design and architecture.
Production deployments of microservices to k8s cluster through a CI/CD pipeline that you will design and setup.
Identifying opportunities for improvements of applications like improving service response time and horizontal scaling or exploring new technologies.
3+ years of relevant experience with Scala and a deep understanding of Functional programming.
Knowledge of Scala frameworks like Akka and Play.
1 year of relevant experience with Spark.
Knowledge of Kafka and/or RabbitMQ.
Experience designing and implementing Rest API and a good understanding of microservices design and architecture.
Familiarity with SQL.
Linux proficiency and experience with containerization tools such as Docker, Kubernetes.
Experience in following Scrum best practices.
Experience in putting machine learning models into production.
Deep understanding of JVM internals.
Experience with ELK stack.
Knowledge of Scala libraries like shapeless, cats, scala.
Familiarity with the whole Hadoop ecosystem like YARN, Hive, Impala, HDFS.
Experience with deploying code into production through CI/CD tools like Jenkins.
Front-end experience with some modern JavaScript frameworks.
Experience with non-relational databases like MongoDB and Redis.",4.6,"Conch Technologies, Inc
4.6","Durham, NC","Memphis, TN",51 to 200 employees,-1,Company - Private,Consulting,Business Services,$5 to $10 million (USD),-1
Data Engineer,-1,"Data Engineer

Bigtime Entertainment Co. building state of the art software and
algorithms to improve the way that our
media company transacts; interacts with consumers and customers;
and makes
vital business decisions with large revenue impacts. As a Data
Engineer
supporting the Data Science team, you will frame, pose and
translate business
problems to build AI-powered solutions that directly contribute
to data
products. As a member of the Data Science & Engineering team, you
will be
designing and building scalable models & architectures upon while
ML algorithms
can thrive, as well as refining existing model implementations so
that they
automatically build context in order to perform above and beyond
expectations.

From creating
experiments and prototyping implementations to designing new
architectures, we
resolve challenging and meaningful problems with compelling
business use cases.
Our team is committed to continuously leveraging and furthering
the latest
advances in ML research to transform the broader media market
through our data
product successes

In this role you will:

· Collaborate with the
data science team to build future-proof frameworks and
abstractions

· Collaborate with
product management and engineering departments to understand
company needs and
devise AI powered solutions

· Build tools that
will increase the productivity of the Data Analytics team-members
developing AI-based systems

· Implement models
that the data science team develops into working prototypes,
proof of concepts,
self-supporting model ecosystems

· Build data pipelines
that contribute to a self-sustaining data model system

· Build demos and
conduct training in conjunction with data scientist to help the
broader
engineering organization (and/or business partners) effectively
use the product

· Demonstrate and
apply theories through research efforts to develop new and
improved products,
processes, or technologies

· Participate in
cutting-edge research in artificial intelligence and machine
learning
applications

· Optimize models for
on-device and multi-modal intelligence

Qualifications:

• Experienced Data
Engineer with a BS, MS or PhD in a quantitative field (CS,
Engineering,
Physics, etc.)

• 4+ years hands-on
business experience, demonstrated implementations of ML models
and techniques
is a plus

• Advanced in Python

• Experience with AWS
infrastructure (AWS Certifications are a plus)

• Strong knowledge of
relational and distributed databases, extremely strong in SQL

• Multiple
Implementations that feature good memory, disk I/O, and CPU/GPU
management.

• Experience with
Apache infrastructure

• Experience with
streaming data and video manipulation

• Familiarity with
common ML algorithms (i.e. neural networks, tree-based methods,
unsupervised
learning, feature engineering)

Familiarity with
ML/AI frameworks, e.g,. TensorFlow, Spark, and modular/modern
software design
practices.

• History of research
publications and/or implementations of state of the art
techniques hosted on
open source repositories is a plus

• Passionate about
ML/AI and how it can improve both the media industry and the
world

Technologies we use:

AWS, Python, Python
Data Science packages, Spark, Hadoop, Apache

Resumes sent to: jim@ingenium.agency

Top base salary, excellent benefits and work culture",5.0,"ingenium.agency
5.0","Los Angeles, CA","New York, NY",1 to 50 employees,2016,Company - Private,Staffing & Outsourcing,Business Services,$1 to $5 million (USD),-1
"Junior Software Engineer, Data Science",-1,"LockerDome is an ad platform with a brain, designed specifically for performance-based advertising. The brain behind the platform is Neo, an in-house AI, which uses machine learning to process billions of data points and make intelligent decisions at lightning speed. Learn more at lockerdome.com.

As a Junior Data Scientist on the Engineering & Product team, you will help design data models that enable decision making at scale.

Your skills should include:
Strong data cleaning skills
In-depth knowledge of statistics and calculus
Experience with R, MATLAB, or other statistics heavy language
Experience with TensorFlow or similar framework is a plus
Familiarity with various categories of neural networks

Powered by JazzHR",3.6,"LockerDome, Inc.
3.6","Saint Louis, MO","Saint Louis, MO",51 to 200 employees,2008,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Kubernetes Engineer,-1,"The Kubernetes / Rancher / Helm Engineer will assist with the design, deployment, and maintenance of a full stack containerized microservices architecture as well as technical systems administration, installation/configuration, and troubleshooting including associated hardware in Reston, VA. We need you to participate in fostering a DevOps culture, and building strong cross-functional collaboration with all areas of development, product, and QA in a dynamic and fast-paced environment supporting the development of a data pipeline and machine learning services integration in support of intelligence community analysts whose mission is to solve unique and challenging problems.

You will work closely with the chief architect, systems engineers, software and data engineers, and data scientists on the following key tasks:
• Manage and maintain system integration tools such as Kubernetes, Rancher, Helm
• Configure and deploy system integration tools such as Kubernetes, Rancher, Helm
• Support management and integration of DevOps tools such as Jenkins
• Support the code transfer and modification of all environments.
• Integrate containers using Kubernetes, Rancher, Helm Dev Ops integration tool stack
• Conduct automated unit and system integration tests to identify and feedback failed modules and components
• Participate in code design reviews and updates
• Design system to system data transfer and integration process of all environments
• Create test plans to verify data quality and integrity between the systems during the transfer process at all levels from component (module), integration testing through system to include and end-to-end (data lifecycle) evaluation
• Conduct automated integration test with fake data
• Evaluate the systems from security point of view to ensure security relevant changes are made to the data before it is transferred to a different classification network
• Design data security checks to ensure dirty data is not passed to other networks
• Create unit and system integration tests to identify and feedback failed modules and components

Required Skills

• BS degree and 8 + years of prior relevant experience or Masters with 6 + years of prior relevant experience
• Must have an active TS/SCI clearance with the ability to obtain and maintain a Polygraph security clearance
• Hands-on experience with Kubernetes, Dockers, Rancher and Helm
• Hands-on DevOps experience and working knowledge of DevOps tools such as Jenkins
• Have a working knowledge of CM tools such as Nexus and Gitlab/Git
• Experience with security requirements derivation
• Excellent verbal and written communication skills
• Ability to work in a team and also a self-starter who can work on their own

It is the policy of PAR to prohibit all forms of discrimination and to affirmatively implement equal opportunity to all qualified employees and applicants for employment without regard to race, color, creed, religion, sex, age, military or veteran status, national origin, disability, marital status, predisposing genetic characteristics, sexual orientation, gender identity, or other legally protected status and positive action shall be taken to insure the fulfillment of this policy. #PGSC

Required Experience

Job Location
Reston, US-VA",3.2,"Par Government Systems Corporation
3.2","Reston, VA","Rome, NY",201 to 500 employees,-1,Contract,Computer Hardware & Software,Information Technology,$25 to $50 million (USD),-1
DevOps Engineer,-1,"DevOps Engineer

Position requires a current Top Secret security clearance with an SCI (TS/SCI)

BigBear, Inc. is a leading provider of big data computing and analytic solutions. We help people make sense of their data using our cloud-based platform and big data processing algorithms. Each day, we crunch massive volumes of structured and unstructured data into usable and actionable information for our customers.

We currently have an opening for a talented and passionate DevOps Engineer to join our top-notch team of forward-thinking engineers, data scientists, analysts, and innovators. The successful candidate will be a self-starter that demonstrates excellent communication and problem-solving skills with a strong drive for innovation.

Required Experience:
Solid experience with Linux
Amazon Web Services such as EC2, S3, SQS, RDS
Deployment automation with tools such as Terraform, CloudFormation, Jenkins, Ansible, or Chef
Advanced scripting skills with Python or Bash.
Bachelor’s or Master’s degree in Computer Science, Engineering, a related field, or equivalent work experience
Preferred Experience:
Experience with ELK Stack (ElasticSearch, Logstash, Kibana, Beats)
AWS Certification
Security+ or CISSP Certification
Current Top Secret security clearance with SCI (TS/SCI)
Technology We Use:
ElasticSearch
PostgreSQL
Python - Django
AWS
Docker
Git
Angular, React
Jenkins
Our Company:

BigBear, Inc. is a software development company with locations in San Diego, Washington DC, Charlottesville, and Reston, VA. Our mission is to enable big data computing and analytics for our customers at a low cost. We leverage capabilities such as machine learning, crowdsourcing, geospatial image processing, and Extract-Transform-Load (ETL) data processing using our on-premise cloud computing technology stack. Our solutions provide a unique offering of products, custom-built software, and services focused within Big Data Analytics, Geospatial Information Systems (GIS), Visualization and Cloud Computing to our Department of Defense, and Commercial customers. We currently have exciting and challenging career opportunities for talented, motivated individuals who want to be part of a fast-growing company.

Our Team:

We like to play with new toys and technologies. We like to break things to see if we can put them back together again in a better way. Our tails wag when we hear the words Big Data, Geospatial or Machine Learning. Each team member provides a unique set of advanced technical skills and trade that contributes to our overall success.

Perks/Benefits:

· 100% employer-paid for Medical, Dental, and Vision insurance (PPO)

· A competitive salary based on experience

· Flexible Spending Account (FSA) - optional

· 401(k) with dollar-for-dollar match up to 6%

· A warm, cozy office with actual chairs and tables

· Life and Disability Insurance 100% paid for by the company

· Education Assistance

· 529 College Savings Plan - optional

· Healthy Rewards Program

· Pre-paid Legal & Identity Theft Protection - optional

· Gym Reimbursement

· Pet Insurance - optional

· A shiny magical machine that does wonderful things

· Flexible Hours

· Unlimited Coffee, Drinks and Snacks

· 6 WEEKS of Paid Time Off (PTO) on top of 11 Paid Holidays!

BigBear is an Equal Employment Opportunity Employer/Veterans/Disabled

Job Type: Full-time

Pay: $90,000.00 - $150,000.00 per year

Benefits:
401(k)
401(k) Matching
Dental Insurance
Disability Insurance
Employee Assistance Program
Flexible Schedule
Flexible Spending Account
Health Insurance
Life Insurance
Paid Time Off
Parental Leave
Professional Development Assistance
Referral Program
Retirement Plan
Tuition Reimbursement
Vision Insurance
Schedule:

Monday to Friday
COVID-19 considerations:
This position will be at our Reston office, however, all of our team members are working from home currently for their safety.

Experience:
DevOps: 5 years (Preferred)
Education:
Bachelor's (Required)
Location:
Reston, VA 20191 (Required)
Work authorization:
United States (Required)
Application Question:
Do you have a CISSP or Security+ certification?
This Job Is:
A job for which military experienced candidates are encouraged to apply
Company's website:
www.bigbear.io
Work Remotely:
Temporarily due to COVID-19",4.4,"BigBear, Inc.
4.4","Reston, VA","San Diego, CA",51 to 200 employees,2008,Company - Public,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Senior Software Development Engineer - Machine Learning,"$136K-$211K
(Glassdoor est.)","Does serving ads to billions of search requests daily and finding the most relevant ads for a search page from billions of ads in 10s of milliseconds excite you?

The Sponsored Products team owns finding the appropriate ads to surface to customers when they search for products on Amazon. We strive to understand our customers intent and identify relevant ads which enable them to discover new and alternate products. This also enables sellers on Amazon to showcase their products to customers, which may at times be buried deeper in the search results.

Our systems and algorithms operate on one of the world's largest product catalogs, matching shoppers with products - with a strict latency constraints. We are a team of machine learning scientists and software engineers working on complex solutions to understand the customer intent and present them with ads that are not only relevant to their actual shopping experience, but also non-obtrusive. This area is of strategic importance to Amazon Retail and Marketplace business, driving long term-growth.

We are looking for a Software Engineer, who can drive appropriate technology choices for the business, lead the way for continuous innovation, and shape the future of ad serving on Amazon search. You will build services to handle billions of requests per day, while maintaining response latencies in milliseconds and meeting strict SLA requirements. It is quite routine for our systems to operate on massive datasets using distributed frameworks. You will design and code, troubleshoot, and support high volume and low latency distributed systems. The solutions you create would drive step increases in coverage of sponsored ads across the retail website and ensure relevant ads are served to Amazon's customers. You will directly impact our customers shopping experience while helping our sellers get the maximum ROI from advertising on Amazon. This role will provide exposure to cutting-edge innovations in product search, vector search, natural language processing (NLP), deep learning, and reinforcement learning. In addition to being a strongly motivated IC, you will also be responsible for mentoring junior engineers and guiding them to deliver high impacting products and services for Amazon customers and sellers.

As a Software Development Engineer at Amazon, you will -
· Leverage Big Data technologies, scalable system design and programming skills to implement large scale data-driven systems
· Build a combination of heuristics and machine learned models to solve for Ad relevance
· Integrate your work with high volume and low latency distributed systems
· Measure the impact of your work through rapid experimentation

Basic Qualifications

· 4+ years of professional software development experience
· 3+ years of programming experience with at least one modern language such as Java, C++, or C# including object-oriented design
· 2+ years of experience contributing to the architecture and design (architecture, design patterns, reliability and scaling) of new and current systems
· Bachelors degree in Computer Science or equivalent.
· 7+ years of professional software development experience
· Programming experience with at least one modern language such as Java, C++, or C# including object-oriented design.
· 5+ years of experience contributing to the architecture and design (architecture, design patterns, reliability and scaling) of new and current systems

Preferred Qualifications

· Experience in building large-scale machine-learning infrastructure for online recommendation, ads ranking, personalization, or search, etc.
· Experience with Big Data technologies such as AWS, Hadoop, Spark, Pig, Hive, Lucene/SOLR or Storm/Samza
· Strong proficiency with Java, Python, Scala or C++
· Coursework or thesis in machine learning, data mining, information retrieval, statistics or natural language processing
· Advanced knowledge of performance, scalability, enterprise system architecture, and engineering best practices
· Understanding of online computational advertising
· Strong written and verbal communication
Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.

#PABDSDE3
#PABDSDE3ADS",3.9,"Amazon
3.9","Palo Alto, CA","Seattle, WA",10000+ employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),"Google, Microsoft, Walmart"
Azure Developer/Data Engineer,-1,"Azure Developer/Data Engineer
Location: Washington DC
Job Type: Full time/Contract

Required Skills:
"" At least 5 years' experience driving impact in a similar capacity at companies creating cutting edge tech using Azure Cloud.
"" Azure Data Factory Pipelines - Create new Azure Data Factory pipelines in cloud based data warehousing systems such as Azure Synapse.
"" Experience with Azure services: Azure Data Lake Gen 2, Data factory, Data Flows, and Synapse (Azure SQL DW).
"" Data Quality and Anomaly Detection - Improve existing tools (dbt cloud) to measure data quality through metrics and automatic alerting.
"" Experience in working with Azure Databricks environment for data transformation.
"" Experience in working with unstructured data (text) and making data available for downstream NLP analysis.
"" Data Modeling - Partner with data consumers to improve existing data models and build different facets of the business for analytic use cases, Build star and snowflake schemas.
"" Development of data pipelines to third party API's both internal providers and external
"" Experience in working with NoSQL data bases like MongoDB and pull data from those databases.
"" Expertise building data pipelines on large complex data sets using Spark or other open source frameworks
"" Expertise in a scripting language like Python (or similar) and a query language like SQL
"" Knowledge of scheduling, logging, monitoring, alert frameworks
"" Experience in Source/Target: ADLSGen2, PostGres DB, Azure SQL DW.
"" Orchestration Using Databricks Jupyter Notebooks preferred.
"" Experience working in large scale/distributed SQL, NoSQL (MongoDB) environments.
"" Experience in modeling and implementing ETL / ELT on columnar MPP database technologies.
"" Experience with Agile software development process.

Preferred:
"" Proven experience deploying machine learning algorithms to production
"" Demonstrated proficiency in writing high-quality and scalable code and integrating with git version control systems
"" Experience leading successful data engineering projects and operationalizing machine learning algorithms
"" Experience with streaming architectures e.g. Kafka, Stream, PubSub.

Responsibilities:
"" Build & Deliver Data pipeline connecting various enterprise data sources both RDBMS, NoSQL & APIs.
"" Clean and process the data for Machine Learning consumption.
"" Load the Client predictions to Azure PostGres
"" Provide Business Intelligence (PowerBI) and Data Warehousing (DW) solutions and support by leveraging project standards and leading analytics platforms
"" Evaluate and define functional requirements for BI and DW solutions
"" Define and build data integration processes to be used across the organization
"" Build conceptual and logical data models for stakeholders and management
"" Analyse and validate data accuracy of report results
"" Work directly with management understand requirement; and propose and develop best business solution that enables effective decision-making, and drive business objectives
"" Interpreting data presented in models, charts, and tables and transforming it into a format that is useful to the business and aids effective decision making
"" Use of statistical practices to analyse current and historical data to make predictions, identify risks, and opportunities enabling better decisions on planned/future events
"" The ability to understand the business problem and determine what aspects of it require optimization; articulate those aspects in a clear and concise manner
"" Partner with business analysts, application engineers, data scientists, leveraging the appropriate tools, solutions, and/or processes as part of their data mining, profiling, blending, and analytical activities.
"" Collaborate in establishing and evolving development, testing, and documentation standards, as well as related code reviews.

Thanks & Regards,

Manas Pani
Account Manager
Resource Logistics Inc.
39 Milltown Road, Floor 2, East Brunswick, NJ 08816.
Phone: (732) 553-0566 Ext 64
Fax: (732) 553-0568
Email: manas@resource-logistics.com",4.7,"Resource Logistics, Inc.
4.7","Washington, DC","Edison, NJ",51 to 200 employees,1997,Company - Private,Logistics & Supply Chain,Transportation & Logistics,$10 to $25 million (USD),-1
Sr. Machine Learning Engineer,-1,"Where good people build rewarding careers.

Think that working in the insurance field cant be exciting, rewarding and challenging? Think again. Youll help us reinvent protection and retirement to improve customers lives. Well help you make an impact with our training and mentoring offerings. Here, youll have the opportunity to expand and apply your skills in ways you never thought possible. And youll have fun doing it. Join a company of individuals with hopes, plans and passions, all using and developing our talents for good, at work and in life.
Job Description
The Data Science & Analytics Engineering team builds software products specifically tailored to Allstates mission to improve customer's lives by re-inventing protection. We are creating scalable platforms for the deployment of cutting-edge predictive analytics, machine learning, and randomized experiments across the enterprise. We succeed by maintaining a steadfast focus on our customers using Lean Startup and Agile principles.

We are looking for a Senior Machine Learning Engineer to help us develop AI software products on a cloud-based platform which is already processing millions of unstructured objects a day. Youll help design and implement a framework that allows machine learning/deep learning models using natural language and image data to be scored in a production environment. You will have high visibility, great potential for growth, and a opportunity to make a distinct impact on how we do data science at Allstate. If you understand mathematics, general data science concepts, and full stack engineering necessary to design self-running software to automate models and analytics, we'd like to meet you. You'll also need to be a strong communicator as you will be working regularly with data science clients, as well as technology, architecture, and applications groups.

In this role, you will:
Help design machine learning systems
Research and implement/enhance machine learning model deployment platform
Run machine learning tests and experiments
Fully own production code, highly preferably REST APIs / microservices
Deploy machine learning applications into production
Work directly with data scientists, cloud engineer, and other stakeholders
Extend existing machine learning libraries and frameworks
Lead projects, including the planning and prioritization of tasks
Ability to context switch and manage multiple projects
Mentor team members and provide guidance on execution
Keep abreast of developments in the field
Job Qualifications
3+ years proven experience as a Machine Learning Engineer or similar role
Understanding of data structures, data modeling and software architecture
Working knowledge of REST APIs/Microservices
Intermediate/advanced Docker
Strong DevOps and CI/CD skills
Ability to write robust code in Python
Good knowledge of Python packages, e.g. Flask, Requests, Pandas, NumPy
Knowledge of math, probability, statistics and algorithms
Familiarity with machine learning frameworks (like Keras or PyTorch) and libraries (like scikit-learn)
Knowledge of AWS/PCF a plus
Familiarity with unstructured data a plus
Familiarity with Java application development is a plus
Excellent interpersonal communicator and collaborator
Outstanding analytical and problem-solving skills
BSc in Computer Science, Mathematics or similar field; Masters degree is a plus
The candidate(s) offered this position will be required to submit to a background investigation, which includes a drug screen.

Good Work. Good Life. Good Hands®.

As a Fortune 100 company and industry leader, we provide a competitive salary but thats just the beginning. Our Total Rewards package also offers benefits like tuition assistance, medical and dental insurance, as well as a robust pension and 401(k). Plus, youll have access to a wide variety of programs to help you balance your work and personal life -- including a generous paid time off policy.

Learn more about life at Allstate. Connect with us on Twitter, Facebook, Instagram and LinkedIn or watch a video.

Allstate generally does not sponsor individuals for employment-based visas for this position.

Effective July 1, 2014, under Indiana House Enrolled Act (HEA) 1242, it is against public policy of the State of Indiana and a discriminatory practice for an employer to discriminate against a prospective employee on the basis of status as a veteran by refusing to employ an applicant on the basis that they are a veteran of the armed forces of the United States, a member of the Indiana National Guard or a member of a reserve component.

For jobs in San Francisco, please click ""here"" for information regarding the San Francisco Fair Chance Ordinance.

For jobs in Los Angeles, please click ""here"" for information regarding the Los Angeles Fair Chance Initiative for Hiring Ordinance.

It is the policy of Allstate to employ the best qualified individuals available for all jobs without regard to race, color, religion, sex, age, national origin, sexual orientation, gender identity/gender expression, disability, and citizenship status as a veteran with a disability or veteran of the Vietnam Era.",3.4,"Allstate
3.4","Charlotte, NC","Northbrook, IL",10000+ employees,1931,Company - Public,Insurance Agencies & Brokerages,Insurance,$10+ billion (USD),"Progressive Insurance, State Farm, Farmers Insurance Group"
Senior Software Engineer - Data,-1,"Who we are:

fuboTV is the fastest growing video streaming startup (backed by some of the world's largest media companies) that is reinventing live television for the entire household in the cord cutting era.

Originally founded as a soccer streaming service, fuboTV is the leading sports-first cable replacement in the U.S.

fuboTV broadcasts most NFL, MLB, NBA and NHL games, all major soccer leagues, and a wide range of college and other sports. fuboTV also broadcasts a wide variety of news, movies, and entertainment programming including the FOX, NBC, CBS, and Turner broadcast catalogs, plus Showtime, AMCand much more! fuboTV can be accessed on multiple platforms, including web, Android, iOS, tvOS, Fire TV, Android TV, Roku and Chromecast.

About the Role:

fuboTV is looking for exceptional Senior Sofware Engineers with a passion for processing data at scale with speed.

As a Senior Software Engineer you will get to build highly-available systems, ingest troves of data, and help power our cutting edge experiences on Android, iOS, Web, Roku, and FireTV. fuboTV's data team has a unique opportunity to build and continuously improve greenfield services.

We are looking for Senior Software Engineers who care about code quality, uptime, performance, continuous deployment, SOLID design principles, test-driven development, and agile methodologies.

Our tech stack:

Go/Golang with govendor

Docker and Kubernetes

Apache Beam with Java/Scala

Redis, Google PubSub, BigTable, BigQuery, and PostgreSQL

fuboTV Software Engineers have the following responsibilities
Architect, design, develop, test, maintain and improve data pipelines and systems
Collaborate with other engineers and members of the fuboTV team to determine priorities and best practices, and refine functional requirements
All fuboTV Senior Software Engineers must:
Have 5+ years of experience in delivering working software.
Experience in processing and serving data at scale
Write clean, well-tested code
Be familiar with BigData pipelines for batch and realtime streaming
Have experience with distributed processing frameworks, filesystems, NoSQL databases (Hadoop, AWS, Google ecosystems)
Experience working closely with data scientists to production-ize machine learning algorithms
Have mastery of at least one modern backend stack, with a willingness to learn new technologies and methodologies
Requires at least a Bachelor's Degree in Computer Science, Engineering, Information Technology, Management Information Systems (MIS), Computer Information Systems (CIS) or related field or equivalent as determined by a professional credentials evaluation.
Perks & Benefits:
fuboTV provides a highly competitive compensation based on experience and market standards.
Robust benefit package including stock options, Health/Dental/Vision coverage sponsored up to 100% for employees, 401k, Life Insurance, and commuter benefits
Free Premium fuboTV Account
Health and Wellness initiatives including discounts on Gym Memberships.
Unlimited PTO days and regular company-wide activities.
fuboTV's main Headquarters are located in Midtown Manhattan.
fuboTV is an e-verified company",4.6,"FuboTV
4.6","New York, NY","New York, NY",51 to 200 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Senior Software Engineer - Full Stack,-1,"Are you looking for a mission driven company where your work will directly impact human lives? Do you have a passion for scientific data and broad experience writing web applications? Do you think that cancer treatment should be personalized and want to build software to accelerate that reality?The OpportunityNotable Labs seeks a full stack software engineer to build out the platform powering our robotic lab. As an early engineer on a small team, you will build backend APIs, craft web apps, and contribute to the engineering vision that drives our mission: all cancer is treatable. We're building a translational drug discovery platform to identify treatment options for relapsed and refractory cancer patients -- starting with Acute Myeloid Leukemia-- to address the long tail of cancer treatment. We have a highly automated lab in San Francisco running on our custom software (Ruby/Rails, Python/Django, JavaScript/React), and are currently testing relapsed/refractory cancer patients as well as samples from a variety of biopharma partnerships.What You'll Do* Write clean, well crafted, modular, and maintainable code.* Drive innovation by learning and teaching new frameworks and technologies.* Build data-rich web applications for scientists and laboratory users to visualize scientific data, talk to robots, drive laboratory workflows, organize medical knowledge, and facilitate cancer treatment discovery.* Write test code that matters, is lightweight, is easy to extend, and supports your quick development cycles.* Work in a dynamic interdisciplinary environment on multi-functional project teams of: software engineers, automation engineers, data scientists, machine learning experts, bioengineers, computational biologists, process engineers, clinical and R&D scientists, etc.Must Haves* BS/MS in Computer Science or equivalent experience/training* Expert in Python web frameworks (Django, Flask)* Expert in React front-end development* Experience in the AWS ecosystem (EC2, ECS, RDS, DynamoDB)* Experience working in biotech or pharma industries* Experience with CI/CD pipelines and basic DevOps fundamentals* 3+ years of production experience* Relational and NoSQL database experience* Unix, Git, and other command line tools* Significant experience testing critical code with modern testing tools and libraries* Passionate about building scientific software for domain experts to improve and personalize the treatment of cancerNice to Haves* Contributions to open source projects* Knowledge of bioinformatics tools and data* Experience with Python data tools (Pandas, Numpy, Jupyter, scikit-learn)* Experience with data visualization tools (d3, Plotly, matplotlib, gg-plot)What we can offer you* The opportunity to directly fight cancer, one patient at a time* Exposure to experts from diverse backgrounds ranging from engineering, data science, operations, clinical medicine, patient advocacy, and beyond* Work in a collaborative environment with a team dedicated to both personal and scientific growth and development* Highly competitive, early stage company compensation package, with incredible growth opportunities* Outstanding healthcare benefits* Flexible vacation policy* did we mention daily catered lunch?More About UsNotable Labs is a precision medicine company that has a translational drug discovery platform focused on identifying therapeutic options for relapsed and refractory cancer patients.Our clinical research lab helps oncologists identify personalized combinations of existing FDA-approved treatments for patients. We've developed a high throughput robotic flow cytometry lab platform that screens thousands of FDA-approved drug combinations against the patient's own cancer cells to help predict safer and more effective cancer treatments. Our lab has completed initial feasibility studies with clinicians in relapsed Acute Myeloid Leukemia & Myelodysplastic Syndrome, with an 84% predictive rate. Focusing on individual patients and existing treatments, we're working to discover novel uses of drugs and defining mechanisms underlying cancer progression and drug resistance.Our research and development platform extends our clinical research to drug discovery, testing novel compounds with primary patient samples for pharmaceutical and biotechnology companies. Using our automated, high-throughput, multi-parametric drug screening research platform, industry partners can assay the biological impact of novel compounds on primary cells in a physiologically relevant environment. This helps our partners stratify patients by their predicted responsiveness, increasing the probability of successful clinical development. We are actively partnering with pharmaceutical companies that have preclinical and clinical stage drug pipelines in Acute Myeloid Leukemia, Myelodysplastic Syndrome, or related hematological malignancies to profile experimental drug activity in patient samples.Our investors include Builders Venture Capital, Founders Fund, First Round Capital, Y Combinator, several prominent angels and seed-stage funds, and Accelerate Brain Cancer Cure, a venture philanthropy firm founded by Steve Case. We have offices and a laboratory in San Francisco's SoMa district.At Notable Labs we value diversity and are an equal opportunity employer. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.",5.0,"Notable Labs
5.0","San Mateo, CA","San Francisco, CA",1 to 50 employees,-1,Company - Private,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,Less than $1 million (USD),-1
Integration Engineer,"$82K-$134K
(Glassdoor est.)","Description

Job Description:


Are you ready to join Leidos all-star team? Through training, teamwork, and exposure to challenging technical work, let Leidos show how to accelerate your career path.

The Leidos Innovations Center has an exciting opening for you, our next Integration Engineer, to assist with the implementation of a state-of-the-art technology stack supporting a developing NMEC program in Reston, VA. Work to help integrate developers, data engineers, release planners, system administrators, management, software architects and others to produce a robust software platform. Focus on design, deployment, and maintenance of a full stack containerized microservices architecture as well as technical systems administration, installation/configuration, and troubleshoot including associated hardware. We would like to see you participate in fostering an integration process incorporating DevOps processes while building strong cross functional collaboration with all areas of development, product, and QA in a dynamic and fast paced environment supporting the development of a data pipeline and machine learning services integration in support of intelligence community analysts whose mission is to solve unique and challenging problems.

You will work closely with the chief architect, systems engineers, software and data engineers, and data scientists on the following key tasks:
• Manage the integration of all D3P environments in an agile environment, incorporating all facets from development to production
• Ability to integrate docker containers using Kubernetes, Rancher, Helm and other DevOps integration tools
• Foster an environment of collaboration with the different team members in the goal of producing a quality project product for our customer
• Ability to research and integrate cutting edge tools in an advanced technology stack
• Participate in system design sessions
• Have a working knowledge of system integration tools
• Have a working knowledge of DevOps tools such as Jenkins
• Have a working knowledge of CM tools such as Nexus and Gitlab/Git
• Design system to system data transfer and integration process
• Verify data quality and integrity between systems during the transfer process
• Ability to evaluate the systems from security point of view to ensure security relevant changes are made to the data before it is transferred to a different classification network
• Design data security checks to ensure dirty data is not passed to other networks
• Create system integration tests to identify and feedback failed modules and components

To be successful in this role you need these skills (required):
• Requires BS degree and 6 + years of prior relevant experience or Masters with 4 years of prior relevant experience
• Must have an active TS clearance with the ability to obtain and maintain a polygraph security clearance
• Experience with Kubernetes
• Experience with Elastic Search
• Experience with security requirements derivation
• Excellent verbal and written communication skills
• Ability to work in a team and also a self-starter who can work on their own

Leidos


Leidos is a Fortune 500® information technology, engineering, and science solutions and services leader working to solve the world's toughest challenges in the defense, intelligence, homeland security, civil, and health markets. The company's 32,000 employees support vital missions for government and commercial customers. For more information, visit www.Leidos.com.

Pay and Benefits


Pay and benefits are fundamental to any career decision. That's why we craft compensation packages that reflect the importance of the work we do for our customers. Employment benefits include competitive compensation, Health and Wellness programs, Income Protection, Paid Leave and Retirement.

Securing Your Data


Leidos will never ask you to provide payment-related information at any part of the

employment application process. And Leidos will communicate with you only through emails that are sent from a Leidos.com email address. If you receive an email purporting to be from Leidos that asks for payment-related information or any other personal information, please report the email to spam.leidos@leidos.com.

Commitment to Diversity


All qualified applicants will receive consideration for employment without regard to sex, race, ethnicity, age, national origin, citizenship, religion, physical or mental disability, medical condition, genetic information, pregnancy, family structure, marital status, ancestry, domestic partner status, sexual orientation, gender identity or expression, veteran or military status, or any other basis prohibited by law. Leidos will also consider for employment qualified applicants with criminal histories consistent with relevant laws.

LInC
D3P
External Referral Eligible

External Referral Bonus:
Eligible
Potential for Telework:
No
Clearance Level Required:
Top Secret/SCI with Polygraph
Travel:
Yes, 10% of the time
Scheduled Weekly Hours:
40
Shift:
Day
Requisition Category:
Professional
Job Family:
Systems Integration
Leidos


Leidos is a Fortune 500® information technology, engineering, and science solutions and services leader working to solve the world's toughest challenges in the defense, intelligence, homeland security, civil, and health markets. The company's 33,000 employees support vital missions for government and commercial customers. Headquartered in Reston, Virginia, Leidos reported annual revenues of approximately $10.19 billion for the fiscal year ended December 28, 2018. For more information, visit www.Leidos.com.

Pay and Benefits


Pay and benefits are fundamental to any career decision. That's why we craft compensation packages that reflect the importance of the work we do for our customers. Employment benefits include competitive compensation, Health and Wellness programs, Income Protection, Paid Leave and Retirement. More details are available here.

Securing Your Data


Leidos will never ask you to provide payment-related information at any part of the employment application process. And Leidos will communicate with you only through emails that are sent from a Leidos.com email address. If you receive an email purporting to be from Leidos that asks for payment-related information or any other personal information, please report the email to spam.leidos@leidos.com.

Commitment to Diversity


All qualified applicants will receive consideration for employment without regard to sex, race, ethnicity, age, national origin, citizenship, religion, physical or mental disability, medical condition, genetic information, pregnancy, family structure, marital status, ancestry, domestic partner status, sexual orientation, gender identity or expression, veteran or military status, or any other basis prohibited by law. Leidos will also consider for employment qualified applicants with criminal histories consistent with relevant laws.",3.5,"Leidos
3.5","Reston, VA","Reston, VA",10000+ employees,1969,Company - Public,Aerospace & Defense,Aerospace & Defense,$10+ billion (USD),-1
Staff Data Warehouse Engineer - Personalization,"$74K-$100K
(Glassdoor est.)","Our Opportunity:

We are hiring a Staff Data Warehouse Engineer - Personalization for our Personalization team in Boston, MA. In this position, you will help us build scalable, robust data solutions for Personalization at Chewy. You will demonstrate a passion for delivering outstanding customer experience, experience of building scalable solutions and will bring communication skills that allow you to instill trust in the team that you are working with. Millions of pet parents with unique needs visit Chewy.com looking for products for their beloved pets. We have the task to decide what products would be most useful to them and help them discover those products. How do we do this? Meet Personalization team @ Chewy. We use best of machine learning techniques and continuously test the outcomes to simplify product discovery for pet parents looking for their pet needs on Chewy.com. Our exceptional multi-disciplinary team of data scientists, data engineers, software engineers and product managers work together to power personalized recommendations and product discovery for pet parents. Our team has single threaded ownership of the space allowing us to decide impactful products that we can experiment, measure with metrics and deliver at a fast pace.

What You'll Do:
You will be responsible for design, development, delivery and support of large-scale, data flows and tools
You will work with the team and other partner teams to define our roadmap on the data engineering front
You will deliver projects successfully and drive initiatives for up keep pace of our data science solutions. in the face of growth
You will drive operational excellence of data systems
What You'll Need:
Bachelor's Degree in Computer Science, Computer Engineering or related field
8+ years professional experience in Data Engineering
Experience working with Hadoop, Spark and other streaming solutions
Experience with, at least, one modern programming language such as C#, Java, Python
Experience implementing high availability data (warehouse) systems
Delivery experience working under an Agile/Scrum methodology
Position may require travel
Bonus:
Master's Degree in Computer Science or related field
E-commerce experience
Experience working with AWS or Similar Cloud Environments
If you have a disability under the Americans with Disabilities Act or similar law, or you require a religious accommodation, and you wish to discuss potential accommodations related to applying for employment at our company, please contact HR@Chewy.com.

To access Chewy's Privacy Policy, which contains information regarding information collected from job applicants and how we use it, please click here: Chewy Privacy Policy (https://www.chewy.com/app/content/privacy).",2.8,"Chewy
2.8","Boston, MA","Dania Beach, FL",10000+ employees,2011,Company - Public,Pet & Pet Supplies Stores,Retail,Unknown / Non-Applicable,-1
Senior Data Engineer,"$106K-$194K
(Glassdoor est.)","The Company:

Personal Capital is a leading digital wealth management company, founded in 2009. Were on a mission to transform financial lives through technology and people, providing both insight-driven advice with free financial tools and personalized wealth management from 200+ registered financial advisors across the country. Personal Capital has raised $315 million in capital from accomplished financial and strategic investors (IVP, Venrock, Crosslink, Corsair, Blackrock, BBVA, USAA, IGM/Power) to disrupt the traditional $30 trillion U.S. wealth management market. Our free personal finance app is utilized by over two million users, helping them track over $840 billion of their personal finances, all in one place. Our award-winning apps paved the way for our advisory firm, which now manages over $12 billion in personalized investment portfolios for American families. Personal Capital is headquartered in Redwood Shores with offices in San Francisco, Denver, Dallas and Atlanta.

The Opportunity

You will play a leading role on the Data and Analytics team, responsible for transforming data from disparate systems to provide insights and analytics for business stakeholders. Youll leverage cloud-based infrastructure to implement technology solutions that are scalable, resilient, and efficient. You will collaborate with Data Engineers, Data Analysts, Data Scientists, DBAs, cross-functional teams, and business leaders. You will architect, design, implement and operate data engineering solutions, using Agile methodology, that empower users to make informed business decisions.

Candidate

You are self-motivated, work independently, and have direct experience with all aspects of the software development lifecycle, from design to deployment. You have a deep understanding of the full life data lifecycle and the role that high-quality data plays across applications, machine learning, business analytics, and reporting, Strong candidates will exhibit solid critical thinking skills, the ability to synthesize complex problems, and a talent for transforming data to create solutions that add value to a myriad of business requirements. You have the demonstrated ability to lead and take ownership of assigned technical projects in a fast-paced environment. Excellent written and speaking communication skills are required as we work in a collaborative cross-functional environment and interact with the full spectrum of business divisions.

Qualifications:
Bachelor of Science degree in Computer Science or equivalent.
At least 7 years of post-degree professional experience.
4+ years development experience building and maintaining ETL pipelines.
3+ years of Python development experience.
Experience with AWS integrations such as Kinesis, Firehose, Aurora Unload, Redshift, Spectrum, Elastic Mapreduce, SageMaker and Lambda.
Experience in mentoring junior team members through code reviews and recommend adherence to best practices.
Deep understanding of writing test cases to ensure data quality, reliability and high level of confidence.
Track record of advancing new technologies to improve data quality and reliabilit
Continuously improve quality, efficiency, and scalability of data pipelines.
Expert skills working with SQL queries, including performance tuning, utilizing indexes, and materialized views to improve query performance.
Advanced knowledge of both OLTP and OLAP environments with successful implementation of efficient design concepts.
Proficiency with the design and execution of NoSQL database to optimize BigData storage and retrieval.
Experience with API code integrations with external vendors to push/pull data between organizations.
Familiarity with data orchestration pipeline using Argo or Airflow.
Knowledge of analytic tools such as R, Tableau, Plotly, Python Pandas.
Financial services industry experience is a plus.
Powered by JazzHR",4.0,"Personal Capital
4.0","Redwood City, CA","Redwood City, CA",201 to 500 employees,2009,Company - Private,Investment Banking & Asset Management,Finance,Unknown / Non-Applicable,-1
Senior Software Engineer - Machine Learning [Remote Opportunity],-1,"We are looking for a Machine Learning (Client) Engineer to help us create artificial intelligence products. Client Engineer responsibilities include creating machine learning models and retraining systems. Your ultimate goal will be to shape and build efficient self-learning applications.

You are:
You can design and build web scale distributed systems. You are passionate about data science and machine learning. You are excited about recommender systems and comfortable reading research papers, interacting with data scientists and implementing Client algorithms from proof of concept to production. Additionally, you understand the constraints of working with a growing team and thrive in an environment that is fast-paced and sometimes scrappy. You understand that serving a user-facing model comes with a set of
restrictions and you know how to be creative to solve them. Finally, you are business focused and proactively thinking about new projects that could have a high impact result for the company.

If this sounds like you, please apply!

We value:Â
Team player
Problem solver
Radical candor
Testing rigor
Humility
Responsibilities:Â
Study and transform data science prototypes
Design and develop machine learning systems for data scientist to create, train and deploy Client models
Research and implement appropriate Client algorithms and tools
Develop machine learning applications according to requirements
Run machine learning tests and experiments
Perform statistical analysis and fine-tuning using test results
Train and retrain systems when necessary
Extend existing Client libraries and frameworks
Keep abreast of developments in the field
Requirements:Â
Proven experience as a Client Engineer or similar role
Understanding of data structures, data modeling and software architecture
Familiarity with machine learning frameworks (like Keras or PyTorch) and libraries (like scikit-learn)
Experience in applying machine learning, predictive analytics and classification techniques towards real product and problems
Ability to write robust code in Python or Java or equivalent modern programming language
Proficiency in SQL, big data technologies and working with large data sets
BS in Computer Science, Mathematics or similar field; Master's degree is a plus
Works independently, able to manage multiple projects simultaneously
Deep curiosity and a demonstrated ability to craft original solutions
Highly communicative with collaborators and manager
Proactive in seeking opportunities for innovation
Pluses:Â
Designed and built web scale distributed systems
Deep knowledge of math, probability, statistics and algorithms
Experience in the media industry

Call or Text:
Sriram
646-877-0206",4.7,"RPO Services
4.7",Alabama,"Visakhapatnam, India",1 to 50 employees,2011,Company - Private,Staffing & Outsourcing,Business Services,Less than $1 million (USD),-1
Software Engineer,"$90K-$131K
(Glassdoor est.)","Software Engineer

OSBU | Denver, CO, United States

Why Join Rincon Research Corporation (RRC)?

At Rincon Research Corporation, our primary business is innovating, developing, and fielding digital signal processing (DSP) products and services for the United States Defense and Intelligence Communities in support of national security.

Rincon Research Corporation seeks a Software Engineer to create cutting edge signal processing, geolocation, and communication systems solutions to challenging national security and defense problems. You will work in a multi-disciplinary R&D environment with similarly skilled and motivated electrical engineers, mathematicians, and computer scientists/engineers in a highly rewarding personal and professional environment.

Come join the team that is creating cutting edge signal processing, geolocation, and communication systems for the future!

What are the primary responsibilities in the Software Engineer position?

Core responsibilities include designing real-time processing solutions, implementing advanced signal processing and geolocation algorithms in efficient software, testing with real data, and deploying to front-line customer facilities. You also create effective user interfaces and data visualization tools. A key responsibility is mastering and evolving framework capabilities as applications migrate to a cloud-based computing environment. RRC personnel can expect to work across all functional areas: systems engineering, development, integration and test, deployment and O&M, and experience the direct mission feedback from the customer and seeing your project provide real-world contributions that make a significant difference.

What required background will make you successful?
Degree (Bachelor’s, Master's, or PhD) in Computer Engineering or Computer Science
Competent in using C/C++/Python for engineering or scientific applications in the Linux environment
Facility with agile software development practices at all stages of the software life cycle
Good speaking skills with the ability to interact with customers and senior engineers
Able to assist in creation of cutting-edge solutions for customer issues
Ability to obtain and maintain a TS/SCI security clearance
(US CITIZENSHIP REQUIRED)
Technical Interest Areas:
High Performance Computing including parallel and distributed computation
Numerical algorithms
GPU acceleration using CUDA
Machine learning
Virtualization and Cloud computing
Visualization of large engineering data
HTML5 for real-time GUI engineering applications
Where is the position located?

This position is located at our Denver, CO office.

What benefits does RRC offer?
100% employer-paid premiums for family medical and dental insurance, employee life insurance, short-term and long-term disability (STD & LTD)
Flexible reimbursement spending accounts for medical expense and dependent care
Immediate participation and vesting in the company’s Employee Stock Ownership Plan (ESOP) and 401(k) Plan
Employer contributions to RRC’s ESOP
Employer matching contributions to the company’s 401( k) Plan
Employer discretionary contributions to the company’s 401(k) Plan
Rincon Research Corporation is an equal opportunity employer and considers qualified applicants for employment without regard to race, color, creed, religion, national origin, sex, sexual orientation, gender identity and expression, age, disability, veteran status, or any other protected factor.",4.3,"Rincon Research Corporation
4.3","Centennial, CO","Tucson, AZ",201 to 500 employees,1983,Company - Private,Aerospace & Defense,Aerospace & Defense,$50 to $100 million (USD),"Raytheon Technologies, General Dynamics, MIT Lincoln Laboratory"
Sr. Data Engineer - SRE,-1,"WHO WE ARE

Signal Sciences is the fastest growing web application security company in the world. Our award-winning next-gen WAF and RASP solution protects 40,000+ applications and APIs with over 2 trillion production requests per month. Signal Sciences' patented architecture allows our customers to embrace cloud and DevOps while bringing actionable security visibility to development, DevOps, and security teams.

We work with some of the world's most recognizable companies, like Datadog, DoorDash, Under Armour, Starbucks, Aflac, and many more across industries. We make web applications more secure. Simple as that. We do it by providing an unparalleled platform that teams actually want to use. It's flexible, exceptionally elastic, collaborativeand protects business initiatives like DevOps and cloud adoption without disrupting current workflows and processes already in place.

SUMMARY

We are looking for a Senior Data Engineer with a strong Site Reliability Engineer (SRE) background who can help on performance, enhancements, and operationally support our system.

You will be architecting highly scalable data integration and transformation platform processing a high volume of data under defined SLA. You will be creating and building the platform that includes ingestion and transformation of data, data governance, machine learning, analytics, and consumer insights.

Our tech stack includes Elasticsearch, Logstash, Kibana, ElastiCache/Redis, MongoDB Atlas, AWS S3, Datadog, Go, RPC

RESPONSIBILITIES
Developing sequencing data pipelines and/or data science platform
Responsible for building and managing end-to-end data pipelines and operations from ingestion and integration through delivery for the data products
Build cross-functional relationships with Business Stakeholders, Architects, Data Scientists, Product Managers and IT to understand data needs and deliver on those needs
Drive the design, building, and launching of new data models and data pipelines in production
Manage the development of data resources and support new product launches
Lead discussion of product-oriented analysis in meetings with clients and partners; comfortable speaking to executives
Primary data liaison for stakeholders to drive transformation and to democratize use of data
Consolidate the fragmented data across the company and provide simplified access to data for the stakeholders, internal users as well as external partners
Support compliance and auditing through a single gateway for data exchange
Stay abreast of technology development in retail and other industries
Act as a sounding board on testing, experimentation, target audience profiling and consumer insights that analyze the relationship between customers, products, partners, conversions, engagement and revenue, and drivers
Work with multiple complex and disparate datasets to enable data delivery through various means and APIs to evaluate performance and amalgamate information to derive strategic insights and recommendations
Establish the core data foundation and common data lake to enable data-driven decisions
Support delivery of scalable data products
QUALITIES / EXPERIENCE WE'RE SEEKING
Software development experience
Exceptional skills in at least one high-level programming language (Java, Scala, Go, Python or equivalent)
ETL and ELT pipelines
Data processing and job orchestration
Implementing analytics pipelines to assess machine learning model results
Setting up data and cloud environments to make data science more efficient
Quickly learning new tools
Strong understanding of ELK Stack
Database experience including MongoDB
Experience with Container technology and AWS services including S3, Amazon ECS
Excellent communication skills to collaborate with cross-functional partners and independently drive projects and decisions
WHY YOU SHOULD JOIN SIGNAL SCIENCES

We're not just rethinking what's possible with web application securitywe're revolutionizing it. At Signal Sciences, we engineer big ideas with an eye on the future, building sustainable and wide-reaching solutions that not only serve teams' immediate needs but also instinctively evolve along with them. We believe in simple, effective actions. We value teamwork.

Signal Sciences is disrupting the web security industry and was recently named one of the Next Billion-Dollar Startups by Forbes. As a team member, you'll enjoy 100% employer-sponsored medical, dental, and vision benefits, 401K retirement plan, and a flexible work environment. Most of all, you will have the opportunity to make a positive impact on improving security in the world's #1 most vulnerable part of technology infrastructure (the web) with the new industry leader in web application security. Join us and find out why we were named Best Place to Work in 2019 by LA Business Journal, and Best Work-Life Balance in 2019 by Comparably.",4.1,"Signal Sciences
4.1",Remote,"Culver City, CA",51 to 200 employees,2014,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
"Sr. Distributed Systems Research Scientist/Engineer, Software","$82K-$164K
(Glassdoor est.)","This is a unique opportunity to join the applied research team at Real-Time Innovations (RTI). As a Senior Distributed Systems Research Engineer on our research team, you will be part of a team that is maintaining our strategic lead in technology and thought leadership for building software communications frameworks for smart machines and critical real-world systems like the Kennedy Space Center launch system and Hyperloop. The RTI Connext software enables 1000s of applications and devices to exchange data in a timely and reliable way. Our software features direct peer-to-peer connections, reliable multicast, automated application discovery, and unique, contractual quality-of-service control.

Our team values creativity, risk-taking, innovation, and open communication. Our research spans an ever-growing range of interesting topics, including for example, advanced compression, machine learning, edge communications and processing, software-defined networking, hardware and software cybersecurity, resiliency, simulation and gaming engines, fault tolerance, embedded computing, microkernels, flight safety and software verification, and much more. Our government customers span a wide array of organizations – and, we continue to have an excellent record of bringing in funding (millions per year).

Real-Time Innovations (RTI) is the largest software framework provider for smart machines and real-world systems. Our software runs the largest power plants on the continent, connects perception to control in over 200 autonomous vehicles, drives the new generation of medical robotics, controls hyperloop and flying cars, and provides 24x7 medical intelligence to hospital patients and emergency victims. We are the best positioned small company in the world to create the very real future of intelligent, distributed systems.

RTI leads the world market for software that connects real-world devices. Our diverse and global workforce believes in working hard and enjoying the journey. We recognize employees for their achievements, offer great opportunities for career growth and development, and provide the tools they need to succeed. We also offer great benefits and flexibility. We commit to making your life as satisfying as your career. And, RTI's team is unmatched; our collaborative, transparent, and creative culture truly sets us apart from the rest.

We solve some of the greatest challenges in technology. Our mission is to transform industries: automotive, medical, power, defense, and control. Our core values emphasize excellence, teamwork, and your potential. Few small companies can truly claim to make the world run better like RTI. Come help make a real difference.

Responsibilities


You will be part of a team of experts researching emerging technologies, coming up with solutions for the problems posed by our research sponsors, exploring new concepts for products, prototyping ideas, and leading small teams to develop and to enhance advanced features related to RTI's secure real-time middleware platform. This is an individual contributor role. Duties will include:
Innovate new solutions that will form the foundation of secure, adaptable, and fast distributed systems
Create and execute long-term strategic research activities
Work with the business development team to define research areas of interest and define interesting research proposal topics
Write research proposals and project reports
Execute and lead research contracts to push our technology forward. Serve in the role of Principal Investigator on externally-funded research projects.
Actively interface with research project sponsors, customers, research partners, and prospects
Participate in and drive industry standards
Communicate technical innovations through papers and presentations
Support the transition of promising technical innovations to product including customer trials, coordinating with product management, design, development, testing and support groups
Requirements
PhD in Computer Science/Engineering, Robotics, Autonomy, Smart Machines, Distributed Systems or related field.
New graduates are welcome; some experience preferred.
Experience in distributed systems research
Excellent written communications skills, and evidence of research publications
Experience writing and winning proposals, and research project management
Solid understanding of computer network protocols; network and system programming, and real-time and/or high-performance applications
Solid programming skills (e.g. C/C++, Java, scripting languages)
Ability to work successfully / actively engage with a highly distributed team
(Preferred, not required!) Experience using OMG Data-Distribution Service (DDS) middleware, including development of distributed applications using DDS
U.S. citizenship required. Work to be performed for this position relates to federal government contracts which require U.S. citizenship.
Job Location

This position could be located at our new office in the Denver Metropolitan Area, Colorado, remote, or at headquarters in Sunnyvale, California.

About RTI


We have a collaborative and inclusive environment where individuals strong on aptitude and attitude will have an opportunity to grow their professional careers. Our culture embraces transparency, learning, and fun. We offer an attractive compensation package consisting of competitive salary, benefits, vacation bonuses, and equity participation.

RTI is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, religion, color national origin, sex, age status as a protected veteran, or status as a qualified individual with disability.",4.9,"Real-Time Innovations
4.9","Denver, CO","Sunnyvale, CA",201 to 500 employees,1995,Company - Private,Computer Hardware & Software,Information Technology,$25 to $50 million (USD),"ADLINK Technology, Wind River, Green Hills Software"
Senior Software Engineer - Big Data,-1,"Job TITLE: Senior Software Engineer - Big Data

Location: Sunnyvale, CA

Term: Contract

Skill: - Build scalable, high- performance, and efficient pipelines and workflows that are capable of processing billions of transactions and real-time customer activities.
Work with big data and provide to our data scientists the right tools, data marts and rollups to build their machine learning models.
Fluent in Pig and/or Hive with experience in building UDFs, Pig and Hadoop streaming.
Build automated reports that can help the team to proactively identify quality and/or coverage problems in releases or new versions of our models.
Apply knowledge of Azkaban, Oozie or Hamake for workflow management and job scheduling.
Provide senior leadership and demonstrable, programming expertise and proficiency in Java, C/C++, or Python.
Work on Data Warehousing architecture and data modeling best practices.

Experience: We are seeking for an accomplished, enthusiastic Senior Big Data Software Engineer to join the Walmart eCommerce team. This exciting position involves many key engineering challenges as we deal with huge data sets (Billions of Transactions, Petabytes of data) to impact real-time customer activities.
Must have demonstrable, programming proficiency in one or more of the following: Java, C/C++, or Python.
Deep understanding of Map Reduce framework & Hadoop.
Fluent in Pig and/or Hive with experience in building UDFs, strong scripting ability.
Proven expertise and understanding of ETL techniques.
Knowledge of Azkaban, Oozie or Hamake for workflow management and job scheduling.
Must be team oriented and collaborative to interact with both managers and cross functional teams.
Ability to thrive in a fast paced environment on multiple projects in various phases and under tight deadlines

Education: Bachelor of Science degree or equivalent in Computer Science, Computer Engineering, Electrical Engineering or a related field plus 7-10 years of software engineering experience at a senior level; OR a Master’s degree or higher with 5-7 years of senior software engineering experience.",4.0,"Flexton
4.0","Sunnyvale, CA","San Jose, CA",51 to 200 employees,2007,Company - Private,IT Services,Information Technology,$10 to $25 million (USD),-1
Big Data - Senior Software Engineer,-1,"Company Overview

Calling the adventurers ready to join a company that's pushing the limits of nanotechnology to keep the digital revolution rolling. At KLA, we're making technology advancements that are bigger-and tinier-than the world has ever seen.

Who are we? We research, develop, and manufacture the world's most advanced inspection and measurement equipment for the semiconductor and nanoelectronics industries. We enable the digital age by pushing the boundaries of technology, creating tools capable of finding defects smaller than a wavelength of visible light. We create smarter processes so that technology leaders can manufacture high-performance chips-the kind in that phone in your pocket, the tablet on your desk and nearly every electronic device you own-faster and better. We're passionate about creating solutions that drive progress and help people do what wouldn't be possible without us. The future is calling. Will you answer?

Responsibilities

Group / Division

With over 40 years of semiconductor process control experience, chipmakers around the globe rely on KLA-Tencor to ensure that their fabs ramp next-generation devices to volume production quickly and cost-effectively. Enabling the movement towards advanced chip design, KLA-Tencor's Global Products Group (GPG), which is responsible for creating all of KLA-Tencor's metrology and inspection products, is looking for the best and the brightest research scientist, software engineers, application development engineers, and senior product technology process engineers.

The Broadband Plasma Division (BBP) provides market-leading patterned wafer optical inspection systems for leading-edge IC manufacturing. Logic, foundry, and memory customers depend on BBP products to detect yield-critical defects for process debug and excursion monitoring at advanced process nodes.

BBP flagship products include the 29xx and 39xx series which leverage Broadband Plasma technology to capture a wide range of defects with ultimate sensitivity at the optical inspection speeds needed for inline defect monitoring.

Responsibilities

We are looking for passionate professionals to join our team!

You will be a key member of our highly integrated multi-disciplinary team of software, systems, applications and also engineers.

You will be responsible for requirement analysis, design, implementing and testing software solutions to solve some of the most advanced technical challenges facing the industry.

As a key member of the High-Performance Computing team, you will be responsible for the design and development of distributed software platforms that will be used for big-data analytics and machine-learning.

Experience with open-source tools on Linux is highly desired along with the ability to experiment, evaluate and recommend best of breed solutions.

You should be somebody who enjoys working on complex system software, is very customer-centric, understands the big picture and feels strongly not only about building good software but about making that software achieve its goals in reality.

Qualifications

Required Qualifications:
Programming in Linux environment using Java & Python
Experience with SQL and NoSQL data-bases
Experience working with modern open-source tools for distributed computing (like Apache Spark, Hadoop, Kafka, Redis etc.)
Experience with Object-Oriented Software Analysis and Design using UML modeling
Excellent mathematical and analytical skills
Experience building distributed RESTful web services
Familiarity with administering, debugging and tuning Linux systems and software
Work in an Agile based development environment
Good to have skills:
Familiarity with Deep Learning frameworks like TensorFlow & Keras
Experience working with open-source software is a plus
Programing in any one of C/C++ or Scala will be considered a positive
Full-stack web-development with emphasis on Python Django, JavaScript, Angular
Experience with test automation a plus
Experience with Cloud technologies for scaling like Linux containers, Kubernetes, Virtual Machines etc. a plus
Minimum Qualifications
Doctorate (Academic) with at least 2 years of experience. OR
Master's Level Degree with at least 4 years of experience. OR
Bachelor's Level Degree with at least 5 years of experience.
KLA-Tencor is an Equal Opportunity Employer. Applicants will be considered for employment without regard to age, race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability, or any other characteristics protected by applicable law.

Equal Employment Opportunity

KLA is an Equal Opportunity Employer. Applicants will be considered for employment without regard to age, race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability, or any other characteristics protected by applicable law.",3.8,"Kla-tencor
3.8","Ann Arbor, MI","Milpitas, CA",5001 to 10000 employees,1976,Company - Public,Industrial Manufacturing,Manufacturing,$2 to $5 billion (USD),"Applied Materials, Nanometrics"
Field Programmable Gate Array (FPGA) Software Engineer,-1,"Job Description
Company Description

IIA is currently looking for a Field Programmable Gate Array (FPGA) Software Engineer to work in either Herndon VA, McLean, VA, or Clarksburg, MD

Job Description

Overview:

As an FPGA Software Engineer you will be a key player in IIA’s innovation and growth efforts. You will support software and firmware design, development, and integration. You will support the porting and acceleration of machine learning and other algorithms from desktop to Field-Programmable Gate Arrays and other embedded devices. You will also participate in the corporate innovation laboratory, open source projects, and strategic business capture. This is a Full-Time position and work location is negotiable among locations in Herndon, VA, McLean, VA, and Clarksville, MD or remote.

Job Responsibilities:

• Work collaboratively in agile, mixed team environment with other FPGA engineers, software developers, data scientists and geospatial experts to port machine learning and other algorithms from CPU to FPGA with tight memory constraints and complex mission requirements

• Support testing, evaluation, installation and configuration of algorithms on FPGAs

• Support production maintenance activities that include the development of automated scripts and scheduled tasks, application/system monitoring, software/security updates and patching, archiving/disposition of system logs and/or data records

• Work with the Chief Technology Officer and Business Development teams to advance corporate capabilities, including the innovation laboratory and open source projects

• Support white paper development, strategic captures, and proposals in your areas of expertise and experience

• Envision and collaborate on open source or proprietary proof of concept pilots or projects

Required Skills:

• Highly skilled programmer in relevant languages, such as C/C++ and Java

• Ability to analyze existing code and rewrite and optimize for FPGA board, such as the Xilinx Kintex Ultrascale

• Ability to work in an Agile DevSecOps environment using tools like Jira, Confluence, Bitbucket, and Slack

• Ability to deploy applications in various on premise and public cloud environments

• Excellent written and verbal communication skills

• Ability to work independently and collaboratively

• Ability to identify and pursue opportunities for program growth



Desirable Skills:

As part of a multidisciplinary, cutting-edge team, the following optional experience is also viewed favorably:

• Development of machine learning inferencing engine

• FPGA in aerospace environments

• GPU and Internet of Things embedded systems programming experience

• Deep learning and machine learning frameworks, libraries, and models, like Caffe2, PyTorch, TensorFlow, and YOLO, and languages such as Python, Go, Julia, Javascript, and shell scripts

• Open source or proprietary geospatial software

• Signals and communications processing

• Hybrid multicloud containerization and serverless computing experience, such as Docker, Kubernetes, CI/CD.

• Interest in emerging computing architectures

• Business development

Education:

Bachelor’s Degree required, Master’s Degree preferred in electrical engineering, computer engineering, physics, mathematics or related field.

Clearance Requirements:

You do not need a current/active clearance to apply, but must be able to pass and hold a government Public Trust (SF-85) background investigation. You must either be a US Citizenship or Green Card Holder to be eligible.

IIA is proud to be an EEO/AA employer M/F/D/V.

Qualifications

Desirable Skills:

As part of a multidisciplinary, cutting-edge team, the following optional experience is also viewed favorably:

• Development of machine learning inferencing engine

• FPGA in aerospace environments

• GPU and Internet of Things embedded systems programming experience

• Deep learning and machine learning frameworks, libraries, and models, like Caffe2, PyTorch, TensorFlow, and YOLO, and languages such as Python, Go, Julia, Javascript, and shell scripts

• Open source or proprietary geospatial software

• Signals and communications processing

• Hybrid multicloud containerization and serverless computing experience, such as Docker, Kubernetes, CI/CD.

• Interest in emerging computing architectures

• Business development

Education:

Bachelor’s Degree required, Master’s Degree preferred in electrical engineering, computer engineering, physics, mathematics or related field.

Additional Information

You do not need a current/active clearance to apply, but must be able to pass and hold a government Public Trust (SF-85) background investigation. You must either be a US Citizenship or Green Card Holder to be eligible.

We are proud to be an EEO/AA employer M/F/D/V.",3.8,"Information International Associates, Inc.
3.8","McLean, VA","Red Bank, NJ",1 to 50 employees,-1,Company - Private,IT Services,Information Technology,Less than $1 million (USD),-1
"Sr Python Machine learning - Rosemont, MN or Wichita, KS - Fulltime",-1,"Role Sr Python Machine learning Location Rosemont, MN or Wichita, KS Duration FULLTIME 1) Senior Level Python Developer - 5+ yearsrsquo experience building Data Integrations andor Machine Learning models for analytics 2) Hands on experience with Object Oriented Programing - as this is what the application is built on 3) Will need to be self-sufficient and solution minded - not just a heads down coder. Really a borderline architect. + Any exposure to Manufacturing or logistics would be a huge plus + any work with AI applications also a big nice to have Bachelor's Degree - Proven professional experience with object oriented programming in a technology focused role (including but not limited to IT Roles such as Software Developer, Data Engineer, DevOpsCloud Engineer, Data Scientist) - 5+ years professional coding experience - 5+ yearsrsquo experience building Data Integrations andor Machine Learning models for analytics Thanks Regards Vijay Kumar Maragoni vijaymusmsystems.com 703-880-9819 469-900-2150571-250-7346",2.7,"USM Business Systems
2.7","Rosemount, MN","Chantilly, VA",51 to 200 employees,1999,Company - Private,Computer Hardware & Software,Information Technology,$25 to $50 million (USD),-1
Lead Data Scientist,"$117K-$186K
(Glassdoor est.)","Please note, this is a proactive search for a role that has been vetted by our leadership team for future hiring.  The recruiting team and hiring managers remain active in discussions with interested, qualified individuals and are committed to being transparent on timelines throughout the process. Thank you.

Who We Are:

Vistaprint’s Data and Analytics (DnA) organization is working to make our company one of the world’s most well-known and successful data-driven companies. The cross-functional team includes product owners, analysts, technologists, data engineers and more – all focused on providing Vistaprint with information and tools we can use to deliver jaw-dropping customer value. DnA team members are empowered to learn new skills, communicate openly and be active problem-solvers.

What You Will Do:

As the Lead Data Scientist, you will be a “go-to” domain specialist in data science and machine learning, leading the charge on ground breaking work, mentoring more junior data scientists, and guiding the organization on methodology and best practices. You will also drive high-profile projects - not just delivering solutions, but helping to seek out new opportunities and own the creation of innovative solutions. Your statistical, computer science and business domain expertise will have a significant impact to our business from day one.

You will join a core team of Data Scientists, working alongside Marketers, Analysts, Engineers and Product Owners to forge new paths and redefine how data is utilized to deliver value. You’ll seek ways to improve, communicate openly, and be an active problem-solver. Throughout the design, development, and delivery stages you will surprise yourself with new levels of professional and personal growth.
Engage with cross-functional business partners to identify analytical project requirements, discuss methodologies and determine deliverables.
Learn, practice, and lead others in using new tools in an ambitious technical environment that combines both coding skills, web technologies and real-time data.
Analyze pre-existing models and algorithms; provide suggestions on how to improve the efficiency and effectiveness, to drive value to the organization
Deliver a range of custom Data Science projects that may include Recommendation Systems, Price Optimization; Time Series Modeling; Customer Lifetime Value Customer, Propensity Modelling); Image Recognition, etc.
Act as a thought leader within the Data Science team, staying ahead of the latest trends and technologies
Your Qualifications:
5+ years machine learning and modeling experience, and have delivered multiple projects as a lead scientist or in a similar capacity
MSc or PhD in Statistics, Mathematics, Operational Research or similar field
Strong programming skills in Python and R
Hands on experience using “big data technologies”
Experience of software engineering techniques including version control, continuous integration, unit testing.
Experience of designing and building DS products for ecommerce like recommendation systems, forecasts, Customer Lifetime Value Models, etc.
Business partner management; ability to independently communicate technical and statistical concepts to non-practitioners, and influence the application.
Nice to Have:
Spark, Java, Scala
Bayesian Statistics
Experience using standard libraries (scikit-learn, MLlib, TensorFlow, MXNet, PyMC3)
Agile working methodology
Relevant work in an e-commerce environment
Why You’ll Love Working Here:

At Vistaprint, we put great importance into the wellbeing of our employees, which is why we offer perks that ensure a phenomenal work/life balance. Perks include flexible schedules, work from home capabilities, and very generous time off, including our unique sabbatical-like program, “Vistabreak”, to name a few! Here in Waltham, we offer a modern and collaborative office environment with a free on-site gym, fully stocked kitchens, and cold brew on tap.

About Us:

As an e-commerce powerhouse, Vistaprint is a dynamic organization that maintains an exciting, entrepreneurial culture. With founder Robert Keane’s return as CEO, we’ve renewed our focus on empowering and helping small businesses. To do this, we create customer value (and delight) through accessible, cutting-edge technology. We thrive on providing opportunities for exploration, collaboration, innovation and growth – for both our customers and our team.

Equal Opportunity Employer:

Vistaprint, a Cimpress company, is an Equal Employment Opportunity Employer. All qualified candidates will receive consideration for employment without regard to race, color, sex, national or ethnic origin, nationality, age, religion, citizenship, disability, medical condition, sexual orientation, gender identity, gender presentation, legal or preferred name, marital status, pregnancy, family structure, veteran status or any other basis protected by human rights laws or regulations. This list is not exhaustive and, in fact, in many cases, we strive to do more than the law requires.

#LI-AC1

Nearest Major Market: Waltham
Nearest Secondary Market: Boston
Job Segment:
Scientific, Database, Engineer, Scientist, Computer Science, Engineering, Technology, Science",3.5,"Vistaprint
3.5","Waltham, MA","Venlo, Netherlands",5001 to 10000 employees,1995,Company - Public,Other Retail Stores,Retail,$1 to $2 billion (USD),"Tripadvisor, Wayfair, Amazon"
Senior Software Engineer,-1,"SiriusXM and Pandora have joined together to create the leading audio entertainment company in the U.S. Together, we are uniquely positioned to lead a new era of audio entertainment by delivering the most compelling subscription and ad-supported audio experiences to millions of listeners -- in the car, at home and on the go. Our talent, content, technology and innovation continue to be at the forefront, and we want you to be a part of it! Check out our current openings below and at www.siriusxm.com/careers.Position Summary:As a senior member of the Voice team at SiriusXM + Pandora you are responsible for building and maintaining the service that supports Voice interactions across our native mobile applications and third-party devices. You work closely with Product Management and Data Science partners to implement innovative features and measure their impact. You're comfortable working in a distributed team, in a fast-paced environment and have excellent written and verbal communication skills. You have a collaborative attitude and love working with others to find elegant solutions to complex problems, always keeping the end user in mind. You have a solid foundation of Java development and are comfortable building services at scale. You are familiar with cloud software deployment and monitoring tools and are enthusiastic about learning new technologies and skills.Supervisory Responsibilities:* NoneMinimum Qualifications:* 5+ years development experience with a focus on microservice development* Experience in designing and developing highly scalable, highly available, highly performant and maintainable internet applications.* Experience with cloud computing (Google Cloud Platform, Amazon Web Services)* Experience with API design/development (i.e. RPC, REST, JSON)* Experience with Spring/SpringBoot* Experience with Unit/Integration testing* Understanding of multi-threading, concurrency, design patterns and their impacts on application concurrency and scalability or equivalent, relevant experience.Plus Requirements:* Experience collaborating with data scientists, exposure to machine learning algorithms and/or statistical modeling methods.* Experience with Voice platforms or Natural Language Processing technologies* Experience with anomaly detection, analysis of high volume metrics, recommender, or search systems.* BA/BS or above in Computer Science or a related fieldRequirements and General Skills:* Good public speaking and presentation skills.* Interpersonal skills and ability to interact and work with staff at all levels.* Excellent written and verbal communication skills.* Ability to work independently and in a team environment.* Ability to pay attention to details and be organized.* Ability to project professionalism over the phone and in person.* Ability to handle multiple tasks in a fast-paced environment.* Commitment to ""internal client"" and customer service principles.* Willingness to take initiative and to follow through on projects.* Creative writing ability.* Excellent time management skills, with the ability to prioritize and multi-task, and work under shifting deadlines in a fast-paced environment.* Must have legal right to work in the U.S.Technical Skills:* Thorough knowledge of MS-Office Suite (Word, Excel, PowerPoint, Access).Our goal at SiriusXM+Pandora is to provide and maintain a work environment that fosters mutual respect, professionalism and cooperation. SiriusXM+Pandora is an equal opportunity employer that does not discriminate on the basis of actual or perceived race, creed, color, religion, national origin, ancestry, alienage or citizenship status, age, disability or handicap, sex, gender identity, marital status, familial status, veteran status, sexual orientation or any other characteristic protected by applicable federal, state or local laws.The requirements and duties described above may be modified or waived by the Company in its sole discretion without notice.",3.1,"Sirius XM
3.1","New York, NY","New York, NY",1001 to 5000 employees,1990,Company - Public,Radio,Media,$2 to $5 billion (USD),-1
Senior Data Engineer,-1,"Data Science at Policygenius...

Policygenius continues to disrupt the insurance industry by delivering innovative technology-driven experiences. We are advancing our tech capabilities and learning to leverage our hordes of data to develop innovative machine learning applications. We are relentless in our drive to reliably deliver outstanding products at scale. We are growing fast, but we can go further faster with experienced, collaborative, challenge-seeking data engineers like yourself.

Our data science team builds machine learning applications that are embedded into our consumer facing applications or power our processes to make us more efficient. We partner with Product, Design, Engineering and numerous stakeholders across the company to develop deeper predictors of behavior and build solutions to optimize our internal and external experiences.

In this role, you will…
Take complicated algorithms, code review, optimize for production and integrate into product features or process flows.
Design data architecture that is simple, fault tolerant and requires little overhead.
Design data pipelines utilizing ETL tools, event driven software or cloud functions and other streaming software.
Partner with both data scientists and engineers to bring our amazing concepts to reality. This requires learning to speak the language of statisticians as well as software engineers.
Work directly with stakeholders to ingest new sources of data, but also work to manage our self service data model.
Develop internal data science specific tooling for solutions such as A/B testing, learning sharing and analysis repositories and machine learning components.
Ensure ultimate reliability in data pipelines and enforce data governance, security and protection of our customer's information.
Mentor data engineering team members and even data scientists in architecture and coding techniques.
We'd love to hear from you if…
You have 3-5+ years of experience as a software engineer or data engineer coding in Python and using SQL.
You are acquainted with designing custom machine learning pipelines that integrate into production environments that are customer facing.
You understand life is not all machine learning and simple pipelining is often extremely relevant to add business value.
You are obsessed with reducing lag, building scalable systems, optimizing performance, automating things and solving complex problems!
You have some awareness of machine learning concepts.
You have 3-5+ years of experience working in a consumer facing business.
You have experience working on product teams, but also collaborating with other data science team members.
You have a background in computer science or related.
You can communicate with a team and articulate ideas to both team members and non-technical stakeholders.
You have a drive to learn and master new technologies and techniques.
You have experience with relational cloud databases like Redshift, BigQuery, Snowflake, but also comfortable working with unstructured files and datasets.
You can expect...
Company-paid health, dental, vision, life & disability insurance
401(k) plan, FSA & commuter benefits
Generous PTO
Training, mentorship and coaching from leadership
The opportunity to grow alongside a company shaking up a big, old-fashioned industry
Fun, diverse, open-minded coworkers
Dog companionship!!!
Technologies You Will Use
Python for data pipelining and automation.
Google Cloud Platform: Kubernetes, Cloud SQL, Cloud Functions, PubSub, BigQuery, DataStore, and more: we keep adopting new tools as we grow!
Airflow for data pipelining.
Tableau for data visualization and consumer facing dashboards.
Many more to come!
About Policygenius

Policygenius is America's leading online insurance marketplace. Since 2014, our mission has been to help people get the financial protection they need (and feel good about it). We make it easy for our customers to understand their options, compare quotes, and buy insurance, all in one place. To date, we've helped more than 30 million people shop for all types of insurance and placed over $45 billion in coverage.

At Policygenius, we're proud of building an environment that encourages our teammates to bring their authentic selves to work. Despite rapid growth (we've doubled in size year over year!), we've continuously maintained our inclusive culture through humility, hard-work, and humor, and we're looking for more people with grit, collaborative attitudes, and creative problem-solving skills to join our team. Come see why we've been voted one of Inc. Magazine's ""Best Workplaces"" two years in a row!

Diversity at Policygenius

Policygenius believes differences should be celebrated and is committed to building a team as diverse as the customers we serve. We welcome different perspectives and opinions to foster innovation, authenticity, and excellence across all parts of our company, and are committed to providing employees with a work environment free of discrimination and harassment.

As an Equal Opportunity Employer, Policygenius highly encourages applicants from all walks of life. All employment decisions at Policygenius are based on business needs, job requirements and individual qualifications without regard to actual or perceived race, color, sex, pregnancy, sexual orientation, gender identity or expression, age, national origin, political affiliation or belief, religion, disability, uniformed service, marital status or any other status protected by law.

Come join the team!",4.5,"Policygenius
4.5","New York, NY","New York, NY",201 to 500 employees,2012,Company - Private,Insurance Agencies & Brokerages,Insurance,Unknown / Non-Applicable,-1
"Senior Machine Learning Engineer, Infrastructure",-1,"Company Description

Cash App is the fastest growing financial brand in the world. Initially built to take the pain out of peer-to-peer payments, Cash App has gone from a simple product with a single purpose to a dynamic app with over 24 million monthly active users. We are bringing a better way to send, spend, invest, and save to anyone who has ever sought an alternative to the traditional banking system.

Loved by customers and pop culture, we’ve consistently held the top spot for finance in the App Store for many years, seeing more engagement with millions of followers across social media in a day than most brands see in a year. We are building an ecosystem to redefine the world’s relationship with money by making it universally accessible.

We want to hire the best talent regardless of location. Our employment model is distributed, offering the opportunity to collaborate with teams across the world in San Francisco, New York, St. Louis, Portland, Toronto, Kitchener-Waterloo, Sydney, and Melbourne.

Interested in learning more?

Job Description

At Cash App we believe Machine Learning, especially Deep Learning powered Artificial Intelligence, is the future. Our mission is to make them available in the present. To achieve this we’re organized into three teams: ML Platform, Data Infrastructure & Risk.

We believe each Machine Learning Engineer has a diverse set of skills, regardless of what your strength is, we would love to talk to you.

Problems you’d be solving:
Prototype new approaches and productionize solutions at scale for our 24+ millions of active users
Help execute our long-term Machine Learning strategy across Cash App
Create a world class platform for training, hosting and maintaining ML models '
Identify opportunities for platformization by communicating with our applied ML team
Balance the needs of Product, Data Scientists, User Research, and other engineers in a small team to develop machine learning approaches that advance our mission to detect fraud
Qualifications

You have:
Demonstrated technical initiative and leadership on previous projects
The ability to work in a fast paced, autonomous and unpredictable environment
Desire to mentor & grow other machine learning engineers across the org to further these efforts
A deep understanding of software that allows you make the right trade offs
Natural curiosity & eagerness to learn (we have one day a week dedicated to Passion Projects)
Technologies we use:

We’re agnostic to what you know walking in the door. You’ll need to be happy working with:
Kotlin, Java, Go & Python
AWS
Kafka, Beam and Flink
Additional Information

Cash App treats all employees and job applicants equally. Every decision is based on merit, qualifications, and talent. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

We will consider for employment qualified applicants with criminal histories in a manner consistent with each office’s corresponding local guidelines.",-1,Cash App,"San Francisco, CA",-1,-1,-1,-1,-1,-1,-1,-1
Software Engineer II,"$56K-$117K
(Glassdoor est.)","Mid/Senior Level Data Engineer- Remote due to COVID, but will be required to sit in Lincolnshire once restrictions are lifted. Start time would be 9AM Central
There is a possibility to move from Temp to FT Hire
Visa sponsorship is not available, now or in the near future, for this position
CTO AI services is a central group innovating new AI centric products, supporting Business Units on program acceleration and building an ecosystem that will allow Client to scale its AI components across the business and partners.
As a Data Engineer in computer vision you will have a unique opportunity to design and manage all of our data infrastructure used by our research team to solve real-world applications.
You will face a variety of challenges from automating data acquisition and annotation to evaluating our latest cutting-edge algorithms, and you will have access to the best hardware to do the job.
We are focusing on leveraging AI to help solve real-world problems on real-world data.
This means embracing noise and complexity, both at the data level and at the methodological level.
You will collaborate closely both with both software developers and research scientists to commercialise our products and manage data collection and management requirements.
You will have experience in machine learning and management, either through your studies or industrial R&D projects and will be equally adept at developing production-quality code.
Must haves in a Candidate:
Computer vision and applications of machine learning.
Collecting, QCing, and analyzing huge datasets.
Using the best tools to streamline data acquisition and processing.
Assisting research scientists achieve their goals
A getting-it-done attitude with a desire to both push the boundary of fundamental knowledge and turn it into great products.
A degree in computer science or a quantitative field and at least one year of industrial experience working with data.
Strong math skills, a problem-solving aptitude and desire to automate
Experience of scientific programming and libraries relevant to image and video processing and management, for example OpenCV.
Experience with at least one programming language such as Python, C++, etc.
Experience working in a diverse and international team.",3.9,"ApTask
3.9","Lincolnshire, IL","Iselin, NJ",201 to 500 employees,2010,Company - Private,IT Services,Information Technology,$50 to $100 million (USD),"Collabera, Mitchell Martin, The Judge Group"
Senior Data Scientist - Algorithms,"$96K-$119K
(Glassdoor est.)","Company Description: Quartet is a pioneering healthcare technology company striving to improve the lives of people with mental health conditions. We connect people to a personalized care team to get them the right care at the right time. Our collaborative technology platform and range of services brings together physicians, mental health providers, and insurance companies to effectively improve patient outcomes and drive down healthcare costs. Backed by $93MM in venture funding from top investors like Oak HC/FT, GV (formerly Google Ventures), F-Prime Capital Partners, and Polaris Partners, Quartet is headquartered in NYC and is currently operating in several markets across the United States — Pennsylvania, Washington, Northern California, and New Jersey.

Role Description: As a Sr. Data Scientist at Quartet, you will work in collaboration with other data scientists, bioinformaticians and platform engineers. In this role, you will build machine learning models and recommendation services to enable our applications to suggest timely and appropriate behavioral health care interventions for patients. You'll work with datasets that include millions of detailed medical, pharmacy, lab claims, EHR, and application data. You will help with development and validation of new algorithms that enhance our system in terms of scalability, reliability and accuracy. The ideal candidate will be an entrepreneurial, motivated data scientist who is well-versed in data analysis and algorithm implementation and eager to learn new things and make an impact on the industry. Health data experience is a plus, but it's not necessary.

Responsibilities:
Work with an interdisciplinary technical team to develop statistical models in Quartet’s platform.
Apply data mining and machine learning techniques to develop better personalization and recommendation for patients’ and doctors’ needs.
Design and develop effective models, features, and algorithms involving multiple datasets - user activity, EHR, ADT, medical claims, pharmacy claims, lab test claims etc.
Derive insights from descriptive analysis that drive a data-informed process for experimenting with new products to improve patient outcomes.
Qualifications:
Experience building high quality data products.
7+ years experience as a data scientist, software engineer with predictive modeling, or similar experience of solving real problems with data mining and machine learning techniques.
PhD or Master’s Degree in computer science, machine learning, applied statistics, physics, or a related quantitative discipline.
Proficiency in building Machine Learning (supervised and unsupervised) models and recommendation systems.
Strong knowledge of mathematical fundamentals: probability theory, linear algebra and statistics.
Ability to execute, starting from problem definition, to a working implementation.
Ability to clearly communicate across disciplines and work collaboratively.
Proficiency in Python and code versioning systems like git.
Expertise with data science toolkits like scikit-learn and pandas.
Knowledge of software architectures and tools such as Scala, Hadoop.
Familiarity working in a Linux server-based environment.
Employee Benefits for Quartet include: Unlimited vacation, volunteer opportunities, catered lunches, snacks, team events and outings, full medical, dental + vision coverage, generous parental leave, commuter benefits, 15 free therapy sessions + unlimited copay reimbursements for mental healthcare, 401K, ESPP, gym benefits.

Want to know what Quartet life is like? Click here to meet our team. Quartet is committed to building a diverse team and fostering an inclusive culture, and is proud to be an equal opportunity employer. We embrace and encourage our employees' differences in race, religion, color, national origin, gender, family status, sexual orientation, gender identity, gender expression, age, veteran status, disability, pregnancy, medical conditions, and other characteristics. Headhunters and recruitment agencies may not submit resumes/CVs through this Web site or directly to managers. Quartet does not accept unsolicited headhunter and agency resumes. Quartet will not pay fees to any third-party agency or company that does not have a signed agreement with Quartet. Please note: Quartet interview requests and job offers only originate from quartethealth.com email addresses (e.g. jsmith@quartethealth.com). Quartet will also never ask for bank information (e.g. account and routing number), social security numbers, passwords, or other sensitive information to be delivered via email. If you receive a scam email or wish to report a security issue involving Quartet, please notify us at: security@quartethealth.com.

Have someone to refer? Email talent@quartethealth.com to submit their details to us.",3.9,"Quartet Health
3.9","New York, NY","New York, NY",201 to 500 employees,2014,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Lead Machine Learning Engineer with Security Clearance,-1,"Company Information Octo Consulting Group (Octo) is an industry-leading, award-winning provider of digital services for the federal government. Octo specializes in providing agile software engineering, user experience design, cloud services, and digital strategy services that address government's most pressing missions. Octo delivers intelligent solutions and rapid results, yielding lower costs and measurable outcomes. Our team is what makes Octo great. At Octo you'll work beside some of the smartest and most accomplished staff you'll find in your career. Octo offers fantastic benefits and an amazing workplace culture where you will feel valued while you perform mission critical work for our government. Voted one of the region's best places to work multiple times, Octo is an employer of choice! Job Description You... As a Lead Machine Learning Engineer at Octo, you will help develop and expand Octo's AI capability. In this role you will have the opportunity to help chart our AI strategy while helping build core offerings. You will work closely with executives, business line stakeholders, and customers to help design, innovate and build our next generation AI/ML solutions and offerings. As a team lead you will provide mentorship/guidance to junior AI team and you will represent the team when participating in internal and external technology initiatives. In this role you will be driving the creation of innovative AI products from ideation, through MVP, Pilot, and production. You will help solve real world problems and challenges that our customers face. From a leadership standpoint, you will directly support the Octo's CTO office and help shape strategy, initiatives, solutions and investments in all things AI. As a team lead, you will work closely with your team to develop and productionize solutions and offerings. You will also be responsible for leading and reviewing the work of multiple engineers, data scientists, developing and testing Machine Learning algorithms. As a lead, you will also serve as a solution architect to help shape AI related proposals. Us... We were founded as a fresh alternative in the Government Consulting Community and are dedicated to the belief that results are a product of analytical thinking, agile design principles and that solutions are built in collaboration with, not for, our customers. This mantra drives us to succeed and act as true partners in advancing our client's missions. Specifics... * Develop an AI roadmap to align to strategic imperatives * Determine metrics of success and systematically track the impact of the program * Use AI to solve customer business problems and build internal solution offerings * Run AI projects/initiatives, build MVPs/prototypes, from beginning to end * Stay up-to-date on new AI products and develop solutions (prototypes, white papers, trainings) * Prototype and demonstrate AI related products and solutions for customers * Execute and drive Executive Management's AI strategy * Identify new business opportunities and prioritize pursuits for AI * Create customized offerings * Build a library of AI assets * Enable strategic partnerships with industry leaders * Create AI white papers * Align, mentor, and manage, team(s) around strategic initiatives Skills & Requirements Requirements... * Hands-on experience using deep learning and computer vision libraries such as PyTorch, TensorFlow, Caffe, MXNet, OpenCV, Keras, and scikit * Experience with containerization of machine learning applications (AWS DL Containers, Docker, Singularity, Apache Mesos Openshift, Kubernetes) * Experience with CUDA and NVIDIA GPU accelerated libraries for AI, ML, DL * Experience with embedded low SWaP GPU computing * Basic understanding of full motion video data formats * Basic understanding of 3D geospatial model formats (OBJ, 3D Tiles, GLTF) Years of Experience: Minimum 3 years building and deploying at scale Machine Learning and Deep Learning models and minimum 3 years of developing machine learning methods, including familiarity with techniques in clustering, regression, optimization, recommender engines, artificial neural networks. Education: Bachelor's dgeree in computer science, data science, physics, applied mathematics/statistics, operation research, or other physical science/engineering field. Clearance: Ability to obtain a DoD Secret Clearance Location: Reston, VA Octo Consulting Group is an Equal Opportunity/Affirmative Action employer. All qualified candidates will receive consideration for employment without regard to disability, protected veteran status, race, color, religious creed, national origin, citizenship, marital status, sex, sexual orientation/gender identity, age, or genetic information. Selected applicant will be subject to a background investigation.",3.9,"Octo Consulting Group
3.9","Reston, VA","Reston, VA",501 to 1000 employees,2006,Company - Private,Consulting,Business Services,$50 to $100 million (USD),"Attain, Deloitte, Booz Allen Hamilton"
Senior Frontend Engineer - Machine Learning,-1,"Are you intrigued or passionate about Machine Learning (ML) and ready to build a new customer-centric product? The Amazon SageMaker team is looking for talented front-end engineering leaders to help us build the next generation of ML tools.

With SageMaker, developers and data scientists have the ability to build, train, and deploy machine learning models quickly. As a fully-managed cloud service, SageMaker covers the entire data science workflow from data preparation and exploratory data analysis to model building and inference; our charter is to make data science and machine learning understandable, affordable, scalable, and accessible to everyone. The foundation of the SageMaker user experience is the industry standard, open-source Jupyter Notebook.

As an front end engineering leader on the SageMaker team, you'll be responsible for starting a new team to build out interactive data-driven ML applications.

Key Responsibilities:
Work closely with senior engineers, UX designers, and product managers to develop friendly UI experiences.
Work closely with engineers to architect and develop the best technical design.
Develop/maintain operational rigor for the frontend of a fast-growing AWS service.
Develop the engineers of an existing ""two pizza"" scrum team.
Collaborate with other SageMaker SDE's for features that cut across SageMaker.
Engage with customers and other AWS partners.
Help with hiring.
You'll be well supported with by a group with deep technical chops, including multiple senior and principal engineers and scientists.

Basic Qualifications
Bachelor's Degree in Computer Science or related field.
Equivalent experience to a Bachelor's degree based on 3 years of work experience for every 1 year of education
5+ years professional experience in software development.
Experience with modern programming languages (Java, C#, Python) and open-source technologies.
Experience with web/mobile technologies (e.g., JavaScript/TypeScript, NodeJS, React, WebPack, HTTP mechanics/performance).
Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.",-1,Amazon Corporate LLC,"Seattle, WA",-1,-1,-1,-1,-1,-1,-1,-1
Sr. Software Engineer - Platform,-1,"LeapYear's secure machine learning platform is deployed by some of the largest enterprises in the world across finance, healthcare, and technology.

Our technology ensures differential privacy, a widely recognized standard of data privacy that enables all data - including sensitive information - to be utilized for analytics, while providing mathematically proven privacy protection.

The LeapYear system is composed of a core set of components that allow private machine learning on data sets that can scale to petabytes. The system includes private algorithms for relational operations, statistical methods and machine learning. A data scientist accesses private data using a Python API. Administration is provided via a web-based GUI or an API.

LeapYear's platform team builds the services that allow our product to integrate with complex enterprise environments and operate effectively on our customers’ most sensitive data.
The platform includes services for authentication, access control, logging, auditing and support for integration of data from a variety of data sources including SQL/NoSQL Databases, HDFS and S3. Queries are processed using Spark to support to enable fast, distributed processing of massive data sets. The services are primarily written in Haskell, with Python, Scala, and Java used as additional supporting languages.

We are looking for platform engineers that have a track record of developing enterprise-ready features for technical end users, including enterprise integrations, rigorous security, flexible deployment, and support for diverse data sources.

Recent technical challenges we've been working on
Developing a Spark-based query engine with strong typechecking.
Achieving terabyte and petabyte scale on Spark.
Refactoring our persistence layer.
Using Haskell to implement enterprise-ready subsystems for authentication, permissioning, job management, and logging.
Extending the platform to support automated daily data updates.

For details on the specific responsibilities and requirements of this role, please see below.
Responsibilities
Develop greenfield systems and scale existing services to support internet-scale deployments.
Own the full software development lifecycle - problem definition, design, development, testing, demoing, and supporting production use of the features you own.
Partner with product management to define problems and identify iterative solutions
Balance immediate business objectives against long-term architectural vision
Contribute to an engineering-wide culture of code quality and shared responsibility for testing
Requirements
7+ years of professional experience writing production code
Acquainted with and interested in functional programming (Haskell, OCaml, Clojure, Erlang, Scala)
Track record of delivering high-quality product features on schedule
Preferred
Experience developing for on-premise enterprise deployments
Professional experience with functional programming
Prior experience developing production-level Spark applications or machine learning platforms
Experience with ODBC/JDBC databases, AWS, CircleCI
Lifelong learners and mentors
A Few of the Perks
Culture of teaching and learning
Competitive compensation package of salary and equity
Catered lunch every day
Company outings
Build your ideal work station
Generous health insurance plan
Relocation support and visa sponsorship",4.2,"LeapYear
4.2","San Francisco, CA","San Francisco, CA",1 to 50 employees,2015,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Senior Data Engineer,"$67K-$127K
(Glassdoor est.)","Join our team dedicated to developing and executing innovative solutions in support of customer mission success.
Job Description:

Novetta has an immediate need for a Senior Data Engineer to join a fast-paced program in support of a government customer with a very critical national security mission. This is a multi-year program, where the successful candidate will work on an interdisciplinary project team of more than 30 highly qualified individuals with a wide array of skills that include client (reactjs), server (spring java), QA Automation Engineers, UI/UX Designers, and DevOps engineers. The team is responsible for building a next generation Mission Information System and is performing greenfield Software Development using modern technologies via an Agile DevOps approach.

This Senior Data Engineer will play a vital role collaborating as part of this cross-functional Agile team to create and enhance data ingestion pipelines and address big data challenges. The Senior Data Engineer will work closely with the Chief Architect, systems engineers, software engineers, and data scientists on the following key tasks:
Provide Extraction, Transformation, and Load (ETL) experience coupled with enterprise search capabilities to solve Big Data challenges
Design and implement high-volume data ingestion and streaming pipelines using Open Source frameworks like Apache Spark, Flink, Nifi, and Kafka on AWS Cloud
Leverage strategic and analytical skills to understand and solve customer and business centric questions
Create prototypes and proofs of concept for iterative development
Learn new technologies and apply the knowledge in production systems
Monitor and troubleshoot performance issues on the enterprise data pipelines and the data lake
Partner with various teams to define and execute data acquisition, transformation, processing and make data actionable for operational and analytics initiatives

Required Qualifications / Experience:
BS in Computer Science, Systems Engineering, or a related technical field or equivalent experience with at least 8+ years in systems engineering or administration (6+ years with a MS/MIS Degree).
Must have an active Top Secret security clearance and able to obtain a TS/SCI with Polygraph.
3 years of experience with big data tools: Hadoop, Spark, Kafka, NiFi.
3 years of experience with object-oriented/object function scripting languages: Python (preferred) and/or Java.
3 years of experience with and managing data across relational SQL and NoSQL databases like MySQL, Postgres, Cassandra, HDFS, Redis, and Elasticsearch.
3 years of experience working in a Linux environment.
2 years of experience working with and designing REST APIs.
Experience in designing/developing platform components like caching, messaging, event processing, automation, transformation and tooling frameworks.
Experience developing data ingest workflows with stream-processing systems: Spark-Streaming, Kafka Streams and/or Flink.
Experience transforming data in various formats, including JSON, XML, CSV, and zipped files.
Experience with performance tuning of ETL jobs.
Experience developing flexible ontologies to fit data from multiple sources and implementing the ontology in the form of database mappings / schemas.
Strong interpersonal and communication skills necessary to work effectively with customers and other team members.
Preferred Qualifications / Experience:
Data engineering experience in the Intelligence Community or other government agencies.
Experience with Microservices architecture components, including Docker and Kubernetes.
Experience developing microservices to fit data cleansing, transformation and enrichment needs.
Experience with AWS cloud services: EC2, S3, EMR, RDS, Redshift, Athena and/or Glue.
Experience with Jira, Confluence and extensive experience with Agile methodologies.
Knowledge about security and best practices.
Experience developing flexible data ingest and enrichment pipelines, to easily accommodate new and existing data sources.
Experience with software configuration management tools such as Git/Gitlab, Salt, Confluence, etc.
Experience with continuous integration and deployment (CI/CD) pipelines and their enabling tools such as Jenkins, Nexus, etc.
Detailed oriented/self-motivated with the ability to learn and deploy new technology quickly.
Clearance Level: TS/SCI with Poly


Novetta, from complexity to clarity.

Novetta delivers highly scalable advanced analytics and secure technology solutions to address challenges of national and global significance. Focused on mission success, Novetta pioneers disruptive technologies in machine learning, data analytics, full-spectrum cyber, cloud engineering, open source analytics, and multi-INT fusion for Defense, Intelligence Community, and Federal Law Enforcement customers. Novetta is headquartered in McLean, VA with over 1,000 employees across the U.S.


Our culture is shaped by a commitment to our core values:

Integrity • We hold ourselves accountable to the highest standards of integrity and ethics.

Customer Success • We strive daily to exceed expectations and achieve customer mission success.

Employee Focus • We invest in our employees' professional development and training, respecting individuality and fostering a culture of diversity and inclusion.

Innovation • We know that discovering new and innovative ways to solve problems is critical to our success and makes us a great company.

Excellence in Execution • We take pride in flawless execution as we build a company that is best in class.


Earn a REFERRAL BONUS for the qualified people you know.
For more details or to submit a referral, visit bit.ly/NovettaReferrals.

Novetta is an equal opportunity/affirmative action employer.
All qualified applicants will receive consideration for employment without regard to sex, gender identity, sexual orientation, race, color, religion, national origin, disability, protected veteran status, age, or any other characteristic protected by law.",4.5,"Novetta
4.5","Reston, VA","Mc Lean, VA",501 to 1000 employees,2012,Company - Private,Enterprise Software & Network Solutions,Information Technology,$100 to $500 million (USD),"Leidos, CACI International, Booz Allen Hamilton"
Azure Data Engineer,-1,"The candidate will be responsible for meeting with business and technical staff, end users, and senior management to define requirements. The candidate must also be able to develop, deploy, and support Data Engineering. The ideal candidate will possess effective communication and interpersonal skills to build and maintain working relationships with clients. The developer will also be expected to prepare and maintain related technical documentation.
RESPONSIBILITIES:
Work with clients to elicit, refine, and document requirements.
Data modeling, process modeling, and rapid prototyping.
Develop/maintain ETL packages.
Develop/maintain Power BI data models and visualizations.
Assist in the design and implementation of a data lake to store structured and unstructured data.
Plan, prioritize, and execute in a rapidly changing, fast-paced environment.
Use version management and issue tracking software to document all changes.
Conduct tuning in Power BI to improve performance.
REQUIRED:
Bachelors Degree in computer science, engineering, mathematics, statistics, data science, analytics bioinformatics, or related program.
3-5 years proven experience with Power BI and/or SSAS/SSIS.
Experience with TSQL.
Experience with programming language such as JavaScript, Python or R.
Application architecture experience.
Excellent interpersonal and organizational skills.
Strong leadership, verbal and written communication skills.
U.S. Citizenship Required
Project management understanding.
Consulting experience a plus.
Ability to obtain a security clearance
DESIRED:


Experience with Power Query/M functions.
ETL experience and/or ML experience with Apache Spark or Apache Hadoop
Azure Data Engineer, Azure Data Scientist, Azure Data Analyst Associate or MCSA: Machine Learning Certification
1+ years of experience with data science, econometrics, statistics, machine learning, or analytics in professional or academic environments
1+ years of experience with managing and manipulating large data sets, developing data science approaches, and executing data science tasks
Experience with machine learning models and applications
Ability to leverage a wide variety of data science capabilities and languages
Ability to communicate results effectively to both technical and nontechnical audiences",4.4,"Definitive Logic
4.4","Arlington, VA","Arlington, VA",201 to 500 employees,1999,Company - Private,Consulting,Business Services,$25 to $50 million (USD),-1
Senior Software Engineer - Machine Learning,"$135K-$210K
(Glassdoor est.)","Amazon is investing heavily in building a world class advertising business and we are responsible for defining and delivering a collection of self-service performance advertising products that drive discovery and sales. Our products are strategically important to our Retail and Marketplace businesses driving long term growth. We deliver billions of ad impressions and millions of clicks daily and are breaking fresh ground to create world-class products. We are highly motivated, collaborative and fun-loving with an entrepreneurial spirit and bias for action. With a broad mandate to experiment and innovate, we are growing at an unprecedented rate with a seemingly endless range of new opportunities.

Our systems and algorithms operate on one of the world's largest product catalogs, matching shoppers with advertised products with a high relevance bar and strict latency constraints. We work hand-in-hand with Machine Learning scientists to come up with novel solutions that deliver highly relevant ads. We consistently strive to improve the customer search and detail page experiences. You will drive appropriate technology choices for the business, lead the way for continuous innovation, and shape the future of e-commerce. This is an opportunity to make a significant impact on the future of the Amazon vision.

As a Senior Software Development Engineer in Machine Learning at Amazon, you will drive the technical direction of our offerings and solutions, working with many different technologies across the sponsored products organization. You will design, code, troubleshoot, and support scalable machine-learning pipelines and online serving systems. You will work closely with applied scientists to optimize the performance of machine-learning models and infrastructure, and implement end-to-end solutions. What you create is also what you own. In addition to being a strongly motivated individual contributor, you will also be responsible for mentoring junior engineers and guiding them to deliver to the full potential.

The team is open to hiring this engineering into the Palo Alto office or with a flexibile schedule of coming into the office or as a full remote/virutal employee.


Basic Qualifications

· 4+ years of professional software development experience
· 3+ years of programming experience with at least one modern language such as Java, C++, or C# including object-oriented design
· 2+ years of experience contributing to the architecture and design (architecture, design patterns, reliability and scaling) of new and current systems
· Bachelor or Master's Degree in Computer Science, Applied Mathematics, or related discipline
· 5+ years professional experience in software development with experience in working on low latency, high volume distributed systems.
· 5+ years experience with computer science fundamentals data structures, algorithm design, problem solving, and complexity analysis
· Exposure to Machine Learning basics (will train for more advanced skills in ML)

Preferred Qualifications

· Experience in building large-scale machine-learning infrastructure for online recommendation, ads ranking, personalization, or search, etc.
· Experience with Big Data technologies such as AWS, Hadoop, Spark, Pig, Hive, etc.
· Strong proficiency with Java, Python, Scala or C++
· Advanced knowledge of performance, scalability, enterprise system architecture, and engineering best practices
· Strong written and verbal communication
Amazon is an Equal Opportunity-Affirmative Action Employer Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation/Age
#PABDSDE3ADS
#PABDSDE3
#VIRBDSDE3

#VIRBDSDE3ADS",3.9,"Amazon
3.9","Palo Alto, CA","Seattle, WA",10000+ employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),"Google, Microsoft, Walmart"
Human Resources - Workforce Analytics - Lead Machine Learning Engineer (Vice President),"$141K-$249K
(Glassdoor est.)","Position Overview & Responsibilities:

JPMC is one of the largest employers in the world. Finding the best people and keeping them happy and productive is critical for our success. This is a problem space rich in opportunities to combine our unique and deep pools of structured and unstructured data with state-of-the-art machine learning to support decision making and create innovative new products that change the way we do business. As our first Lead Machine Learning Engineer you will be responsible for designing, building, and deploying data products that integrate ML and NLP with other internal applications and platforms. This individual will report to the Head of Data Science and join a cross-functional team of data scientists, quants, BAs and software engineers that drives some of the most critical projects in HR.

Candidate Profile

The ideal candidate will be skilled, innovative, self-motivated, and inclined to create genuine business value through the alignment of technology, data, and business interests. He or she will have hands-on experience with the development of data products, from data ingestion to deployment. Additionally, excellent communication skills and a collaborative attitude will be crucial to success, as this role will partner closely with aligned Technology teams in addition to the immediate data science team.

Key Responsibilities
Lead the redevelopment of Python-based monolithic ML & NLP products as RESTful microservices
Deploy data science products using standard CI/CD workflows into the firm's cloud and Hadoop platforms
Prototype and build data pipelines. Support configuration and management of ETL and workflow management jobs. Perform ad-hoc ingestion of data from varied sources into HDFS or S3
Collaborate with a team of data scientists and engineers on a variety of innovative machine learning and natural language processing projects
Requirements
Bachelor's Degree in Computer Science or a related field desired
4+ years of experience in software engineering, preferably in a data-driven domain
High proficiency in one or more programming languages - Java, Python, Golang, etc.
Expertise with API or web service development
Experience with one or more - Docker, Kubernetes, Airflow, Kafka, public cloud services
Exposure to modern SDLC processes& tools and ML model management is desired
Excellent verbal and written communication skills and a team-oriented attitude
JPMorgan Chase & Co., one of the oldest financial institutions, offers innovative financial solutions to millions of consumers, small businesses and many of the world's most prominent corporate, institutional and government clients under the J.P. Morgan and Chase brands. Our history spans over 200 years and today we are a leader in investment banking, consumer and small business banking, commercial banking, financial transaction processing and asset management.

We recognize that our people are our strength and the diverse talents they bring to our global workforce are directly linked to our success. We are an equal opportunity employer and place a high value on diversity and inclusion at our company. We do not discriminate on the basis of any protected attribute, including race, religion, color, national origin, gender, sexual orientation, gender identity, gender expression, age, marital or veteran status, pregnancy or disability, or any other basis protected under applicable law. In accordance with applicable law, we make reasonable accommodations for applicants' and employees' religious practices and beliefs, as well as any mental health or physical disability needs.

Equal Opportunity Employer/Disability/Veterans",3.9,"JPMorgan Chase Bank, N.A.
3.9","Jersey City, NJ","New York, NY",10000+ employees,1799,Company - Public,Investment Banking & Asset Management,Finance,$10+ billion (USD),-1
Data Engineer,"$37K-$73K
(Glassdoor est.)","About XSELL

Ready to write the best chapter of your career? XSELL Technologies is an artificial intelligence company focused on increasing sales. Our cloud-based machine learning engine uses predictive analytics and natural language processing to equip sales professionals with the best real-time responses, driving improved conversion rates and customer experiences. We pride ourselves on our high performing, collaborative culture. We are passionate about our product, our clients, and our industry leading results.

XSELL is currently seeking a Data Engineer to serve as a data expert to help structure, manage and optimize our applications data layer. This role will partner with the Engineering team and ensure the data layer powers the model development and reporting for our customers. The XSELL platform using a combination of data science and machine learning to derive the best actions, tactics, and strategies from top customer representatives and make those available to all representatives driven by sales and service outcome data.

The ideal candidate is an experienced data pipeline builder and wrangler who enjoys optimizing data systems. The Data Engineer will support our software developers, data scientists and customer success managers on data initiatives and will be on the ground floor as we scale our data architecture.

Job Description
Mapping heterogeneous data sources, including descriptions of the business meaning of the data, its uses, its quality, the applications that maintain it and the database technology/schema in which it is stored.
Managing a task-queue/message broker architected system for data pipelines and interfacing with the infrastructure team
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, data indexing, re-designing infrastructure for greater scalability, etc.
Document data relationships and translate business rules to data rules.
Build a scalable infrastructure and tiered persistence that will enable our data scientists to derive insights and build models faster and more efficiently
Work with stakeholders including the Executive, Product, Data Science, and Client Success teams to assist with data-related technical issues and support their data infrastructure needs.
Be able to perform manual data quality testing as requested in business requirements.
Deploy these data flows in modern cloud environments: AWS and Azure.
Background & Qualifications

In order to be successful, you will need the following:
2+ years of experience in a Data Engineer/Data Architect role and knowledge of building data pipelines from multiple data sources including third party APIs, flat files or DB queries.
Advanced working knowledge of SQL and Relational Databases.
Python with scientific python libraries (numpy, pandas, scikit-learn, etc)
Be a consummate collaborator, able to establish good relationships with technical, product, and business owners also to work with vendor technical teams
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement. Strong analytic skills related to working with unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large distributed datasets.
Preferred:
Experience supporting and working with cross-functional teams in a dynamic environment.
Experience in developing and maintaining ETL/ELT data pipelines.
Having experience in the following software/tools/languages:
PostGres SQL, Amazon RDS, EC2 and EMR
Python, Git
Flask, Redis, Kubernetes
Sisense Self Hosted instances or other Reporting platforms.
We provide competitive compensation, generous benefits, and a professional atmosphere. XSELL fosters an entrepreneurial, results driven work environment where you will have the opportunity to be part of a collaborative, inclusive team and be able to grow and develop your professional career.

XSELL Technologies is an Equal Employment Opportunity Employer and all employment decisions shall be made without regard to age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status or any other basis as protected by federal, state, or local law.

Powered by JazzHR",3.8,"XSELL Technologies
3.8","Chicago, IL","Chicago, IL",51 to 200 employees,2014,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Sr. Machine Learning Engineer,"$75K-$134K
(Glassdoor est.)","IQVIA is the leading human data science company focused on helping healthcare clients find unparalleled insights and better solutions for patients. Formed through the merger of IMS Health and Quintiles, IQVIA offers a broad range of solutions that harness the power of healthcare data, domain expertise, transformative technology, and advanced analytics to drive healthcare forward.

Title: Machine Learning Engineer

Technology Solutions division of IQVIA develops and markets healthcare-focused enterprise software applications including Master Data Management, CRM, Multi-channel Marketing, Content Management, Social and Compliance solutions. The Digital Office leads the transformation of the Technology Solutions product portfolio and is developing a cloud-based micro-intelligence platform bringing a layer of smart services to Technology Solutions software offering called Ada. Adas algorithms use machine learning, natural language processing and deep learning techniques as appropriate.

Role Purpose:

As an Ada Machine learning engineer, you will develop algorithms that enhance the daily life and professional outcomes of our end-users. You will join a team of other ML engineers / data scientists, big data and software engineers, all responsible for the delivery of Ada from the ground up. You will work with product and business stakeholders to deliver algorithms with very clear business objectives, including requirements gathering, model development, prototyping, and interfacing with the software engineering team. Ideal candidates will bring a well-rounded skillset capable of spanning customer-focus, data science and software development disciplines to shape early stage ideas into fully assessed, designed, and implemented machine learning solutions.

The Ada team is looking for a Machine Learning Engineer.

Do you have a passion for building great products? Do you believe in customer-centricity? Do you have strong analytical, interpretative and problem-solving skills? Do you want to work in a positive, can-do environment where collaboration and growth mindset are valued?
Join us!

Our teams values:
We focus on building software that adds value for our customers
We believe that the best idea or opinion precedes the title of its author
We are respectful of everybodys think time, optimizing meetings and limiting interruptions as much as possible
We value ownership, accountability, openness in collaboration and feedback
We test our code before handing it off: unit tests, ML tests, (continuous) integration tests, etc
We believe in reusing existing solutions over reinventing the wheel, and automating where possible
We seek continuous improvement, individually and as a team
Principle Accountabilities:
Build production-grade algorithms, utilizing machine learning & deep learning models and/or NLP processes to create actionable insights and recommendations for end-users
Work closely with technical stakeholders to optimize and integrate machine learning models and algorithms into the Ada platform, to productize models and algorithms
Interface with software engineering team for the development of the product
Design and develop proof-of-concept solutions as needed
Minimum Education, Experience, & Specialized Knowledge Required:
MS or PhD degree in Computer Science, Artificial Intelligence, Machine Learning, or related technical field or 3+ years relevant experience in data science (Machine learning or NLP solution development)
Creative problem solver with a strong knowledge of statistics/data analytics, text analytics/natural language processing and machine learning methods and strategies
Advanced proficiency with at least one statistical computing language for data analysis, such as Python or Scala
Good scripting and programming skills, including object-oriented programming
Experience with software engineering best practices (programming, testing, version control, agile development, etc)
Experience with source control (GitHub) and working in a Linux/Unix environment
Experience with Spark, Hadoop and MLib is a plus
Experience with SQL (MySQL, Redshift/Postgres)
Experience distilling and presenting complex concepts to a business audience
Excellent communication (written and oral) and interpersonal skills
To be successful as a member of the Digital Office Team, the candidate must also:
Work well in a collaborative, team-based environment (both work autonomously and as part of a team)
Be a self-starter who enjoys collaborating
Is flexible and able to work in a fast-paced, dynamic environment
Is fast and efficient and able to juggle multiple projects
#LI-TJ1

Join Us

Making a positive impact on human health takes insight, curiosity, and intellectual courage. It takes brave minds, pushing the boundaries to transform healthcare. Regardless of your role, you will have the opportunity to play an important part in helping our clients drive healthcare forward and ultimately improve outcomes for patients.

Forge a career with greater purpose, make an impact, and never stop learning.

IQVIA is an EEO Employer - Minorities/Females/Protected Veterans/Disabled

IQVIA, Inc. provides reasonable accommodations for applicants with disabilities. Applicants who require reasonable accommodation to submit an application for employment or otherwise participate in the application process should contact IQVIAs Talent Acquisition team at workday_recruiting@iqvia.com to arrange for such an accommodation.",3.6,"IQVIA
3.6","Plymouth Meeting, PA","Durham, NC",10000+ employees,2017,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,$2 to $5 billion (USD),"PPD, INC Research, PRA Health Sciences"
Senior Machine Learning Engineer - SEAL,-1,"ID: 495319
Type: Researchers
Location: Smyrna, GA
Categories: Algorithm Development, Artificial Intelligence, Electronic Warfare, Embedded Systems, High Performance Computing, ISR & Tactical Systems, Software Development/Design, System Architecture, Testing, Machine Learning, Modeling/Simulation, Radar, Sensors Integration, Sensors/Optics, Signal Processing
Job Description


The Sensors and Electromagnetic Applications Laboratory (SEAL) of the Georgia Tech Research Institute (GTRI) is seeking technical personnel to be part of an established software team that has multiple opportunities for software engineers within the Software Engineering and Architecture Division (SEAD) at Smyrna, GA. The SEAD group mission is to provide world-class software to be used in sensors, signal processing, electronic warfare, tracking, and intelligence surveillance reconnaissance (ISR) systems deployed on land, air and sea.

Our software team employs a modern software engineering process to design, code, integrate and test capabilities on a continuous basis resulting in a mature and quality solution for our customers. We strive for technical excellence by drawing upon a diverse workforce whose knowledge base covers the complete spectrum of modern computing languages and platforms.

Job Duties


The successful candidates will be involved in the artificial intelligence (AI) software design, development, integration and testing of the systems. Our real-time machine learning software applications are developed using C++ and Python in a Linux environment. Our group utilizes productive modern (Agile) and industry-proven software development processes and environments. The candidate will get the opportunity to creatively solve problems, design features, and independently and work in a team environment to implement projects.

The candidate will have the opportunity to leverage machine learning techniques to build processes to gather insights from a high volume of data from multiple sources. You will develop systems to efficiently process the data in our platform. The candidate will ultimately be responsible for developing powerful software systems that reinforce our place as a technical research leader in machine learning and deploying software. The candidate will also lead and mentor junior engineers in the development of our quality, efficient and open software products.

Travel Requirements


10% - 25% travel

Education & Length of Experience


Senior Research Engineer/Scientist
A Master’s degree in Computer Engineering, Computer Science, Electrical Engineering, Mathematics, Physics, or related field of study and seven (7) years of relevant full-time experience after completion of that degree,
A Master’s degree in Computer Engineering, Computer Science, Electrical Engineering, Mathematics, Physics, or related field of study and nine (9) years of relevant full-time experience after completion of a Bachelor’s degree, or
A Doctoral degree in Computer Engineering, Computer Science, Electrical Engineering, Mathematics, Physics, or related field of study and four (4) years of relevant full time experience after completion of a Bachelor's degree.
Required Minimum Qualifications
Candidates currently enrolled in an accredited Master's or Doctoral degree program relevant to this position will be considered. Candidate must have a graduation date of no later than May, 2020
Artificial Intelligence algorithms utilized for applications
Knowledge of industry AI tools (e.g., TensorFlow, PyTorch, etc.)
Experience with C and C++
Experience with Linux or Windows
Experience in software engineering and development
Knowledgeable in version control software such as GIT
Knowledgeable in JIRA, Bitbucket and Confluence
Experience in the technical management of software engineers
Good verbal and written communication skills
Self-starter and ability to work in a team environment
Preferred Qualifications
Knowledge of computer architectures including multi-core environments
Familiarity with software applications requiring multi-threaded programming implementation
Complex programs that involved hardware, software, communications and networking
Experience with Object-Oriented Design Knowledge
Existing secret clearance, or the ability to obtain an interim clearance within 30 days and full clearance thereafter
U.S. Citizenship Requirements


Due to our research contracts with the US federal government, candidates for this position are required to be US Citizens.

Clearance Type Required


Ability to obtain Secret Clearance upon hire

Diversity & Inclusion


Diversity & Inclusion (D&I) at Georgia Tech Research Institute aims to enhance the Institute’s mission of solving the world’s most complex technical problems by creating a workforce with a shared appreciation for diversity, raising awareness around inclusiveness, and fostering a sense of belonging and appreciation for all members of our community.

Equal Employment Opportunity


Georgia Tech Research Institute is an Equal Opportunity Employer of individuals with disabilities and protected veterans and actively seeks diversity among its employees. Equal Employment Opportunity is the Law.

Posted: 02/18/2020
Closes: 08/18/2020",3.6,"Georgia Tech Research Institute
3.6","Smyrna, GA","Atlanta, GA",1001 to 5000 employees,1943,Subsidiary or Business Segment,Research & Development,Business Services,$100 to $500 million (USD),"MIT Lincoln Laboratory, Johns Hopkins University Applied Physics Laboratory"
Software Engineer Senior,-1,"Software Engineer Senior C++ Senior Software Engineer- Remote due to COVID, but will be required to sit in Lincolnshire once restrictions are lifted. Start time would be 9AM Central CTO AI services is a central group innovating new AI centric products, supporting Business Units on program acceleration and building an ecosystem that will allow us to scale its AI components across the business and partners. As C++ Developer C++ Software Engineer at our company you will be responsible for participating in the full development lifecycle of our back-end systems, helping design innovative new products, planning and writing code and creating Unit tests. Our team consists of top Engineers, Scientists and thought leaders internationally - so as a C++ Software Engineer you will have the chance to learn and work in an environment where you will get exposure to cutting edge artificial intelligence techniques. You will also get the opportunity to shape architecture and be influential in applying best practice using Continuous Integration and TDD. You will also be developing scalable products for cloud platforms, such as Google Cloud and on device AIoT. You must be passionate, pro-active, ambitious and open to learn latest technologies and trends. Ensuring good coding practice throughout the team code review, documenting code and choices, share knowledge with other team members and be able to reuse code without reinvent the wheel. Responding to time critical issues, understand how to balance delivering projects on time, find goodbetter solutions when building software with the ability to be technology agnostic and testing out different solutions to find the best fit for every challenge. Required Skills A Computer Science degree or related technical field or equivalent practical experience Strong C++ programming ability - ability to write high quality and maintainable code A good understanding of algorithms, software architecture and design An ability to collaborate within an Agile team and communicate effectively Good problem solving and analysis skills Must be a team player communicative person who works well as individual (doesnt need hand holding) as well as part of a team. Keen to learn - happy to ask questions, eager to push the boundaries - bring their own ideas, delivery focused who also follow requirements. Keen to take ownership, attention to detail and make a difference Ability to respond under a dynamic work environment with quickly changing priorities Solid experience of coding in C++11 or newer, multi-threading, parallel-processing, code-optimisation, and low-level debugging. At least 5 years experience in commercial environment and full development life cycle and testing. Working knowledge of TDD is essential. Excellent Object-oriented design principles and data structures Good experience using GIT or other version control systems. Familiar with Agile development methodology. A plus in a candidate would have the below knowledgequalifications Experience with parallel-processing on GPUs using CUDA. Experience with any machine-learning frameworks (OpenVino, TensorFlow, Caffe, Torch). Experience of development within Google Cloud. Experience of scripting using Bash or Python. Experince of MLFlow Shift Type Day Shift Interested candidates please send resume in Word format to hpewgdhinc.com Please reference job code 70713 when responding to this ad. GDH Consulting, Inc. provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability, genetic information, veteran's status or any other category protected by law. In addition to federal law requirements, GDH Consulting, Inc. complies with applicable state and local laws governing nondiscrimination in employment in every location in which the company has facilities andor employees. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation, benefits and training.",4.3,"GDH
4.3","Lincolnshire, IL","Tulsa, OK",501 to 1000 employees,2001,Company - Private,Staffing & Outsourcing,Business Services,$50 to $100 million (USD),"TEKsystems, Insight Global, Kforce"
Senior Data Scientist,"$120K-$135K
(Glassdoor est.)","Thank you for your interest in joining the Centauri team. Together, we can leverage the next generation of advanced technologies to deliver industry-leading capabilities across land, air, sea, space, and cyberspace. Our goal is to deliver innovative solutions using an agile, mission-first approach to address the most difficult technical challenges facing our customers. The only way that we can tackle these challenges is by recruiting the brightest minds in the industry to join our team.
Description
Centauri is seeking a Data Scientist for long term employment to develop breakthrough products and innovative software applications for government and commercial customers. As a software engineer you work individually or on a small team. Many of our projects have immediate impact on national security leader decision making options. Projects may vary in duration offering you the opportunity to take on new challenges. We need engineers who are versatile, enjoy working in a fast-paced environment, like to consistently tackle new problems, and exceed customers’ expectations.

Responsibilities:
Work with team lead to define software requirements
Design & develop system software for our customers
Explore new areas or program in new languages to deliver a complete product
Support on-site meetings and deliveries to customers
Analyze, troubleshoot, and optimize deployed web app/database systems
Minimum Qualifications:
Minimum of 5 years’ experience with data analysis, database federation, or data quality projects
Minimum of 5 years software development, and object-oriented design and programming, including design, coding, and testing experience
Experience with Postgres, NoSQL, and REST APIs
Experience with Web Services and JavaScript (e.g., ReactJS)
Bachelor’s degree in Computer Science, Engineering, or related discipline
Strong communication and interpersonal skills
Ability to work independently as well as part of a team to achieve customer and company goals
Preferred Qualifications:
Hands-on Experience with PeopleSoft HCM
Hands-on Experience with Java, C/C++, C#, and/or Python
Experience using machine learning for anomaly detection, data clustering, or NLP
MS/PhD in Computer Science, Engineering, or related discipline
Azure, AWS, Security+ certifications
Security Requirements: Must meet eligibility requirements for a security clearance.

Travel: up to 25%
Centauri is an Equal Opportunity / Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, protected veteran status or any other factor protected by law.

Are you a returning applicant?
Previous Applicants:


Email:


Password:
If you do not remember your password click here.
Back to Search Results

New Search",4.6,"Centauri
4.6","Carlsbad, CA","Chantilly, VA",501 to 1000 employees,1999,Company - Private,Aerospace & Defense,Aerospace & Defense,$100 to $500 million (USD),"TASC, Vencore, Booz Allen Hamilton"
Software Engineer (Python/Spark),-1,"TVision is the leader in TV engagement metrics. We measure what was previously unmeasurable - how people actually watch TV. We enable the media industry - advertisers, networks, and technology partners alike - to reduce waste and drive greater and more efficient marketing results.

Utilizing cutting edge technology, TVision goes beyond traditional TV data to include measurement of presence in room, co-viewing and attention, producing best-in-class TV data. This allows us to provide critical data to inform the decision making of a $100B/year industry.

Our growth and innovation have been recognized by The New York Times, Advertising Age, AdWeek, Business Insider, MediaPost, and Forbes. We were selected as a Best Place to Work 2019 by Built in Boston, and were named one of the top companies to watch in advertising technology by Business Insider in December 2019.

The Role

Measurement and data analysis lie at the foundation of TVision's data products. As an engineer working on TVision's data pipeline, you might find yourself working on
the framework for training and tracking changes to our computer vision models;
the data collection software that runs on our measurement devices;
the error correction and statistical analyses in our back end that help us extract meaning from the raw measurements;
or the compute and data storage infrastructure that makes all of this possible.
Because we believe strongly in working together with domain experts to build our software, our data analysis pipeline is built in the common language of data science, which is Python. Together with state of the art machine learning frameworks such as Tensorflow and OpenVINO, our primary tool for organizing computation is Apache Spark. The successful candidate for this position will be an experienced and confident developer with both Python and Spark.

But this role is not just about data science and data analysis; we expect you to be a generalist software engineer first. This is a centrally located, interdisciplinary role. You will be working closely with colleagues from all parts of our engineering and data science organizations, from customer-facing data analysts to systems and devops engineers.

In addition, because we also believe in the value of statically proven correctness, the back end services that manage our device and data ecosystem are built in Haskell. If you have experience or are interested in statically typed functional programming, so much the better.

The Candidate

You are a software engineer first, with experience working in an agile development environment following sound engineering practices. You are thoroughly familiar with Python and Spark, and some related technologies (machine learning frameworks, relational databases, other big data ecosystem tools). If you are primarily a data scientist, and your expertise with these tools is purely using them rather than developing with and integrating with them, this is not the role for you.

The specific requirements are as follows:
3 - 7 years of industry experience
BS/MS in Computer Science or closely related discipline (math, computer engineering).
Substantial experience with Python and Spark, including enough confidence in Scala to understand what's going on in Spark under the hood.
Experience with at least one relational database (we use Postgres). If you are also familiar with columnar databases (Redshift, Vertica, etc) even better.
Engineering experience with at least one deep learning framework (Tensorflow, PyTorch, etc) is desirable. You don't need to know how to build and train models, though it certainly doesn't hurt.
Knowledge of Haskell is a plus, but not a requirement.
Strong communications skills with both technical and non-technical team members.
Collaborative and enthusiastic approach to software development.
Strong sense of project ownership and personal responsibility.
Benefits
Competitive pay and stock options
Your choice of comprehensive health benefits for you and your family (health, dental, vision)
Short and long-term disability, Life and AD&D insurance
FSA/HSA accounts
401(k) retirement plan options
Pre-tax commuter benefits
Monthly phone reimbursement
Unlimited PTO and paid holidays
Gym membership discounts
Financial support for ongoing professional development
Casual dress and fun atmosphere",4.4,"TVision Insights
4.4","Boston, MA","New York, NY",1 to 50 employees,2014,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Senior Machine Learning,-1,"Job Description
Title: Senior Machine Learning

Location: Remote in continental U.S. or Richmond, VA; must be available 8am-5pm EST

Type: Contract ( 6 months +) Potential Contract to Hire

Key Skills: Python, C#, APIs, Azure and Databricks (In between Data Scientist and Data Engineer)

Essential Responsibilities:

Work collaboratively and creatively with other developers to productionize and operationalize models using the latest Microsoft Azure technologies and leading industry practices
Develop scalable model-as-a-service patterns and enterprise capabilities
Build scalable online/offline feature stores and streaming capabilities
Partner with Data Scientists, Product Managers, and Data Engineers to deliver creative, cutting-edge, high-quality engineering solutions, enhancing the iconic CarMax experience for our customers

Qualifications:

5+ years software development experience using Python and C# including strong understanding of software engineering principles
2 years experience developing REST APIs and deploying microservices in Azure
2 years experience with Databricks
1-year experience deploying and managing containerized applications, preferably using Azure Kubernetes Services
1-year experience developing streaming capabilities
1-year experience with Azure Machine Learning Services and MLflow
Exposure to machine-learning libraries and tools, such as PyTorch, Tensorflow, or scikit-learn.
2 years experience working on Agile teams implementing DevOps/DataOps/MLOps practices
Excellent communication skills, adapting to various audience types
Passionate about innovation and loves solving complex problems in a highly- collaborative, fast-paced team environment

MINIMUM QUALIFICATIONS

Bachelor's Degree or master's degree in the field of Computer Science or Information Systems or a related field.",5.0,"IKCON Technologies Inc
5.0","Richmond, VA","South Plainfield, NJ",1 to 50 employees,-1,Company - Public,-1,-1,Unknown / Non-Applicable,-1
Sr. Data Science Innovation Engineer,-1,"Overview:
This is not your ordinary engineering job! Do you want a startup environment with the stability of large established company? Do you want to work with some of the world’s best data analytics leaders? Does your entrepreneurial mindset drive you to constantly level-up your technical skills? Then we want you!

Alteryx Venture Engineers work with the world’s leading companies every day to develop cutting edge data and analytic solutions to solve real world business problems. From financial services to communications, retail, to healthcare, you’ll work with business partners and data scientists that are on the leading edge of the analytic revolution to create innovative new vertical solutions leveraging Alteryx’s amazing platform of products.
***The company will not provide sponsorship for work visas or other employment authorization for this position***

Responsibilities:
Leverage the existing Alteryx Platform to create new businesses
Quickly code minimum viable products (MVPs) to fully harness and push the limits of existing frameworks
Implement data pipelines, machine learning, visualizations and deliver insights to businesses in an automated manner
Research, evaluate, and commercialize new technologies

Required qualifications:
Bachelor’s degree in Engineering, Computer Science or Data Science related field or equivalent experience
Programming fluency in a minimum of two languages as well as experience with at least one database technology (e.g. SQL, Server, Teradata, Hadoop, etc.)
3-5 years’ experience with HTML5, React / Redux, TypeScript, JavaScript
Experience with Python
Experience with C#/Java
Working knowledge of all Microsoft Windows operating systems and server platforms
Willingness to travel up to 25%
Top-notch interpersonal skills, with excellent written communication to match
Excellent troubleshooting skills (databases, environments, network communications, applications)
Ability to communicate technical concepts to non-technical users
Ability to work in a fast-paced environment, under pressure and prioritize multiple tasks
Proficient English written and verbal communication skills

Brownie Points For:
Experience with cloud based microservice solution architecture
Experience with data replication technology and managing curated data products
Experience with collaborative coding (paired programming, peer reviews, source control)
Experience with building customer facing front ends
Experience using SQL or similar technology, understanding of ODBC, Oracle’s OCI, APIs and connection strings
Experience troubleshooting database connections (SQL Server, Oracle, Teradata, PostgreSQL, and/or Hadoop)
Experience working with Linux environments
Experience maintaining and/or administrating computer hardware and software, file servers, firewalls and/or Active Directory
Demonstrated ability to use in-depth troubleshooting to resolve or workaround customer issues using troubleshooting tools i.e. Wireshark, Fiddler
Computer, Network, and Software certifications
Experience in Data Analysis
Experience with Alteryx Designer / Server Platform
Experience with Visualization Tools and Techniques
#LI-JE1",5.0,"ClearStory Data
5.0","Ann Arbor, MI","Menlo Park, CA",51 to 200 employees,2011,Company - Private,Enterprise Software & Network Solutions,Information Technology,$1 to $5 million (USD),-1
Mid-Level Engineer (Electrical/Software/Computer),-1,"The Position


EngeniusMicro is looking for an Engineer to join our multi-disciplinary staff of engineers and scientists. We seek a candidate able to work in a fast-paced, small team environment through all phases of the product life cycle from conceptual development and detailed design through manufacturing, testing, delivery, and support.

Primary work duties include the development, troubleshooting, maintenance and improvement of control and application software used in 3D printer operation and automation including the interface, integration and testing of software with various hardware systems.

Basic Qualifications


This position requires a bachelor's degree from an ABET School in Software, Electrical, Robotic, Mechatronics, or Computer Engineering with aminimum of 3+ yearsof experience in the development and implementation of control and electro-mechanical systems software including demonstrated project experience.

Experience both embedded system programming and UI development is required.

*This position requires the ability to obtain a US Security Clearance for which the US Government requires US Citizenship

Required Skills / Experience


Strong knowledge and demonstrated experience is required in:
UI programming (Python, Javascript, React, Vue, HTML, CSS, QT)
Experience with Git
Control system programming (C, C++, Java, Spin)
Firmware for various MCU families
Computer vision (OpenCV)
Embedded microcontroller-based hardware design
Interfacing to sensors and mixed-signal components
Strong written and verbal communication skills
Test equipment and debug/test methods
Preferred Skills / Experience


Familiarity or experience is preferred in:
Experience with 3D Printing or automated systems
Electronics packaging design
Data processing and machine learning principles
Computational geometry and path planning algorithms
Circuit design and schematic capture
PCB layout
Why should you apply?
You like solving problems and developing new technology in a fast-paced team driven environment
You're interested in building hardware and prototypes
You enjoy strong technical challenges in a collaborative environment
Job Posted by ApplicantPro",5.0,"EngeniusMicro, LLC.
5.0","Huntsville, AL","Huntsville, AL",1 to 50 employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Senior Software Engineer - iOS (Remote),"$104K-$198K
(Glassdoor est.)","ABOUT HOPPER

At Hopper, we’re on a mission to make booking travel faster, easier, and more transparent. We are leveraging the power that comes from combining massive amounts of data and machine learning to build the world’s fastest-growing travel app -- one that enables our customers to save money and travel more. With over $235M CAD in funding from leading investors in both Canada and the US, Hopper is primed to continue its path toward becoming the go-to way to book travel as the world continues its shift to mobile.

Recognized as the fastest-growing travel app by Forbes and one of the world’s most innovative companies by Fast Company two years in a row, Hopper has been downloaded over 40 million times and has helped travelers plan over 100 million trips and counting. The app has received high praise in the form of mobile accolades such as the Webby Award for Best Travel App of 2019, the Google Play Award for Standout Startup of 2016 and Apple’s App Store Best of 2015.

Take off with us!

THE ROLE
As a Senior Mobile Software Engineer, you will contribute to building a product that impacts millions of users. You will help drive the product direction, making sure we solve the right user problems and find new and innovative ways to delight our customers. You will collaborate with a team of talented engineers, product managers, and data scientists to break down complex problems, and experiment with new ideas very quickly. You will also help design and evolve the mobile architecture to enable teams to run experiments and iterate very quickly.
IN THIS ROLE, YOU WILL:
Collaborate with a team of talented engineers to develop innovative solutions to challenging, impactful technical problems
Quickly prototype new ideas and run experiments to identify features that users love
Create delightful user experiences in our app (iOS)
Help evolve our mobile architecture to consistently improve development efficiency
Influence the technical direction for the team
Influence the strategic direction of the product
A PERFECT CANDIDATE HAS:
4+ years professional experience in full-stack or mobile development
Thorough understanding of Swift and the iOS mobile API
A proven ability to build prototypes and take a data-driven approach to product development, testing and measuring new ideas very quickly
Passion for technical leadership and mentoring
BENEFITS

• Well-funded and proven startup with large ambitions, competitive salary and stock options
• Dynamic and entrepreneurial team where pushing limits is everyday business
• 100% employer paid medical, dental, vision, disability and life insurance plans
• Access to a 401k (US) or Retirement Savings Plan (Canada)",3.5,"Hopper
3.5","Boston, MA","Montreal, Canada",501 to 1000 employees,2007,Company - Private,Travel Agencies,Travel & Tourism,Unknown / Non-Applicable,-1
Senior Software Engineer,"$99K-$124K
(Glassdoor est.)","About Us

Ready to write the best chapter of your career? XSELL Technologies is an artificial intelligence company focused on increasing sales. Our cloud-based machine learning engine uses predictive analytics and natural language processing to equip sales professionals with the best real-time responses, driving improved conversion rates and customer experiences. We pride ourselves on our high performing, collaborative culture. We are passionate about our product, our clients, and our industry leading results.

XSELL is currently seeking a Sr. Software Engineer to serve as a key member of our development team.. This role will work within the SAFe Agile framework of continuous delivery, provide leadership and guidance to junior developers, and be a critical resource for our growing development staff.

Job Description
Design and implement full stack applications/services/tools/script for pipelines running in AWS and other cloud services
Work closely with technical product managers and data scientists to design, implement, test highly scalable automated solutions.
Participate in design reviews, code reviews of your work and the work of your peer engineers.
Participate in architecture and design efforts with the team members and/or across multiple teams.
Automate deployment processes and provide adequate test coverage by utilizing test framework
Mentor junior engineers to develop quality code and review the design/code
Respond to internal customers issue requests
Background & Qualifications

In order to be successful, you will need the following:
Bachelor’s Degree
5+ years of software development experience
2+ years of development experience with Ruby on Rails
IT Project and Management principles and techniques (SAFe Agile)
Backend: Ruby on Rails, Sidekiq, Python and Flask
Frontend: VueJS, jQuery
Database: PostgreSQL, Redis
Infrastructure: AWS, Linux
Deployment: Capistrano, Ansible
Capable of working in a fast-paced environment
Ability to lead the development of a product or large project
Ability to create project specs and identify roadblocks before writing code
Set coding standards and creates standard processes
Focused on writing clean, readable, and testable code
We provide competitive compensation, generous benefits, and a professional atmosphere. XSELL fosters an entrepreneurial, results driven work environment where you will have the opportunity to be part of a collaborative, inclusive team and be able to grow and develop your professional career.

XSELL Technologies is an Equal Employment Opportunity Employer and all employment decisions shall be made without regard to age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status or any other basis as protected by federal, state, or local law.",3.8,"XSELL Technologies
3.8","Chicago, IL","Chicago, IL",51 to 200 employees,2014,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Automated Test Engineer (QA),"$48K-$84K
(Glassdoor est.)","About the Role
We are seeking a talented and creative Quality Assurance (QA) Engineer to join our Baton Rouge team to design, innovate, and support one of FiscalNote’s range of applications and technology stacks.

In this role you will collaborate closely with a dedicated, cross-functional team - engineers, interaction and product designers, product managers, and scrum masters - working on FiscalNote’s advocacy applications. Utilizing Agile methodologies and incorporating data and user research, you and your team will design, build, and deliver high quality products, features, and services to serve your end-users. Regardless of level, you will be called upon to present your work, communicate with technical and non-technical teammates and executives, and guide and mentor members of your team.

About FiscalNote Engineering
Our team has a wealth of diverse life and career experiences that allow us to think outside of the box and ahead of the curve. You'll get the opportunity to work at an institution pushing the boundaries of open data transparency while collaborating with some of the industry’s brightest engineers and data scientists to devise, nurture, and implement cutting-edge solutions to continuously evolving engineering challenges.

About You:
A successful Automated Test Engineer is:
-Curious
-Ego-less
-Leadership Mindset
-Tenacious
-Adaptable
-Transparent

Success In This Role Includes:
- Creating and executing test plans/cases in multiple environments and cross-browser
- Testing web applications in a series of web browsers and environments
- Designing and creating test conditions and scripts to address business and technical use cases
- Working with scrum team(s) to design, develop, and execute scripts which validate test cases defined within the project’s test plan
- Collaborating with our product, engineering, and client support teams
- Participating in troubleshooting and triaging of issues with different teams to drive towards resolution
- Ensuring the appropriate testing and monitoring tools/technologies are configured accordingly with the test objectives/project team requirements
- Ensuring the test execution results fulfill the defined test objectives
- Tracking and communicating task progress, status, and key performance metrics

What Sets You Apart:
-A working knowledge of manual and automated testing techniques and strategies
-Strong hands-on experience with test automation tools (ex. Selenium, Appium, Postman, etc.)
-Experience with Agile methodologies and practices
-An ability to communicate to technical and non-technical audiences
-Empathy for your peers, stakeholders, and our customers
About Us
FiscalNote is a technology-powered global software data and media company that uses powerful machine learning to provide clients with the right policy information and insights, and at the right time so that they can better navigate market risk and uncertainty and maximize new opportunities.

As the premier hub of domestic and global information for more than 5,000 clients worldwide, FiscalNote’s tools, analysis, news, and award-winning journalism delivers context, clarity, and a competitive edge in a rapidly changing world.

If your background and experience align with the competencies above, we encourage you to apply so that we can review your experience and learn more about how you can add to FiscalNote’s growth and success.

Company Benefits
FiscalNote offers competitive salaries, equity packages, and retirement accounts to ensure we’re all FN owners. We work hard, so our open vacation policy helps us ensure you’re getting the R&R you need. We offer comprehensive health, vision, and dental insurance options supplemented by a flexible spending account (FSA). We have a slew of other benefits which you can check out at careers.FiscalNote.com.

FiscalNote values diversity. We are committed to equal opportunities and creating an inclusive environment for all our employees. We welcome applicants regardless of ethnic origin, national origin, gender, race, religious beliefs, disability, sexual orientation or age. FiscalNote is an EEOC employer.

FiscalNote uses E-Verify to confirm the employment eligibility of all new employees. To learn more about E-Verify, including your rights and responsibilities, please visit www.DHS.gov/E-Verify.",3.9,"FiscalNote
3.9","Baton Rouge, LA","Washington, DC",201 to 500 employees,2013,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Sr. Software Engineer - Machine Learning,-1,"About Raise
Raise is the leading mobile payments and prepaid gift card platform where millions of consumers earn instant cash back and save money on purchases. The company has transformed traditionally simple pieces of plastic into one powerful payment mechanism that can be seamlessly used at 300,000+ retail locations nationwide.

As a marketplace with 4,000+ brands and 450+ retail partners, Raise enables consumers to save money and instantly pay for in-store or online purchases at their favorite stores using their digital mobile wallet. In addition to offering value and convenience for consumers, Raise allows retailers to unlock a new, data-driven channel to activate targeted segments of the platform's more than 2.5 million members.

Since 2013, Raise has saved members more than $150 million. The company is based in Chicago and has received $147 million in funding from investors including Accel, Bessemer Venture Partners, New Enterprise Associates, and PayPal. Raise is available on both iOS and Android and at www.raise.com.

About the Position
Raise has a number of exciting new initiatives in the pipeline this year, and we need a talented and experienced Sr. Software Engineer, focused in Machine Learning, to join the team driving one of those initiatives – rZero. rZero was born out of the realization that, in order to combat some of the most sophisticated and complex attacks in e-commerce, a platform was needed; one designed to evaluate the intentions of users based on digital behavior.

The rZero team draws on decades of experience from its team of market-leading data scientists, engineers, and executives with extensive backgrounds from industry pioneers such as eBay, LexisNexis Risk Solutions, American Express, and PayPal. The r0 fraud detection platform strikes the fine balance between security and customer friction and provides digital behavioral risk evaluation with pinpoint accuracy while giving partners peace of mind to make decisions instantly and confidently.

Our Sr. Software Engineer - Machine Learning is expected to design and code solutions which translate the needs of machine learning/data science teams into production. These solutions should be performant, scalable, well-tested, and written cleanly. The Sr. Software Engineer is responsible for understanding how to translate the needs of an offline learning system into production without affecting performance in a major way, both from the production system perspective as well as the algorithm perspective. The ideal candidate will possess a broad technical background including both production software engineering experience as well as machine learning experience.

Responsibilities
Design, develop, test, deploy, maintain, and improve new products and services
Work with machine learning team to negotiate solution approaches which will work out better in production
Thoroughly test and validate both your solutions and the overall system solutions to ensure minimal issues in production, including tests applying to machine learning system bounds
Document and communicate your technical approaches and solutions in a clear and concise manner
Provide ongoing maintenance, support, and enhancements in existing systems and platforms
Assist product/technical leaders in project planning and driving technical direction
Keep abreast of new trends and best practices in the technology landscape and be Raise's thought leader in innovation and creativity
Skills & Qualifications
5+ years of experience in software development and machine learning including code/model design, coding/scripting, testing
Experienced in Java/Spark
Experience with machine learning feature generation/training/model validation
Capable of distilling needs from customers/teams to create generalized solutions with little supervision
Passionate about both machine learning and production engineering
Based in Pacific Time Zone preferred
Benefits

Raise offers a comprehensive benefits package to all our employees, including:
Medical, dental, and vision insurance
401(K) plan with discretionary company match
Company-paid short-and-long-term disability
Company-paid life insurance
Pre-tax health flex spending and dependent care plan
Flexible Paid Time Off Policy, including sick time, unlimited vacation, and Raise Gives Back time off for volunteering
Pre-tax commuter program
Paid parental leave
Voluntary benefits, such as Pet Insurance and Identity Protection",2.4,"Raise Marketplace, LLC
2.4",Remote,"Chicago, IL",51 to 200 employees,2013,Company - Private,Other Retail Stores,Retail,$1 to $5 million (USD),-1
Senior Machine Learning Engineer,-1,"Analytics
Senior Machine Learning Engineer - QuantumBlack

Boston

Apply Now

Qualifications

MSc or degree in Computer Science or a relevant subject
Strong coding skills in Python, experience with pandas, scikit-learn, matplotlib a huge plus
Practical experience with machine learning methods, such as Linear Regression, Decision Trees, Random Forest, Deep Learning, etc.
Experience in object-orientated programming such as C, C++, Java OR Scala
Deep understanding of good software engineering principles
Knowledge of technologies, such as Spark, Hadoop/MapReduce is desirable but not essential
Good knowledge of testing frameworks and libraries
Experience with a range of database management languages e.g. SQL, PostgreSQL

Who You'll Work With


You'll join us in Boston and will have the opportunity to work on complex problems with our clients across a number of domains. You will work part of a highly collaborative and cross-functional team of Data Scientists, Data Architects, Engineers and Designers.

Who you are

A core value at QuantumBlack is fusion and at the heart of our multi-disciplinary teams is the belief that the sum of individual parts will always be less than the impact of the entire team. You are a highly collaborative individual who is capable of laying aside your own agenda, listening to and learning from colleagues, challenging thoughtfully and prioritising impact. You search for ways to improve things and work collaboratively with colleagues. You believe in iterative change, experimenting with new approaches, learning and improving to move forward quickly. Trust between colleagues is paramount here – you are an individual who can always be trusted to work in the best interests of all colleagues and to achieve the best outcome for QuantumBlack and our clients. You are naturally enthusiastic and enjoy sharing your passion with others.

What You'll Do


As a Senior Machine Learning Engineer at QuantumBlack in Boston...

You are a keen problem solver who uses technology to solve complex analytical problems. You have a deep interest in Big Data technologies, Analytics and Data Science. You know how to engineer beautiful code in Python and/or Scala (and Spark) but also can read R and take pride in what you produce.

Responsibilities
Work closely with Data Scientists and Data Engineers to productionise and deploy machine learning models
Work with the guild leadership to set the standards for software engineering practices within the machine learning engineering team and support across other disciplines
Play an active role in leading team meetings and workshops with clients
Choose and use the right analytical libraries, programming languages, and frameworks for each task
Produce high-quality code that allows us to put solutions into production
Refactor code into reusable libraries, APIs, and tools
Help us to shape the next generation of our products
Rotate between client project work and internal product development in alignment with your personal development plan
Who we are

QuantumBlack teams work in multi-disciplinary environments harnessing data to provide real-world impact. We bring together the brightest data scientists, engineers and designers to take on the biggest problems facing the world’s most influential organisations. Our projects range from helping pharmaceutical companies bring lifesaving drugs to market quicker to optimising a Formula1 car’s performance. At QuantumBlack you have the best of both worlds; all the benefits of being part of one of the leading management consultancies globally and the autonomy to thrive in a fast growth tech culture.
No project is ever the same - we work across multiple sectors, providing unique learning and development opportunities internationally.
Fusing Tech & Leadership – We work with the latest technologies and methodologies and offer first class learning programmes at all levels
Multidisciplinary Teamwork - Our teams include data scientists, engineers, project managers, UX and visual designers who work collaboratively to enhance performance.
Innovative Work Culture - Creativity, insight and passion come from being balanced. We cultivate a modern work environment through an emphasis on wellness, insightful talks and training sessions.
Striving for Diversity – With colleagues from over 40 nationalities, we recognise the benefits of working with people from all walks of life.
What we do

We guide global companies through data science solutions to transform their businesses and enhance performance across industries including healthcare, automotive, energy and elite sport.
Healthcare Efficiency - We helped a healthcare provider improve their clinical trial practices by identifying congestion in diagnostic testing as a key indicator of admissions breaches.
Environmental Impact – We designed and built the first data-driven application for a state of the art centre of excellence in urban innovation by collecting real-time data from environmental sensors across London and deploying proprietary analytics to find unexpected patterns in air pollution.
Product Development - We worked with the CEO of an elite automotive organisation to reduce the 18-month car development timeframe by improving processes, designs and team structures.
Visit our Careers site to watch our video and read about our interview processes and benefits.

Industries
High Tech

Functions
Technology

Apply Now
FOR U.S. APPLICANTS: McKinsey & Company is an Equal Opportunity/Affirmative Action employer.
All qualified applicants will receive consideration for employment without regard to sex, gender
identity, sexual orientation, race, color, religion, national origin, disability, protected Veteran
status, age, or any other characteristic protected by applicable law.

FOR NON-U.S. APPLICANTS: McKinsey & Company is an Equal Opportunity employer. For additional details
regarding our global EEO policy and diversity initiatives, please visit our
McKinsey Careers and
Diversity & Inclusion sites.",3.8,"QuantumBlack
3.8","Boston, MA","London, United Kingdom",501 to 1000 employees,2009,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,"Palantir Technologies, Google, Microsoft"
Senior Machine Learning Engineer,"$147K-$169K
(Glassdoor est.)","The machine learning engineering team is developing the brain of the BounceX communication and personalization platform. As a Senior Machine Learning Engineer, you will be working with a team of Data Engineers and Data Scientists in order to build out our next-generation platform. You will be utilizing cutting edge technologies such as Spark MLLib, Tensorflow, Google AI Platform, and Cloud Dataproc to build the required ML pipelines to enhance our customer's experience.

Responsibilities:
Build & maintain production ready ML pipelines
Build & maintain a production-ready experimentation platform to run models in parallel and A/B test
Prepare and preprocess data in collaboration with the data engineering team
Qualifications:
Deep understanding of ML problems such as classification, clustering, anomaly detection, association rules, deep learning, and recommendation
Deep understanding of test analysis
Previous work with Spark MLlib
Previous work with TensorFlow
B.S. or M.S in Computer Science
Nice to have:
Experience with Google Cloud BigQuery
Experience with Google Cloud BigTable
BounceX is proud to be an equal opportunity workplace. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status.

JOIN US ON OUR MISSION
BounceX is an international marketing technology solution that brings a ""logged-in"" experience to logged-out website visitors across all their devices. A category leader in device identity resolution, BounceX helps companies like Uniqlo, HelloFresh and Tribune Interactive orchestrate real-time, multichannel marketing programs customized for the individual behind each device. They're best known for their impact on triggered email performance and website personalization.

Having raised over $44.9 million in funding from proven firms like Battery Ventures, Cross Creek Advisors and Primary Ventures, BounceX was named the Fastest Growing Software Company in America by Inc Magazine. With headquarters in New York and London, BounceX has been recognized by Glassdoor and Crain's for its exceptional culture and being one of the top places to work in the country. The company recently signed both the White House Equal Pay Pledge and the United Nations Women's Empowerment Pledge and continues to set the bar as a pioneer in technology innovation and workplace inclusion initiatives.

What bonds our community together is our commitment to 5 Core Values:
Come Hungry
Carry Each Other
Drive Undeniable Performance
Respect People, Privacy, Ideas
Bounce Back
Come join us on our mission.",4.1,"Bounce Exchange
4.1","New York, NY","New York, NY",201 to 500 employees,2012,Company - Private,Advertising & Marketing,Business Services,Unknown / Non-Applicable,-1
Enterprise Data Engineer,"$99K-$121K
(Glassdoor est.)","Job title: Enterprise Data Engineer
Job type: Permanent
Emp type: Full-time
Salary:
Negotiable
Location: New York, NY
Job published: 2019-12-16
Job ID: 41913

Job Description


Our client is searching for an experienced Enterprise Data Engineer to join their team in Chicago. Enterprise Data Engineers build pipelines that support datasets used by all investment teams and strategies across the firm. They manage the firm’s most critical data sets and focus on applying software development best practices to solve complex data challenges. The expectation is that the data engineer has sound programming skills, strong business acumen, and a strong interest in finance.

Responsibilities:
Develop solutions that enable internal analysts to efficiently extract insights from data. This includes owning the ingestion (web scrapes, S3/FTP sync, bespoke processes), transformations (Python, Perl) and interface (API, schema design, events, etc.)
Build tooling and automation around data pipelines that improve the efficiency, quality and resiliency of the data platform
Partner with internal analysts, quants and data scientists to design, develop, test and deploy solutions that answer fundamental questions about financial markets.
Take on an entrepreneurial mentality by building and selling your own ideas. The company works in an evolving space and they expect you to help design their evolution by challenging the status quo and independently identifying opportunities to improve the entire data organization.


Requirements:
A passion for working with data and developing software to address data processing challenges
Proficiency with Python, C++, Java or equivalent
Proficiency with RDBMS, NoSQL, distributed compute platforms such as Spark, Dask or Hadoop
Prior experience building data pipelines from structured or unstructured data preferably including web crawlers
Prior work developing BI tooling and/or application development for data analytics
Advanced technical communication skills
Working knowledge of statistics, predictive analytics or machine learning techniques
Strong business acumen with prior experience in investment research or direct exposure to product or data science teams AND passionate about using data for investment decisions
If you would like to be considered for the position of Enterprise Data Engineer or wish to discuss the role further then please leave your details below. Your resume will be held in confidence until you connect with a member of our team

Email: info@njf.com or call London (0207 604 4444,) New York (212 400 4845) or Chicago (312 204 72176) to speak to a member of our team. Thank you",4.2,"NJF Global Holdings
4.2","New York, NY","London, United Kingdom",51 to 200 employees,2003,Company - Private,Staffing & Outsourcing,Business Services,$10 to $25 million (USD),-1
Senior Machine Learning Engineer,-1,"About ConcertAI

ConcertAI is the leading provider of precision oncology solutions for biopharma and healthcare, leveraging the largest collection of research-grade Real-world Data and the only broadly deployed oncology-specific AI solutions. Our mission is to improve translational sciences; accelerate therapeutic clinical development; and provide new capabilities for post-approval studies to accelerate needed new medical innovations to patients and to improve patient outcomes.
ConcertAI has emerged as one of the highest growth technology companies in Real-world Data and AI, backed by industry leading private equity companies: SymphonyAI, Declaration Partners, Maverick Ventures, and Alliance|Bernstein.

ConcertAI is looking for a talented Senior Machine Learning Engineer to build advanced AI and Machine solutions as part of our eurekaHealth solution team engaging in projects and programs of high priority. You should have a good mix of programming/CS skills and data science experience. You will be responsible for designing, implementing and maintaining software that powers the company’s data operations, production analytics (AI/ML/DS) and products. You will collaborate with data scientists on prototypes and work on productization, focusing on scalability and robustness (tests, documentation, etc).This role reports to the Vice President of Data Science.
Responsibilities
Lead, design, develop, and implement AI production software to address client’s needs.
Collaborate on software projects with data scientists, and provide technical guidance.
Develop ML/AI algorithms using high level libraries and high performing implementation.
Stay current on the most recent AI/ML algorithms, design principles, and programming paradigms.
Write documentation and test suites, and help maintain several codebases.
Requirements
PhD in computer science, math, physics, or engineering and 3+ years of relevant work experience.
Experience with Python or another high level programming language (e.g. Java, C++).
Production software development experience.
Expertience with advanced data science and machine learning concepts and libraries.
Experience with data munging with Spark/Scala/Sq.
Experiece with cloud technologies (AWS, Docker, Git).
Experience with healthcare data (Electronic Health Records, claims data) is preferred.
Strong communication, project management and technical leadership skills with an enthusiasm for working in an interdisciplinary environment.
Learn More About ConcertAI

ConcertAI is transforming how healthcare is delivered and dedicated to improving patient outcomes in oncology by offering innovative solutions on how data and intelligence is used to solve healthcare problems. We are creating something special in our culture, by building a collaborative, engaged, patient focused, team approach to our mission. Our high-performance teams are looking to add great talent to the mix and we are hiring for the right mix of new skills and diverse mindset. Learn more about ConcertAI at www.concertai.com or on LinkedIn .",3.4,"Concerto HealthAI
3.4","Boston, MA","Boston, MA",501 to 1000 employees,2018,Company - Private,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,Unknown / Non-Applicable,-1
"Senior Software Engineer, Reasoning",-1,"OpenAI’s mission is to discover and enact the path to safe, beneficial AGI. On this path, the Reasoning team aims to develop machine learning systems that achieve high performance on tasks that require reasoning for humans, such as answering questions about the world, understanding logic puzzles and games, solving math problems, and proving theorems. To do this, we believe that we will need to develop systems for acquiring data of unprecedented scale and quality.

We are looking for an experienced full-stack software engineer to develop systems that enable us to procure and process data for a wide variety of research projects. This includes maintaining and scaling a web application for collecting data from human annotators, harvesting datasets from the web, and building new tools that use machine learning to clean and prepare data. This is a core role integrated within a team of research scientists and engineers working on pushing the limits of reasoning capabilities.
You will:
Work at all levels of the web application stack, using HTML and CSS, VueJS or React, NodeJS, Python (Django), as well as Heroku, AWS, or another cloud platform
Own the process of finding large-scale datasets and acquiring them via crawling and scraping
Develop and implement new deep learning-based methods for getting feedback from humans and for cleaning and curating datasets, in order to make them accessible for research within OpenAI
Partner with researchers across OpenAI to understand their research and data needs
Design reusable, scalable data infrastructure that can be applied across multiple teams
You’ll be a good fit for this role if you are:
Excited to work closely with a fast-paced results-oriented research team with dynamic requirements
An expert in Javascript, Python, and Linux, and comfortable with large Python and Javascript codebases
Experienced in maintaining and scaling performant web applications
Experienced in developing web crawlers and scrapers, and processing web-sourced data
Comfortable with the fundamentals of machine learning and excited to develop expertise in deep learning
Excited to use machine learning to develop tools for filtering, balancing, and deduplicating data
Engaged with OpenAI’s mission of building safe and beneficial artificial general intelligence
About OpenAI
We’re building safe Artificial General Intelligence (AGI), and ensuring it leads to a good outcome for humans. We believe that unreasonably great results are best delivered by a highly creative group working in concert. We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

This position is subject to a background check for any convictions directly related to its duties and responsibilities. Only job-related convictions will be considered and will not automatically disqualify the candidate. Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.

Benefits
Health, dental, and vision insurance for you and your family
Unlimited time off (we encourage 4+ weeks per year)
Parental leave
Flexible work hours
Lunch and dinner each day
401(k) plan",5.0,"OpenAI
5.0","San Francisco, CA",-1,51 to 200 employees,-1,Nonprofit Organization,-1,-1,Unknown / Non-Applicable,-1
Sr. Software Engineer - AI/Machine Learning,"$133K-$160K
(Glassdoor est.)","C3.ai is a leading enterprise AI software provider for accelerating digital transformation. The comprehensive and proven C3 AI Suite uses a model-driven abstraction layer to enable organizations to develop, deploy, and operate enterprise scale AI applications 40x to 100x faster than alternative approaches. www.c3.ai

We are looking for a seasoned software engineer to build the next generation AI platform scaling to petabyte level data volumes.

As a member of C3.ai's platform engineering team, you will be responsible for the entire software engineering lifecyle, i.e design, document, build, test, maintain. As one of the core teams, this role is integral to the success of the company. A successful candidate will thrive in a fast-paced, highly collaborative environment and demonstrate an ability to execute precisely and quickly. The ideal candidate will have in-depth experience with Data Science workflows and built scalable machine learning systems.

- Build systems and tools that enable data scientists to create machine learning applications using the C3.ai Platform.
Enable scalable, end-to-end machine learning pipelines in a distributed system.
Work with other platform engineering teams to enable streaming, batch, or ad-hoc data analysis.
Collaborate with and support data scientists to understand the utility of the C3.ai Platform and define new requirements.
Define and lead the development of longer-term C3.ai Platform capabilities.
Mentor junior members of the team.

Requirements:

- Advanced degree in computer science, math, or similar field.
Excellent programming and algorithmic skills and a taste for DRY code.
In-depth understanding of supervised and unsupervised machine learning algorithms.
Proven track record of applying learning algorithms in a production system.
Strong programming skills in Java, Python and JavaScript.
Demonstrated end-to-end ownership of projects.
Stellar listening and explanation skills.
Thorough knowledge of data structures, algorithms, profiling/optimization, and Object-Oriented and Functional Programming.
A minimum of 3 years of work experience in a fast-paced software company.

C3.ai provides a competitive compensation package and excellent benefits including:
Competitive salary, generous stock options, 401K, medical, dental, and vision benefits. At the office, we offer a fully stocked kitchen with catered breakfast and lunch, table tennis and pool table, free membership at our on-site gym, Friday evening social hours with food, drink and music and a fun team of great people.
C3.ai is proud to be an Equal Opportunity and Affirmative Action Employer. We do not discriminate on the basis of any legally protected characteristics, including disabled and veteran status.",4.7,"C3.ai
4.7","Redwood City, CA","Redwood City, CA",201 to 500 employees,2009,Company - Private,Enterprise Software & Network Solutions,Information Technology,$100 to $500 million (USD),"GE Digital, Palantir Technologies, Uptake"
"Senior Software Engineer, Data",-1,"The Company You'll Join


At Carta we create owners and make private markets liquid.

We live in a world where some people live on the equity stack and enjoy exponential wealth growth and preferential tax treatment; others live on the debt stack and may work their entire lives for a company and retire only with the cash they've managed to save from their paychecks. Our contribution to solving the wealth inequality problem is moving people from the debt stack (payroll) to the equity stack. By making it as easy to issue equity to employees as it is to put them on payroll, we can create more owners.

At Carta, we are helpful, transparent, fair, and kind. We are relentless executors, unconventional thinkers, and masters of our craft.

To learn more, here is what one of our investors wrote about leading our Series F.

The Team You'll Work With


The Data team at Carta is transforming what decision making looks like at the company. We believe that our data is what is key to setting us apart and will help us succeed as a data driven company. Members of the data team are working on understanding and making sense of data while partnering with product and business teams on helping drive direction with data. The team is currently composed of professionals in Data Science/ Machine Learning space, advanced Data Analytics space, and Data engineering. We like to partner with each other and with Cartans across the company to get our work done, and we like to constantly think about how we can improve. We also like to come up with new product ideas based on data.

The Problems You'll Solve


As a member of this team, you will be responsible for building and scaling our pipelines to make data accurate, accessible and secure. You will build systems that will allow the rest of the company answer questions they need in a self-service manner, and allow analysts and data scientists to quickly analyze and prototype new ideas. You will partner with the rest of the team on prototyping those new ideas and build scalable products. Examples of responsibilities will include:
Build resilient data pipelines based on internal and external data sources
Implement data security practices to support CartaX, compliance & legal, and other areas of the company that require additional safeguards
Build or evaluate tooling for data accuracy detection and alerting
Partner with the rest of the team on prototyping and building scalable products driven by the data team
Partner with teams throughout Carta on identifying opportunities and building solutions to help in simplifying operations while producing rich and accurate data sets for us to use
Constantly identify opportunities for providing self-service tooling to our internal partners
The Impact You'll Have


By building scalable self-service solutions you will enable easier and faster decision making. In addition, you will be able to increase productivity and accuracy of our data team, and operations and product teams as well

About You


Successful candidates in this role will always look for a balance between fast delivery and building for scale. You don't follow the status quo but look for ways to improve how we do things. You are able to talk to technical and business users and explain your work, and are able to be a good partner to your team and to your customers. Building relationships is a priority. Even though our toolstack (Airflow, DBT, Redshift & Looker) are a good start, you will always be in the know on the latest and greatest technology we could utilize. You concentrate on automation and self service. You are also excited to build new products, starting with ideas and all the way to execution. Example of problems you will solve include:
Building tools to automate data anomaly detection and alerting
Scaling our data infrastructure and developing software that allows for improved data processing and automation
Evaluating build vs buy tooling
Scaling Looker as a platform to solve operational use cases as well as increase self service adoption around the company
Evaluating and rearchitecting our data model to support existing and future products
Partnering with external teams to help in data modeling requirements to support analytics
Understanding the needs of external teams, identify pain points and opportunities, and come back with proposals on how data engineering practice can help
Rearchitecting solutions such as Amplitude to allow for faster and more accurate reporting
Partner with the rest of data team to develop best in class software solutions to stand up products based on our data
Carta is a Series E company and is backed by top-tier VCs like Andreessen Horowitz, Lightspeed Venture Partners, Meritech Capital, and more.

We are an equal opportunity employer. As a company, we value fairness, helpfulness, transparency, leadership and build our teams around these values. Check out our careers page to get to know us better as you think about your next step at Carta.

Please read about our candidate privacy policy here.",3.9,"Carta
3.9",Remote,"San Francisco, CA",501 to 1000 employees,2012,Company - Private,Venture Capital & Private Equity,Finance,Unknown / Non-Applicable,-1
"Software Engineer (Data Scientist, C,C++,Linux,Unix) - SISW - MG","$72K-$142K
(Glassdoor est.)","During the current global health crisis, the priority for Siemens Digital Industries Software is the health and well-being of our entire community including current and future employees, which may add time to our hiring processes. We appreciate your patience and invite you to visit our website to learn more about how Siemens is responding to the pandemic.
Company: SISW - MG
Job Title: Software Engineer (Data Scientist, C,C++,Linux) - 189288
Job Location: USA - CA - Fremont
Job Category: R&D SW Engineering

Job Description:

We are looking for a highly motivated engineer to work in the RET team in the Calibre business unit. In this role you will be responsible for analyzing modeling data (experimental and synthetic/simulated) and coming up with novel ways to organize it, while deriving meaningful operations and extracting maximum information from this data.

You will also be expected to develop supporting software that will be properly integrated in the modeling suite of tools that are used specifically in modeling of semiconductor manufacturing.

You will be teaming up with a group of senior software engineers contributing to final production-level quality of new components and algorithms and to support existing components.

This is a unique role that will challenge you and allow you to grow in interdisciplinary areas of software engineering and data analysis.

Knowledge and experience in the area of data science/data analysis is preferred.

Some familiarity with physical modeling of any discipline (e.g. from fields in electrical or mechanical engineering) will be very useful for the suitable candidate.

Job
Qualifications:

The successful candidate will possess the following
combination of education and experience:
BS or
MS in Data Sciences, Computer Science, Electrical Engineering, Physics or
Applied Mathematics.
Working
knowledge in development of C and C++ on UNIX and/or LINUX platforms.
Excellent
programming skills in at least one mainstream scripting language, preferably
Python.
Experience/knowledge
in data analysis.
Experience/knowledge
in machine learning technology.
Experience
with Python, Keras and Tensorflow.
Demonstrated
ability to learn and explore new technologies.
Excellent
analysis and problem-solving skills.
Must
have the ability to collaborate closely with other members of the team and
develop critical components consistently and in a timely manner.
Experience
with MATLAB/R or equivalent mathematical package is expected.
This position may require access to export-controlled technology. If an export license is required and Mentor Graphics elects to apply for such a license, then candidates must be approved and licensed by the applicable government authorities as a condition of employment.

#LI-MGRP
#LI-JE1

Organization: Digital Industries

Company: Mentor Graphics Corporation

Experience Level: Recent College Graduate

Job Type: Full-time

Equal Employment Opportunity Statement
Siemens is an Equal Opportunity and Affirmative Action Employer encouraging diversity in the workplace. All qualified applicants will receive consideration for employment without regard to their race, color, creed, religion, national origin, citizenship status, ancestry, sex, age, physical or mental disability unrelated to ability, marital status, family responsibilities, pregnancy, genetic information, sexual orientation, gender expression, gender identity, transgender, sex stereotyping, order of protection status, protected veteran or military status, or an unfavorable discharge from military service, and other categories protected by federal, state or local law.

EEO is the Law
Applicants and employees are protected under Federal law from discrimination. To learn more, Click here.

Pay Transparency Non-Discrimination Provision
Siemens follows Executive Order 11246, including the Pay Transparency Nondiscrimination Provision. To learn more, Click here.

California Privacy Notice
California residents have the right to receive additional notices about their personal information. To learn more, click here.",4.2,"Mentor Graphics
4.2","Fremont, CA","Wilsonville, OR",5001 to 10000 employees,1981,Company - Public,Computer Hardware & Software,Information Technology,$1 to $2 billion (USD),"Cadence Design Systems, Synopsys, Altium Limited"
"Senior Software Engineer, Data",-1,"The Company You'll Join


At Carta we create owners and make private markets liquid.

We live in a world where some people live on the equity stack and enjoy exponential wealth growth and preferential tax treatment; others live on the debt stack and may work their entire lives for a company and retire only with the cash they've managed to save from their paychecks. Our contribution to solving the wealth inequality problem is moving people from the debt stack (payroll) to the equity stack. By making it as easy to issue equity to employees as it is to put them on payroll, we can create more owners.

At Carta, we are helpful, transparent, fair, and kind. We are relentless executors, unconventional thinkers, and masters of our craft.

To learn more, here is what one of our investors wrote about leading our Series F.

The Team You'll Work With


The Data team at Carta is transforming what decision making looks like at the company. We believe that our data is what is key to setting us apart and will help us succeed as a data driven company. Members of the data team are working on understanding and making sense of data while partnering with product and business teams on helping drive direction with data. The team is currently composed of professionals in Data Science/ Machine Learning space, advanced Data Analytics space, and Data engineering. We like to partner with each other and with Cartans across the company to get our work done, and we like to constantly think about how we can improve. We also like to come up with new product ideas based on data.

The Problems You'll Solve


As a member of this team, you will be responsible for building and scaling our pipelines to make data accurate, accessible and secure. You will build systems that will allow the rest of the company answer questions they need in a self-service manner, and allow analysts and data scientists to quickly analyze and prototype new ideas. You will partner with the rest of the team on prototyping those new ideas and build scalable products. Examples of responsibilities will include:
Build resilient data pipelines based on internal and external data sources
Implement data security practices to support CartaX, compliance & legal, and other areas of the company that require additional safeguards
Build or evaluate tooling for data accuracy detection and alerting
Partner with the rest of the team on prototyping and building scalable products driven by the data team
Partner with teams throughout Carta on identifying opportunities and building solutions to help in simplifying operations while producing rich and accurate data sets for us to use
Constantly identify opportunities for providing self-service tooling to our internal partners
The Impact You'll Have


By building scalable self-service solutions you will enable easier and faster decision making. In addition, you will be able to increase productivity and accuracy of our data team, and operations and product teams as well

About You


Successful candidates in this role will always look for a balance between fast delivery and building for scale. You don't follow the status quo but look for ways to improve how we do things. You are able to talk to technical and business users and explain your work, and are able to be a good partner to your team and to your customers. Building relationships is a priority. Even though our toolstack (Airflow, DBT, Redshift & Looker) are a good start, you will always be in the know on the latest and greatest technology we could utilize. You concentrate on automation and self service. You are also excited to build new products, starting with ideas and all the way to execution. Example of problems you will solve include:
Building tools to automate data anomaly detection and alerting
Scaling our data infrastructure and developing software that allows for improved data processing and automation
Evaluating build vs buy tooling
Scaling Looker as a platform to solve operational use cases as well as increase self service adoption around the company
Evaluating and rearchitecting our data model to support existing and future products
Partnering with external teams to help in data modeling requirements to support analytics
Understanding the needs of external teams, identify pain points and opportunities, and come back with proposals on how data engineering practice can help
Rearchitecting solutions such as Amplitude to allow for faster and more accurate reporting
Partner with the rest of data team to develop best in class software solutions to stand up products based on our data
Carta is a Series E company and is backed by top-tier VCs like Andreessen Horowitz, Lightspeed Venture Partners, Meritech Capital, and more.

We are an equal opportunity employer. As a company, we value fairness, helpfulness, transparency, leadership and build our teams around these values. Check out our careers page to get to know us better as you think about your next step at Carta.

Please read about our candidate privacy policy here.",3.9,"Carta
3.9",Remote,"San Francisco, CA",501 to 1000 employees,2012,Company - Private,Venture Capital & Private Equity,Finance,Unknown / Non-Applicable,-1
"Senior Software Engineer, Python Platform","$87K-$173K
(Glassdoor est.)","Why TrueAccord?

Debt collection is failing consumers. Every year, more than 70 million Americans have negative experiences with the collections process, and they deserve a much better treatment - more relevant, more digital, less abrasive. That’s why banks, lenders, and industry leaders are coming to TrueAccord for innovative solutions in recovering outstanding receivables.

TrueAccord is a category-defining company. We combine machine learning with a human-based approach to guide both lenders and borrowers through a challenging financial process. With a world-class leadership team, passionate and driven team members, and a diverse and growing client base, TrueAccord is well positioned for continued success.

Your Role:

TrueAccord is looking for a Senior Python Engineer to join our Engineering team.

You will join a multi-functional engineering team of dedicated to creating a data driven culture, improving the efficiency and dependability of the way we make decisions, and developing our automated debt collection strategy. In this role, you will work closely with Data Scientists to understand the data science development process and take architectural owner take ownership of HeartBeat - our python based decision engine.

We’re looking for strong computer science fundamentals and an enthusiasm for system architecture, data and supporting others. You should be passionate about leading conversations on system architecture, implementing clean code, and determined to have a huge impact at TrueAccord.
Key Responsibilities:
Own and maintain HeartBeat as a platform - TrueAccord’s patented decision engine at the “heart” of its debt collection process
Lead discussion and development of our reactive decision making architecture as we enter the hyper growth phase
Partner with data science and product to understand the experimentation lifecycle and help design the underlying infrastructure for experiment development
Assist our data scientists in developing production quality models and model pipelines
You Have:
5+ years work experience | BA in Computer Science, Engineering or related field | Equivalent training
Excellent Python skills with dedication to writing clean understandable, testable code with an eye towards maintainability
Ability to lead technical architecture discussions and help drive technical decisions, as well as implement day-to-day changes
Zeal for building high throughput, real-time analytics systems
Project management and communication skills with experience working alongside cross-departmental partners
Desire to work in San Francisco.
You might also have:
Proficiency with statistical or data management Python libraries (scikit-learn, statsmodels etc. - huge plus if experience with Pandas)
Familiarity with machine learning or predictive modeling and related development technologies (Tensorflow, Spark, Jupyter etc.)
Interest in helping onboard new team members, mentoring, and teaching others
Knowledge of functional Scala
FinTech background


What TrueAccord offers you + Culture & Benefits

TrueAccord is distributed company with a major presence in the San Francisco Bay area and Lenexa, KS. We offer a healthy work environment that continuously builds an inclusive and diverse culture where everyone is able to develop the best version of themselves. We are a dynamic group of people who are subject matter experts with a passion for change.

We offer:
*** Generous paid time off
*** Paid training
*** We promote work/life harmony
*** Paid holidays
*** Health, dental and vision benefits
*** 401K with matching

Our teams are crafting solutions to big problems every day. If you’re looking for an opportunity to do impactful work, join TrueAccord and make a difference.

Our Dedication to Diversity & Inclusion

TrueAccord is an equal opportunity employer. We promote, value, and thrive with a diverse & inclusive team. Different perspectives contribute to better solutions and this makes us stronger every day. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.",3.2,"TrueAccord
3.2","San Francisco, CA","San Francisco, CA",51 to 200 employees,2013,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"As a Data Engineer, you'll join our growing team of data scientists and engineers, reporting into Operations organization but working across multiple teams throughout the company. In this role, you(TM)ll be responsible for handling the design and construction of scalable data management systems "" ensuring that all data systems meet our company requirements "" and will also research and recommend new uses for data acquisition. As a Data Engineer, you will implement the data models and data structures needed for each use case, in the most convenient format to be used by the Data Science and Business Intelligence teams. Through regular interactions with stakeholders and functional business unit leaders, you will build high-performance algorithms, predictive models, and prototypes that influence data storage, piping, and usage. Additionally, you will participate in data requirements, modeling and testing activities. Each day will be unique, requiring an ability to think strategically and on your feet, be creative, take initiative, and employ a diverse set of skills.

WHO YOU ARE

Knowledgeable, Analytical, and Solution-Oriented. Without a doubt, you(TM)ve got strong quantitative skills and are comfortable analyzing large data set, spotting trends and patterns, and synthesizing relevant observations. You use a hypothesis-driven approach to engage in analysis that will deliver on your client questions. You like thinking outside the box to come up with innovative points of view on new challenges, relying on your previous analytic work and experience to help guide you along the way.

Results-Oriented. You demonstrate an inherent sense of urgency to drive great results, while being precise in executing your work. You are facile with creating and communicating a clear project plan, tracking progress, and keeping your business partners in the loop along the way.

Intellectually Curious. You're inherently interested in the ""why"" so that you can identify opportunities that represent unconventional solutions to the problems you are trying to solve.

Strong Communicator. Your writing and speaking skills are concise, articulate, and effective, providing an ability to interact with all levels/various teams across the organization, be understood, and develop trust and rapport within the organization.

Technologically Savvy. Microsoft Excel is a basic tool to you that you know like the back of your hand. You also have a strong skill set in R, Python, ArcGIS, machine learning, neural networks and/or other advanced analytics tools and techniques.

A Trusted Team Player. You enjoy partnering with others and build constructive working relationships that foster the collaboration necessary to deliver great results. You are accountable to your teammates and follow through on commitments.

Organized and Confident. You are flexible, composed, and able to prioritize multiple tasks and deadlines simultaneously, while confidently interacting with a variety of individuals, across all levels of the organization. You handle pressure well and do so with confidence.

WHAT YOU(TM)LL DO

Create data models and data processes, providing the right format and structure for use case solutions.

Participate in early data modeling and testing for use case development, providing input on how to improve proposed solutions and implement necessary changes.

Help to build, document, and maintain best practices, including but not limited to codebase management, work and issue tracking, testing and quality control/assurance measures, data dictionaries, and a documentation hub for both production level code and ad hoc analyses.

Interact with stakeholders and functional subject matter experts to understand all data requirements in order to develop effective business insights and translate them into actionable data structures and data models.

Assemble large, complex data sets that meet both functional and non-functional business requirements.

Extract relevant data to solve analytical challenges the organization and/or functional business units may face.

Work closely with IT teams on internal data acquisition (e.g., CRM, ERP, etc.).

Partner with stakeholders to provide technical support related to data structures, data models, data management and data infrastructure needs.

Work with data and analytics experts to strive for greater functionality in our data systems. Recommend different ways to constantly improve data reliability and quality.

Research new uses for existing data.

Create data tools for Business Intelligence, Analytics and Data Scientist team members that assist them in building and optimizing our Company use of data.

Collaborate regularly with key stakeholders to support and enhance the day-to-day operations of our business.

Produce various reports for stakeholders, as requested, to highlight areas of opportunity; works with teams to develop and implement changes, as needed.

Develop and maintain formal documentation that describes data and data structures, including data modeling.

PREVIOUS EXPERIENCE & REQUIREMENTS

Bachelor's Degree required, preferably in computer science, software/computer engineering, applied mathematics, or physics statistics.

Minimum 2 years data modeling experience and working with data management systems; deep expertise in data modeling and structuring required.

2+ years experience in high volume data environments and core data engineering activities (i.e. familiarity with cloud database set up, automation scheduling using directed acyclic graph (such as Airflow) and database optimization, including but not limited to partitioning, group and sort keys, and indexes).

Familiarity with a broad base of analytical methods e.g. data modeling (variable transformation and summarization) and processing (i.e. Spark, SQL Server, Hadoop/Hive, neo4j, etc).

Strong attention to detail and ability to think critically/conceptually.

Team oriented and flexible with proven track record in collaborating with multiple stakeholders.

Effective written and verbal communication skills required. Demonstrated ability to quickly learn new technologies a must.

Ability to think creatively when problem solving for new solutions and to work on numerous projects concurrently while effectively prioritizing workload. Tolerance for ambiguity required.

Tools/software:

Familiarity with data loading and management tools (i.e. Azure Storage""BlockBlob and relational and NoSQL databases and tools such as SQL Server, MongoDB, Data Stax, etc) required.

Must have programming and/or scripting experience (Python, Java) as well as experience with version control systems (Git/GitHub), continuous integration (circleCI) and other programming frameworks/approaches.

Proficiency in MS and Google application suites.

Must be available for overnight travel (approximately 10%)

Authorization to work in the US (without need for Visa sponsorship from employer) is required.",5.0,"CultureFit Technology Staffing
5.0","Chicago, IL","Deerfield, IL",1 to 50 employees,1997,Company - Private,Advertising & Marketing,Business Services,$1 to $5 million (USD),-1
Sr Software Development Engineer-Fire OS,"$112K-$170K
(Glassdoor est.)","Amazon Lab126 is an inventive research and development company that designs and engineers high-profile consumer electronics. Lab126 began in 2004 as a subsidiary of Amazon.com, Inc., originally creating the best-selling Kindle family of products. Since then, we have produced groundbreaking devices like Fire tablets, Fire TV, Fire phone, and Amazon Echo. What will you help us create?

Work hard. Have fun. Make history.

The Role:

We are looking for a passionate Sr. Software Development Engineer to help develop critical services and machine learning applications that drives the device health improvements release over release. You must be responsive, flexible and able to succeed within an open collaborative peer environment. You will take the lead in designing, prototyping, and building solutions to hard problems in the Amazon ecosystem. You will assist more junior engineers with designs and code structure to improve the functionality, quality, and maintainability of the teams work. You will work closely with engineers, data scientists, product and project managers, and other service teams to drive development from the concept stage to launch.

We are looking for hard-working and talented Software Development Engineers who have experience building innovative, mission critical, highly optimized applications. You will have an enormous opportunity to make a large impact on the design and architecture of cutting-edge products used every day by people you know. In this role, you will:
· Design, implement and maintain a high-volume, highly available, distributed big data processing system in AWS.
· Work with Data Scientists to design and implement data analytics and machine learning solutions.
· Be a champion for engineering excellence, applying best practices to all stages of the software development process.


Basic Qualifications

· 7+ years of experience in software development of large-scale data infrastructure and distributed systems
· 7+ years of experience in data extraction, transformation, statistical analysis and data modeling
· 7+ years of experience developing enterprise software using Java or Python



Preferred Qualifications


· Masters degree in Computer Science, Computer Engineering, Machine Learning, or related field;
· Advanced knowledge in performance, scalability, numerical accuracy, enterprise system architecture
· Experience building solutions using AWS big data and machine learning services
· Experience in applying Data Mining and Machine Learning techniques to solve business problems
· Working knowledge of major database systems and a statistical modeling tools such as R, SAS, SciKit-learn, or TensorFlow
· Ability to communicate complex technical concepts and solutions to all levels of the organization
· Excellent communication and consensus building

Lab126 is part of the Amazon.com, Inc. group of companies and is an Equal Opportunity Employer Minority / Women / Disability / Veteran / Gender Identity / Sexual Orientation / Age.",3.9,"Amazon
3.9","Sunnyvale, CA","Seattle, WA",10000+ employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),"Google, Microsoft, Walmart"
Senior Software Engineer - Backend,-1,"Freenome is hiring a Senior Software Engineer - Backend to develop software to combat cancer and other age-related diseases. You will work as part of an interdisciplinary team of engineers and scientists building end-to-end solutions for our ML team and clinical and R&D labs.

At Freenome, we're building a multi-omics platform that ingests clinical-grade, high-dimensional, biological data for early cancer detection. We're a diverse group of Engineers building tools and services which enable our Molecular and ML Scientists to turn great research into even better products. We will create actionable insights for health systems and will guide change for the way doctors think about early detection of colon cancer.

As a member of a fast-growing team, you'll take the lead on major projects and collaborate actively with our world-class team of engineers, scientists, designers, and product managers. You'll build reliable, maintainable, scalable, and fault-tolerant backend services that enable the rapid growth of our business and our mission to save lives.

Depending on your skills and our needs you'll be working on projects including ML platform development, job scheduler development, EMR system integration, and data CRUD operations and ETL. Our systems are built using the latest web software development technologies and methodologies.

Responsibilities:
Design, develop, and deploy reliable, maintainable, scalable, and fault-tolerant backend services that power both our internal and external systems
Collaborate with team members for code and design review
Work with scientists, designers, product managers, and other engineers to solve complex problems in the face of lots of dynamism and uncertainty
Take a mindful, transparent, and humane approach to your work and your interactions with others
Guide and champion engineering hygiene and culture as a core part of the engineering backbone
What We're Looking For:
5+ years of experience as a part of a software development team successfully shipping a software product
BS, MS, or PhD in Computer Science, Engineering or related field, or equivalent training, fellowship, and/or work experience
Experience with Python or similar scripting language
Excellent written and verbal communication skills
Direct experience with web service development
The ability to thrive in an environment where collaboration, communication, and compromise are an expected part of your day-to-day work
A mindful, transparent, and humane approach to your work and your interactions with others
Nice to Haves:
Expertise with Python
Experience with SQLAlchemy, Flask, or Django frameworks
Experience in Kubernetes, Docker, PostgreSQL, Google Cloud Platform
Previous experience leading teams or managing projects
Understanding of, and practical experience with, statistical and machine learning methods
Domain-specific experience in computational biology, genomics or a related field
Direct experience with clinical interoperability standards such as FHIR, IHE ITI Profiles or HL7v2
About Freenome

Freenome is on a mission to empower everyone with the tools they need to detect, treat, and ultimately prevent diseases.

By applying advanced machine learning techniques to recent breakthroughs in genomic science, Freenome is developing simple blood tests to detect early-stage cancer and make treatments more effective. The company has raised $238 million from investors such as RA Capital, Polaris Partners, Perceptive Advisors, Andreessen Horowitz, funds and accounts advised by T. Rowe Price Associates, Inc., GV (formerly Google Ventures), Roche Venture Fund, Kaiser Permanente Ventures, American Cancer Society's BrightEdge Ventures, Data Collective Venture Capital, Novartis and Verily Life Sciences (formerly Google Life Sciences).

Our Science

Freenome is building technology to gain an understanding of the body through several analytes derived from blood. These signals include cell-free DNA, methylation of cell-free DNA, cell-free RNA, circulating proteins, and immune profiling derived from thousands of prospective samples. By developing novel statistical learning methods and applying them to integrate various -omics datasets, Freenome is a leader in modeling specific biological mechanisms to capture disease dependent signatures such as gene expression, immune response, tumor burden, the tissue of origin, and 3D chromatin structure.

By building comprehensive discovery datasets and modeling critical biological systems, Freenome is learning what biological changes are present within the blood between a variety of different disease states including cancer, autoimmune disorders, infections, drug response, and aging. With the combination of Freenome's datasets, cross-functional technical expertise, and mission to uncover the biological truth, we seek to positively change the lives of millions through the early detection and early treatment of disease.

Our Culture

Freenomers are technical and creative, visionary and grounded, empathetic and passionate. We build teams around divergent expertise, which allows us to solve problems and uncover opportunities in unique ways. Freenomers are some of the most talented experts in their fields, coming together to advance healthcare one breakthrough at a time.

We value empathy, integrity, and trust in one another. That means embracing other's perspectives, those of our coworkers and those of the patients and communities we serve. It means knowing when to push, and when to listen. At Freenome, we give each other the benefit of the doubt in the belief that we're all working as a team toward the same goals, and empower others to grow in a collaborative environment.

What does a successful person look like at Freenome?

Those who thrive at Freenome prioritize, manage, and execute their own goals in alignment with those of the company. They embrace our values of empathy, integrity, and trust, and hold themselves and their team accountable. They crave collaboration with brilliant minds from unfamiliar fields of study and believe that hiring and mentorship are fundamental to our success. Above all, they welcome and provide constructive feedback and criticism, trusting in the good intentions of others, and secure in the knowledge that embracing mistakes is the best way to learn and move on. For those who crave challenges, understudied problems, and the chance to see their work impact the lives of millions of people affected by cancer every year, there's no better place to be.

Freenome is proud to be an equal opportunity employer, we value diversity in every way. Freenome does not discriminate on the basis of race, religion, color, sex, gender identity, sexual orientation, age, non-disqualifying physical or mental disability, national origin, veteran status or any other basis covered by appropriate law.",5.0,"Freenome
5.0","South San Francisco, CA","South San Francisco, CA",51 to 200 employees,2014,Company - Private,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,Unknown / Non-Applicable,-1
"Lead Data Scientist - NLP, Machine Learning",-1,"Lead Data Scientist - NLP, Machine Learning We are disrupting enterprise analytics and business intelligence by killing dashboards. We transform enterprise data into actionable natural language insights for business leaders. Our mission is to empower all businesses to tell their own data story. Top Reasons to Work with Us Based in Santa Monica, we have successfully closed our seed funding and are looking for our first hires. Our founders have led teams at Facebook and PayPal and have built core technologies at several startups that have had successful exits. What You Will Be Doing As a Sr. Data Scientist, you will be working closely with the clients and our engineering team to build our product that auto-generates actionable business insights. You will be creating algorithms that analyze business data at scale for several different kinds of businesses. You must have an expertise in end-to-end data analytics processes from ETL to executive level presentations. -Business / Performance Forecasting -Designing and evaluating experiments -Identifying new levers to help move key metrics -Monitoring key product metrics -Evaluating and defining metrics -Understanding root causes of changes in metrics -Building and analyzing dashboards and reports -Building key data sets to empower operational and exploratory analysis -Understanding ecosystems, user behaviors, and long-term trends -Building models of user behaviors for analysis or to power production systems -Influencing product teams through presentation of data-based recommendations -Communicating state of business, experiment results, etc to product teams -Spreading best practices to analytics and product teams What You Need for this Position -2+ years' experience doing quantitative analysis at a top-tier tech company -BA/BS in Computer Science, Math, Physics, Engineering, Statistics or another technical field from top-tier institution (Graduate degrees preferred) -Experience in SQL. -Development experience in Python or R -Ability to communicate the results of analyses with product and leadership teams -Understanding of statistics (e.g., hypothesis testing, regressions) -Experience manipulating data sets through statistical software (ex. R, Pandas) or other methods -Experience with distributed computing Spark/Hadoop -Experience with Amazon Redshift and Athena is a plus What's In It for You -Competitive benefits package (including Healthcare, Dental, Vision) -Help shape and grow a venture-backed tech company from the ground floor -Life Insurance -15 days of PTO per year -unlimited sick days -paid holidays -401k Retirement Savings Plan -Free snacks and drinks -Professional Development -Performance Bonuses -Equity Package -Relocation costs (if applicable) So, if you are a Senior Data Engineer with experience, please apply today! - Applicants must be authorized to work in the U.S.
CyberCoders, Inc is proud to be an Equal Opportunity Employer

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, protected veteran status, or any other characteristic protected by law.

Your Right to Work In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification document form upon hire.

CyberCoders will consider for Employment in the City of Los Angeles qualified Applicants with Criminal Histories in a manner consistent with the requirements of the Los Angeles Fair Chance Initiative for Hiring (Ban the Box) Ordinance.",4.2,"CyberCoders
4.2","Santa Monica, CA","Irvine, CA",201 to 500 employees,1999,Subsidiary or Business Segment,Staffing & Outsourcing,Business Services,$100 to $500 million (USD),-1
Senior Software Engineer,"$51K-$108K
(Glassdoor est.)","Company Description

Atmospheric and Environmental Research (AER), a Verisk business, has been helping businesses and governments better anticipate and manage climate and weather-related risks for more than 40 years. Large government agencies like NOAA, NASA and the Departments of Defense and Energy rely on AER’s scientists to help solve weather and climate related problems of vital national importance in energy, environment and national security. Large insurance, energy and investment firms count on AER to help them decrease weather-related losses and increase profitability by integrating state-of-the-art climate science and weather information into their planning and decision processes.  To learn more about AER please visit us at: www.aer.com. We are proud to be a part of the Verisk family of companies!

At the heart of what we do is help clients manage risk. Verisk (Nasdaq: VRSK) provides data and insights to our customers in insurance, energy and the financial services markets so they can make faster and more informed decisions.

Our global team uses AI, machine learning, automation, and other emerging technologies to collect and analyze billions of records. We provide advanced decision-support to prevent credit, lending, and cyber risks. In addition, we monitor and advise companies on complex global matters such as climate change, catastrophes, and geopolitical issues.

But why we do our work is what sets us apart. It stems from a commitment to making the world better, safer and stronger.

It’s the reason Verisk is part of the UN Global Compact sustainability initiative. It’s why we made a commitment to balancing 100 percent of our carbon emissions. It’s the aim of our “returnship” program for experienced professionals rejoining the workforce after time away. And, it’s what drives our annual Innovation Day, where we identify our next first-to-market innovations to solve our customers’ problems.

At its core, Verisk uses data to minimize risk and maximize value. But far bigger, is why we do what we do.

At Verisk you can build an exciting career with meaningful work; create positive and lasting impact on business; and find the support, coaching, and training you need to advance your career. We have received the Great Place to Work® Certification for the fourth consecutive year. We’ve been recognized by Forbes as a World’s Best Employer and a Best Employer for Women, testaments to our culture of engagement and the value we place on an inclusive and diverse workforce.

Job Description

Atmospheric and Environmental Research (AER) is seeking a motivated individual to work as part of an energetic team developing complex software for multiple Dept. of Defense and commercial programs providing solutions to real-world problems related to space weather impacts on operations. The successful applicant will interact closely with scientists, product developers and engineers in an agile development process to rapidly design, develop, test, integrate and deploy software capabilities with a DevOps mindset.

The position requires both new software development and ability to adapt/extend existing codes. New development will be mainly in C++ and Python but existing code also includes C and FORTRAN. Candidates must have a BS degree plus 8 years experience, MS degree plus 6 years experience, or PhD plus 4 years experience in computer science, electrical engineering, mathematics or sciences involving programming. A successful applicant will have demonstrated the ability to develop quality software for science or engineering applications and to rapidly learn new problem domains and software technologies. Strong technical and communication skills, teamwork, and problem solving in a fast-paced R&D environment are required.

Qualifications

The following are required:
Candidates must have a BS degree plus 8 years experience, MS degree plus 6 years experience, or PhD plus 4 years experience in computer science, electrical engineering, mathematics or sciences involving programming.
Strong modern C++ and Python programming skills and object-oriented design.
Development experience in Linux environments, including shell programming.
Demonstrated experience in software development of scientific, geospatial or engineering applications.
Understanding of the software lifecycle and experience in the use of software process tools including source control (Git, Subversion)
Demonstrated ability and enthusiasm for rapidly learning and applying new software technologies to complex problems.
An understanding or background in signal processing, RF propagation, and/or wave propagation.
An ability to manage and lead projects
An interest in participating on proposals and publishing / presenting in professional venues
Ability to obtain security clearance and US citizenship required.
The following are desired:
High performance computing and code optimization, including experience in multithreading and multiprocessing applications, and distributed programming
Data analytics, numerical methods, or modern machine learning experience
Interest in remote sensing/satellites, physics, meteorology, or other geophysical sciences
Experience with continuous integration tools such as Jenkins
#LI-SH1

Additional Information

Verisk Analytics is an equal opportunity employer.

All members of the Verisk Analytics family of companies are equal opportunity employers. We consider all qualified applicants for employment without regard to race, religion, color, national origin, citizenship, sex, gender identity and/or expression, sexual orientation, veteran's status, age or disability.

http://www.verisk.com/careers.html

Unsolicited resumes sent to Verisk, including unsolicited resumes sent to a Verisk business mailing address, fax machine or email address, or directly to Verisk employees, will be considered Verisk property. Verisk will NOT pay a fee for any placement resulting from the receipt of an unsolicited resume.

Consumer Privacy Notice",3.5,"AER
3.5","Albuquerque, NM","Lexington, MA",51 to 200 employees,1977,Subsidiary or Business Segment,Research & Development,Business Services,$25 to $50 million (USD),-1
Sr. Machine Learning Engineer,-1,"Every day our employees make their mark by helping clients better
manage and service their financial assets around the world.
Whether providing financial services for institutions,
corporations or individual investors, clients count on us across
time zones and in 35 countries and more than 100 markets. It's
the collective ambition, innovative thinking and exceptionally
focused client service paired with a commitment to doing what is
right that continues to set us apart.

Client Technology Solutions provides our business partners with
client-focused, technology-based solutions. These enhance their
ability to be successful through world-class software solutions
and leading-edge infrastructure. Client Technology Solutions
provides employees with the tools and resources to enhance their
professional qualifications and careers.

Description
Our Innovation Center is currently seeking Senior Data Scientists
to join our rapidly growing team. We are a startup within an
enterprise, focused on applied research that can be quickly
brought to market as production services and new financial
services products. We are the worlds leading provider of
financial services technology, and current business operations
provide a wealth of fascinating business opportunities and
requirements, as well as terabytes of the worlds most
interesting data science challenges. Help us revolutionize global
financial services!

Responsibilities
You will lead the development and enhancement of the relevance
engine in our new enterprise search platform.

Experience and Skills:
Advanced degree in Computer Science or related field (Masters
required, Ph.D. preferred) with a solid understanding of
Information Retrieval, Learning to Rank, Text Mining and Machine
Learning.
Experience with search engine log analysis and applying Machine
Learning to improve search engine relevance.
Experience in Text Mining, Information Extraction and Document
Classification.
Software development experience with Java.
Experience programming for a search platform like Lucene.
Experience with a scripting language like Python, Perl.
Strong communication and presentation skills; experience in
communicating results of machine learning and statistical
analysis to a broad audience

Make your mark!",-1,Stride Search,"Palo Alto, CA","Westlake Village, CA",1 to 50 employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Software Engineer,"$71K-$146K
(Glassdoor est.)","Feedzai is the market leader in managing financial risk with AI. We're coding the future of commerce with today's most advanced risk management platform powered by big data and machine learning. Founded and developed by data scientists and aerospace engineers, Feedzai has one mission: to make banking and commerce safe. The world's largest banks, processors, and retailers use Feedzai's fraud prevention and anti-money laundering products to manage risk, while improving customer Experience.

The Customer Success team ensures our global customers achieve their business goals using our product. Everything you do matters: all your code, machine learning models, advisory, management, and other actions/roles will have a material impact on the way our clients run their business and how effectively we fight fraud and protect people from wrongdoing. You will be able to interact and meet many people from widely different cultures around the world and understand the business like few others. You will be able to say you protect people on a daily basis. You will be challenged with new technology, new processes, and new mindsets and will be asked to contribute to ensure continuous improvement. Come and change the world with us.

Responsibilities:
Execute full software development life cycle
Develop flowcharts, layouts and documentation to identify requirements and solutions
Write well-designed, testable code
Integrate software components into a fully functional software system
Troubleshoot, debug and upgrade existing systems
Deploy and support systems in production
Comply with best practices and industry standards
Requirements:
7+ years of professional experience in Java software development
BS or MS in computer science, or a comparable field, or equivalent experience
Project/ team leading experience
Excellent English communication skills, both verbal and written
Availability to travel up to 10%
Experience with Zookeeper, RabbitMQ, Cassandra, Ansible or Docker
Experience in the financial services, payments industry or e-commerce is a plus!
Feedzai is an equal opportunity Employer

Feedzai does not accept unsolicited resumes from recruiters or employment agencies",3.6,"Feedzai
3.6","Atlanta, GA","San Mateo, CA",201 to 500 employees,2009,Company - Private,Computer Hardware & Software,Information Technology,$50 to $100 million (USD),-1
Senior Software Engineer/Cloud,-1,"At Atomwise, we invented the first deep learning neural networks for structure-based small molecule drug discovery, and we're currently deploying it in one of the largest applications of machine learning for life sciences. We work on Alzheimer's, cancer, diabetes, drug-resistant antibiotics, and other diseases. We've partnered with 4 of the top-10 US pharma companies, raised over $50M from top VCs, and have 100+ diverse projects currently running.

You should think about joining us if you care about enabling the application of machine learning to essential problems. For example, we are not constrained by latency or uptime but by scaling and parallelization. Today we can analyze more than 1 billion molecules per day, but there are about 10^24 synthetically-accessible molecules. Come help us pick up a couple of orders-of-magnitude.

Our team has over 35 Ph.D. scientists who contribute to a collaborative academic-like culture that fosters robust scientific and technical discussion. We strongly believe that data wins over opinions, and aim for as little dogma as possible in our decision making. Our team members have expertise in a wide range of disciplines--from computational chemistry and structural biology to cloud-native best practices--and we regularly have internal seminars open to anyone interested in learning about these topics.

Our Engineering team is small and growing quickly. As a result, there's plenty of opportunities for career growth and to have a significant impact on our success.

You will
Have the opportunity to learn and improve how we run machine learning at scale to deliver new drugs.
Play an essential role in designing and building cloud-based solutions consisting of 500+ CPU and GPU instances in a highly dynamic scaling environment.
Foster high-quality and adaptable software using engineering and Agile best practices.
Interact closely with our scientists (your users) to scope, design and implement software to tackle cheminformatic and machine learning problems.
Required Qualifications
Bachelor's degree in Computer Science with 4+ years of software engineering experience.
High proficiency in Python and a compiled language (e.g., C++, golang, Java, etc).
A record of designing and implementing cloud software using docker containers.
High proficiency with the Linux command-line environment.
Preferred Qualifications
Experience building and deploying batch computing workloads or microservices onto Kubernetes.
Experience implementing machine learning architectures in PyTorch or TensorFlow
Background in Biology or a related field.
Compensation & benefits
Competitive salary, commensurate with experience
Stock compensation plan you'll be an Atomwise co-owner
Platinum health, dental, and vision benefits
401k with 4% match
Flexible work schedule
Generous parental leave
Strong emphasis on collaborative learning and career development
Atomwise is not currently offering visa sponsorships for any position. Please only apply if eligible to work in the U.S.

Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.",5.0,"Atomwise
5.0",Remote,"San Francisco, CA",1 to 50 employees,2012,Company - Private,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,Unknown / Non-Applicable,-1
"Senior Software Engineer, Backend","$126K-$193K
(Glassdoor est.)","Mercari is the selling app. We make it super easy to sell (or buy) almost anything. We all have things we don't use, never used or simply outgrew. But that stuff still has value. Mercari gives you the power to simply sell it, ship it, and earn some cash for it. Fashion to toys. Sporting goods to electronics. All the brands you know and love. Our mission is simple: to make selling easier than buying. And with 45M+ downloads in the U.S. and 225k new listings every day, we're just getting started.

We are aggressively growing our Backend team to develop large-scale systems with the latest technology.

What you'll be doing:
Coding in Go and PHP
Design, develop, test, deploy, maintain, and improve the backend system for our product
Design distributed systems with microservices architecture running on Kubernetes
Work with Product Managers and Designers for the design and specification of our product
Collaborate with iOS, Android, Web, Machine Learning, and Data engineers to develop new features on our product
Collaborate with QA Engineers to test and deliver the feature with high-quality and high-speed
Solve complex performance problems and architectural challenges
Write and maintain technical documentation
Manage own project requirements, deadlines, and qualities
Mentor software engineers in the same team or project
Requirements:
6+ years of experience in software engineering
Full-time working experience as software engineer with consumer applications
Excellent knowledge of data structures and algorithms
Experience with developing complex software systems scaling to millions of users with production quality deployment, monitoring, and reliability
Experience designing, developing, and managing microservices
Knowledge of software testing and the ability to write testable code and proper tests
An insatiable desire and ability to learn with a positive attitude
Ability to collaborate with team members including Product Managers, Data Scientists, Designer, Engineers, and QA Engineers to solve complex business problems
Ability to mentor engineers in an open, respectful, flexible, and empathetic manner
Nice-to-haves:
Deep knowledge of Go or PHP
Proficient computer science background such as a bachelor's, master's, or Ph.D. degree
Strong knowledge of container and orchestration technologies like Docker and Kubernetes
Experience working on cloud infrastructures like GCP or AWS
Technologies We Use:
Databases: Cloud Spanner & MySQL
Programming Language: Go & PHP
Containers & Orchestration: Docker, Kubernetes
Web Services & Hosting: Google Cloud Platform (GCP) & Amazon Web Services (AWS)
Perks:
Competitive medical, dental, and vision insurance options
401k match
Life & disability insurance
Employee Assistance Program
New parent paid leave
Rocket Lawyer legal services
Fond perks and rewards
Commuter reimbursement
Time when you need it - flexible vacation days
Catered lunches everyday
Team outings and events",2.7,"Mercari
2.7","Palo Alto, CA","Tokyo, Japan",1001 to 5000 employees,2013,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Principal Software Engineer,-1,"Job Description
Principal Software Engineer, Clearance Required – TS/SCI w/Polygraph

Please note, this position requires all candidates to currently possess an active Top-Secret SCI Clearance with a Polygraph. This position is not an opportunity to be sponsored or nominated for a government security clearance.
The Challenge:

We encode mission critical software for our partners who analyze more than 25 petabytes of data a day. We ingest millions of signals confidentially utilizing our sensible solutions that identify and respond to attacks before they are even executed. We incorporate automated tools and cutting-edge technology that saves lives and protects property of everyday people. With our technology we are looking to refine our software to more securely protect, analyze, and increase the number of petabytes we work with.
How We Meet the Challenge:

A combination of utilizing the right people and giving them the tools, resources, support, and freedom to develop effective signal processing algorithms, excellent software, and use strong intuition on what works for a scalable system.
Minimum Qualifications:
A current Top-Secret/SCI government security clearance with polygraph is required.
At least sixteen years of general experience in computer science, computer engineering, mathematics, or a related discipline.
At least five years of experience in software-intensive projects and programs for government or industry customers.
At least five years of the experience must have been as a software engineer supporting software architecture development, requirement analysis, process execution and evaluation, selection and evaluation of COTS/GOTS tools, and integration (with both new and existing systems).
Experience in Cybersecurity and/or Cyber Defense is required.
Experience with Scripting languages (Python, Perl, Bash, Jupyter Notebook) experience is required.
Bonus Points:
Must be able to work in a team environment and collaborate well with others.
Experience in providing analytic support to operations is desired.
Experience utilizing Splunk is highly desired.
Experience utilizing containers such as Docker is desired.
Experience in software development is desired.
Experience in data science and machine learning is desired.
As a Principal Software Engineer, You Will:
Provide Analytic and Software Engineering support to CyberSecurity Operation missions by designing and implementing cybersecurity analytical solutions and developing prototype solutions using a variety of tools, APIs, frameworks and programming languages.
Be part of a robust Cybersecurity Defense development team and assist with utilizing Cybersecurity Analysis techniques to rapidly develop solutions to support emerging mission requirements.
Work closely with mission operators to identify the requirements and implement solutions for both the short and the long term.
Work in collaboration with a highly skilled development team consisting of software engineers and data scientists in DevOps/agile development environment.
Work Site: Greater Ft. Meade, MD area.

To Learn More About Our Team and Solutions, Check Out the Following:
Corporate Website: www.ssati.com
GlassDoor Page: https://www.glassdoor.com/Overview/Working-at-SSATI-EI_IE1260475.11,16.htm
Indeed Page: https://www.indeed.com/cmp/Ssati/reviews
LinkedIn Page: https://www.linkedin.com/company/ssati/
Facebook Page: https://www.facebook.com/ssati2003/
Twitter Page: https://twitter.com/ssati2003?lang=en
At Sensible Solutions and Technologies, Inc. (SSATI), we don’t just accept difference—we celebrate it, we support it, and we thrive on it for the benefit of our employees, our services, and our community. SSATI is honored to be an equal opportunity workplace. We are committed to equal employment opportunity regardless of race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or veteran status.",5.0,"SSATI
5.0","Annapolis Junction, MD","Annapolis Junction, MD",1 to 50 employees,2003,Company - Private,Computer Hardware & Software,Information Technology,$10 to $25 million (USD),-1
Senior Machine Learning Engineer,"$130K-$211K
(Glassdoor est.)","Leading the future of luxury mobility

Lucid’s mission is to inspire the adoption of sustainable energy by creating the most captivating luxury electric vehicles, centered around the human experience. Working at Lucid Motors means having a shared vision to power the future in revolutionary ways. Be part of a once-in-a-lifetime opportunity to transform the automotive industry.

We are looking for a Senior Machine Learning Engineer who enjoys thinking big and looking to make their mark on an incredibly fast-growing company. If building large and building fast, working with a very talented team of engineers, and collaborating with the brightest mind in the Automotive industry is what you like, Lucid is the best to experience it.
The Role
Work on state-of-the-art large-scale machine learning projects
Perform advanced platform research and lead the architecture design for efficient ML model training and deployment in scale
Adapt machine learning and data mining algorithms to solve problems across several teams
Develop new machine learning models using structured and unstructured data.
Perform model training, hyper parameter tuning and model parallelization and distributed training to achieve top performance for accuracy and latency.
Perform research and utilize state-of-the-art and best practices for model compression, quantization and optimization for deployment
Perform and streamline continuous model performance monitoring and debugging in production
Research and develop ML computing paradigm such as in-memory on-device or in the cloud distributed learning and employ concepts such as online learning, etc.
Articulate business questions and use mathematical techniques to translate ideas to actionable projects to arrive at an answer.
Partner with internal stakeholders on projects to identify and articulate opportunities, see beyond the data to identify solutions that will raise the bar for decision making.
Use quantitative analysis and the presentation of data to see beyond the numbers and understand what can improve our processes.
Engage broadly with the organization to identify, prioritize, frame, and structure complex and ambiguous challenges, where advanced AI projects or tools can have the biggest impact.
Qualifications
Bachelor’s or advanced degree (Masters/PhD) in computer science or STEM field.
2+ years of deploying machine learning solutions in the cloud or edge devices.
Or 4+ years of experience working as Machine learning scientist or Data Scientist collaborating on implementing end-to-end ML pipelines
Programming experience with at least one modern language such as Java, Scala, C++, C# or Python including object-oriented design
Proficiency with machine/deep learning frameworks such as TensorFlow, Keras, Pytorch, Caffe, MXNet, etc
Experience in creating production level ML models for training, validation, and inference leveraging real-time systems
Experience working with cloud-based accelerated computing, GPU/TPU, CUDA, parallel computing
Experience with major cloud computing services for model training and hyper-parameter tuning
Experience deploying containers, scaling machine learning algorithms and monitoring programmatically, using open source ML platforms or managed services.
Software development skills; unit testing, integration testing, monitoring and debugging
Critical Thinking and good communication skills
Nice to Haves
Ph.D. or Masters in Computer Science, Statistics, Operations Research or related field.
Technical expertise and in-depth knowledge in one or more of the following areas:
-- 1-Anomaly detection and signal processing
-- 2-Advanced machine learning and unsupervised learning
-- 3-Deep learning, convolutional neural networks. RNN, LSTM or Machine Vision
-- 4-Bayesian inference
-- 5-Natural Language Processing (NLP), text mining, sentiment analysis, information retrieval, etc.
Experience with model compression, quantization and optimization is a huge plus
In-depth theoretical knowledge of Statistics, traditional ML, Deep Learning, CNNs and optimization algorithms.
Experience with RESTful API design and Web based application development (e.g. ASP .NET, Javascript or C#)
Experience with analytics and big data tools (Spark, SQL, Presto, Hive) to create horizontally scalable solutions.
Technical expertise and in-depth knowledge in one or more of the following areas:

1-Anomaly detection and signal processing
2-Advanced machine learning and unsupervised learning
3-Deep learning, convolutional neural networks. RNN, LSTM or Machine Vision
4-Bayesian inference
5-Natural Language Processing (NLP), text mining, sentiment analysis, information retrieval, etc.


Be part of something amazing

Come work alongside some of the most accomplished minds in the industry. Beyond providing competitive salaries, we’re providing a community for innovators who want to make an immediate and significant impact. If you are driven to create a better, more sustainable future, then this is the right place for you.

At Lucid, we don’t just welcome diversity - we celebrate it! Lucid Motors is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, national or ethnic origin, age, religion, disability, sexual orientation, gender, gender identity and expression, marital status, and any other characteristic protected under applicable State or Federal laws and regulations.

To all recruitment agencies: Lucid Motors does not accept agency resumes. Please do not forward resumes to our careers alias or other Lucid Motors employees. Lucid Motors is not responsible for any fees related to unsolicited resumes.",3.9,"Lucid Motors
3.9","Newark, CA","Newark, CA",1001 to 5000 employees,2007,Company - Private,Transportation Equipment Manufacturing,Manufacturing,Unknown / Non-Applicable,-1
Cloud Engineer,-1,"Job Description
Responsibilities:
Develop and implement technical efforts to design, build, and deploy AWS applications at the direction of lead architects, including large scale data processing, computationally intensive statistical modeling, and advanced analytics
Participate in all aspects of the software development life cycle for AWS solutions, including planning, requirements, development, testing, and quality assurance
Provide guidance, thought leadership and mentorship to development teams to build cloud competencies
Provide innovative thought leadership around Mathematica’s cloud solutions strategy and approach, including AWS best practices and market trends
Position Requirements:

6+ years of experience architecting, designing, developing and implementing cloud solutions on AWS platforms
Demonstrated experience with designing and implementing solutions using AWS platform and tools, such as: EC2, S3, Redshift, API Gateway, Lambda, DynamoDB, CloudFormation, RDS, VPC, IAM and security, QuickSight, CloudTrail, Config, CloudWatch, SNS, AMI generation
Understanding of and experience with the five pillars of a well-architected framework
Knowledge of SQL, R, and Python for data manipulation and statistical analysis is desirable
Familiarity with federal security regulations and standards (e.g. HIPAA, FISMA, FIPS, NIST, and FedRAMP)
Experience with security, especially knowledge of FedRAMP, HIPAA, PII/PHI, is desirable
Experience in several of the following areas: database architecture, ETL, Business Intelligence, Big Data, Machine Learning, Advanced Analytics
Proven ability to work collaboratively with multi-disciplinary teams of business analysts, developers, data scientists, and subject matter experts
Strong written, verbal and interpersonal communication skills
AWS Certifications (such as AWS solutions architect or other specialty certifications) are a plus
Bachelor's degree or equivalent combination of education and experience; degree in computer science, mathematics or related field preferred
Experience with other cloud platforms like Google Cloud Platform (GCP) is a plus",4.8,"RICEFW Technologies Inc
4.8","Princeton, NJ","East Lansing, MI",51 to 200 employees,2009,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Software Engineer,"$64K-$132K
(Glassdoor est.)","Every Analyst a Scientist - One of our primary goals is to empower intelligence analysts to be able to study their data like scientists. The tools we develop focus on streamlining intelligence analysis through integrated algorithms and software that provide insight into the geopolitical landscape for use in operational intelligence missions around the world.

The Role:
As a Software Engineer, you will be part of a team that transforms large and complex customer data into real-world, high-impact solutions. You will work with researchers and engineers to design and implement solutions to challenging national security problems. You will be responsible for building the software infrastructure to clean, ingest, and expose datasets and algorithms to both developers and end users. You will deploy algorithms, generate workflows, create engineer-facing tools, and design customer-facing prototype systems. You will occasionally travel to customer sites to engage with end users, demonstrate prototypes, and integrate analytics into customer systems.

If you would like to help intelligence and defense analysts keep pace with technology-driven innovation, then this role is for you!

Who you are:
A U.S. Citizen with the ability to obtain a Security Clearance
A degree in a scientific or engineering field, such as Computer Science, Mathematics, Physics, or Software Engineering
Proficiency with a scientific programming language such as Python, Java, or C++
Experience with database management and common query syntax
Motivated collaborator and excellent communicator of ideas to both technical and non-technical audiences
Knowledge of AWS, Spark, Dask, and/or similar technologies for working with data at scale
Even better:
Active Security Clearance
Track record of architecting, developing, deploying, or maintaining enterprise software
Experience with software development best practices and tools
Understanding of web development and visualization technologies, such as d3, Leaflet, Bootstrap, or others
Familiarity with machine learning or statistical modeling techniques",4.5,"Systems & Technology Research
4.5","Woburn, MA","Woburn, MA",201 to 500 employees,2010,Company - Private,Aerospace & Defense,Aerospace & Defense,$100 to $500 million (USD),-1
"Senior/Staff Software Engineer, Data Infrastructure","$116K-$227K
(Glassdoor est.)","Senior/Staff Software Engineer, Data Infrastructure job posting

Every year, while Americans wait for their paychecks, more than $1 trillion of their hard-earned money is held up in the pay cycle. As a result, we accumulate over $50 billion in late and overdraft fees and turn to high-interest loans. Overdraft charges and bank fees often trap people in a cycle of debt that can lead to unhealthy decisions and falling victim to predatory businesses disguised as helpful services. We don't accept that.

Earnin is an app that creates products that help people gain control of their finances. Cash Out lets people get paid as soon as they leave work, with no fees, interest, or hidden costs. With Health Aid, Earnin negotiates on behalf of community members to lower their total unpaid medical bill and work out a budget-friendly payment plan. Cash Back Rewards is a way for members to earn up to 10% cash back on purchases from over a thousand local and national businesses without needing a credit card or having to reach spend thresholds to earn cash rewards — and they can withdraw the money at any time. We also offer free tools to help avoid overdrafts, to remind people when recurring bills are due, and we're working on more! There is never any required cost to use any of these products or services, users can choose to tip what they think is fair to support the service and pay it forward to keep the movement going.

Earnin is supported by funding partners including Andreessen Horowitz, Matrix Partners, Ribbit Capital, Felicis Venture, Thrive Capital, and others. Join us and help build a new financial system focused on fairness and people's needs.

You can help make a difference.

About the Team:

We are a data driven mobile financial tech company. The Data Infrastructure team builds the data services and data infrastructure that powers data science, analytics, and product development throughout Earnin. We are looking for a product-minded, self-driven Senior Software Engineer to own multiple large-scale projects that advance our mission of enabling people to gain access to their paycheck on demand.

What sets us apart:
High impact roles at a relatively small company that's aggressively growing our user base.
We are a collaborative team and genuinely enjoy working with each other.
We believe in empowering our people to be successful.
We're building a product that inspires fairness across the financial world and helps people not get taken advantage of.
As a Senior Engineer you will:
Break down complex problems into their bare essentials, translate this complexity into elegant design and create high quality, maintainable code.
Build massively scalable, production-grade data services.
Champion data quality and governance throughout the organization.
Build a world class data lake and data warehouse.
Design and develop new systems and tools to enable all of Earnin to consume and understand data faster.
Own the end to end design, build, and maintenance of platform services, data pipelines, and data products.
Implement comprehensive monitoring, logging, and alerting across our data infrastructure.
Work cross functionally with other teams (data science, design, product, marketing, and analytics) in high visibility roles as an engineering leader.
Build and deploy the data architecture that supports machine learning model development and actionable analytics.
Work with product engineering and data science teams to design scalable, performance model deployment architectures.
Communicate the tradeoffs of technical decisions to multiple stakeholders, including non-technical audiences.
Collaborate with and mentor other engineers and provide engineering direction to data scientists and analysts.
Actively engage and drive design reviews and code reviews.
Some skills we consider critical to being a Senior Engineer:
BS or MS degree in Computer Science, Engineering, or a related technical field.
8+ years of development experience in a fast-paced environment, especially startups.
5+ years of experience working with data systems.
Strong Python and SQL skills.
Strong programming and architecture skills.
Excellent written and verbal communication skills, including the ability to identify and communicate data driven insight.
Taking pride in your code quality and helping others elevate their own code quality.
Substantial experience with testing, data validation, and data quality assurance.
You can articulate the tradeoffs of different deployment architectures (e.g. streaming vs. batch vs. service-based).
Experience designing data platforms and services on cloud infrastructure, preferably AWS.
Hands-on experience designing and building large-scale solutions with the Hadoop stack and/or Spark.
Experience tuning and optimizing Spark-based applications.
Experience deploying and/or using query engines like AWS Athena, Presto, and Impala.
Experience with AWS analytical services like Redshift.
Hands-on experience working with a varied set of data storage technologies (e.g. Mysql, Postgres, DynamoDB, S3, etc.). You know where and when to use each.
Extensive experience with data modeling for multiple use cases and application styles, including NoSQL data modeling.
Experience working with data formats such as Avro and Parquet.
Experience working with alerting and monitoring tools like DataDog and PagerDuty.
Nice to haves:
You have experience building and deploying machine learning models.
You have experience using Terraform.
You have substantial experience working at a startup.
You have experience with data modeling in Redshift.
Experience with streaming infrastructure like Kafka.
Experience working with Kubernetes.
Experience building and deploying AWS Lambda applications.",3.1,"Earnin
3.1","Palo Alto, CA","Palo Alto, CA",201 to 500 employees,2012,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Senior Data Engineer,-1,"This is a Data Engineer position for supporting a Navy program located in Quantico, Virginia.

We are seeking a Data Engineer to join our team of committed technical professionals to protect those who serve against criminal, terrorism and emerging threats. Are you passionate about analytics and innovation? Our employees enjoy a fast-paced, collaborative culture and the ability to directly impact our business. You will identify technical issues and opportunities for efficiency and provide technical insights through system design and configuration perspectives. This role is both challenging and rewarding.

You will support the mission through the implementation of a modern, integrated internal data infrastructure with a focus primarily on exploiting the established data foundation to make internal and customer-centric business processes as effective and efficient as possible, laying the foundation for cognitive capabilities that can sense and respond to both internal and external customer data needs. The candidate will also focus on expanding the organization’s data ecosystem to include context-rich data while maintaining the agility needed to spark innovation.

How you will make a difference:
Establish shared operational data and integrated enterprise data, all while managing and/or improving data quality and security through the creation of business-driven governance structures and culture change management.
Establish data policies, standards, and procedures that improve data quality, availability, accessibility, security, usability, and enforcement of enterprise information management (EIM) program requirements.
Establish enterprise standards – including a uniform and repeatable system development lifecycle methodology for Reference Data and Master Data (e.g., a common set of standards for data naming, abbreviations, and acronyms).
Develop a Master Data Management (MDM) Plan that focuses on the technology, tools, and processes ensuring master data is coordinated across the enterprise. MDM is a method used to define and manage the critical data of an organization to provide, with data integration, a single point of reference. The data that is mastered may include reference data – the set of permissible values, and the analytical data supporting decision making. MDM provides a unified master data service intended to provide accurate, consistent and complete master data across the enterprise and to business partners.
Recommend solutions based on performing industry-specific analysis, such as case studies describing data management best practices, identifying trends across the industry.
Make recommendations to improve the efficiency and effectiveness in how the agency acquires, stores, manages, shares and applies its data.
Engage business users and stakeholders for the increased release of actionable high-quality data on key operational and tactical activities at NCIS.
Develop technology solutions to provide the platform, training, and standardized tools enabling querying, data mining, statistical analysis, reporting, scenario modeling, data visualization, and dash-boarding, and processes for a centralized, or analytics as a service model, allowing for the sharing of data across the enterprise from a common hub, facilitates cross-organizational data initiatives due to its enterprise-wide view of data assets and needs.
Basic Qualifications
Required: A bachelor’s or master’s degree in computer science, data science, operations research, statistics, applied mathematics, or a related quantitative field [or equivalent work experience such as, economics, engineering and physics] is [preferred/required]. Alternate experience and education in equivalent areas such as economics, engineering or physics, is acceptable. Experience in more than one area is strongly preferred.
Required: Three to six (midlevel) of relevant project experience in successfully launching, planning, and executing data science projects. Preferably in the domains of risk modelling and quality assessment.
Preferred: Specialization in text analytics, image recognition, graph analysis or other specialized ML techniques such as deep learning, etc.
Preferred: the candidates are adept in agile methodologies and well-versed in applying DevOps/MLOps methods to the construction of ML and data science pipelines.
Coding knowledge and experience in several languages: for example, R, Python, Java, C++, Excel, MATLAB, etc.
Experience with popular database programming languages including SQL, PL/SQL, others for relational databases and upcoming non-relational databases such as NoSQL/Hadoop-oriented databases such as MongoDB, Cassandra, others.
Preferred: Specialized/operational data scientists may need further high-performance computing (HPC)/compute skills; larger data science teams, in particular, may require further degrees of specialization such as:
Experience with distributed data/computing tools such as MapReduce, Hadoop, Hive, Kafka, and MySQL
Experience of working across multiple deployment environments including cloud, on-premises and hybrid environments, multiple operating systems and through containerization techniques such as Docker, Kubernetes, AWS Elastic Container Service, and others.
Experience in one or more of the following commercial/open-source data discovery/analysis platforms: RStudio, Spark, KNIME, RapidMiner, Alteryx, Dataiku, H2O, SAS Enterprise Miner (SAS EM) and/or SAS Visual Data Mining and Machine Learning, Microsoft AzureML, IBM Watson Studio or SPSS Modeler, Amazon SageMaker, Google Cloud ML, SAP Predictive Analytics.
Preferred: Expertise in solving vision, text analytics, credit scoring, and failure prediction problems.
Knowledge and experience in statistical and data mining techniques such as generalized linear model (GLM)/regression, random forest, boosting, trees, text mining, hierarchical clustering, deep learning, convolutional neural network (CNN), recurrent neural network (RNN), T-distributed Stochastic Neighbor Embedding (t-SNE), graph analysis, etc.
Strong documentation skills. Required: Certifications as per Cybersecurity Workforce Management and Qualification Manual, SECNAV M-5239.2.
Required: Eligible AND adjudicated to the Top Secret (TS SCI) clearance level is required to start.
About Inventium.io:

Inventium.io LLC is a technical consulting and software development services company dedicated to protecting and advancing our national defense and scientific capabilities. Based out of the Washington DC area, we rely on innovation to continually advance our employees' skills and provide digital transformation solutions to our customers.

With proven records of successfully delivering quality services and solutions to multiple federal agencies, our technical competencies include Emerging Technology Solutions, DevSecOps, Cloud Migration, Machine Learning, System Modernization, and Technology Management.

Benefits and Perks
Employer paid Health Benefits (Medical, Dental and Vision)
Retirement Plan
Paid Time Off and Federal Holidays
Training and Development
Employee Referral Program
Awards and Recognition",5.0,"inventium.io LLC
5.0","Quantico, VA","Washington, DC",1 to 50 employees,2016,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Senior Modeling & Simulation Engineer,-1,"Applied Research Associates, Inc. is looking for a Senior Modeling and Simulation Engineer to join our multi-disciplinary team of engineers and scientists in the Capital Area Division, located in Alexandria, VA. The ideal candidate has a passion for predicting the behavior of physical systems in challenging environments and operational impact on mission success. Models will be developed, used, and improved to support a Department of Homeland Security customer to safeguard the nation’s borders and interior from chemical, biological, radiological, nuclear, and explosive materials, equipment, technologies, and their actors. Models may be based on the underlying physics or may be process or agent based to predict operational performance and impact. Modeling and analysis may require the use and development of 3D virtual worlds or geospatial data. Models will be verified and validated, and they will be used in support of test and evaluation activities of systems intended to detect and identify threats. The candidate may participate in test and evaluation activities to support the verification, validation, and overall improvement of models. Models may become part of larger, integrated modeling and simulation activities, and may require the use of high performance computing technologies and federated simulations.

This position is contingent upon award of a contract expected in Summer 2020 supporting the Department of Homeland Security.

Required Qualifications:
Ability to program in a high level programming language, such as Fortran, C++, or Java
Eagerness to learn new tools and techniques
Strong verbal and written communication skills
Must be a U.S. Citizen with the ability to obtain and maintain a security clearance
Bachelor’s degree with minimum of 10 years of experience or greater in a physical science (physics, chemistry, biology), engineering-related discipline (nuclear, chemical, civil, mechanical, electrical), or modeling& simulation disciple (computer modeling, computational science, operations research)
Ability to present to senior leadership on the status and issues associated with research or test efforts in preparation for acquisition decision meetings
Desired Experience and Qualifications:
Experience modeling CBRNE detectors or effects
Experience using multiple software tools such as MCNP, GadRas, SWORD, ExtendSim, Arena, SolidWorks, Fluent, ArcGIS, QGIS, VisIt, ParaView, or Cubit
Experience creating 3D models of systems, i.e., CAD
Experience using high performance computers (i.e., supercomputers)
Experience developing and using discrete event or agent based models and simulations to predict and assess system performance
Experience developing machine learning models
Background in a physical science or engineering discipline, such as Physics, Chemistry, Biology, Mechanical Engineering, Nuclear Engineering
Active DoD Secret or Top Secret clearance, DoE Q clearance, or DHS Suitability
COMPANY INFORMATION:

Applied Research Associates, Inc. is an employee-owned international research and engineering company recognized for providing technically superior solutions to complex and challenging problems in the physical sciences. The company, founded in Albuquerque, NM, in 1979, currently employs over 1200 professionals. ARA offices throughout the United States and Canada provide a broad range of technical expertise in defense technologies, civil technologies, computer software and simulation, systems analysis, environmental technologies, and testing and measurement. The corporation also provides sophisticated technical products for environmental site characterization, pavement analysis, and robotics.

At ARA, employees are our greatest assets. The corporation realizes that employee ownership spawns greater creativity and initiative along with higher performance and customer satisfaction levels. ARA gives its employees the tools, training, and opportunities to take more active roles as owners. The culture is challenging; innovation and experimentation are the norm. Employees are eligible for contributions which not only add to the company’s success, but also their own through the Employee Stock Ownership Plan (ESOP). The motto,“Engineering and Science for Fun and Profit” sums up the ARA experience. For additional information and an opportunity to join this unique workplace, please visit our website atwww.ara.com.",3.5,"Applied Research Associates
3.5","Alexandria, VA","Albuquerque, NM",1001 to 5000 employees,1979,Company - Private,Federal Agencies,Government,$100 to $500 million (USD),-1
Senior Software Engineer,-1,"As a Senior Software Engineer at Crisis Text Line, you will architect, build, and scale the world’s largest free, 24/7 service for engaging with people in crisis over SMS and other messaging platforms. The technology you develop can help our trained Crisis Counselors save lives.

Location: Flexible. Ideally based in New York City, Durham, NC, the Bay area, or the Seattle area.

About our team:


Crisis Text Line has served over 140 million messages across four countries, trained more than 30,000 Crisis Counselors, and built the largest mental health conversation data set in the world. Now we’re looking to grow rapidly to provide support in other countries and languages.

Our team aspires to reflect the diverse audiences and voices that our products serve. We think that diversity of perspectives, cultures, and ideas makes everything we build better, and we aim to recruit and hire accordingly.

What you'd work on:

Our modern web platform based on Symfony, Node.js, TypeScript, and React, hosted in AWS, where thousands of people in crisis get support every day by connecting with an individual from our corps of trained volunteers
Other custom-built applications to support our volunteer base and the employees that support them
Multiple integrations with 3rd parties including Twilio, Facebook, Salesforce, Okta
Tooling for developing and serving machine learning models developed by our in-house data scientist
Requirements

We want you to:
Build. You should have 5+ years of experience developing web applications and write straightforward, well-structured code
Collaborate. We’re looking for empathetic team players who can communicate with Engineers, Product Managers, and other colleagues with kindness and clarity
Teach. You are generous with your time and experience, can mentor other engineers, and promote technical best practices
Learn. You are flexible with languages and tools and are willing to learn whatever is necessary to get the job done
Benefits
3 weeks paid vacation
12 weeks paid parental leave (applies to full-time regular employee who's been with the company for at least 6 months and experiences the birth of a child or the placement of a child for adoption or foster care)
Paid Holidays including
Standard federal holidays
Valentine's day
Your birthday
Half day on Halloween
The week between Christmas and New Years
Paid sick/safe and personal leave
Bereavement leave (in the case of death of an immediate family member)
Family or medical leave
403B retirement plan (the nonprofit equivalent of a 401K) that matches 3% of your salary
FSA and Transit Benefits
A selection of Medical and Dental plans at nominal cost to the employee and additional buy up plans if you want more coverage, and vision plans for a small fee
Professional development stipend
Staff retreats
We host 1-2 staff retreats a year for bonding and the ability to meet coworkers (face-to-face when we’re not dealing with COVID-19)
Volunteer sabbatical
4 week volunteer sabbatical after 2 years of continuous, full-time work to work with a nonprofit anywhere in the world
Crisis Text Line is an equal opportunity employer.",3.9,"Crisis Text Line
3.9","New York, NY","New York, NY",51 to 200 employees,2013,Nonprofit Organization,Health Fundraising Organizations,Non-Profit,Unknown / Non-Applicable,-1
"Senior SDE, Catalog Big Data and Machine Learning",-1,"Amazon's Catalog DataWorks team is looking for highly motivated engineers. We are embarking on multiple new initiatives to re-organize Amazon's catalog of billions of products, in new and interesting views, that drive several features Amazon's customers love. Today, these views drive hundreds of popular features like product recommendations, clustering of similar products, and shopping with Alexa. We will build a new near real-time Catalog Data Lake on AWS, to enable engineers and scientists across Amazon to solve customer problems faster. Come join us on this exciting journey!

As an engineer on this team, you will own the Catalog Data Lake end-to-end. You will work closely with business partners to synthesize technical requirements. You will design and implement significant parts of the platform. You will learn and use industry standards like Spark and Parquet as well as modern AWS offerings like EMR, Glue, Athena, and Redshift. We are fortunate to be at the cusp of innovation in both the e-commerce business as well as cloud technology. As a key stakeholder, you will constantly learn new patterns, solve key customer problems and strive to make AWS better along the way.Basic Qualifications
Bachelor's degree or higher in computer science or math is required.
Strong computer science fundamentals - algorithms, data structures and design patterns.
At least 8 years of software development experience.
At least 3 years of experience building and operating Big Data systems.
Experience mentoring, guiding and influencing peers.
Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.",-1,Amazon Corporate LLC,"Seattle, WA",-1,-1,-1,-1,-1,-1,-1,-1
Senior Software Engineer,"$107K-$209K
(Glassdoor est.)","Bluecore is a marketing technology company that's reimagining how the world's fastest growing retail brands transform casual shoppers into lifetime customers. Through our patented retail data model and the recent release of Bluecore Communicate and Bluecore Site, we replace manual processes with an intelligent, AI-driven workflow. We are credited with doubling email revenue, and increasing customer retention for more than 400 brands, including Express, Tommy Hilfiger, The North Face, Teleflora, and Bass Pro Shops. We have been recognized as one of the Best Places to Work by Glassdoor and ranked No. 241 on the Inc. 500 List, the most prestigious ranking of the nation's fastest-growing private companies.We are looking for Senior Software Engineers to work across our engineering teams to build web applications and backend systems that perform at scale. The ideal candidate is adept at writing robust, extensible, and efficient code and has a knack for solving complex problems with simple solutions. Our stack consists primarily of Python and Golang on the backend and React on the frontend. We see technology as a means to solving problems and getting things done and thus prioritize talent over existing skill set. We use Google Cloud hosted infrastructure services including Google App Engine, Kubernetes, BigQuery, and Cloud SQL. Our culture emphasizes making good tradeoffs, working as a team, and leaving your ego at the door.Responsibilities* Design, architect, and build performant, reliable, high-quality systems at scale.* Own projects end-to-end, including gathering requirements, designing, implementing, testing, deploying, and maintaining systems.* Work cross-functionally with product managers, data scientists, and engineers to deliver high quality products.* Coaching and growing junior developers through mentorship and leading by exampleRequirements* 5-8 years of relevant professional experience* B.E./B.S. in one of the following departments (i) Computer Science, (ii) Computer Engineering, (iii) Information Sciences, (iv) Electronics, (v) Mathematics or relevant field/equivalent work experience* Significant programming expertise.* Experience with languages such as Python, C++, Java, or Go is a plus.* Track record of delivering high quality products* Passion for learning new technologies and developing skills* Knack for getting things done, whether it be independently or in a team* Experience/Passion for exploring diverse fields such as Machine Learning, AI, microservice architectureBenefits:Highly competitive compensation package including salary and equity as well as the opportunity to work for one of the fastest growing marketing technology companies.* Comprehensive medical, dental, and vision insurance* 401(k) plan* Monthly discretionary reimbursement towards fitness, home office and/or Learning and Development opportunities* Generous Parental Leave & flexible vacation policyAt Bluecore we believe in fostering an inclusive environment in which employees feel encouraged to share their unique perspectives, leverage their strengths, and act authentically. We know that diverse teams are strong teams, and welcome those from all backgrounds and varying experiences.Bluecore is a proud equal opportunity employer. We are committed to fair hiring practices and to creating a welcoming environment for all team members. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, disability, age, familial status or veteran status.",4.3,"Bluecore
4.3","New York, NY","New York, NY",51 to 200 employees,2013,Company - Private,Internet,Information Technology,$25 to $50 million (USD),-1
SENIOR SOFTWARE ENGINEER & SOFTWARE ARCHITECT,-1,"Job Description
Senior Software Engineer, Software Architect
JOB SUMMARY

The Senior Software Engineer, Software Architect will develop software for Company innovative semiconductor X-Ray inspection system. The Senior Software Engineer will collaborate with Applications, QA, and Algo teams for high performance solutions and optimization per customer issues. It will be important to be comfortable working in a small company environment and a typical startup with engineers and scientists.

ABOUT THE CLIENT

Based in San Jose, California, client was founded in 2013 expressly to bring high speed inspection and metrology technology to the semiconductor packaging industry. Client founders anticipated the need to deploy inline 100% transmissive inspection into the semiconductor packaging manufacturing process and developed the company’s technology with this end in mind. The results, Client’s HR-AXI technology suite brings together the company’s unique data acquisition architecture with proprietary machine learning analysis techniques to provide customers with process monitoring and defect detection capabilities not found on any other products in the market. This job description can be updated at any time.

RESPONSIBILITIES
Designs, develops, troubleshoots, and debugs software programs for enhancements and new products, focused on creating high quality and high-performance solutions while maintaining high-level coding standards.
Develops software and tools in support of design, infrastructure, and technology platforms. Develops software solutions by studying information needs, conferring with users, and studying systems flow, data usage, and work processes
Supports hardware compatibility and/or influences hardware design based on software needs; work as part of cross-functional team to solve and implement system level problems.
Monitor application stability, performance, and availability. Promptly resolve issues impacting operations.
Work with engineering, documentation, and applications departments to ensure successful development and delivery of overall product.
Provide appropriate project feedback to management in a timely and appropriate format.
QUALIFICATIONS AND REQUIRED SKILLS
Education requirement: Bachelor’s degree in Computer Science, Electrical Engineering, or similar technical field required. Master’s or PhD strongly preferred.
Experience requirement: Minimum of 8 years of related experience working in software development.
Strong expertise in C# .NET. WCF, WPF, Database development. In addition, Python experience a plus.
Experience with Image processing algorithms implementations is a plus
Experience with software development for Factory Automation for Semiconductor equipment, a plus.
Self-starter able to think and act independently to translate general objectives into tangible results, with a record of delivering successful designs on schedule.
Demonstrated ability to organize, manage, and complete multiple assignments with challenging timelines independently and effectively.
Demonstrated analytical and problem-solving skills with high attention to detail.
Proactive approach to problem-solving. Build relationships with stakeholders to support successful design, build and testing.
Strong verbal and written communication, good attitude, and work ethic. Ability to communicate technical concepts and results clearly.
Experience with Git and Azure DevOps, a plus.",3.0,"Simple Solutions
3.0","San Jose, CA","Morgantown, WV",1 to 50 employees,2006,Company - Private,IT Services,Information Technology,Less than $1 million (USD),-1
Senior Software Engineer - Infrastructure,-1,"Freenome is looking for an experienced Senior Software Engineer - Infrstructure to help build a cloud-native machine learning platform for the world's largest multi-analyte cancer genomics dataset.As an engineering-forward biotech company, we apply modern engineering practices to build reliable, maintainable, scalable, and secure production systems for our clinical lab and Computational and Molecular Research Scientists.Our infrastructure team is a small group where you will help set the culture and build the systems that allow us to move fast without breaking things. This is an opportunity to do meaningful engineering work that will directly save lives.We value:* Rapid iteration and tight feedback loops* Continual improvement rather than disruption* Technical simplicity and elegance* A focus on the larger goals* Mutual respect and blameless postmortems* A culture of diversity and inclusionResponsibilities include:* Improving the reliability and scalability of our platform for genomic research in concert with the Software Engineers and Computational Scientists who depend on it daily* Planning for significant growth and scaling challenges as we transition from research to product development* Lending your expertise to design and code reviews* Anticipating technical scaling limits before we reach them* Continually improving our security posture* Reinforcing good development practices across the entire organizationWhat We're Looking For:* 5+ years of experience with production infrastructure, automation, and monitoring* B.S. or M.S. in computer science or a related technical field, or comparable experience* Experience in analyzing and troubleshooting distributed systems* Software design and development expertise, especially in Python* Practical knowledge of Linux internals* A systematic problem-solving approach, coupled with effective communication skills and a sense of ownership and driveNice to Haves:* Machine learning and data science tools, such as TensorFlow, PyTorch, Jupyter, or Kubeflow* Systems programming languages such as Go, Rust, or modern C++* Kubernetes, including tools such as Helm or Flux* Docker and Linux containers* Production deployment automation tools, such as Terraform or Ansible* Large-scale and/or high-performance storage systems, such as PostgreSQL, MySQL, Redis, HBase, Spanner, or Cassandra* Microservices, service meshes, or distributed tracing* Security, encryption, and certificate management* Networking, firewalls, load balancers, and HTTP internals* Monitoring, alerting, logging, and tracing tools, such as Prometheus, fluentd, or Jaeger* Data pipelines, such as Kafka, Spark, Airflow, Argo, Beam, or Flink* Google Cloud Platform experience* Experience with software in a regulated environment* Genomics or bioinformatics backgroundAbout FreenomeFreenome is on a mission to empower everyone with the tools they need to detect, treat, and ultimately prevent diseases.By applying advanced machine learning techniques to recent breakthroughs in genomic science, Freenome is developing simple blood tests to detect early-stage cancer and make treatments more effective. The company has raised $238 million from investors such as RA Capital, Polaris Partners, Perceptive Advisors, Andreessen Horowitz, funds and accounts advised by T. Rowe Price Associates, Inc., GV (formerly Google Ventures), Roche Venture Fund, Kaiser Permanente Ventures, American Cancer Society's BrightEdge Ventures, Data Collective Venture Capital, Novartis, and Verily Life Sciences (formerly Google Life Sciences).Our ScienceFreenome is building technology to gain an understanding of the body through several analytes derived from blood. These signals include cell-free DNA, methylation of cell-free DNA, cell-free RNA, circulating proteins, and immune profiling derived from thousands of prospective samples. By developing novel statistical learning methods and applying them to integrate various -omics datasets, Freenome is a leader in modeling specific biological mechanisms to capture disease dependent signatures such as gene expression, immune response, tumor burden, the tissue of origin, and 3D chromatin structure.By building comprehensive discovery datasets and modeling critical biological systems, Freenome is learning what biological changes are present within the blood between a variety of different disease states including cancer, autoimmune disorders, infections, drug response, and aging. With the combination of Freenome's datasets, cross-functional technical expertise, and mission to uncover the biological truth, we seek to positively change the lives of millions through the early detection and early treatment of disease.Our CultureFreenomers are technical and creative, visionary and grounded, empathetic and passionate. We build teams around divergent expertise, which allows us to solve problems and uncover opportunities in unique ways. Freenomers are some of the most talented experts in their fields, coming together to advance healthcare one breakthrough at a time.We value empathy, integrity, and trust in one another. That means embracing other's perspectives, those of our coworkers and those of the patients and communities we serve. It means knowing when to push, and when to listen. At Freenome, we give each other the benefit of the doubt in the belief that we're all working as a team toward the same goals, and empower others to grow in a collaborative environment.What does a successful person look like at Freenome?Those who thrive at Freenome prioritize, manage, and execute their own goals in alignment with those of the company. They embrace our values of empathy, integrity, and trust, and hold themselves and their team accountable. They crave collaboration with brilliant minds from unfamiliar fields of study and believe that hiring and mentorship are fundamental to our success. Above all, they welcome and provide constructive feedback and criticism, trusting in the good intentions of others, and secure in the knowledge that embracing mistakes is the best way to learn and move on. For those who crave challenges, understudied problems, and the chance to see their work impact the lives of millions of people affected by cancer every year, there's no better place to be.Freenome is proud to be an equal opportunity employer, we value diversity in every way. Freenome does not discriminate on the basis of race, religion, color, sex, gender identity, sexual orientation, age, non-disqualifying physical or mental disability, national origin, veteran status or any other basis covered by appropriate law.",5.0,"Freenome
5.0","South San Francisco, CA","South San Francisco, CA",51 to 200 employees,2014,Company - Private,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,Unknown / Non-Applicable,-1
Software Engineer,-1,"Perceptronics Solutions is seeking very strong candidates for the position of Software Engineer on our research and development team. In this role, you will work with a small team of highly dedicated engineers and scientists to apply cutting-edge algorithms to real-world problems and data sets and to deploy them in production quality software tools. We are seeking candidates who are particularly interested in a position that involves a mix of both software development and algorithmic research.
Responsibilities include:
Evaluate candidate technologies and standards to implement solutions
Design and integrate software modules and components
Rapidly prototype user interface test-beds to support algorithmic development.
Implement, test, and maintain customer-facing applications.
Participate in Agile planning and development of new features and system maintenance.
Minimum qualifications:
BS or MS, Computer Science, Computer Engineering
Exceptional software development skills
Strong academic training in Computer Science fundamentals (particularly algorithms, data structures, and machine learning).
Stellar communication skills (both technical details and high-level conceptual ideas).
Enjoys collaborating with small and dedicated development teams.
US Citizen with qualification to obtain a DoD security clearance.
Preferred qualifications:
In-depth knowledge of Java; experience with Kotlin, JavaScript, Python, Swift or C++ is a bonus.
Knowledge of modern development practices (Agile, object-oriented programming, test-driven development, microservices).
Experience with web application development
Perceptronics Solutions is a growing company with an excellent track record of achievement in developing technical solutions to complex problems. We hire people with a broad set of technical skills who are motivated to work on challenging problems and novel ways to interact with machines and advanced algorithms. We create cutting edge technologies in the domains of training, electronic warfare, intelligence analysis, unmanned systems, and complex planning.
We offer competitive salaries, great benefits including a top health insurance policy with employees premium 100% covered, generous PTO policy, and flexible work schedule.
AAP/EEO Statement - Perceptronics Solutions, Inc., is an equal opportunity employer and considers qualified applicants for employment without regard to race, color, creed, religion, national origin, sex, sexual orientation, gender identity or expression, age, disability, Vietnam era, or other eligible veteran status, or any other protected factor.
Job Type: Full-time
Education:
Bachelor's (Preferred)
Location:
El Segundo, CA (Required)
Work authorization:
United States (Required)
Work Location:
One location
Benefits:
Health insurance
Dental insurance
Retirement plan
Paid time off
Flexible schedule
Tuition reimbursement
Relocation Assistance Provided:
Yes
This Company Describes Its Culture as:
Innovative -- innovative and risk-taking
Outcome-oriented -- results-focused with strong performance culture
Stable -- traditional, stable, strong processes
Team-oriented -- cooperative and collaborative
This Job Is:
A job for which military experienced candidates are encouraged to apply
A job for which people with disabilities are encouraged to apply
Schedule:
Monday to Friday
Company's website:
www.percsolutions.com
Benefit Conditions:
Only full-time employees eligible
Work Remotely:
Temporarily due to COVID-19",3.8,"Perceptronics Solutions, Inc
3.8","El Segundo, CA","Sherman Oaks, CA",1 to 50 employees,2003,Company - Private,Computer Hardware & Software,Information Technology,$5 to $10 million (USD),-1
Senior Machine Learning Engineer,-1,"About Labelbox

Labelbox is building infrastructure for data science teams to manage training data for neural networks. It's easy to take for granted the existence of collaborative tools for tasks like writing and debugging code; the machine learning world has no standard tooling for labeling data, storing it, debugging models and continually improving their accuracy. Enter Labelbox. Our vision is to become the go-to software platform for data scientists to collaboratively manage their data and train neural networks, all in a tight feedback loop.

Labelbox is experiencing massive growth, and we are looking to expand our engineering team to meet the demands of our burgeoning customer base which includes companies like American Family Insurance, Lytx, Airbus, Genius Sports, Keeptruckin and others. Labelbox is venture backed by Andreessen Horowitz, Gradient Ventures (Google’s AI-focused venture fund), Kleiner Perkins and First Round Capital and has been featured in Tech Crunch, Web Summit and Forbes.

Qualifications
• Masters or PhD in CS preferred or equivalent experience
• Expert in deep learning and computer vision
• Excellent developer with experience building production-scale data pipelines and web applications in Python
• Intimate experience with deep learning frameworks (TensorFlow, Pytorch, Caffe, Keras)
• Previously built and shipped ML products

Bonus Qualifications
• PhD in Computer Science with focus on Computer Vision
• Comfortable with speaking at tech / industry conferences.

Responsibilities
• Build, implement, deploy computer vision algorithms that significantly speed up labeling
• Deliver product innovation in how teams using Labelbox are able to improve the accuracy of their model

We believe that AI has the power to transform every aspect of our lives -- from healthcare to agriculture. The exponential impact of artificial intelligence will mean that mammograms can happen quickly and cheaply irrespective of the limited number of radiologists in the world and that farmers will know the instant disease hits their crops without needing to be there in person.

We’re building a platform to accelerate the development of this future. Rather than requiring companies to create their own expensive and incomplete homegrown tools, we’ve created a training data platform that acts as a central hub for humans to interface with AI. When humans have better ways to input and manage data, machines have better ways to learn.

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.",4.0,"Labelbox
4.0","San Francisco, CA","San Francisco, CA",1 to 50 employees,2018,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Machine Learning Architect / Data Engineer / eCommerce Startup,-1,"Are you a principal/staff level data engineer interested in taking a late stage eCommerce startup to the next level? If so, a Playa startup is looking for you. With an expanding team, this company is looking for someone who has experience building data pipelines for Machine Learning. You will be automating a Machine Learning platform and building tools for Data Scientists. This company is using Python, Spark, AWS, and Kubernetes for its tech stack. If you're interested in building pipelines from the ground up, mentoring junior engineers, and growing alongside a stable organization, then this role is for you. Fully covered health insurance, 401k match, and Remote options are provided with the role.Required Skills & Experience* 4+ years of professional Data Engineering Experience* Architecture Experience* Experience building Machine Learning pipelines* 4+ years of Python, AWS, and Spark* Solid understanding of Kubernetes/DevOpsDesired Skills & Experience* Prior Software Development/API experience* Experience coordinating with Data Scientists* Bachelor's or Master's in Computer Science or MathWhat You Will Be DoingDaily Responsibilities* 100% Data EngineeringThe Offer* Competitive Pay: Up to $200,000/yearYou will receive the following benefits:* Fully covered Medical, Dental, Vision Insurance* Health Savings Account (HSA)* 401(k) matching* Competitive PTO* Remote FlexibilityApplicants must be currently authorized to work in the United States on a full-time basis now and in the future.Jobspring Partners, part of the Motion Recruitment network, provides IT Staffing Solutions (Contract, Contract-to-Hire, and Direct Hire) in major North American markets. Our unique expertise in today's highest demand tech skill sets, paired with our deep networks and knowledge of our local technology markets, results in an exemplary track record with candidates and clients.",1.6,"Management Decisions, Inc.
1.6","Playa del Rey, CA","Milwaukee, WI",1 to 50 employees,-1,Company - Public,Advertising & Marketing,Business Services,$1 to $5 million (USD),-1
Machine Learning Research Scientist - Lidar/Camera/3D,-1,"The Hyundai-Aptiv Autonomous Driving Joint Venture develops world class production-ready autonomous driving systems. The joint venture leverages Hyundai Motor Group’s design, engineering, and manufacturing expertise and Aptiv’s autonomous driving solutions to commercialize an SAE Level 4 platform for robotaxi providers, fleet operators, and automotive manufacturers.

Headquartered in Boston, the Hyundai-Aptiv Autonomous Driving Joint Venture has operations in the US and Asia. An official name for the new joint venture will be unveiled soon!

About our team: we are a diverse group of software developers that focus in providing simulation and data manipulation tools to support the development activities of our scientists, and also to enable virtual testing of our autonomous driving software before it hits the road.

We are seeking a talented and motivated Machine Learning Research Engineer or Scientist to support our efforts to automate creation of synthetic 3D environments based on real world data (camera and lidar). Your work will help us develop and roll out the next generation of advanced tools to support virtual autonomous driving tests.

What you'll do:
Design, implement, and deploy novel algorithms (re)building realistic large-scale 3D virtual environments using vision and LIDAR data, where the generated 3D environment can be used for autonomous driving simulation.
Develop processes and tools that can use sensor data (lidar+camera) to generate large-scale 3D virtual environments for a simulation platform, enabling realistic virtual tests of core autonomous driving systems.
Design, implement, and maintain software tools for simulation.
Collaborate with teams and stakeholders in offices around the world.
Use and develop state-of-the-art tools and methods to automate the 3D assets generation pipeline, making it possible to scale the process of generating 3D environments for new locations.
Work closely with various groups (e.g. perception, localization, planning and control, test and validation, etc.) to provide simulated environment solutions for their development and to test autonomous driving requirements.
Conduct experiments, write reports, patents and publications.
What you'll bring:
Masters or PhD in Machine Learning, Computer Science, Applied Mathematics, Statistics, Physics or a related field.
Experience with photogrammetry and/or point cloud meshing technologies.
Experience designing, training, and analyzing neural networks for at least one of the following applications: Object detection/classification, Image segmentation, Sensor fusion, Tracking, Multitask learning, Network compression, Reinforcement learning, Unsupervised learning.
Fluency in Python or C++.
Experience with PyTorch (preferred), TensorFlow, or other deep learning frameworks.
Experience with (1) LiDAR point cloud data & software development or (2) camera image data & software development.
Experience with 3D objects data formats and object creation pipelines.
Experience with Linux work environment, software, and toolchains.
Excellent analytical, communication, and writing skills.
Experience developing software as part of a team.
Bonus Points:
Database file manipulation using C++ / Python
Docker
Unity
Professional experience in software development for robotics systems (mapping, localization) or complex system simulations
Geographical Information Systems (GIS) tools and standards
Familiarity with CUDA, Git, CMake, continuous integration tools and the agile development process.
Hyundai-Aptiv AD LLC is an EOE. We celebrate diversity and are committed to creating an inclusive environment for all employees. To comply with Federal Law, we participate in E-Verify. All newly-hired employees are queried through this electronic system established by the DHS and the SSA to verify their identity and employment eligibility.",-1,Hyundai-Aptiv AD LLC,"Pittsburgh, PA",-1,-1,-1,-1,-1,-1,-1,-1
Data and Software Engineer,-1,"Data and Software Engineer


The Data and Software Engineer will join the engineering team of a rapidly growing and global start-up in the Alternative Data and FinTech space. You will be responsible for developing cutting edge data analytics, and AI applications as well as onboarding new datasets to be used by our Data Showcasing and PaaS Financial Technology Businesses. You will be responsible for working on numerous innovative technologies and projects that enable date vendors to accelerate their data sales and for global fundamental and quantitative investment managers to generate a higher ROI on their data purchases.

We have developed innovative, next-generation data exploring, and algorithmic testing and trading systems. This position will have the opportunity to participate in pushing your technology and knowledge skills to the next level. The learning curve never stops at CloudQuant.

Day to Day Responsibilities


• Dataset onboarding: You will work with new datasets and internal tools to bring datasets into our data driven systems. This includes mapping data to related companies and building configurations for APIs that utilize those datasets.

• Software Development: Python and C++ development projects depending upon skill set.

Compensation & Benefits:


This is a full-time salaried position with paid time-off, medical and dental benefits, and opportunities for advancement. Bonuses are paid based upon individual and company performance.

Requirements:


• Python 3 (2+ years) with understanding of Pandas, Numpy, Asyncio

• C++ with Templates (2+ years)

• Jupyter Hub / JupyterLab / Jupyter Notebooks (1+ years)

• Bachelor’s Degree – Financial or Technical

• Debugging

• GIT

• Linux

• Continuous Building and Test Systems

• Communication skills (verbal, written)

Would be great if you also have:


• Trading industry interest and/or experience (stocks, futures, FX, crypto, etc.)

• Data science/engineering experience

• Exposure to Machine learning and Recommendation Systems

• Kubernetes

• QT experience

• Javascript

• Grafana
• Airflow

Location:


Chicago, IL

About CloudQuant


CloudQuant provides alternative data showcasing services to alternative data providers including bespoke AI, Machine Learning, and data science services. Fundamental and quantitative investors utilize the cloud-based institutional-grade analytics technology and detailed backtests to quickly research alternative datasets in a novel “try-before-you-buy” data shopping experience.

CloudQuant demonstrates the value in alternative data to accelerate data sales for vendor partners and increase ROI for data purchasers.

We are Quantitative Investors, Proprietary Traders, Machine Learning Experts, Fundamental Investors, CPAs, CFAs, MBAs, PhDs, MFMs, CIOs, Data Scientists, AI Research Consultants

We are a global crowd research network.

We use and license PaaS technology solutions for Visualization, Data Science, Advanced Data APIs, Artificial Intelligence, High-Resolution Backtesting, High-Frequency Trading Engines, Machine Learning, Natural Language Processing, and Proprietary Alpha Signal broadcasting.",3.2,"Kershner Trading Group
3.2","Chicago, IL","Austin, TX",51 to 200 employees,-1,Company - Private,Investment Banking & Asset Management,Finance,$10 to $25 million (USD),-1
Signal Processing and Machine Learning Engineer - ATAS,-1,"ID: 495711
Type: Researchers
Location: Smyrna, GA
Categories: Acoustics, Algorithm Development, Artificial Intelligence, Data Analytics/Science, Health Informatics, Machine Learning, Modeling/Simulation, Signal Processing
Job Description


The Aerospace Transportation and Advanced Systems Laboratory (ATAS), Aerospace and Acoustics Technologies Division (AATD) is searching for a Signal Processing and Machine Learning engineer who can think outside of the box and is looking for a dynamic and challenging work environment. The candidate will support multiple opportunities in the Biosensing and Signal Analytics Branch (BSAB), as it relates to physiological sensing, biomedical signal processing, and machine learning, communications, tactical sensing, and related tactical applications. The role of this position is to apply technical skills to support the development of software and hardware in support of ongoing projects and support the development of new research opportunities.

Job Duties


The ideal candidate will display skills and an educational background in electrical engineering and in one or more of the following areas: signal processing, statistical signal processing, machine learning, data processing, array processing, and beamforming, acoustics, and related topics. The desired candidate should be familiar with the application of digital signal processing and machine learning to data analysis and exploration and algorithm development using modern programming techniques. Moreover, candidates should also possess familiarity with data measurement techniques, data acquisition systems and transducers, have familiarity with a laboratory environment, have excellent communication skills and be familiar with the peer-review publishing and review process.

Travel Requirements


10% - 25% travel

Education & Length of Experience


Research Engineer/Scientist I
A Bachelor's degree in Electrical and Computer Engineering, Electronic Engineering, Computer Science, Mechanical Engineering, Aerospace Engineering, or a related field of study.
Research Engineer/Scientist II
A Master’s degree in Electrical and Computer Engineering, Electronic Engineering, Computer Science, Mechanical Engineering, Aerospace Engineering, or a related field of study and three (3) years of relevant full-time experience after completion of that degree,
A Master’s degree in Electrical and Computer Engineering, Electronic Engineering, Computer Science, Mechanical Engineering, Aerospace Engineering, or a related field of study and five (5) years of relevant full-time experience after completion of a Bachelor’s degree, or
A Doctoral degree in Electrical and Computer Engineering, Electronic Engineering, Computer Science, Mechanical Engineering, Aerospace Engineering, or a related field of study.
Required Minimum Qualifications
Candidates currently enrolled in an accredited Bachelor's degree program relevant to this position will be considered. Candidate must have a graduation date of no later than December 2020
Experience in signal processing and machine learning algorithms utilized for applications
Programming experience in Matlab, Python, C, and C++
Experience with Linux and Windows and open-source software tools
Knowledgeable in version control software such as GIT
Experience with the acquisition and analysis of measured data
Good verbal and written communication skills
Self-starter and ability to work in a team environment
Preferred Qualifications
A Master or Ph.D. in Electrical Engineering or related fields
Active Secret Clearance
Record of publications and technical seminar presentations
Experience in applied ML to time series analysis and development of predictive models
Knowledge of array signal processing with emphasis on acoustic applications and infrasound
Experience in time-frequency analysis and wavelets
Experience with one or more of the following Matlab Toolboxes: Signal Processing, Statistics and Machine Learning, Phased Array, Wavelets
Experience managing research projects, making technical presentations, and report writing
U.S. Citizenship Requirements


Due to our research contracts with the US federal government, candidates for this position are required to be US Citizens.

Clearance Type Required


Ability to obtain Secret Clearance upon hire

Diversity & Inclusion


Diversity & Inclusion (D&I) at Georgia Tech Research Institute aims to enhance the Institute’s mission of solving the world’s most complex technical problems by creating a workforce with a shared appreciation for diversity, raising awareness around inclusiveness, and fostering a sense of belonging and appreciation for all members of our community.

Equal Employment Opportunity


Georgia Tech Research Institute is an Equal Opportunity Employer of individuals with disabilities and protected veterans and actively seeks diversity among its employees. Equal Employment Opportunity is the Law.

Posted: 06/15/2020
Closes: 09/15/2020",3.6,"Georgia Tech Research Institute
3.6","Smyrna, GA","Atlanta, GA",1001 to 5000 employees,1943,Subsidiary or Business Segment,Research & Development,Business Services,$100 to $500 million (USD),"MIT Lincoln Laboratory, Johns Hopkins University Applied Physics Laboratory"
"Big Data Engineer, Sr Principal","$127K-$214K
(Glassdoor est.)","Description
Position Description:

The Vanguard 2.2.1 contract currently has an opening for a Data
Architect/Scientist to support the Department of State (DoS) Bureau of
Information Resource Management (IRM) Artificial Intelligence and Emerging
Technologies Directorate. This program develops leading-edge technologies and
delivers innovative solutions to the DoS. SAIC is seeking a highly qualified
Data Architect/Scientist to support the various initiatives; Artificial
Intelligence, Machine Learning, consolidation and centralized data lake for
various Splunk platforms, IaaS, PaaS, and SaaS initiatives within the Amazon,
Google, and Microsoft cloud environments. The preferred candidate will develop
solutions utilizing quantitative analysis, predictive analytics, data modeling,
data lake design, and machine learning in support of the DoS mission.
REQUIRED SKILLS:
Experience in applying
Database Design, Data Lake, and Data Mining principles within virtual, cloud,
and hybrid cloud environments.
Familiar with Big Data
Architecture (Hadoop, Cloudera, Spark), distributed system, data warehousing
(example: Apache Hive), and Data Lakes
Experience with
Infrastructure as a Service, Platform as a Service and Software as a Service
within at least one of the 3 major cloud providers (Amazon, Google, or
Microsoft)
Strong Technical Skills in
MS SQL, MySQL, PostgreSQL, or MongoDB
Programming languages -
XML, JavaScript, Python
Strong development,
debugging, testing and troubleshooting skills.
Experience with Splunk
and Tableau
Experience with data
modeling, predictive analytics, quantitative analysis, data lake design,
machine learning
Experience with database
security hardening processes in a Government environment
Experience with shell
scripting
Experience with Agile,
Scrum, DevOps process
Proficient working within
Windows and Linux Operating Systems
DESIRED SKILLS:
Team oriented approach
and capable of working independently
Mission/customer driven
solution architect
Ability to integrate
customer vision/mission with emerging technologies
Excellent oral and
written communication skills
Excellent analytical and
troubleshooting skills
Qualifications

TYPICAL EDUCATION AND EXPERIENCE: Bachelors and eight (8) years or more experience; Masters and five (5) years or more experience",3.7,"SAIC
3.7","Springfield, VA","Reston, VA",10000+ employees,2013,Company - Public,Enterprise Software & Network Solutions,Information Technology,$5 to $10 million (USD),"Booz Allen Hamilton, CACI International"
Algo Software Engineer (C++/Python),"$141K-$180K
(Glassdoor est.)","At HRT, we program computers to intelligently trade on the stock market. We make the world's markets more financially efficient using smart algorithms. To get the job done, we hire some of the smartest computer scientists in the world to develop both our low latency trading platform and our massive distributed research platform.

Algo Software Engineers (AE) are programmers that are embedded in HRT's trading teams and work hand-in-hand with Algo Strategy Developers (AD). Whereas ADs tend to use their math skills to make smarter strategies, AEs focus on the software that powers trading and research. Because of this close collaboration, AEs tend to be the type of engineers that thrive on constant interaction and discussion. Hearing how their most recently deployed system allowed for whole new types of research would make their week. AEs are the type of engineers that don't mind juggling a few projects at once and have a varied portfolio of project types, from long-term ambitious new systems to fire-fighting live issues.

Our environment is particularly well suited to driven, self-motivated programmers. For one, the company's Partners are all programmers. Team Leads spend a majority of their time doing technical work. Algo teams run on a very bottom-up approach that encourages everyone on the teams to come up with ideas and dictate the direction of each team together. Finally, there is very little emphasis placed on project management process (almost no meetings and no project managers) and there is a lot of emphasis placed on engineering process such as automated testing, design/code reviews, and technical training.

We are a Linux/Unix shop with a codebase written primarily in C++ and Python. If you are not a C++ or Python or Linux expert, that's probably OK. We really care more about your technical fundamentals, practical experience and that intense desire to make things better for other people. That being said, we want someone who is familiar with a non-scripting language such as C++ or Java.

Here are a few examples of programmers who are currently AEs at HRT:
When he's not solving riddles and dancing salsa, David's writing distributed computing APIs. He regularly solves bugs like ""one out of a million jobs are dying on only these machines and only on Tuesdays"". He likes bridging the gap between Algo Strategy Developers and Systems Engineers to explore how to use distributed computing to run research. He really enjoys coming up with ways to make millions of jobs more efficient.
Kai came to HRT after 3.5 years of programming C++ at a company that provides large amounts of data to the finance industry. He plays several musical instruments and has tasted thousands of wines, yet he finds his work to be an even more rewarding experience. He builds tools to discover opportunities and aid live trading. He is excited about automating strategies and implementing ideas from his teammates, in addition to applying his technical skills to the world of trading.
Aaron started programming at age 5 and previously ran the research team at a music software company, bringing over 7 years of experience to HRT. He cooks and practices partner acrobatics in his free time. He gets joy from his teammates' happiness when their research runs twice as fast, from building them tools that help them visualize their strategies, and from keeping code organized and maintainable. He's gotten coworkers from other teams involved in latency improvements to his group's live trading. He enjoys the collaborative environment and learning from his coworkers.
Culture:
Hudson River Trading (HRT) brings a scientific approach to trading financial products. We have built one of the world's most sophisticated computing environments for research and development. Our researchers are at the forefront of innovation in the world of algorithmic trading.

At HRT we come from all sorts of backgrounds: mathematics, computer science, statistics, physics, and engineering. We're a community of self-starters who are motivated by the excitement of being at the cutting edge of automated trading. Our culture celebrates great ideas whether they come from HRT veterans or new hires. At HRT we're friends and colleagues, whether we are sharing a meal, playing the latest board game, or writing elegant code. We embrace a culture of togetherness that extends far beyond the walls of our office.

Seem like something you might be interested in? Our goal is to find the best people and bring them together to do great work in a place where everyone is valued. HRT is proud of our diverse staff; we have offices all over the globe and benefit from our varied and unique perspectives. HRT is an equal opportunity employer; so whoever you are we'd love to get to know you.",5.0,"Hudson River Trading
5.0","New York, NY","New York, NY",201 to 500 employees,2002,Company - Private,Financial Analytics & Research,Finance,Unknown / Non-Applicable,-1
Data Engineer,-1,"Immediate need for a talented Data Engineer with experience in the Energy/Utility Industry. This is a 12+ Months Contract opportunity with long-term potential and is located in Charlotte, NC. Please review the job description below,

Job ID: 20-20310

Key Responsibilities:
Our client is looking for a highly skilled ‘Data Engineer’ who has a passion for all things data.
• You will be responsible for data architecture, building data pipelines using ETL tools, provide data to the data scientist, and participate in the re-training of machine learning models.
• You will be an integral member of our product teams, working very closely with architects and software engineers on different layers of the infrastructure and design.
• You will be developing both on-prem and cloud solutions.

Key Requirements and Technology Experience:
• Bachelor’s degree in computer science, Information Systems, or related discipline; or 6 years of prior equivalent work-related experience in lieu of a degree.
• Must have leadership skills to lead and deliver projects, be proactive, take ownership, interface with business, represent the team, and spread the knowledge.
• Experienced in ETL Tools (SSIS, Kafka, Sqoop, Informatica, NiFi).
• Expert SQL knowledge (All types of Joins, CTE’s, Indexes, Stored Procedures, SQL performance).
• Should have a knowledge feedback loop into Model Re-Training (Data and model pipelines).
• Should be able to work with the MLOps to build data pipelines to model executions.
• Experience in Python & PySpark using Spark Client, Spark DL, Hive.
• Experience in data ingestion from various data sources like SQL Server, Oracle, Hive, etc.
• Good knowledge in Git, GitHub, Bitbucket.

Our client is a leading Energy/Utility Industry and we are currently interviewing to fill this and other similar contract positions. If you are interested in this position, please apply online for immediate consideration. #cha",3.7,"Pyramid Consulting, Inc
3.7","Charlotte, NC","Alpharetta, GA",1001 to 5000 employees,1996,Company - Private,Computer Hardware & Software,Information Technology,$100 to $500 million (USD),"TEKsystems, Collabera, Artech Information Systems"
"Analytics, Data Engineer Retail Finance | RI - Woonsocket",-1,"POSITION SUMMARY:

You will partner with business partners to identify opportunities to leverage big data technologies in support of Pharmacy Operations and Retail Finance with a common set of tools and infrastructure to make analytics faster, more insightful, and more efficient. You will build and architect next-generation Big Data machine learning framework developed on a group of core Azure and Hadoop technologies. You will design highly scalable and extensible Big Data platforms which enables collection, storage, modeling, and analysis of massive data sets from numerous channels. You will define and maintain data architecture, focusing on applying technology to enable business solutions. You will assess and provide recommendations on business relevance, with appropriate timing and deployment. You will perform architecture design, data modeling, and implement Big Data platforms and analytic applications. You will bring a DevOps mindset to enable big data and batch/real-time analytical solutions that leverage emerging technologies. You will develop prototypes and proof of concepts for the selected solutions, and implement complex big data projects. You will apply a creative mindset to a focus on collecting, parsing, managing, and automating data feedback loops in support of business innovation.

Data Engineer Job Responsibilities
Expanding and optimizing data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. Work closely with business partners, data scientists, and UI developers in order to transform data into a format that can be easily analyzed.
Fundamental Components:
Extract information from databases to prepare and analyze data.
Perform data wrangling/cleansing techniques to conduct statistical analysis and identifying key insights for decision makers.
Create and maintain optimal data pipeline architecture from various databases that include Oracle DB, Teradata, On-Prem Hadoop, Azure Data Lake, etc.
Identify, design and implement internal process improvements: automating manual processes, optimizing data delivery and re-designing infrastructure for greater scalability.
Learn quickly and take on new challenges.
Background Experience:

Required Qualifications
Hands-on experience with “big data” platforms including Hadoop and Spark as well as experience with traditional RDBMS (eg, Teradata, Oracle).
Proficiency in “big data” technologies including MapReduce, Spark, Airflow, Kafka, Hbase, Pig, NoSQL databases, etc.
Proficiency in the following programming languages: Python, Pyspark, shell scripting, SQL (preferably Teradata and PL/SQL syntax) and Hive.
Ability to design and build a framework to orchestrate data pipelines and ML models.
Familiarity with data modeling and data architecture concepts.
Knowledge of workflow and configuration management tools such as Conda, H2O, Airflow / Oozie / Jenkins, and Git.
Proficient in Software Engineering Techniques, Software Engineering Architecture, Software Engineering Life cycle and Data Management.
Experience in Business Analysis, Business Knowledge, Software Engineering, Architecture Knowledge and Technical Solution Design.

Preferred Qualifications
Design and implement end-to-end solutions using Machine Learning, Optimization, and other advanced computer science technologies, and own live deployments.",-1,HopHR,"Woonsocket, RI","San Ramon Village, CA",1 to 50 employees,-1,Company - Private,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
Spacecraft and Launch Vehicle Battery Technology Research Scientist / Engineer,"$84K-$173K
(Glassdoor est.)","Requisition ID: 53481

All Locations: El Segundo, CA (California)

A trusted partner. A national resource. A leader in national security space. We are THE Aerospace Corporation. A team that takes pride in our readiness to solve some of the most complex technical challenges in existence. With challenges spanning clandestine to commercial, you’ll have the unique opportunity to work on projects that are literally evolving our nation's space and launch capabilities. We all share a common passion and aspiration – to serve a mission much bigger than ourselves. When you join our team, you’ll be part of a rare collection of thought leaders and game-changing innovators. Are you ready to launch your career?
Responsibilities
Energy Storage Technology section of the Energy Technology Department focuses on battery and energy storage technology for spacecraft and launch vehicle applications. The department performs independent research, verification, and validation of battery and cells for spacecraft and launch vehicles. Our multidisciplinary staff provides research and development, technical oversight, and evaluation of energy storage systems to support acquisition, launch, and operations of launch vehicles and spacecrafts. We provide laboratory capabilities and maintain strong links to the U.S. and international space battery community.

Key Functions
Initiates, plans, and conducts research and development projects to resolve complicated energy storage, battery, and battery material related technical problems
Devises new approaches to energy storage and battery technology, modeling, data analysis, test and evaluation, verification, battery management system, and application of machine learning
Systematically reviews prior arts and publications and presents new relevant developments to the team
Actively interacts with staff, management, and technicians to execute projects. Frequent intra and inter-organizational communication
Performs data analysis, conducts tests, develops details of specifications, prepares detail reports, assists in planning and development of studies and research projects
Participates in development of battery testing and evaluation systems
Assists in technology planning and development; performs testing and evaluation of materials and devices
Qualifications
Required
Bachelor’s or Master’s degree in Electrochemistry, Chemistry, Chemical Engineering, Physical Chemistry, Materials Science Engineering, or related fields with ≥ 3 years of professional research/work experience in one of these areas
Experience in lithium based electrochemistry for batteries
Experience using laboratory instruments, analytical instruments, software and data acquisition systems
Highly motivated and goal oriented, with strong interpersonal skills and an ability to work in inter-organizational and inter-disciplinary teams
This position requires the ability to obtain and maintain a security clearance, which is issued by the U.S. government. U.S. citizenship is required to obtain a security clearance
Preferred
Ph.D. in above-mentioned areas
Ability to obtain SCI clearance
Technical leadership experience (project lead, program management, etc.)
Transcript Requirement
Transcripts are required for this position.

Additional Requisition Details

System Job Title: MEMBR-TCH STF SR

Clearance Requirement: Secret

Access: None

Polygraph: None

Relocation Available: Yes

Employment Type: Regular

Work Schedule: Full Time

Company Statement

The Aerospace Corporation has provided independent technical and scientific research, development, and advisory services to national security space programs since 1960. We operate a federally funded research and development center (FFRDC) for the United States Air Force and the National Reconnaissance Office, and support all national security space programs. We also apply more than 50 years of experience with space systems to provide critical solutions to technologically complex systems in such areas as communications, shipping, law enforcement, and cyber, among others.

From our inception, our highly skilled technical staff has focused on ensuring the success of every mission and developing the most effective and economic space-related hardware and software in the world. Our greatest asset is the technical expertise of our people. Our state-of-the-art laboratory facilities are staffed by some of the leading scientists in the world.

Equal Opportunity Commitment

The Aerospace Corporation is an Equal Opportunity/Affirmative Action employer. We believe that a diverse workforce creates an environment in which unique ideas are developed and differing perspectives are valued, producing superior customer solutions. All qualified applicants will receive consideration for employment and will not be discriminated against on the basis of race, gender, gender identity or expression, color, religion, national origin, sexual orientation, protected veteran status, or disability status.

You can also review The Equal Employment Opportunity is the Law poster and the supplement, as well as the Pay Transparency Policy Statement.

Nearest Major Market: Los Angeles
Job Segment:
Chemistry, Scientific, Research Engineer, Research Scientist, Engineer, Science, Engineering",3.9,"The Aerospace Corporation
3.9","El Segundo, CA","El Segundo, CA",1001 to 5000 employees,1960,Nonprofit Organization,Aerospace & Defense,Aerospace & Defense,$1 to $2 billion (USD),-1
"Sr Software Development Engineer - Machine Learning, Alexa AI","$142K-$221K
(Glassdoor est.)","The main responsibilities for this position include:
· Develop scalable architecture for conversational dialogue platform with continuous learning capabilities
· Build technical strategy for integrating business policies with machine learned models to best fulfill a customers intent, crossing multiple skills and service providers
· Develop approaches for fast inference for conversational models to reduce user perceived latency
· Audit and influence the design for storing and accessing context collected from heterogeneous sources first-party domain verticals, third-party skills, explicit & implicit user preferences
· Develop multi-turn dialog strategies inclusive of representations for how developers can easily integrate their services/capabilities into Alexa with minimal code authoring
· Develop offline and online machine learning modeling architecture for fast, scalable supervised, semi-supervised, and unsupervised learning from heterogeneous data sources live interaction data, catalogs, knowledge bases, etc.
· Contribute to the architecture for running large-scale end-to-end A/B testing for a complex AI system like Alexa that has multiple ML-based stochastic decision-making steps before giving a response to the user.
Strong candidates will have the following experience:
• Deep technical experience with real-world Spoken Language Systems and/or Web Search
• Industry luminary who can attract top science and engineering talent
Ability to work with multi-disciplinary, geographically distributed team of machine learning scientists, software developers, product managers, data specialists, etc.


Basic Qualifications

· 3+ years of programming experience with at least one modern language such as Java, C++, or C# including object-oriented design
· 2+ years of experience contributing to the architecture and design (architecture, design patterns, reliability and scaling) of new and current systems
· 4+ years of professional software development experience
· 10+ years of industry experience developing scalable architecture
· Bachelors/MS/PhD in Computer Science or other Engineering, Math or Science Disciplines or equivalent years of experience


Preferred Qualifications

· Proven track record of scalable engineering systems in real-world applications /products
· Excellent written and verbal communication skills with the ability to present complex information in a clear and concise manner to a variety of audiences
· Ability to think strategically and create long-term roadmap",3.9,"Amazon
3.9","Sunnyvale, CA","Seattle, WA",10000+ employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),"Google, Microsoft, Walmart"
Geospatial Engineer,"$41K-$70K
(Glassdoor est.)","Geospatial Engineer
Cambridge, MA
Comprehensive Salary and Relocation Package Offered
Geospatial Engineer will join a team that works closely with crop scientists, data scientists, bioinformaticians, and quantitative geneticists to solve problems at the intersection of breeding, gene editing and agronomy. You will help develop and scale our computational/data science, data processing, storage and overall software platforms.
Geospatial Engineer Responsibilities:
Develop applications that operate on GIS and/or spatial data.
Work with breeders and scientists to develop tools to enable our crops team to make decisions.
Build APIs to make data, models and general system functionality accessible to data scientists for model development and analytics
Partner with data scientists, plant breeders and agronomists to develop, scale and manage machine learning models and their pipelines.
Develop and productionalize data pipelines or other custom applications that integrate with and extend our breeding, phenotyping, field trial analytics, and overall agronomic data platforms to process spatial and environmental data sets.
Develop robust integrations with strategic third party tools, platforms and models.
Contribute to design and roadmap for overall computational platform.
Collaborate x-functionally with data scientists, agronomists, breeders, crop product managers, and software engineering team at large to continuously improve and scale our ability to generate, process, and analyze data and conduct cutting-edge research.
Geospatial Engineer Requirements:

Minimum of a Bachelor’s degree in Computer Science or a related field.
Experience with working with GIS/spatial datasets and interested in developing applications that are data-driven.
Significant experience with professional software engineering, including automated testing, agile methodologies, pair programming, refactoring, relational databases, and microservices.
Experience building computational pipelines for front-end products.
Extensive experience extracting, modeling, and manipulating data: sql / nosql.
Extensive experience with object oriented programming: Python, Go, Scala, or Java.
Ability to work in a fast-paced, x-functional environment and handle ambiguity gracefully.
Geospatial Engineer Preferred Qualifications:

Experience with AWS tools, DevOps, infrastructure-as-code, containerization, and Kubernetes.
Experience working with agricultural, remote sensing, weather, or other data which is spatial & temporal in nature; experience with crop modeling or environmental simulation.
Experience with clustering algorithms, soil and weather data.
Experience with simulation, predictive, machine learning models.",4.9,"Hunter International
4.9","Cambridge, MA","Avon, OH",201 to 500 employees,2006,Company - Private,-1,-1,Unknown / Non-Applicable,-1
"Software Engineer, Lead: Big Data for Machine Learning Product Platform","$88K-$171K
(Glassdoor est.)","As an experienced member of our Software Engineering Group we look first and foremost for people who are passionate around solving business problems through innovation & engineering practices. You will be required to apply your depth of knowledge and expertise to all aspects of the software development lifecycle, as well as partner continuously with your many stakeholders on a daily basis to stay focused on common goals. We embrace a culture of experimentation and constantly strive for improvement and learning. You'll work in a collaborative, trusting, thought-provoking environment-one that encourages diversity of thought and creative solutions that are in the best interests of our customers globally.* BS/BA degree or equivalent experience* Solid experience in building data-intensive systems with good understanding of performance tradeoffs* Experience in Test Driven Development and Agile Software Development with CI/CD* Ability to work in large, collaborative teams to achieve organizational goals, and passionate about building an innovative culture* Proficiency in at least 2 of the modern programming languages: Java, Scala, Python, C++* Advanced experience in Big Data Technology with Hadoop, Spark, Flink* Mindset to work with highly sensitive data and appropriate controls framework.* Experience with data management, manipulating large data sets through statistical software and data warehousing environments processing large volume of transactions.* Ability to work in large, collaborative teams to achieve organizational goals, and passionate about building an innovative culture* Collaborate with product owners, data scientists, engineers, end users, and other stakeholders to build data product platformHighly Desirable Skills:Kafka, GraphQL API, Panda, Jupyter, Gaia, AWSCIB (Corporate & Investment Bank)Our Corporate & Investment Bank relies on innovators like you to build and maintain the technology that helps us safely service the world's important corporations, governments and institutions. You'll develop solutions for a bank entrusted with holding $18 trillion of assets and $393 billion in deposits. The Corporate & Investment Bank provides strategic advice, raises capital, manages risk, and extends liquidity in markets spanning over 100 countries around the world.When you work at JPMorgan Chase & Co., you're not just working at a global financial institution. You're an integral part of one of the world's biggest tech organizations. In our global technology centers, our team of 50,000 technologists design, build and deploy everything from enterprise technology initiatives to big data and mobile solutions, as well as innovations in electronic payments, cybersecurity, machine learning, and cloud development. Our $11B annual investment in technology enables us to hire people to create innovative solutions that are transforming the financial services industry.At JPMorgan Chase & Co. we value the unique skills of every employee, and we're building a technology organization that thrives on diversity. We encourage professional growth and career development, and offer competitive benefits and compensation. If you're looking to build your career as part of a global technology team tackling big challenges that impact the lives of people and companies all around the world, we want to meet you.",3.9,"JPMorgan Chase & Co.
3.9","New York, NY","New York, NY",10000+ employees,1799,Company - Public,Investment Banking & Asset Management,Finance,$10+ billion (USD),-1
Software Development Engineer - Alexa AI,"$119K-$149K
(Glassdoor est.)","Alexa is the groundbreaking cloud-based intelligent agent that powers Echo and other devices designed around your voice. Our mission is to push the envelope in Artificial Intelligence (AI), Natural Language Understanding (NLU), Machine Learning (ML), Dialog Management, Automatic Speech Recognition (ASR), and Audio Signal Processing, in order to provide the best-possible experience for our customers. Were looking for a Software Development Engineer to help build industry-leading conversational technologies that customers love.


As a Software Development Engineer for the Alexa team, you will be responsible for translating business and functional requirements into concrete deliverables with the design, development, testing, and deployment of highly scalable distributed services. You will also partner with scientists and platform engineers to help invent, implement, and connect sophisticated algorithms to our cloud based engines. A successful candidate should have knowledge of research domains including AI, NLU, ML, and Dialog Management. They should also be very agile in developing flexible software with respect to scientific, experimentation methods and usage patterns. Additional responsibilities include:

· Developing and maintaining core system features
· Helping define product features, drive the system architecture, and spearhead the best practices that enable a quality product
· Working with scientists and other engineers to investigate design approaches, prototype new technology, and evaluate technical feasibility
· Operate in an Agile/Scrum environment to deliver high quality software against aggressive schedules s


Basic Qualifications

· 2+ years of non-internship professional software development experience
· Programming experience with at least one modern language such as Java, C++, or C# including object-oriented design
· 1+ years of experience contributing to the architecture and design (architecture, design patterns, reliability and scaling) of new and current systems.

· Bachelor's degree in Electrical Engineering, Computer Sciences, Mathematics, or related technical field
·
· Knowledge of programming languages such as C/C++, Java, Perl or Python and open-source technologies (Apache, Hadoop)
·
· Experience with OO design and common design pattern
·
· Knowledge with data structures, algorithm design, problem solving, and complexity analysis
·
· Experience defining system architectures and exploring technical feasibility trade-offs



Preferred Qualifications


· Master's in Electrical Engineering, Computer Sciences, Mathematics, or related technical field
·
· Experience developing cloud software services and an understanding of design for scalability, performance and reliability
·
· Experience optimizing for short term execution while planning for long term technical capabilities
·
· Ability to prototype and evaluate applications and interaction methodologies
·
· Ability to produce code that is fault-tolerant, efficient, and maintainable
·
· Academic and/or industry experience with standard AI and ML techniques, NLU, and scientific thinking
·
· Experience working effectively with science, data processing, and software engineering teams
·
· Ability and willingness to multi-task and learn new technologies quickly
·
· Written and verbal technical communication skills with an ability to present complex technical information in a clear and concise manner to a variety of audiences



Amazon is an Equal Opportunity Employer Minority / Women / Disability / Veteran / Gender Identity / Sexual Orientation / Age",3.9,"Amazon
3.9","Sunnyvale, CA","Seattle, WA",10000+ employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),"Google, Microsoft, Walmart"
Principal Data Scientist,"$107K-$171K
(Glassdoor est.)","Please note, this is a proactive search for a role that has been vetted by our leadership team for future hiring.  The recruiting team and hiring managers remain active in discussions with interested, qualified individuals and are committed to being transparent on timelines throughout the process. Thank you.

Who We Are:


Vistaprint’s Data and Analytics (DnA) organization is working to make our company one of the world’s most well-known and successful data-driven companies. The cross-functional team includes product owners, analysts, technologists, data engineers and more – all focused on providing Vistaprint with information and tools we can use to deliver jaw-dropping customer value. DnA team members are empowered to learn new skills, communicate openly and be active problem-solvers.

About Our Team:


As the Principal Data Scientist, you will be a “go-to” domain specialist in data science and machine learning. You will lead the charge on innovative work, mentoring more junior data scientists, and guiding the organization on methodology and the best ways to work. You will also guide high-profile projects - not just delivering solutions, but finding opportunities and owning the work. Your statistical, computer science and business domain expertise will have a significant influence on our business.

You will join a core team of Data Scientists, working with Marketers, Analysts, Engineers and Product Owners to forge new paths and redefine how data is utilized to deliver value!

What You Will Do:
Engage with partners to advise on analytical project requirements, discuss methodologies and collaborate on work you're doing.
Learn, practice, and lead others to use new tools in an inspiring technical environment that combines both coding skills, web technologies and real-time data.
Analyze pre-existing models and algorithms; suggest how to improve the efficiency and effectiveness, to drive value to the organization
Deliver a range of custom Data Science projects that may include Recommendation Systems, Price Optimization; Time Series Modeling; Customer Lifetime Value Customer, Propensity Modeling); Image Recognition; The list goes on.
Be a thought leader within the Data Science team, knowing the latest trends and technologies
Your Qualifications:


PhD in Statistics, Mathematics, Operational Research or similar field
Extensive machine learning and modeling experience, and have delivered multiple projects as a lead scientist or in a similar capacity
Strong programming skills in Python and R
Hands-on experience using “big data technologies”
Experience using standard libraries (scikit-learn, MLlib, TensorFlow, MXNet, PyMC3)
Experience of software engineering techniques including version control, continuous integration, unit testing.
Proven ability to independently communicate technical and statistical concepts to non-practitioners within the business, and influence the application.
Experience of designing and building DS products for ecommerce like recommendation systems, forecasts, Customer Lifetime Value Models, etc.
Nice to Have:


Spark, Java, Scala
Bayesian Statistics
Agile working methodology


Why You’ll Love Working Here:


At Vistaprint, we put great importance into the wellbeing of our employees, which is why we offer perks that ensure a phenomenal work/life balance. Perks include flexible schedules, work from home capabilities, and very generous time off, including our unique sabbatical-like program, “Vistabreak”, to name a few! Here in Waltham, we offer a modern and collaborative office environment with a free on-site gym, fully stocked kitchens, and cold brew on tap.

About Us:


As an e-commerce powerhouse, Vistaprint is a dynamic organization that maintains an exciting, entrepreneurial culture. With founder Robert Keane’s return as CEO, we’ve renewed our focus on empowering and helping small businesses. To do this, we create customer value (and delight) through accessible, cutting-edge technology. We thrive on providing opportunities for exploration, collaboration, innovation and growth – for both our customers and our team.

Equal Opportunity Employer:


Vistaprint, a Cimpress company, is an Equal Employment Opportunity Employer. All qualified candidates will receive consideration for employment without regard to race, color, sex, national or ethnic origin, nationality, age, religion, citizenship, disability, medical condition, sexual orientation, gender identity, gender presentation, legal or preferred name, marital status, pregnancy, family structure, veteran status or any other basis protected by human rights laws or regulations. This list is not exhaustive and, in fact, in many cases, we strive to do more than the law requires.

#LI-KM1

Nearest Major Market: Waltham
Nearest Secondary Market: Boston
Job Segment:
Database, Scientific, Scientist, Engineer, Computer Science, Technology, Engineering, Science",3.5,"Vistaprint
3.5","Waltham, MA","Venlo, Netherlands",5001 to 10000 employees,1995,Company - Public,Other Retail Stores,Retail,$1 to $2 billion (USD),"Tripadvisor, Wayfair, Amazon"
Frontend Software Engineer - UI/UX Development and Design,-1,"Are you a Frontend Software Engineer who loves to create beautiful software design in an engaging environment?. We are looking for exceptional web developers with strong software engineering chops and solid UI/UX design skills to join our front-end development team.

You will design and develop innovative user interfaces and information visualizations for a growing web application to help our end users make sense of their challenging problems. This position is unique among front-end development positions in that you will be responsible for building and maintaining a front-end codebase that is used across many products at the company. This requires a keen focus on keeping the interface intuitive while still enabling all of the powerful data analysis tools necessary to slice and dice a problem.

You will work with our superlative team that includes Systems Engineers, Mathematicians, Computer Scientists, UI/UX Designers, and Developers. Solving fun and challenging problems is in our DNA - at CCRi, we only take on interesting projects.

Requirements

Are dedicated to designing and building superb user interfaces

· Have strong experience with JavaScript, HTML, and CSS

· Have experience developing and iterating on mockups, translating these to style and code

· Have excellent debugging and problem-solving skills

· Have a strong visual design sense and appreciation for developing a stellar user experience

· Enjoy researching and testing the latest and greatest technologies

· Have the ability to multitask, prioritize, and respond quickly in a fast-paced environment

· Learn quickly and want to share knowledge

· Enjoy working in an exciting, dynamic environment with a great team of intelligent co-workers

· Bachelor’s Degree in a technical field with at least 3 additional years of related professional experience

· US citizenship required

Bonus points if you also:

· Use Angular, or have experience with other JS frameworks

· Have experience writing in TypeScript

· Have experience with css pre-processors (Stylus, LESS, SASS, etc)

· Use data visualization tools/toolkits such as d3 or similar libraries

· Have experience developing map based applications using OpenLayers, Leaflet, Google Maps, etc.

· Are familiar with all aspects of software development, including client/server programming

· Have the ability to drive and review APIs for back-end functionality

· Are interested in data mining, analytics, and/or machine learning

We’re looking for candidates with solid technical foundations and a desire to continue learning. Preference given to candidates with an active security clearance.

In compliance with federal law, all persons hired will be required to verify identity and status as a US citizen, and to complete the required employment eligibility verification document form upon hire. Failure to do so can and will result in dismissal.

Benefits
Intellectually Challenging Work and Learning Opportunities· Health Insurance· Short Term Disability Insurance· Generously Defined Benefit Retirement· Extremely Flexible Vacation Policy· Relocation
Want to know more about CCRi? https://www.youtube.com/watch?v=xjIqoDmAg4I
The job description above is not intended to be comprehensive list. Responsibilities, activities, duties, and/or tasks may change or be assigned at any time.

CCRi is committed to a diverse and inclusive workforce because we know that our differences benefit our employees, our customers, and our community. We are proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, color, religion, age, sex, sexual orientation, gender identity, national origin, status as a an individual with a disability, status as a protected veteran, or any other applicable legally protected characteristics.",4.5,"CCRi
4.5","Charlottesville, VA","Charlottesville, VA",51 to 200 employees,1989,Company - Private,Aerospace & Defense,Aerospace & Defense,$10 to $25 million (USD),-1
Software Engineer,-1,"IMMEDIATE OPENING !!

***An active Top Secret/SCI Full Scope Poly security clearance is mandatory for this position***

MOJA is seeking a Software Engineer to support our Customers’s warehouse management application.

In this position you will provide application development support. You will be part of a team with full stack multitasking capabilities working with our talented group of Developers, PMs, and Designers. You will apply IT acumen to engineer, design, and build the 2.0 System.

You will provide development engineering, and programming support to projects and infrastructure support activities, as well as designing and developing enterprise applications in a web environment. This includes analyzing user needs and developing, creating, and modifying general computer applications/software or specialized utility programs and solutions to match. You will design software or customize software for our client's use with the aim of optimizing operational efficiency. You will manage websites, including designing, developing, deploying, and maintaining activities, as well as performing testing and quality assurance of websites and web applications. You will analyze and design databases within an application area, working individually or coordinating database development with our customer as part of the larger sponsor team. To do this, you will need to maintain a strong awareness of technical trends in information technology, and develop and maintain a strong awareness of on-going IT projects and business unit requirements. You will need to be able to apply the project management model (Agile) for a given development effort; and provide analysis, design, development, deployment, and lifecycle support for innovative hardware systems and applications. Your work will involve being able to develop end-to-end cost analysis for projects, ensuring systems being developed comply with the enterprise technical architecture, and leading teams consisting of contractor personnel. You will manage and track user stories through the customer’s JIRA site, help project and program teams prepare for IT Project Management Program control gates, and keep senior management apprised of project or program status.

REQUIRED SKILLS:
Experience working with Amazon Web Services environments, including S3, EMR, SQS, and SNS, to design, develop, deploy, maintain, and monitor web applications within AWS infrastructures.
Experience providing technical direction to software and data science teams.
Experience collaborating with staff, IT customers, and other technical and non-technical staff and contractors at all levels.
Experience with Apache Spark.
Experience with PostgreSQL.
Experience working with RDS databases.
Experience developing complex data transformation flows using graphical ETL tools.
Experience engineering large scale data-acquisition, cleansing, transforming, and processing of structured and unstructured data.
Experience translating product requirements into system solutions that take into account technical, schedule, cost, security, and policy constraints.
Experience working in an agile environment and leading agile projects.
Experience providing technical direction to project teams of developers and data scientists who build web-based dashboards and reports.
DESIRED SKILLS
Experience engineering natural language processing and machine learning techniques into automated workflows. (Example techniques include clustering, ontologies and topic modeling, entity extraction Latent Semantic Indexing, and collaborative filtering.)
Experience working with data science tools technologies, particularly Python.
Experience developing non-traditional or innovative means of applying technical solutions to difficult analytic problems.
Experience working and applying creativity in a fast paced environment.
Experience with coordination and facilitation of meetings and technical discussions of requirements; tracking project status, plans, action items and drafting meeting minutes.
Experience with AWS Data Pipeline.
Experience with Kinesis.
Experience with Apache NiFi and Apache Kafka.
Experience developing in Java, Scala and Python.
Experience with Presto, Hive, Hadoop, and Cloudera.
Experience programming web applications in HTML, CSS, and JavaScript using jQuery.
Experience with Solr, Elasticsearch, or similar tool.
Experience with developing REST APIs and interfacing with REST APIs using AJAX.
*Referral Bonus Eligible**
MOJA is an information technology and intelligence analysis company based in Northern Virginia that has been providing information management solutions since it’s conception in 1995. We specialize in system integration, application development, network management, and intelligence analysis in support of the intelligence community and national level decision-makers. MOJA is a proud Certified Veteran Owned, Minority Owned company.

Have Questions? Not ready to apply, but want to submit your resume? You can email us directly: hr@moja.net or call us at (703) 369-4339.

MOJA benefits include: Health/Vision/Dental, Life/Disability, AFLAC & 401k.
MOJA is a proud Certified Veteran Owned, Minority Owned company and an equal opportunity employer.
MOJA is an e-verify employer.
Visit our website: www.moja.net",5.0,"MOJA
5.0","Springfield, VA","Manassas, VA",1 to 50 employees,-1,Company - Private,Aerospace & Defense,Aerospace & Defense,$1 to $5 million (USD),-1
Jr. Machine Learning Implementation Engineers,-1,"Benefits & Perks
Full benefits including Medical/Dental/Vision
Paid travel to and from the Atlanta HQ
Paid Time Off
401(k) savings plan
12-week training in Atlanta, GA prior to going on live projects

Jr. Machine Learning Implementation Engineer
Full-Time. Multiple Location
Annual Salary Range: Based on experience

Who We Are:
Enhance IT is an IT/Management firm that specializes in training, placement and IT consultation. We are an industry leader in providing top-level skilled and experienced consultants in a variety of technologies to meet our client’s needs in today’s fast paced environment.

What you will be doing:
You will be joining our ever-expanding data scientist team as it grows to meet the needs of the market. We want individuals who think “outside the box” and are comfortable asking “why?” The ideal candidate for this role is highly analytical with a knack for analysis, math and statistics. They are a team player possessing critical thinking and problem-solving skills with a passion for machine-learning and research. They need to possess the technical skills to explain the “how” and “what” behind technical decisions to non-tech stakeholders.

What you need for this position:
Master's degree from an accredited college/university in Computer Science, Statistics, Mathematics, Engineering, Econometrics, or related fields, PhD is preferred. Alternatively, Bachelor’s Degree with at least 2 years’ experience as a Data Analyst, Data Scientist, or Research Assistant.
Strong Proficiency in Python or Java programming language, or expertise with functional/object-oriented programming.
Ability to translate objectives to a project plan with milestones, and resource/technology requirements, and teach, lead, and manage projects/people/clients to successful execution.
Ability to work across multiple engagements with clients to assess needs, provide assistance, and resolve problems, using structured problem solving and communication to both technical and non-technical audiences.
Availability to travel and live in the U.S.
Bonus points:
Experience with command-line scripting, data structures and algorithms and ability to work in a Linux environment, processing large amounts of data in a cloud environment.
Experience in machine learning, artificial intelligence and/or artificial neural networks.
Proficiency in applying various mathematical and statistical models to include, but not limited to: discrete event simulation, factor analysis, genetic algorithms, Bayesian probability models, hidden Markov models, sensitivity analysis, sampling, probability, multivariate data analysis, regression, PCA, time-series analysis.
Broad understanding of databases (e.g. SQL, NoSQL, Lucene, Mongo), and high-performance or distributed processing (e.g. using MapReduce, Spark, Pig, and/or Hive).
Experience with visualization software (Tableau, D3, MicroStrategy, PowerBI).
Experience delivering solutions in an Agile environment.
Experience with Tensorflow, Theano or Keras.
Portfolio of public & private data science projects you’re proud of (GitHub, Kaggle, DrivenData, etc.)
Publications in peer-reviewed journals.
Other programming languages such as Scala, Java, R",2.7,"Enhance IT
2.7","Atlanta, GA","Atlanta, GA",51 to 200 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Sr Data Scientist,"$103K-$143K
(Glassdoor est.)","Overview


How have you impacted someone's life today? At Hackensack Meridian Health our teams are focused on changing the lives of our patients by providing the highest level of care each and every day. From our hospitals, rehab centers and occupational health teams to our long-term care centers and at-home care capabilities, our complete spectrum of services will allow you to apply your skills in multiple settings while building your career, all within New Jersey's premier healthcare system.

The Senior Data Scientist will be leading advanced analytic projects supporting Hackensack Meridian Health, using data to solve strategic, operational, and research problems. The Senior Data Scientist will wrangle large and complex data sets, and build machine learning models to aid Hackensack Meridian Health initiatives across all departments. The Senior Data Scientist will conduct appropriate analyses and present results in an innovative format and informative visualizations for a broad audience. The Senior Data Scientist employs investigative design, performs data collection and statistical analyses of data, interprets results, verifies data accuracy, and prepares final reports using a variety of software and tools. In addition, the Senior Data Scientists will participate in peer review and provide training on analytics and data science.

Responsibilities


1. Responsible for the end-to-end creation and deployment of new analytic offerings that distill complex data into actionable and timely insights in support of HMH initiatives. 2. Co-develop efficient analytic pipelines that include re-usable components related to data acquisition, exploratory analyses, feature extraction, modeling, and interactive data storytelling that will serve as the foundation for a scalable approach to HMHÂ¿s analytic maturation. 3. Design, build, and extract large and complex data sets, including both structured and unstructured data, while thinking strategically about uses of data and how data use interacts with data design. 4. Apply quantitative methods to evaluate effectiveness of new initiatives and present findings to drive a data-informed improvement process. 5. Participate in all aspects of the project lifecycle from requirement gathering, hypothesis generation, data extraction and transformation, programming, testing, and implementation, to delivery and conclusion. 6. Train and validate machine learning models and algorithms to solve a diverse set of problems by incorporating up-to-date research findings to drive evidence-based practices. 7. Share ownership of advancing the departmentÂ¿s capabilities in technical and analytical areas and provide feedback to team members by participating in peer review. 8. Educate the organization on data science and analytics and provide consultation across the network.

Qualifications


Education, Knowledge, Skills and Abilities Required: 1. Advanced degree (M.S. or Ph.D.) in quantitative fields (computer science, machine learning, applied statistics, physics, or a related quantitative discipline). 2. 7+ yearsÂ¿ experience in data scientist, software engineer with predictive modeling, or similar experience of solving real problems with data mining and machine learning techniques. 3. Strong expertise in building machine learning (supervised and unsupervised models) and recommendations systems, and knowledge in optimization, natural language processing, and deep learning. 4. Experience working with both structured and unstructured data and extracting features. 5. Hands-on experience with hyper-parameter optimization, model selection and validation. 6. Published in peer reviewed journals or contributed to open source project in a quantitative field. 7. Track record of building high quality data products and delivering analytical projects, including structuring and conducting analyses to generate business insights and recommendations. 8. Ability to work beyond familiar algorithms - to get out of oneÂ¿s comfort zone and earnestly seek to integrate the best solutions to business challenges. 9. Experience with visualization/BI tools and automated reporting tools preferred (SSRS, Crystal Reports, Tableau, Power BI etc.). Education, Knowledge, Skills and Abilities Preferred: 1. Knowledge or experience in healthcare and health delivery sciences highly preferred. 2. Ability to perform complex analyses for strategic and research projects, such as study design/sample size estimations and analysis of study results preferred. 3. Familiarity with programming and/or scripting languages (Python, C, C++, Java etc.) preferred. 4. Track record of delivering analytical solutions to poorly scoped problems preferred. Licenses and Certifications Required: Licenses and Certifications Preferred:",3.3,"Hackensack Meridian Health
3.3","Edison, NJ","Edison, NJ",10000+ employees,-1,Nonprofit Organization,Health Care Services & Hospitals,Health Care,$5 to $10 billion (USD),-1
Staff Software Engineer - Data Platform,"$87K-$173K
(Glassdoor est.)","At the intersection of technology, science, business and sports, Strivr offers an end-to-end, VR-based immersive learning platform that changes the way people around the world train, learn, and perform. With a mission to elevate performance through immersive experience, we are redefining an industry in real time and shaping the future of learning.

Strivr was founded in 2015 out of Stanford University’s Virtual Human Interaction Lab, using the football field as our proving ground. Since then, we have quickly expanded from the athlete to the enterprise, partnering with leading Fortune 500 companies including Walmart, Verizon, and Fidelity to innovate and elevate employee development.

At Strivr, our engineering teams develop immersive experience software and a cloud-based software platform that powers the creation, management, and experience of immersive learning with a unique level of insights and predictive analytics. The platform is scalable, secure, and compliant which is critical to making our customers and users successful on our platform. The engineering team is distributed and located in offices in Seattle and Palo Alto. In addition to the five company values of teamwork, grit, transparency, impact, and passion, we index on strong communication skills, a growth mindset, responsibility and ownership, and a collaborative and respectful work culture.

We capture and analyze device, usage, sentiment, and assessment data, attention and engagement data based on spatial (gaze, hand) and voice data over tens of millions of in-headset immersive learning and training sessions. We are developing a streaming analytics platform that will allow us to process, join, aggregate, reform, and query data across these very large structured and unstructured datasets to produce immersive analytics with deep insights on learning sessions. Consumers include customers and external users for insights on their learning and training performance, and internal users like Data Scientists and Analysts who need access to raw and processed data from pipelines using notebooks and machine learning frameworks to develop, experiment with, and train learning models.

We are hiring software engineers who are passionate about data engineering and analytics, and developing secure, scalable, and reliable data pipelines and platforms. As an engineer working on the Strivr’s data platform, you will have the opportunity to own the full cycle development of distributed services, data pipelines, and infrastructure that needs to scale to process petabytes of data and deliver insights and immersive analytics to hundreds of thousands of users and devices, all in real-time access. You will be expected to prioritize scalability, reliability, and security in your designs and implementation. You will work cross-functionally with other engineering teams, Product Managers and Data Scientists to deliver end-to-end user-facing functionality and experience.

Your responsibilities:
Systems architecture, design, implementation, and support of the following platform areas and capabilities:
Real-time and batch processing pipelines to process data into logical data sets in data lakes and analytical databases
Business and semantic layer services to transform data into reports, insights, and immersive analytics
APIs for querying raw and processed data for consumption by user-facing visualizations and dashboards in web applications
Tooling and infrastructure for machine learning frameworks, notebooks, and pipelines for querying raw and processed data for training and experimentation
Tooling and infrastructure for data validation in the different phases of the pipeline and in the data stores
Tooling and infrastructure to implement and enforce security and compliance policies for data protection and governance
Write secure, reliable, and performant code and add monitoring for everything you develop
Be data-driven, use instrumentation and monitoring to make improvements to the platform, functional or for-performance, or otherwise
Be a visible technical leader in the organization. Influence engineers by advocating for and practicing a culture of engineering excellence. Mentor and coach lesser experienced engineers to make a positive impact on their career development
Minimum Qualifications:
5+ years of software engineering experience, specifically with development of data pipelines and platforms, and a solid background in software development with one or more of C#, Java, Go
Experience with development and operationalization of large-scale data pipelines and distributed services for structured and unstructured data using streaming frameworks and systems like Kafka, Beam, Spark
Strong database fundamentals including SQL and operational experience with relational (like Postgres) and non-relational databases (like Druid, BigQuery, Elastic)
Experience with development of a data platform with tools and infrastructure for machine learning, training models, and experimentation
Strong written and verbal communication skills, both technical and non-technical
Ability to apply concepts from computer science, data-structures, and algorithms in order to solve problems in a pragmatic and efficient way
Passion for writing secure, readable, modular, and maintainable code and a drive for shipping high quality software with an emphasis on testing, data validation, monitoring, and SLOs to ensure data accuracy with high availability
Bachelors in Computer Science or related field, or equivalent experience
Preferred Qualifications:
Experience developing secure and scalable API services based on GraphQL or REST for web applications
Experience developing on public cloud platforms (Google Cloud, AWS, or Azure) including experience with orchestration using Kubernetes and Docker
Experience with one or more of the following: Natural Language Processing, text understanding, classification, pattern recognition, or similar",4.5,"Strivr
4.5","Palo Alto, CA","Palo Alto, CA",51 to 200 employees,2015,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Principal Cybersecurity Software Engineer for Machine Learning Applications,-1,"DESCRIPTION


MORSE is looking a Principal Cybersecurity Software Engineer to improve the security of deployed machine learning models. The candidate will be among the first cybersecurity experts at MORSE, but will have a support team full of excellent software developers, data scientists, and engineers. Therefore, the candidate is expected to grow a team focused on upon cybersecurity for machine learning, with freedom to explore other areas of cybersecurity. Our machine learning applications provide cutting-edge, algorithmic-based simulation, situational awareness, and mission planning capabilities to a wide variety of DoD customers.

Skills and Requirements


The Principal Cybersecurity Software Engineer will be responsible to highlight security vulnerabilities in models, create a practical plan for increasing security, then implementing and deploying those security enhancements. A successful candidate will be able to communicate well and learn new areas quickly. Creative candidates who want to make an immediate impact will thrive in the MORSE environment. Additionally, the candidate must be eager to learn new technologies and stay on top of the latest cybersecurity and machine learning trends.
US CITIZENSHIP REQUIRED or the ability to obtain a U.S. Security Clearance
10 or more years professional experience in cybersecurity
5 or more years leading cybersecurity teams
Expertise in Python, Java, C, and/or C++
Proficiency in relational databases
Experience with version control systems
Experience with Agile development (Scrum or Kanban)
Strong communication skill
Self-starter and driven
BS or MS (preferred) in computer science or equivalent degree, or significant professional experience
Desired Skills
Experience with machine learning models
Experience with cloud computing, such as AWS and GovCloud",5.0,"MORSE Corp
5.0","Cambridge, MA","Cambridge, MA",1 to 50 employees,2014,Company - Private,-1,-1,Unknown / Non-Applicable,-1
R&D Software Expert Engineer,"$61K-$123K
(Glassdoor est.)","Keysight is the world's leading electronic measurement company, helping scientists and engineers address their toughest technical challenges with confidence through innovations in wireless, modular, and software solutions. Our employees leverage their insight and passion to deliver measurement solutions in wireless communications, aerospace and defense, and semiconductor markets with world-class platforms, software and consistent measurement science.

This job will be part of the Communications Solutions Group, which is responsible for Keysight's portfolio in the Wireless Data Ecosystem, including wireless devices, operators, internet infrastructure, and Aerospace & Defense. Our software-centric solutions accelerate our customers' time to market and reduce their costs - giving them a competitive advantage in today's and tomorrow's technology waves.
Job Listing Detail
Keysight Technologies has been unlocking electronic measurement insights for 75 years. We are the world's leading electronic measurement company Keysight employees serve customers in more than 100 countries, delivering solutions in wireless communications, aerospace and defense and semiconductor markets with world class platforms, software and measurement solutions. This job will be part of Communications and Solutions Group (CSG) Organization, which is responsible for delivering world leading solutions to the market. This position is focused on new product development for Keysight’s 5G/6G products and is based out of our R&D office in Santa Rosa, CA.
Job Description
This is one of those rare opportunities to continuously challenge your own creativity and design skills by developing solutions for the fast moving, emerging standards for the 5G/6G ecosystem. You will join a highly talented and motivated team of software and hardware engineers creating cutting edge technology test products for 5G/6G customer base. Will get to work on multiple operating systems, the latest generation of FPGAs, and powerful server class machines. You will have the opportunity to lead, learn and contribute to new and emerging technologies in fast paced projects to work closely with customers.
Job Qualifications
BS (MS Preferred) with degree in CSE, EE, CS or related discipline
5+ years of embedded Software development
Strong experience building software using C++, C# and C
Experience with designing modular software for multiple target environments (Windows, Linux, Bare metal)
Hands-on development experience with embedded systems
Fluency in various standard tools, e.g. scripting languages, IDEs, source control, and bug tracking systems
Extremely strong verbal communications skills and a desire for strong team collaboration
A passion for building things, including working in a fast-paced environment with hands-on design and development cycles
Over and above, a deep commitment to your own quality work and a strong desire to help the entire team to succeed
Additional Preferred Qualifications
7+ years of Experience with RF and Digital communication concepts (modulation, demodulation, mixing, etc.)
Academic knowledge or equivalent experience with wireless communications, especially 3GPP standards such as 4G, 5G
Experience with building real-time embedded system software and Linux application development
Experience with reading schematics and datasheets
Ability to debug circuits that interface with embedded software – spanning from the debugger down to the oscilloscope level
Experience using Visual Studio Team and developing embedded applications running a Windows operating system
Job Function
R&D
Shift:

Day Job
Schedule:

Full Time (F)
Travel Required:
Duration (Temp Positions Only):

Not Applicable

Careers Privacy Statement

***Keysight is an Equal Opportunity Employer.***

Keysight Technologies Inc. is an equal opportunity employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability or any other protected categories under all applicable laws.

Candidates can be considered to work from the following locations:

Americas : United States : California : Santa Rosa

Job ID : 36669",4.1,"Keysight Technologies
4.1","Santa Rosa, CA","Santa Rosa, CA",10000+ employees,2014,Company - Public,Electrical & Electronic Manufacturing,Manufacturing,$2 to $5 billion (USD),-1
Sr. Data & ML Engineer,"$106K-$137K
(Glassdoor est.)","At Amazon Web Services (AWS), were hiring highly technical Data and Machine Learning engineers to collaborate with our customers and partners on key engagements. Our consultants will develop and deliver proof-of-concept projects, technical workshops, and support implementation projects. These professional services engagements will focus on customer solutions such as Machine Learning, Data and Analytics, HPC and more.

In this role, you will work with our partners, customers and focus on our AWS offerings such Amazon Kinesis, AWS Glue, Amazon Redshift, Amazon EMR, Amazon Athena, Amazon SageMaker and more. You will help our customers and partners to remove the constraints that prevent them from leveraging their data to develop business insights.

AWS Professional Services engage in a wide variety of projects for customers and partners, providing collective experience from across the AWS customer base and are obsessed about customer success. Our team collaborates across the entire AWS organization to bring access to product and service teams, to get the right solution delivered and drive feature innovation based upon customer needs.

You will also have the opportunity to create white papers, writing blogs, build demos and other reusable collateral that can be used by our customers. Most importantly, you will work closely with our Solution Architects, Data Scientists and Service Engineering teams.

The ideal candidate will have extensive experience with design, development and operations that leverages deep knowledge in the use of services like Amazon Kinesis, Apache Kafka, Apache Spark, Amazon Sagemaker, Amazon EMR, NoSQL technologies and other 3rd parties.

This is a customer facing role. You will be required to travel to client locations and deliver professional services when needed.





Basic Qualifications


Bachelors degree in Computer Science, Engineering, Mathematics or a related field or equivalent professional or military experience
8+ years of experience of Data platform implementation
3+ years of hands-on experience in implementation and performance tuning of Kinesis, Kafka, Spark or similar implementations
Hands on experience with building data or machine learning pipeline
Experience with one or more relevant tools (Flink, Spark, Sqoop, Flume, Kafka, Amazon Kinesis)
Experience developing software code in one or more programming languages (Java, JavaScript, Python, etc)
Current experience with hands-on implementation



Preferred Qualifications


Masters or PhD in Computer Science, Physics, Engineering or Math.
Experience in the telco industry
Familiar with Machine learning concepts
Hands on experience working on large-scale data science/data analytics projects
Hands-on experience with technologies such as AWS, Hadoop, Spark, Spark SQL, MLib or Storm/Samza.
Experience Implementing AWS services in a variety of distributed computing, enterprise environments.
Experience with at least one of the modern distributed Machine Learning and Deep Learning frameworks such as TensorFlow, PyTorch, MxNet Caffe, and Keras.
Experience building large-scale machine-learning infrastructure that have been successfully delivered to customers.
Experience defining system architectures and exploring technical feasibility trade-offs.
3+ years experiences developing cloud software services and an understanding of design for scalability, performance and reliability.
Ability to prototype and evaluate applications and interaction methodologies.
Experience with AWS technology stack.
Written and verbal technical communication skills with an ability to present complex technical information in a clear and concise manner to a variety of audiences.


Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.",3.9,"Amazon
3.9","Dallas, TX","Seattle, WA",10000+ employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),"Google, Microsoft, Walmart"
Data Engineer,-1,"About Lokavant
Lokavant is a technology company whose mission is to ensure that no clinical trial fails due to operational error. By integrating and analyzing the disparate data sources within clinical trials, Lokavant provides real-time visualizations and risk alerts to study sponsors and contract research organizations (CROs) to enable data-driven decisions. These insights expedite trial timelines and reduce the costs of development, allowing safe and efficacious treatments to get to patients.

Lokavant centralizes trial data to power a machine learning model that anticipates trial risk, provides data-driven risk mitigation strategies, and predicts the impact of mitigation strategy implementation. Lokavant's anticipatory monitoring capability is grounded in a compendium of data from over 1,000 clinical trials and will improve with each deployment.
About the Opportunity

How often are you given the opportunity to build something from the ground up, with an abundance of resources at your disposal; to be part of a team of people accomplished in diverse scientific and engineering disciplines, focused on using the best of what lies at the forefront of technology to address complex, real-world problems that have a positive impact on potentially millions of peoples' lives? This is that kind of opportunity.

We are seeking a thoughtful, hands-on technology enthusiast with a strong aptitude for data engineering to join the rapidly growing Lokavant team in our New York City headquarters. The Data Engineer will work very closely with our front-end developers, back-end developers, development operations engineers, and data scientists. Our platform is fully cloud-based and is being built around modern tools and frameworks in an incredibly fast-moving agile environment.

Key Responsibilities
Design, develop, and implement data infrastructure and pipelines that ingest and transform data from various external sources, storing it in highly optimized database systems, and making it useful to our application and reporting layers
Create automation systems and tools to configure, monitor, and orchestrate data infrastructure and pipelines
Create data integration services to help onboard new customers as quickly as possible
Maintain ongoing reliability, performance, and support of the data infrastructure, providing solutions based on application needs and anticipated growth
Participate in creating and maintaining strict compliance, data privacy and security measures
Develop robust and production-level code to implement new product features in collaboration with other engineers and subject matter experts
Identify and resolve performance and scalability issues, troubleshoot problems, and improve product quality
Collaborate with the Front-End Development team to thread the right information through to forward-facing applications
Interface with the Development Operations colleagues to evaluate and implement methodologies and workflows to facilitate the frequent and continuous release of high-quality software
Work closely with Data Science colleagues to implement descriptive and predictive algorithms and models using the latest technologies
Keep up to date on emerging technology solutions, particularly those on AWS, for continuous improvements in data engineering
Help recruit highly capable engineers to the team from diverse backgrounds
Mentor and be mentored by engineers of varied experience levels and subject matter areas

Minimum Requirements
3+ years relevant experience with data engineering
Strong proficiency with Python (ideally PySpark) and SQL
Experience with AWS S3, EC2, EMR, or an equivalent cloud-hosted infrastructure
Experience with cloud-hosted database/data warehouse architecture (e.g. Redshift, Snowflake, etc.)
Experience writing and productionizing complex data transformations in SQL and related frameworks
Interest in building distributed computing and orchestration frameworks (e.g. Spark, Kubernetes, Airflow, etc.)
Experience working in an Agile software development environment
Exceptional written and verbal communication skills
Strong attention to detail and highly organized, with effective multi-tasking and prioritization skills
Proactive, self-motivated and self-directed, with the ability to learn quickly and autonomously
Comfortable with ambiguity
Superior problem-solving and troubleshooting skills
Ability to work as part of a collaborative cross-functional team in a fast-paced environment
Sincere interest in working at a rapidly changing start-up and scaling with the company as we grow
Bachelors degree with strong academic performance in Computer Science, Software Engineering, Applied Science, or equivalent field
Preferred (Nice-to-have) Qualifications
Experience building and deploying large-scale data processing pipelines
Experience integrating data from disparate data sources
Experience with continuous integration and automation tools and processes (e.g. Jenkins, Semaphore, etc.)
Experience with healthcare data, ideally clinical/operational clinical trial data
Knowledge of clinical data standards (e.g. CDISC, FHIR, HL7, etc.)
Knowledge of e-clinical systems and technologies (e.g. EDC, CTMS, IRT, etc.)
Employee Benefits
Competitive salary and equity compensation
Full medical, dental, and vision benefits
One Medical membership
401(k) plan
Flexible PTO policy
Generous parental leave
Great NYC office located in the heart of Times Square
Team events and outings
Lokavant is an equal opportunity employer, indiscriminate of race, color, religion, ethnicity, ancestry, national origin, sex, gender, gender identity, sexual orientation, age, marital status, veteran status, disability, medical condition, or any other protected characteristic. We celebrate diversity and are committed to creating an inclusive environment for all employees.",-1,"Lokavant, Inc.","New York, NY","New York, NY",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Scientist,-1,"About Infinitive:

At Infinitive, we do mission-critical work for great companies. We specialize in digital marketing and digital advertising solutions, customer data & analytics, digital & business transformation, and Technology solutions. Our Technology solutions focus on Managed Cloud Services, Cloud Enablement, Digital Operations, Application Development, DevOps, Product Development, Cloud Security, Data Science and Analytics, AI/ML, IoT, and everything in between.

Our experts are results-obsessed, focused and flexible, highly engaged and hugely experienced having sat in our clients seats. Those qualities are what make us different than old-school consulting shops. And surely, they are why clients and partners describe us as the gold standard in client experience.

Infinitive has been named a Best Small Firms to Work For by Consulting Magazine seven times, a Washington Post Top Workplace three times, a Washington Business Journal Best Places to Work twice, and is a seven time winner of Virginia Business Best Places to Work.

About this Role:

Infinitive is growing its team in the Northern Virginia area and is currently seeking a Data Scientist to join our growing Technology practice. This person will utilize their experience in analytics, IoT, machine learning, and artificial intelligence advances to create value from structured and unstructured data. The ideal candidate has experience designing novel data analytic methods and workflows, including full data pipelines from raw data through analysis results. They must also have exposure to a variety of data mining/data analysis methods, data tools, building and implementing models, using/creating algorithms, and creating/running simulations.

We are looking for candidates who are accountable, passionate, assertive, proactive, open & honest, results oriented, and adaptable. Each project engagement represents a new challenge that will give you exposure to new clients, business issues, technologies, and people and will involve a range of responsibilities to include:
Developing in Java, Python, R, or other high-level languages.
Managing disparate data sources with varying data structures of content and preparing these for data science and machine learning applications.
Working with distributed scalable Big Data storage, processing, and computation, including AWS EMR, Spark, etc.
Implementation knowledge of, or desire to learn AWS / Azure data science capabilities.
Developing solutions and integrating and extending free and Open-source software (FOSS) or COTS products.
Conduct MapReduce programming with Apache Hadoop, the Hadoop Distributed File System (HDFS), and processing large data stores.
Knowledge of SQL and query languages.
Utilize real-time, large-scale data processing engine, including Apache Spark.
Lead and create Data Science and Analytics methodologies and frameworks for implementation.
Ability to build and develop Data Science demonstrations for clients
Qualifications:
3+ years of development experience (Java, Python, R)
2+ years of experience with distributed scalable Big Data storage, including AWS EMR, Spark, etc.
Desire to become AWS / Azure Certified architect / engineer.
Interest in being involved internally and growing a small business (entrepreneurial spirit)
Ability to travel (up to 20%) and to work independently
Ability to commute to client site
Experience using Agile software development methods in a DevOps environment.
Excellent leadership, peer management, and communication skills
Management consulting experience (preferred)
Bachelor's degree
Applicants for employment in the U.S. must possess work authorization which does not require sponsorship by the employer for a visa.

Infinitive is an Equal Opportunity Employer.

Powered by JazzHR",3.4,"Infinitive Inc
3.4","McLean, VA","Cedar Rapids, IA",201 to 500 employees,1997,Company - Private,Enterprise Software & Network Solutions,Information Technology,$10 to $25 million (USD),-1
Software Engineer,"$58K-$122K
(Glassdoor est.)","Software Engineer

Why YOU want this position

Enverus delivers business-critical insights to the global energy industry through a state-of-the-art SaaS platform built on industry-leading data and energy analytics. Our solutions deliver value across the entire energy value chain, empowering customers to be more agile, efficient, and competitive. The range of energy industry participants we serve includes exploration and production (E&P) companies and related businesses such as oilfield services, midstream, capital markets, power generators and utilities, energy traders, and downstream commercial & industrial energy consumers.

Enverus Software Engineering culture emphasizes team building, mentorship, and accountability that fits well with individuals who are self-starters, team players, and have a strong desire for continuous learning and growth. We offer a competitive compensation package along with industry-leading perks that include:
Casual dress code
Annual technical training budget
A well-stocked kitchen with snacks and beverages
We are currently seeking a highly driven Software Engineer to join our Data Science team in Conshohocken, PA, Denver, CO, or Calgary, AB. This role offers the opportunity to join a rapidly growing company delivering industry-leading solutions to customers in the worlds most dynamic and fastest-growing sector. Enverus is the right company at the right time.

Performance Objectives
Collaborate with Data Scientists to productize machine learning models
Design, develop, test, and maintain production-ready code
Support and maintain current production platform
Evaluate different tools and algorithms for reliable functionality and scalability
Participate in performance and stress testing with the development team
Participate in scrum planning and daily team standup
Competitive Candidate Profile
5+ years of Python experience
Solid understanding of algorithms and data structures
Solid Linux and git expertise
Preferred Qualifications
Pandas, NumPy, scikit-learn, TensorFlow, multiprocessing
Docker, Airflow, Kubernetes, Spark, Jenkins
SQL Server
GoLang
Azure cloud computing",3.6,"Enverus
3.6","Conshohocken, PA","Austin, TX",1001 to 5000 employees,1999,Company - Private,Energy,"Oil, Gas, Energy & Utilities",$100 to $500 million (USD),-1
Senior Software Engineer - Machine Learning,"$103K-$174K
(Glassdoor est.)","Senior Software Engineer Machine Learning

Team: Product Line

Location: Pittsburgh, PA

What We Do:

Company: We create AI software that allows enterprises to design, build, experiment, customize, operate and own vertical AI solutions in a wide range of industries and areas, such as healthcare, industrial manufacturing and utilities, financial services, telecommunications, autonomous driving, and beyond. Petuum lets enterprises easily understand and apply AI to gain deep insight for better decision-making and improved productivity and efficiency. Our mission is to enable organizations to own, build and become informed users of their AI solutions, without relying on expensive talents.

Team: The Solutions Division is aimed at addressing the needs of any given business within a discernible vertical market (specific industry or market). While horizontal market software can be useful to a wide array of industries (such as word processors or spreadsheet programs), vertical market software is developed for and customized to a specific industry's needs.

What You Will Do:
Design, implement and evaluate new models and software prototypes to solve problems in machine learning and systems engineering.
Provide software design and programming support to machine learning projects.
Implement and evaluate machine learning algorithms.
Report and present software developments including clear and efficient status and results both internally and externally, verbally and in writing.
Architect and implement software libraries.
Experience leading a team of Machine Learning Engineers, Data Scientists, and Software Engineers.
Review code and mentor junior engineers on best practices.
Build the code architecture on which any future development might be based on.
Other duties as assigned.
What You've Already Done:
You have a Master's Degree in Computer Science or related quantitative field. A Ph.D. or equivalent practical work experience is a plus.
You have 4+ years of experience.
Experience with implementing statistical or machine learning algorithms, algorithm design and software engineering.
Experience in machine learning, recommendation systems, pattern recognition, analytics or artificial intelligence. Proven ability to translate insights into business recommendations.
Experience with filesystems, server architectures, and distributed systems is a plus.
Startup experience is a plus.
What You Already Know:
Languages: Python, C++
What We Offer for your Valuable Work:

Petuum offers Medical, Dental, Vision, Life/Disability, Paid Time Off, Parental Leave, and more.

Petuum is a welcoming workplace that considers applicants for employment without regard to, and does not discriminate on the basis of, gender, race, protected veteran status, disability, or any other legally protected status. Petuum is an at-will employer.",2.5,"Petuum
2.5","Pittsburgh, PA","Pittsburgh, PA",51 to 200 employees,2016,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,"$84K-$154K
(Glassdoor est.)","We're looking for a Data Engineer to join Procore's Information Technology Engineering team to help evolve our data-driven culture and become a world-class data organization. In this role, you'll help us gain a data advantage by leveraging our data assets and designing the foundation for which our advantage is constructed.

As a successful Data Engineer, you have a strong background in cloud infrastructure, particularly AWS and Google Cloud Platform. You strive to excel at everything you do while being able to prioritize between the must-haves and nice-to-haves. If you're intrinsically motivated and ready to roll up your sleeves and dive in—we'd love to hear from you!

This position will report into our Director, IT Engineering and has the option to be based in our Austin, TX offices located at the heart of downtown. We're looking for candidates to join us immediately.

What you'll do:
Create ETL (Extract, Transform & Load) pipelines to deliver sanctioned data to stakeholders, while maintaining high accuracy and reliability
Tune and monitor data infrastructure Performance to support a growing organization
Brainstorm data product ideas and partner closely with Data Scientists, Product Management and Operations teams to develop, test, deploy, and operate high-quality software
Develop data infrastructure that ingests and transform data from different sources and customers at scale.
Partner end-to-end with Business Managers, Product Managers, and Data Scientists to understand customer requirements and design prototypes and bring ideas to production
Work with internal business leaders to ingest data to enrich their data modeling and work products.
Participate in conversations with teams about business-impacting topics and brainstorm innovative ways to transform data into information and knowledge that drives revenue and reduces cost
What we are looking for:
BS or MS in Computer Science or equivalent
5+ years of data warehousing or data engineering experience with a distinguished track record on technically demanding projects
Deep knowledge of SQL databases (preferably PostgreSQL)
Comfort working with cloud-managed data warehouse technologies (Amazon Redshift, Google BigQuery, Snowflake)
Strong experience working with Python, particularly for ETL or Data Science related tasks
Experience working in a data lake architecture, separating compute from storage
Passion for creating new products and services, including being comfortable with the ambiguity associated with designing new products
Experience working with REST APIs to ingest and enrich data sets
Experience with Apache Airflow for workflow management is preferred
Comfort using Hadoop related technologies(Spark, Hive, Presto, etc.) is preferred
Data Science/Machine Learning background is preferred
Familiarity with the construction industry is preferred
About Us
Procore Technologies is building the software that builds the world. We provide cloud-based construction management software that helps clients more efficiently build skyscrapers, hospitals, housing complexes, and more. Our headquarters is located on the bluffs above the Pacific Ocean in Carpinteria, CA, with growing offices worldwide. Check us out on Glassdoor to see what others are saying about working at Procore!

We are an equal opportunity employer and welcome builders of all backgrounds. We thrive in a diverse, dynamic and inclusive environment. We do not tolerate discrimination against employees on the basis of age, color, disability, gender, gender identity or expression, marital status, national origin, political affiliation, race, religion, sexual orientation, veteran status, or any other classification protected by law.

Perks & Benefits
You are a person with dreams, goals, and ambitions—both personally and professionally. That's why we believe in providing benefits that not only match our Procore values (Openness, Optimism, and Ownership) but enhance the lives of our team members. Here are just a few of our benefit offerings: competitive health care plans, unlimited paid time off (Procore Values Time), employee enrichment and development programs, and volunteer days.",4.2,"Procore Technologies
4.2","Austin, TX","Carpinteria, CA",1001 to 5000 employees,2002,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Senior Software Engineer - CTJ,"$116K-$167K
(Glassdoor est.)","Are you interested in working for one of the most exciting products at Microsoft to help advance Microsoft's AI Platform? Are you excited about being part of a product group working with Microsoft researchers, data scientists and AI engineering teams to ensure success as they move forward with cloud computing in Azure? If so, then look no further than the AI Platform team. AI Platform is responsible for the Azure Machine Learning (Azure ML) and Cognitive Services products.Azure ML is building the machine learning development platform that makes it easy for all data scientists and AI developers to create and deploy robust and highly scalable ML and AI solutions in the cloud using the best of the open source ecosystem and innovation from inside the company along with the latest breakthroughs in research.Artificial intelligence (AI) is dramatically transforming people's work and life now, and Cognitive Services bring AI within reach of every developer-without requiring machine-learning expertise. All it takes is an API call to embed the ability to see, hear, speak, search, understand, and accelerate decision-making into your apps.We are hiring engineers who are passionate about building scalable, distributed, highly available, and secure cloud services for Microsoft AI Platform. We value creativity and a desire to learn new technologies, agility and accountability.Join our team and help us build the best AI Platform for the world!Qualifications:* A minimum of a Bachelor's degree in Computer Science or Engineering, or a related field, or equivalent alternative education, skills, and/or practical experience is required.* At least 8 years of software development experience in C#, Java, Scala, C++, Go, Python or similar languages.* Solid Computer Science fundamentals, fluent in multi-threaded programming, experience/inclination for architecting at scale* Demonstrated technical design, problem solving, coding and debugging skills* Experience with distributed systems design and implementation, especially microservices architecture, and Kubernetes, Linux, and related technologies is a plus* Good written and oral communication skillsSecurity Clearance Requirements:* Citizenship Verification: This position requires verification of US Citizenship to meet federal government security requirements* Candidates must have an active TS and be willing to upgrade to TS/SCI (with polygraph) or have an active TS/SCI and be willing to upgrade to TS/SCI (with polygraph). This role will require candidates to maintain the TS/SCI (with polygraph) clearance.* Microsoft Cloud Background Check: This position will be required to pass the Microsoft Cloud background check upon hire/transfer and every two years thereafterMicrosoft is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable laws, regulations and ordinances. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. If you need assistance and/or a reasonable accommodation due to a disability during the application or the recruiting process, please send a request via the Accommodation request form.Benefits/perks listed below may vary depending on the nature of your employment with Microsoft and the country where you work.As a member of our team, you will participate in developing innovative solutions across AI Platform. Responsibilities include the following.* Write concise and clean code with unit tests* Build scalable, high-performance services that are highly reliable* Design and implement new features as well as add functionality to existing systems* Investigate pre-production and production issues, implement and deploy fixes* Participate in an on-call rotation (typically 24/7 for one week every 6-8 weeks)* Being enthusiastic, self-motivated, and a great collaborator* Being passionate about making customers successful",4.3,"Microsoft Corporation
4.3","Reston, VA","Redmond, WA",10000+ employees,1975,Company - Public,Computer Hardware & Software,Information Technology,$10+ billion (USD),"Google, Amazon, Apple"
Data Engineer,-1,"Hello,
Â
Data Engineer
Durham, NC
12+months
Â
7+ years of software development with two recent years of Scala development.
3+ years of using Spark
Experience developing web servicesÂand connecting to APIs. Preference will be given to candidates who have developed in a micro-service architecture.

Scala Data Science Developer â the role
As a member of a fast-growing team, within a growing area of the business, this role presents exciting opportunities for career progression.Â
Working with an enormous breadth of data, you will be able to design and develop data science applications on the latest big data platforms.Â
As a member of the team of data science software engineers and data scientists, you will have the opportunity and support to develop truly innovative solutions in support of the business.
Collaborating with data scientists, data engineers, and other developers to develop data science applications and services to support CRO business, including optimizing the design and execution of clinical trials, and improving risk management.
Collaborating on projects from concept to completion.
Designing and developing microservices to enable integration with legacy applications.
Comprehensive testing of your own code.
Documenting the application design and architecture.
Production deployments of microservices to k8s cluster through a CI/CD pipeline that you will design and setup.
Identifying opportunities for improvements of applications like improving service response time and horizontal scaling or exploring new technologies.
3+ years of relevant experience with Scala and a deep understanding of Functional programming.
Knowledge of Scala frameworks like Akka and Play.
1 year of relevant experience with Spark.
Knowledge of Kafka and/or RabbitMQ.
Experience designing and implementing Rest API and a good understanding of microservices design and architecture.
Familiarity with SQL.
Linux proficiency and experience with containerization tools such as Docker, Kubernetes.
Experience in following Scrum best practices.
Experience in putting machine learning models into production.
Deep understanding of JVM internals.
Experience with ELK stack.
Knowledge of Scala libraries like shapeless, cats, scala.
Familiarity with the whole Hadoop ecosystem like YARN, Hive, Impala, HDFS.
Experience with deploying code into production through CI/CD tools like Jenkins.
Front-end experience with some modern JavaScript frameworks.
Experience with non-relational databases like MongoDB and Redis.",4.6,"Conch Technologies, Inc
4.6","Durham, NC","Memphis, TN",51 to 200 employees,-1,Company - Private,Consulting,Business Services,$5 to $10 million (USD),-1
"Junior Software Engineer, Data Science",-1,"LockerDome is an ad platform with a brain, designed specifically for performance-based advertising. The brain behind the platform is Neo, an in-house AI, which uses machine learning to process billions of data points and make intelligent decisions at lightning speed. Learn more at lockerdome.com.

As a Junior Data Scientist on the Engineering & Product team, you will help design data models that enable decision making at scale.

Your skills should include:
Strong data cleaning skills
In-depth knowledge of statistics and calculus
Experience with R, MATLAB, or other statistics heavy language
Experience with TensorFlow or similar framework is a plus
Familiarity with various categories of neural networks

Powered by JazzHR",3.6,"LockerDome, Inc.
3.6","Saint Louis, MO","Saint Louis, MO",51 to 200 employees,2008,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Principal Software Engineer - Recommendations,"$115K-$220K
(Glassdoor est.)","Udemy is looking for a software engineer to join our Recommendations Team. Udemy's personalized recommendations system is composed of batch (e.g., feature and machine learning pipelines), streaming (i.e., feature computation in real-time), and online (i.e., microservices to serve personalized recommendations) components. The team is responsible for all these components, as well as the underlying algorithms and evaluation methodologies.

In this role, you will design, build, and integrate scalable systems, platforms, and tools to provide better recommendations and personalization data with low latency. You will work in a wide stack, including both data-related technologies and backend development, as a part of a cross-functional agile team of software engineers, data scientists, and product managers.

Are you passionate about learning, willing to take technical challenges, care about making an impact, and looking for a diverse, collaborative, and fun environment that also values quality? If so, come help us improve lives through learning at Udemy!

Responsibilities:
Design, develop, test, and deploy recommendation- and personalization-related systems, platforms, and tools at scale.
Lead design and architecture of Udemy's next-generation recommendation systems.
Identify and evaluate new technologies that improve the performance, maintainability, and elegance of our software implementation.
Partner with data scientists to troubleshoot and optimize complex data pipelines.
Collaborate with data scientists, engineers, and product managers to identify opportunities to improve our platform through personalization.
Advocate for technical quality, effective team processes, and engineering best practices.
Lead complex cross-organizational initiatives.
Mentor junior and senior data scientists and engineers.
Qualifications:
7+ years of full-time experience with data or backend engineering or equivalent
Strong knowledge of computer science fundamentals, including object-oriented design, data structures, and algorithms
Broad knowledge of web application technologies, frameworks, scalability, and operations
Proficiency with Python, Java, Kotlin, or Scala
Experience with the design, development, and operational maintenance of large-scale platforms and services
Experience with data storage and processing frameworks such as Hadoop, Hive, Spark, Kafka, MySQL, Redis, and Cassandra
Self-driven, highly motivated, and able to learn quickly
Excellent written and oral communication skills
Preferred but not required:
Experience with machine learning
Experience with Spark MLlib
Experience with infrastructure as code tools such as Terraform, Ansible and Packer
Experience with SQL performance tuning and query optimization
About Udemy

We believe anyone can build the life they imagine through online learning. Today, more than 50 million students around the world are advancing their careers and passions by exploring and mastering new skills on Udemy, and expert instructors are able to share their knowledge with the world. Through our global marketplace and our solutions for businesses and governments, we connect people everywhere with the skills they need for success in work and life. We're a close-knit bunch that enjoys problem-solving and collaboration, and we share a serious belief in the power of learning and teaching to change lives. Udemy's culture encourages innovation, creativity, passion, and teamwork. We also celebrate our milestones and support each other every day.

Founded in 2010, Udemy is privately owned and headquartered in San Francisco's SOMA neighborhood with offices in Denver (Colorado), Dublin (Ireland), Ankara (Turkey), Gurugram (India), and São Paulo (Brazil).

Udemy in the News

Udemy Raises 50 Million at a 2 Billion Dollar Valuation from Japanese Publisher Benesse

Paid Paternity Leave Should be the Norm in the U.S.

Breakdown of Most In-Demand Skills for 2020-Finance, Marketing, Sales and Engineering

How Investing in Yourself Today Will Set You Up for Career Success Tomorrow

Feedback Isn't the Problem, but the Way That We Deliver It Is Broken",4.4,"Udemy
4.4","Mountain View, CA","San Francisco, CA",501 to 1000 employees,2010,Company - Private,Education Training Services,Education,Unknown / Non-Applicable,-1
Full-stack Software/ML Engineer,"$67K-$120K
(Glassdoor est.)","Who we are:

Dynam.AI is a cutting-edge Machine Learning as a Service company developing and deploying tailored Machine Learning, Computer Vision, and Data Science solutions and applications for a wide range of corporate clients. We are leveraging our many years of experience in exact sciences, software engineering, and artificial intelligence to provide our customers with solutions to complex problems, with a focus on the knowledge gap between science and machine learning.

Job Description:

Dynam.AI is looking for a Full-stack Software Engineer to become part of its core team of scientists and engineers. You will be working as a part of one or more agile R&D teams to develop, implement and deploy Machine Learning solutions to address customer needs. Examples of problems to solve include cloud applications orchestration; design and implementation of APIs between modules; robust code design, implementation, and validation; and so on.

Required Qualifications
A Bachelor's degree or higher in Computer Science or related field.
3 years or more of Python development experience.
Proven expertise in full-stack Python development.
Proven expertise in cloud application design, development, and deployment.
Experience building ML and Deep Learning inference and training pipelines
Experience with cloud application orchestration, containers.
Experience with cloud and web APIs.
Experience with prototype to deployment code conversion, software QA.
Experience with Agile R&D, Scrum and/or Kanban.
Desired Qualifications
Both front-end and back-end development experience.
TensorFlow, PyTorch familiarity.
Knowledge of Rust, Julia, Go.
Parallel Computing, distributed Cloud Computing.
Scalability issues and analysis.
Databases, Data Analysis, Large Datasets.
CI/CD
Work Authorization/Security Clearance

We are willing to sponsor an H1-B visa if required. We expect that all applicable visas and paperwork are in order before the first interview. No security clearance is required. Candidates must consent to a background check.",3.5,"Dynam.AI
3.5","San Diego, CA","Reston, VA",10000+ employees,1952,Company - Public,Aerospace & Defense,Aerospace & Defense,$10+ billion (USD),-1
DevOps Engineer,-1,"DevOps Engineer

Position requires a current Top Secret security clearance with an SCI (TS/SCI)

BigBear, Inc. is a leading provider of big data computing and analytic solutions. We help people make sense of their data using our cloud-based platform and big data processing algorithms. Each day, we crunch massive volumes of structured and unstructured data into usable and actionable information for our customers.

We currently have an opening for a talented and passionate DevOps Engineer to join our top-notch team of forward-thinking engineers, data scientists, analysts, and innovators. The successful candidate will be a self-starter that demonstrates excellent communication and problem-solving skills with a strong drive for innovation.

Required Experience:
Solid experience with Linux
Amazon Web Services such as EC2, S3, SQS, RDS
Deployment automation with tools such as Terraform, CloudFormation, Jenkins, Ansible, or Chef
Advanced scripting skills with Python or Bash.
Bachelor’s or Master’s degree in Computer Science, Engineering, a related field, or equivalent work experience
Preferred Experience:
Experience with ELK Stack (ElasticSearch, Logstash, Kibana, Beats)
AWS Certification
Security+ or CISSP Certification
Current Top Secret security clearance with SCI (TS/SCI)
Technology We Use:
ElasticSearch
PostgreSQL
Python - Django
AWS
Docker
Git
Angular, React
Jenkins
Our Company:

BigBear, Inc. is a software development company with locations in San Diego, Washington DC, Charlottesville, and Reston, VA. Our mission is to enable big data computing and analytics for our customers at a low cost. We leverage capabilities such as machine learning, crowdsourcing, geospatial image processing, and Extract-Transform-Load (ETL) data processing using our on-premise cloud computing technology stack. Our solutions provide a unique offering of products, custom-built software, and services focused within Big Data Analytics, Geospatial Information Systems (GIS), Visualization and Cloud Computing to our Department of Defense, and Commercial customers. We currently have exciting and challenging career opportunities for talented, motivated individuals who want to be part of a fast-growing company.

Our Team:

We like to play with new toys and technologies. We like to break things to see if we can put them back together again in a better way. Our tails wag when we hear the words Big Data, Geospatial or Machine Learning. Each team member provides a unique set of advanced technical skills and trade that contributes to our overall success.

Perks/Benefits:

· 100% employer-paid for Medical, Dental, and Vision insurance (PPO)

· A competitive salary based on experience

· Flexible Spending Account (FSA) - optional

· 401(k) with dollar-for-dollar match up to 6%

· A warm, cozy office with actual chairs and tables

· Life and Disability Insurance 100% paid for by the company

· Education Assistance

· 529 College Savings Plan - optional

· Healthy Rewards Program

· Pre-paid Legal & Identity Theft Protection - optional

· Gym Reimbursement

· Pet Insurance - optional

· A shiny magical machine that does wonderful things

· Flexible Hours

· Unlimited Coffee, Drinks and Snacks

· 6 WEEKS of Paid Time Off (PTO) on top of 11 Paid Holidays!

BigBear is an Equal Employment Opportunity Employer/Veterans/Disabled

Job Type: Full-time

Pay: $90,000.00 - $150,000.00 per year

Benefits:
401(k)
401(k) Matching
Dental Insurance
Disability Insurance
Employee Assistance Program
Flexible Schedule
Flexible Spending Account
Health Insurance
Life Insurance
Paid Time Off
Parental Leave
Professional Development Assistance
Referral Program
Retirement Plan
Tuition Reimbursement
Vision Insurance
Schedule:

Monday to Friday
COVID-19 considerations:
This position will be at our Reston office, however, all of our team members are working from home currently for their safety.

Experience:
DevOps: 5 years (Preferred)
Education:
Bachelor's (Required)
Location:
Reston, VA 20191 (Required)
Work authorization:
United States (Required)
Application Question:
Do you have a CISSP or Security+ certification?
This Job Is:
A job for which military experienced candidates are encouraged to apply
Company's website:
www.bigbear.io
Work Remotely:
Temporarily due to COVID-19",4.4,"BigBear, Inc.
4.4","Reston, VA","San Diego, CA",51 to 200 employees,2008,Company - Public,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Senior Software Development Engineer - Machine Learning,"$136K-$211K
(Glassdoor est.)","Does serving ads to billions of search requests daily and finding the most relevant ads for a search page from billions of ads in 10s of milliseconds excite you?

The Sponsored Products team owns finding the appropriate ads to surface to customers when they search for products on Amazon. We strive to understand our customers intent and identify relevant ads which enable them to discover new and alternate products. This also enables sellers on Amazon to showcase their products to customers, which may at times be buried deeper in the search results.

Our systems and algorithms operate on one of the world's largest product catalogs, matching shoppers with products - with a strict latency constraints. We are a team of machine learning scientists and software engineers working on complex solutions to understand the customer intent and present them with ads that are not only relevant to their actual shopping experience, but also non-obtrusive. This area is of strategic importance to Amazon Retail and Marketplace business, driving long term-growth.

We are looking for a Software Engineer, who can drive appropriate technology choices for the business, lead the way for continuous innovation, and shape the future of ad serving on Amazon search. You will build services to handle billions of requests per day, while maintaining response latencies in milliseconds and meeting strict SLA requirements. It is quite routine for our systems to operate on massive datasets using distributed frameworks. You will design and code, troubleshoot, and support high volume and low latency distributed systems. The solutions you create would drive step increases in coverage of sponsored ads across the retail website and ensure relevant ads are served to Amazon's customers. You will directly impact our customers shopping experience while helping our sellers get the maximum ROI from advertising on Amazon. This role will provide exposure to cutting-edge innovations in product search, vector search, natural language processing (NLP), deep learning, and reinforcement learning. In addition to being a strongly motivated IC, you will also be responsible for mentoring junior engineers and guiding them to deliver high impacting products and services for Amazon customers and sellers.

As a Software Development Engineer at Amazon, you will -
· Leverage Big Data technologies, scalable system design and programming skills to implement large scale data-driven systems
· Build a combination of heuristics and machine learned models to solve for Ad relevance
· Integrate your work with high volume and low latency distributed systems
· Measure the impact of your work through rapid experimentation

Basic Qualifications

· 4+ years of professional software development experience
· 3+ years of programming experience with at least one modern language such as Java, C++, or C# including object-oriented design
· 2+ years of experience contributing to the architecture and design (architecture, design patterns, reliability and scaling) of new and current systems
· Bachelors degree in Computer Science or equivalent.
· 7+ years of professional software development experience
· Programming experience with at least one modern language such as Java, C++, or C# including object-oriented design.
· 5+ years of experience contributing to the architecture and design (architecture, design patterns, reliability and scaling) of new and current systems

Preferred Qualifications

· Experience in building large-scale machine-learning infrastructure for online recommendation, ads ranking, personalization, or search, etc.
· Experience with Big Data technologies such as AWS, Hadoop, Spark, Pig, Hive, Lucene/SOLR or Storm/Samza
· Strong proficiency with Java, Python, Scala or C++
· Coursework or thesis in machine learning, data mining, information retrieval, statistics or natural language processing
· Advanced knowledge of performance, scalability, enterprise system architecture, and engineering best practices
· Understanding of online computational advertising
· Strong written and verbal communication
Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.

#PABDSDE3
#PABDSDE3ADS",3.9,"Amazon
3.9","Palo Alto, CA","Seattle, WA",10000+ employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),"Google, Microsoft, Walmart"
Azure Developer/Data Engineer,-1,"Azure Developer/Data Engineer
Location: Washington DC
Job Type: Full time/Contract

Required Skills:
"" At least 5 years' experience driving impact in a similar capacity at companies creating cutting edge tech using Azure Cloud.
"" Azure Data Factory Pipelines - Create new Azure Data Factory pipelines in cloud based data warehousing systems such as Azure Synapse.
"" Experience with Azure services: Azure Data Lake Gen 2, Data factory, Data Flows, and Synapse (Azure SQL DW).
"" Data Quality and Anomaly Detection - Improve existing tools (dbt cloud) to measure data quality through metrics and automatic alerting.
"" Experience in working with Azure Databricks environment for data transformation.
"" Experience in working with unstructured data (text) and making data available for downstream NLP analysis.
"" Data Modeling - Partner with data consumers to improve existing data models and build different facets of the business for analytic use cases, Build star and snowflake schemas.
"" Development of data pipelines to third party API's both internal providers and external
"" Experience in working with NoSQL data bases like MongoDB and pull data from those databases.
"" Expertise building data pipelines on large complex data sets using Spark or other open source frameworks
"" Expertise in a scripting language like Python (or similar) and a query language like SQL
"" Knowledge of scheduling, logging, monitoring, alert frameworks
"" Experience in Source/Target: ADLSGen2, PostGres DB, Azure SQL DW.
"" Orchestration Using Databricks Jupyter Notebooks preferred.
"" Experience working in large scale/distributed SQL, NoSQL (MongoDB) environments.
"" Experience in modeling and implementing ETL / ELT on columnar MPP database technologies.
"" Experience with Agile software development process.

Preferred:
"" Proven experience deploying machine learning algorithms to production
"" Demonstrated proficiency in writing high-quality and scalable code and integrating with git version control systems
"" Experience leading successful data engineering projects and operationalizing machine learning algorithms
"" Experience with streaming architectures e.g. Kafka, Stream, PubSub.

Responsibilities:
"" Build & Deliver Data pipeline connecting various enterprise data sources both RDBMS, NoSQL & APIs.
"" Clean and process the data for Machine Learning consumption.
"" Load the Client predictions to Azure PostGres
"" Provide Business Intelligence (PowerBI) and Data Warehousing (DW) solutions and support by leveraging project standards and leading analytics platforms
"" Evaluate and define functional requirements for BI and DW solutions
"" Define and build data integration processes to be used across the organization
"" Build conceptual and logical data models for stakeholders and management
"" Analyse and validate data accuracy of report results
"" Work directly with management understand requirement; and propose and develop best business solution that enables effective decision-making, and drive business objectives
"" Interpreting data presented in models, charts, and tables and transforming it into a format that is useful to the business and aids effective decision making
"" Use of statistical practices to analyse current and historical data to make predictions, identify risks, and opportunities enabling better decisions on planned/future events
"" The ability to understand the business problem and determine what aspects of it require optimization; articulate those aspects in a clear and concise manner
"" Partner with business analysts, application engineers, data scientists, leveraging the appropriate tools, solutions, and/or processes as part of their data mining, profiling, blending, and analytical activities.
"" Collaborate in establishing and evolving development, testing, and documentation standards, as well as related code reviews.

Thanks & Regards,

Manas Pani
Account Manager
Resource Logistics Inc.
39 Milltown Road, Floor 2, East Brunswick, NJ 08816.
Phone: (732) 553-0566 Ext 64
Fax: (732) 553-0568
Email: manas@resource-logistics.com",4.7,"Resource Logistics, Inc.
4.7","Washington, DC","Edison, NJ",51 to 200 employees,1997,Company - Private,Logistics & Supply Chain,Transportation & Logistics,$10 to $25 million (USD),-1
Machine Learning / Data Infrastructure Engineer,-1,"Machine Learning/Data Infrastructure Engineer

*
Who we are
Wise Systems builds cloud-based autonomous dispatching and routing software used by some of the world’s largest fleets to improve efficiency and customer service. Wise Systems is on a mission to optimize the world, helping logistics operations compete in an increasingly dynamic and connected world.

Wise Systems was started out of MIT with the goal of using data to help cities and industries operate in smarter ways. Wise Systems has grown steadily, building an incredible, diverse team that shares a deep commitment to our customers’ success. Wise Systems also has a highly engaged network of advisors, mentors, and investors passionate about enabling new standards and capabilities in delivery and logistics through engineering and data science.

As we continue to grow, we are eager to bring together people who are curious, ambitious, and creative. If you are excited about solving real-world problems and building powerful and cutting-edge products, we need you.

What we are looking for

Wise Systems is looking for a Machine Learning and Data Infrastructure Engineer to work on ensuring that our platform continually evolves to provide solutions for our customer needs. This data-driven engineer will be focused on gathering insights from our proprietary datasets, designing and deploying ML algorithms, and implementing best practices around ML development at Wise Systems.

The ideal candidate will have experience with the entire machine learning development lifecycle, from research and development to deploying solutions in production environments. We are looking for someone with a strong background in statistics and machine learning techniques to help discover opportunities to both improve existing solutions and implement new ones.

Strong programming skills are necessary.

Responsibilities:
Apply broad knowledge of technology options, technology platforms, design techniques and approaches across the data warehouse life cycle phases to design an integrated, high quality solution to address the business requirements
Design, develop, and evaluate machine learning models to solve business problems
Assist development teams with integrating ML into technology architecture
Build and maintain automated pipelines for onboarding new client data into ML applications and evaluating effectiveness
Build robust and scalable data integration (ETL) pipelines using SQL, EMR, Python and Spark.
Build and deliver high quality data architecture to support BI needs of business analysts, data scientists, and external customers.
Continually improve ongoing reporting and analysis processes, automating or simplifying self-service support for customers
Design and deliver highly available data management systems
Provide high-level perspective and input on all development projects and contribute to the creative process across other disciplines and features
Qualifications
3+ years working as a ML or Data Engineer using Python or similar language
Extensive knowledge with big data ecosystems and cloud based technology. AWS experience is a plus.
Experience deploying machine learning in applications to solve real world problems
Proficient understanding of data infrastructure and backend systems
Demonstrated experience developing ETL pipelines and solutions
Strong communicator with ability to effectively convey complex topics to audiences of varying technical expertise
Please send resumes in PDF format.
Thank you and we look forward to hearing from you!

https://hire.withgoogle.com/public/jobs/wisesystemscom/view/P_AAAAAACAALbJ2gwfFqogpj?trackingTag=indeed

Job Type: Full-time

Benefits:
401(k)
Dental Insurance
Health Insurance
Paid Time Off
Vision Insurance
Location:
Cambridge, MA 02140 (Required)
Schedule:
Monday to Friday
Work Remotely:
Temporarily due to COVID-19",1.9,"Wise Systems
1.9","Cambridge, MA","Cambridge, MA",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Sr. Machine Learning Engineer,-1,"Where good people build rewarding careers.

Think that working in the insurance field cant be exciting, rewarding and challenging? Think again. Youll help us reinvent protection and retirement to improve customers lives. Well help you make an impact with our training and mentoring offerings. Here, youll have the opportunity to expand and apply your skills in ways you never thought possible. And youll have fun doing it. Join a company of individuals with hopes, plans and passions, all using and developing our talents for good, at work and in life.
Job Description
The Data Science & Analytics Engineering team builds software products specifically tailored to Allstates mission to improve customer's lives by re-inventing protection. We are creating scalable platforms for the deployment of cutting-edge predictive analytics, machine learning, and randomized experiments across the enterprise. We succeed by maintaining a steadfast focus on our customers using Lean Startup and Agile principles.

We are looking for a Senior Machine Learning Engineer to help us develop AI software products on a cloud-based platform which is already processing millions of unstructured objects a day. Youll help design and implement a framework that allows machine learning/deep learning models using natural language and image data to be scored in a production environment. You will have high visibility, great potential for growth, and a opportunity to make a distinct impact on how we do data science at Allstate. If you understand mathematics, general data science concepts, and full stack engineering necessary to design self-running software to automate models and analytics, we'd like to meet you. You'll also need to be a strong communicator as you will be working regularly with data science clients, as well as technology, architecture, and applications groups.

In this role, you will:
Help design machine learning systems
Research and implement/enhance machine learning model deployment platform
Run machine learning tests and experiments
Fully own production code, highly preferably REST APIs / microservices
Deploy machine learning applications into production
Work directly with data scientists, cloud engineer, and other stakeholders
Extend existing machine learning libraries and frameworks
Lead projects, including the planning and prioritization of tasks
Ability to context switch and manage multiple projects
Mentor team members and provide guidance on execution
Keep abreast of developments in the field
Job Qualifications
3+ years proven experience as a Machine Learning Engineer or similar role
Understanding of data structures, data modeling and software architecture
Working knowledge of REST APIs/Microservices
Intermediate/advanced Docker
Strong DevOps and CI/CD skills
Ability to write robust code in Python
Good knowledge of Python packages, e.g. Flask, Requests, Pandas, NumPy
Knowledge of math, probability, statistics and algorithms
Familiarity with machine learning frameworks (like Keras or PyTorch) and libraries (like scikit-learn)
Knowledge of AWS/PCF a plus
Familiarity with unstructured data a plus
Familiarity with Java application development is a plus
Excellent interpersonal communicator and collaborator
Outstanding analytical and problem-solving skills
BSc in Computer Science, Mathematics or similar field; Masters degree is a plus
The candidate(s) offered this position will be required to submit to a background investigation, which includes a drug screen.

Good Work. Good Life. Good Hands®.

As a Fortune 100 company and industry leader, we provide a competitive salary but thats just the beginning. Our Total Rewards package also offers benefits like tuition assistance, medical and dental insurance, as well as a robust pension and 401(k). Plus, youll have access to a wide variety of programs to help you balance your work and personal life -- including a generous paid time off policy.

Learn more about life at Allstate. Connect with us on Twitter, Facebook, Instagram and LinkedIn or watch a video.

Allstate generally does not sponsor individuals for employment-based visas for this position.

Effective July 1, 2014, under Indiana House Enrolled Act (HEA) 1242, it is against public policy of the State of Indiana and a discriminatory practice for an employer to discriminate against a prospective employee on the basis of status as a veteran by refusing to employ an applicant on the basis that they are a veteran of the armed forces of the United States, a member of the Indiana National Guard or a member of a reserve component.

For jobs in San Francisco, please click ""here"" for information regarding the San Francisco Fair Chance Ordinance.

For jobs in Los Angeles, please click ""here"" for information regarding the Los Angeles Fair Chance Initiative for Hiring Ordinance.

It is the policy of Allstate to employ the best qualified individuals available for all jobs without regard to race, color, religion, sex, age, national origin, sexual orientation, gender identity/gender expression, disability, and citizenship status as a veteran with a disability or veteran of the Vietnam Era.",3.4,"Allstate
3.4","Charlotte, NC","Northbrook, IL",10000+ employees,1931,Company - Public,Insurance Agencies & Brokerages,Insurance,$10+ billion (USD),"Progressive Insurance, State Farm, Farmers Insurance Group"
Principal Data Engineer,-1,"Analytics
Principal Data Engineer - QuantumBlack

Boston

Apply Now

Qualifications

Proven experience working in a hands on technical role role delivering impact through analytics
Strong experience with at least two of the following technologies: Python, Scala, SQL, Java
Commercial client-facing project experience is beneficial, including working in multi-disciplinary teams of engineers, data scientists
Good experience in multiple database technologies such as: distributed processing (Spark, Hadoop, EMR), traditional RDBMS (MS SQL Server, Oracle, MySQL, PostgreSQL) MPP (AWS Redshift, Teradata) NoSQL (MongoDB, DynamoDB, Cassandra, Neo4J, Titan)
Experience in software engineering best practices such as code reviews, testing frameworks, maintainability and readability
Experience deploying applications into production environments e.g. code packaging, integration testing, monitoring, release management
The ability to work across structured, semi-structured, and unstructured data, extracting information and identifying linkages across disparate data sets
Proven ability in clearly communicating complex solutions
Strong understanding of Information Security principles to ensure compliant handling and management of client data
Experience and interest in cloud platforms such as: AWS, Azure, Goole Platform or Databricks
Flexibility to travel regional or internationally up to 80% depending on client and base location
Strong experience in traditional data warehousing / ETL tools (Informatica, Talend, Pentaho, DataStage)

Who You'll Work With


You will be based in Cambridge, Boston and will join QuantumBlack, a highly collaborative team of exceptionally talented Data Scientists, Data Architects, and Machine Learning Engineers.

QuantumBlack helps companies use data to drive decisions. We combine business experience, expertise in large-scale data analysis and visualization, and advanced software engineering know- how to deliver results. From aerospace to finance to Formula One, we help companies prototype, develop, and deploy bespoke data science and data visualisation solutions to make better decisions.

What You'll Do


As a Principal Data Engineer at QuantumBlack in Boston...

You'll work closely with senior client stakeholders to understand their data, design the ingestion process to store the data locally and prepare it for Data Analytics.

As someone passionate about data and the opportunity it provides to organisations, you'll have the opportunity to play a critical role in database design and development, data integration and ingestion, as well as designing ETL architectures using a variety of ETL tools and techniques.

You are someone with a drive to implement the best possible solutions for clients in close collaboration with a highly skilled Data Science team. As such, you will partner with clients to model their data landscape, obtain data extracts and define secure data exchange approaches. You'll also plan and execute secure, good practice data integration strategies and approaches. This is a fantastic opportunity to be involved in end-to-end data management for cutting edge Advanced Analytics and Data Science.

You’ll lead workstreams in acquiring, ingesting, and processing data from multiple sources and systems into Big Data platforms. You’ll help create and manage data environments in the Cloud. You will collaborate with our data scientists to map data fields to hypotheses and curate, wrangle, and prepare data for use in their advanced analytical models. You will have a strong understanding of Information Security principles to ensure compliant handling and management of client data.

Please submit your CV in English

Visit our Careers site to watch our video and read about our interview processes and benefits

Industries
Financial Services
Aerospace & Defense
Public Sector
Media & Entertainment
Capital Projects & Infrastructure
Social Sector
Electric Power & Natural Gas
Advanced Electronics
Private Equity & Principal Investors
High Tech
Automotive & Assembly
Semiconductors
Healthcare Systems & Services
Retail
Metals & Mining
Chemicals
Telecommunications
Paper & Forest Products
Oil & Gas
Consumer Packaged Goods
Travel, Transport & Logistics
Pharmaceuticals & Medical Products


+ 21 More

Functions
Technology

Apply Now
FOR U.S. APPLICANTS: McKinsey & Company is an Equal Opportunity/Affirmative Action employer.
All qualified applicants will receive consideration for employment without regard to sex, gender
identity, sexual orientation, race, color, religion, national origin, disability, protected Veteran
status, age, or any other characteristic protected by applicable law.

FOR NON-U.S. APPLICANTS: McKinsey & Company is an Equal Opportunity employer. For additional details
regarding our global EEO policy and diversity initiatives, please visit our
McKinsey Careers and
Diversity & Inclusion sites.",3.8,"QuantumBlack
3.8","Boston, MA","London, United Kingdom",501 to 1000 employees,2009,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,"Palantir Technologies, Google, Microsoft"
Senior Software Engineer - Data,-1,"Who we are:

fuboTV is the fastest growing video streaming startup (backed by some of the world's largest media companies) that is reinventing live television for the entire household in the cord cutting era.

Originally founded as a soccer streaming service, fuboTV is the leading sports-first cable replacement in the U.S.

fuboTV broadcasts most NFL, MLB, NBA and NHL games, all major soccer leagues, and a wide range of college and other sports. fuboTV also broadcasts a wide variety of news, movies, and entertainment programming including the FOX, NBC, CBS, and Turner broadcast catalogs, plus Showtime, AMCand much more! fuboTV can be accessed on multiple platforms, including web, Android, iOS, tvOS, Fire TV, Android TV, Roku and Chromecast.

About the Role:

fuboTV is looking for exceptional Senior Sofware Engineers with a passion for processing data at scale with speed.

As a Senior Software Engineer you will get to build highly-available systems, ingest troves of data, and help power our cutting edge experiences on Android, iOS, Web, Roku, and FireTV. fuboTV's data team has a unique opportunity to build and continuously improve greenfield services.

We are looking for Senior Software Engineers who care about code quality, uptime, performance, continuous deployment, SOLID design principles, test-driven development, and agile methodologies.

Our tech stack:

Go/Golang with govendor

Docker and Kubernetes

Apache Beam with Java/Scala

Redis, Google PubSub, BigTable, BigQuery, and PostgreSQL

fuboTV Software Engineers have the following responsibilities
Architect, design, develop, test, maintain and improve data pipelines and systems
Collaborate with other engineers and members of the fuboTV team to determine priorities and best practices, and refine functional requirements
All fuboTV Senior Software Engineers must:
Have 5+ years of experience in delivering working software.
Experience in processing and serving data at scale
Write clean, well-tested code
Be familiar with BigData pipelines for batch and realtime streaming
Have experience with distributed processing frameworks, filesystems, NoSQL databases (Hadoop, AWS, Google ecosystems)
Experience working closely with data scientists to production-ize machine learning algorithms
Have mastery of at least one modern backend stack, with a willingness to learn new technologies and methodologies
Requires at least a Bachelor's Degree in Computer Science, Engineering, Information Technology, Management Information Systems (MIS), Computer Information Systems (CIS) or related field or equivalent as determined by a professional credentials evaluation.
Perks & Benefits:
fuboTV provides a highly competitive compensation based on experience and market standards.
Robust benefit package including stock options, Health/Dental/Vision coverage sponsored up to 100% for employees, 401k, Life Insurance, and commuter benefits
Free Premium fuboTV Account
Health and Wellness initiatives including discounts on Gym Memberships.
Unlimited PTO days and regular company-wide activities.
fuboTV's main Headquarters are located in Midtown Manhattan.
fuboTV is an e-verified company",4.6,"FuboTV
4.6","New York, NY","New York, NY",51 to 200 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Integration Engineer,"$82K-$134K
(Glassdoor est.)","Description

Job Description:


Are you ready to join Leidos all-star team? Through training, teamwork, and exposure to challenging technical work, let Leidos show how to accelerate your career path.

The Leidos Innovations Center has an exciting opening for you, our next Integration Engineer, to assist with the implementation of a state-of-the-art technology stack supporting a developing NMEC program in Reston, VA. Work to help integrate developers, data engineers, release planners, system administrators, management, software architects and others to produce a robust software platform. Focus on design, deployment, and maintenance of a full stack containerized microservices architecture as well as technical systems administration, installation/configuration, and troubleshoot including associated hardware. We would like to see you participate in fostering an integration process incorporating DevOps processes while building strong cross functional collaboration with all areas of development, product, and QA in a dynamic and fast paced environment supporting the development of a data pipeline and machine learning services integration in support of intelligence community analysts whose mission is to solve unique and challenging problems.

You will work closely with the chief architect, systems engineers, software and data engineers, and data scientists on the following key tasks:
• Manage the integration of all D3P environments in an agile environment, incorporating all facets from development to production
• Ability to integrate docker containers using Kubernetes, Rancher, Helm and other DevOps integration tools
• Foster an environment of collaboration with the different team members in the goal of producing a quality project product for our customer
• Ability to research and integrate cutting edge tools in an advanced technology stack
• Participate in system design sessions
• Have a working knowledge of system integration tools
• Have a working knowledge of DevOps tools such as Jenkins
• Have a working knowledge of CM tools such as Nexus and Gitlab/Git
• Design system to system data transfer and integration process
• Verify data quality and integrity between systems during the transfer process
• Ability to evaluate the systems from security point of view to ensure security relevant changes are made to the data before it is transferred to a different classification network
• Design data security checks to ensure dirty data is not passed to other networks
• Create system integration tests to identify and feedback failed modules and components

To be successful in this role you need these skills (required):
• Requires BS degree and 6 + years of prior relevant experience or Masters with 4 years of prior relevant experience
• Must have an active TS clearance with the ability to obtain and maintain a polygraph security clearance
• Experience with Kubernetes
• Experience with Elastic Search
• Experience with security requirements derivation
• Excellent verbal and written communication skills
• Ability to work in a team and also a self-starter who can work on their own

Leidos


Leidos is a Fortune 500® information technology, engineering, and science solutions and services leader working to solve the world's toughest challenges in the defense, intelligence, homeland security, civil, and health markets. The company's 32,000 employees support vital missions for government and commercial customers. For more information, visit www.Leidos.com.

Pay and Benefits


Pay and benefits are fundamental to any career decision. That's why we craft compensation packages that reflect the importance of the work we do for our customers. Employment benefits include competitive compensation, Health and Wellness programs, Income Protection, Paid Leave and Retirement.

Securing Your Data


Leidos will never ask you to provide payment-related information at any part of the

employment application process. And Leidos will communicate with you only through emails that are sent from a Leidos.com email address. If you receive an email purporting to be from Leidos that asks for payment-related information or any other personal information, please report the email to spam.leidos@leidos.com.

Commitment to Diversity


All qualified applicants will receive consideration for employment without regard to sex, race, ethnicity, age, national origin, citizenship, religion, physical or mental disability, medical condition, genetic information, pregnancy, family structure, marital status, ancestry, domestic partner status, sexual orientation, gender identity or expression, veteran or military status, or any other basis prohibited by law. Leidos will also consider for employment qualified applicants with criminal histories consistent with relevant laws.

LInC
D3P
External Referral Eligible

External Referral Bonus:
Eligible
Potential for Telework:
No
Clearance Level Required:
Top Secret/SCI with Polygraph
Travel:
Yes, 10% of the time
Scheduled Weekly Hours:
40
Shift:
Day
Requisition Category:
Professional
Job Family:
Systems Integration
Leidos


Leidos is a Fortune 500® information technology, engineering, and science solutions and services leader working to solve the world's toughest challenges in the defense, intelligence, homeland security, civil, and health markets. The company's 33,000 employees support vital missions for government and commercial customers. Headquartered in Reston, Virginia, Leidos reported annual revenues of approximately $10.19 billion for the fiscal year ended December 28, 2018. For more information, visit www.Leidos.com.

Pay and Benefits


Pay and benefits are fundamental to any career decision. That's why we craft compensation packages that reflect the importance of the work we do for our customers. Employment benefits include competitive compensation, Health and Wellness programs, Income Protection, Paid Leave and Retirement. More details are available here.

Securing Your Data


Leidos will never ask you to provide payment-related information at any part of the employment application process. And Leidos will communicate with you only through emails that are sent from a Leidos.com email address. If you receive an email purporting to be from Leidos that asks for payment-related information or any other personal information, please report the email to spam.leidos@leidos.com.

Commitment to Diversity


All qualified applicants will receive consideration for employment without regard to sex, race, ethnicity, age, national origin, citizenship, religion, physical or mental disability, medical condition, genetic information, pregnancy, family structure, marital status, ancestry, domestic partner status, sexual orientation, gender identity or expression, veteran or military status, or any other basis prohibited by law. Leidos will also consider for employment qualified applicants with criminal histories consistent with relevant laws.",3.5,"Leidos
3.5","Reston, VA","Reston, VA",10000+ employees,1969,Company - Public,Aerospace & Defense,Aerospace & Defense,$10+ billion (USD),-1
Staff Data Warehouse Engineer - Personalization,"$74K-$100K
(Glassdoor est.)","Our Opportunity:

We are hiring a Staff Data Warehouse Engineer - Personalization for our Personalization team in Boston, MA. In this position, you will help us build scalable, robust data solutions for Personalization at Chewy. You will demonstrate a passion for delivering outstanding customer experience, experience of building scalable solutions and will bring communication skills that allow you to instill trust in the team that you are working with. Millions of pet parents with unique needs visit Chewy.com looking for products for their beloved pets. We have the task to decide what products would be most useful to them and help them discover those products. How do we do this? Meet Personalization team @ Chewy. We use best of machine learning techniques and continuously test the outcomes to simplify product discovery for pet parents looking for their pet needs on Chewy.com. Our exceptional multi-disciplinary team of data scientists, data engineers, software engineers and product managers work together to power personalized recommendations and product discovery for pet parents. Our team has single threaded ownership of the space allowing us to decide impactful products that we can experiment, measure with metrics and deliver at a fast pace.

What You'll Do:
You will be responsible for design, development, delivery and support of large-scale, data flows and tools
You will work with the team and other partner teams to define our roadmap on the data engineering front
You will deliver projects successfully and drive initiatives for up keep pace of our data science solutions. in the face of growth
You will drive operational excellence of data systems
What You'll Need:
Bachelor's Degree in Computer Science, Computer Engineering or related field
8+ years professional experience in Data Engineering
Experience working with Hadoop, Spark and other streaming solutions
Experience with, at least, one modern programming language such as C#, Java, Python
Experience implementing high availability data (warehouse) systems
Delivery experience working under an Agile/Scrum methodology
Position may require travel
Bonus:
Master's Degree in Computer Science or related field
E-commerce experience
Experience working with AWS or Similar Cloud Environments
If you have a disability under the Americans with Disabilities Act or similar law, or you require a religious accommodation, and you wish to discuss potential accommodations related to applying for employment at our company, please contact HR@Chewy.com.

To access Chewy's Privacy Policy, which contains information regarding information collected from job applicants and how we use it, please click here: Chewy Privacy Policy (https://www.chewy.com/app/content/privacy).",2.8,"Chewy
2.8","Boston, MA","Dania Beach, FL",10000+ employees,2011,Company - Public,Pet & Pet Supplies Stores,Retail,Unknown / Non-Applicable,-1
"Data Engineer, Analytics (Lead) - Music Entertainment Ecosystem","$153K-$249K
(Glassdoor est.)","Facebook's mission is to give people the power to build community and bring the world closer together. Through our family of apps and services, we're building a different kind of company that connects billions of people around the world, gives them ways to share what matters most to them, and helps bring people closer together. Whether we're creating new products or helping a small business expand its reach, people at Facebook are builders at heart. Our global teams are constantly iterating, solving problems, and working together to empower people around the world to build community and connect in meaningful ways. Together, we can help people build stronger communities - we're just getting started.Our more experienced data engineers are clearly characterized by in-depth technical experience and proven progression in leadership responsibility. If you have an interest in being responsible for the dynamics of a fast-paced environment, this is the right role for you. You will be working on many projects at a time, but also focused on the details while finding creative ways to pursue big picture challenges.Facebooks Entertainment Organization has strategically aligned to incorporate Music into its ecosystem to sit alongside with Videos and Games. This is one of the largest bets Entertainment has ever made for music rights. This provides you with a unique opportunity to build the Music data ecosystem from the ground up and to influence product direction with data.In this role, you will partner closely with the Sound Platform, Rights Management, Music Product and Music Reporting teams that are responsible for the entire Music Ecosystem, from ingestion, to applying appropriate copyrights, to building music products across the family of apps.The Sound Platform and Rights Management teams own the ingestion of music assets, extracting metadata to provide rich features on the music asset such as genre, artist, album etc. as well as the application and arbitration of copyrights.The Music Product team owns the narrative on how these music assets are distributed and presented to the users across 2 main themes: Music Videos and Music Streaming.The Music Reporting team works on the reporting contractual obligations with labels for a continued mutually beneficial relationship.You will be responsible for building a strong data foundation and architecture that will allow us to understand the music ecosystem end to end from ingestion to distribution to usage. In this role, you will have the opportunity to define technical specifications for logging, define and influence the right metrics and build the core datasets and visualizations that will be used by our Data Scientists, Machine Learning engineers, Product Engineers and Product Managers.A few examples of the story your dataset will tell:How can we digest the available music asset metadata such as artist, genre and make it usable for Machine Learning.How does the Music convert an unconnected content discovery for someone into a connected content discovery experience for another, using Social as the catalyst.Understanding the relationship between user preference and music consumption & engagement.Provide understanding into the music interactions, devices, markets, media types.How do we build a scalable platform for external Music reporting.

Responsibilities:

Ability to design a scalable, loosely coupled, highly aligned data architecture
Implement and own this optimal ETL data processing architecture and server-side system for data processing
Build fault-tolerant pipelines
Build data anomaly detection, data quality checks, and optimize pipelines for ideal compute and storage
Define and own the data engineering roadmap for the Music Ecosystem
Collaborate with Software Engineers and Data Scientists to design technical specification for logging and add logging to production code to generate metrics both online as well as offline
Actively mentored team members in their careers
Mininum Qualifications:

4+ years experience in the data warehouse space
4+ years experience working with either a MapReduce or an MPP system
7+ years experience in writing complex SQL and ETL processes
4+ years experience with object-oriented programming languages
7+ years experience with schema design and dimensional data modeling
Preferred Qualifications:

BS/BA in Technical Field, Computer Science or Mathematics
Knowledge in Python or Java or Scala
Experience analyzing data to identify deliverables, gaps, and inconsistencies
Experience in effectively collaborating and communicating complex technical concepts to a broad variety of audiences
Experience working in a fast-paced product environment
Facebook is proud to be an Equal Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law.

Facebook is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.",4.5,"Facebook
4.5","Menlo Park, CA","Menlo Park, CA",10000+ employees,2004,Company - Public,Internet,Information Technology,$5 to $10 billion (USD),"Google, Microsoft, Apple"
Data Engineer All Levels,-1,"At DataSync Technologies, our data engineering professionals touch every area of our company. Their insights drive our decisions and their innovations fuel projects. When you join our team of data experts, youre helping DataSyncs customers make better, smarter and faster decisions every day. See how you can help us solve some our customers most challenging data problems while you grow your skills and build your own future.

Job Description

DataSync Technologies is seeking Data Engineers to support a mission critical program within the Intelligence Community.

ONLY CANDIDATES WITH ACTIVE GOVERNMENT SECURITY CLEARANCES AND APPROPRIATE POLY WILL BE CONSIDERED. MUST BE A U.S. CITIZEN.

Responsibilities will vary by specific data engineer role Data Architect, Data Scientist, Database Engineer, Data Governance to include the following:
Design and develop methods, processes, and systems to consolidate and analyze structured and unstructured data from diverse sources including big data sources.
Develop and use advanced software programs, algorithms, query techniques, model complex business problems, and automated processes to cleanse, integrate, and evaluate datasets.
Analyze the requirements and evaluate technologies for data science capabilities including one or more of the following: Natural Language Processing, Machine Learning, predictive modeling, statistical analysis and hypothesis testing.
Develop information tools, algorithms, dashboards, and queries to monitor and improve business performance. Maintain awareness of emerging analytics and big-data technologies.
Designs, implement, and maintain standard data interfaces for data ingest including Extract/Transform/Load (ETL) methodology and implementation, APIs, RESTful Web Services, data quality, and data cleansing.
Provide data services, data administration, data management, and Big Data support in client/server, virtual machine, Hadoop, and cloud infrastructure environment and/or migrations between these environments.
Database installation, configuration, and the upgrading of database server software and related products, backup and recovery policies and procedures, database implementation, security, optimization, multi-domain operation, and performance management.
Hadoop, cloud, and other technologies associated with data storage, processing, management, and use.
The migration/transition of database capability into cloud based technologies and/or creation of interfaces between classic relational databases and key indexes to cloud based columnar databases and map reduce index capabilities.
Preferred Qualifications (All not required):
Databases/Data Stores: Oracle, MySQL, HIVE, HBASE, and HDFS
Frameworks: Hadoop, Rails, JavaScript Frameworks, SOA/WebServices, JSP
Indexing: SOLR and Lucine
Development/Scripting Languages: JAVA (J2EE), Python, Ruby, JavaScript, MapReduce, Pig, XML, SQL, JAQL, HTML, CSS, XML, BASH, ANT, and Perl
________________________

What makes DataSync Technologies different?

Leadership Training: We provide employees with a variety of learning opportunities, including access to exclusive classes, professional growth training and more.

Feedback & Mentoring: We believe in talkingoften. So we have one-on-one feedback sessions for every employee.

Community Service: We believe in helping the community where we work. DataSync and its employees donate time and services on a regular basis to local military charities. We believe in helping, both inside and outside of the office.

Social Events: We plan social events on a regular basis to help our employees relax and socialize so we get to know one another outside of our job titles.

Equal Employment Opportunity
DataSync is an EEO and Affirmative Action Employer of Female/Minorities/Veterans/Individuals with Disabilities. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.

Information about Equal Employment Opportunity (EEO) and Employee Polygraph Act (EPPA) provisions in addition to other Federal labor laws can be found at the Department of Labor's Website.

DataSync is committed to providing veteran employment opportunities to our service men and women.

Find out more about DataSync on Social Media.
www.datasynctech.com
www.facebook.com/DatasyncTechnologies
www.twitter.com/Jobs at DataSync (@DatasyncJobs)
www.twitter.com/datasynctech
#datasynctech on Instagram
Interested in Joining Our Team? - Check out this YouTube video!
#CJ

Powered by JazzHR",5.0,"DataSync Technologies, Inc
5.0","Reston, VA","Reston, VA",1 to 50 employees,2003,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Senior Data Engineer,"$106K-$194K
(Glassdoor est.)","The Company:

Personal Capital is a leading digital wealth management company, founded in 2009. Were on a mission to transform financial lives through technology and people, providing both insight-driven advice with free financial tools and personalized wealth management from 200+ registered financial advisors across the country. Personal Capital has raised $315 million in capital from accomplished financial and strategic investors (IVP, Venrock, Crosslink, Corsair, Blackrock, BBVA, USAA, IGM/Power) to disrupt the traditional $30 trillion U.S. wealth management market. Our free personal finance app is utilized by over two million users, helping them track over $840 billion of their personal finances, all in one place. Our award-winning apps paved the way for our advisory firm, which now manages over $12 billion in personalized investment portfolios for American families. Personal Capital is headquartered in Redwood Shores with offices in San Francisco, Denver, Dallas and Atlanta.

The Opportunity

You will play a leading role on the Data and Analytics team, responsible for transforming data from disparate systems to provide insights and analytics for business stakeholders. Youll leverage cloud-based infrastructure to implement technology solutions that are scalable, resilient, and efficient. You will collaborate with Data Engineers, Data Analysts, Data Scientists, DBAs, cross-functional teams, and business leaders. You will architect, design, implement and operate data engineering solutions, using Agile methodology, that empower users to make informed business decisions.

Candidate

You are self-motivated, work independently, and have direct experience with all aspects of the software development lifecycle, from design to deployment. You have a deep understanding of the full life data lifecycle and the role that high-quality data plays across applications, machine learning, business analytics, and reporting, Strong candidates will exhibit solid critical thinking skills, the ability to synthesize complex problems, and a talent for transforming data to create solutions that add value to a myriad of business requirements. You have the demonstrated ability to lead and take ownership of assigned technical projects in a fast-paced environment. Excellent written and speaking communication skills are required as we work in a collaborative cross-functional environment and interact with the full spectrum of business divisions.

Qualifications:
Bachelor of Science degree in Computer Science or equivalent.
At least 7 years of post-degree professional experience.
4+ years development experience building and maintaining ETL pipelines.
3+ years of Python development experience.
Experience with AWS integrations such as Kinesis, Firehose, Aurora Unload, Redshift, Spectrum, Elastic Mapreduce, SageMaker and Lambda.
Experience in mentoring junior team members through code reviews and recommend adherence to best practices.
Deep understanding of writing test cases to ensure data quality, reliability and high level of confidence.
Track record of advancing new technologies to improve data quality and reliabilit
Continuously improve quality, efficiency, and scalability of data pipelines.
Expert skills working with SQL queries, including performance tuning, utilizing indexes, and materialized views to improve query performance.
Advanced knowledge of both OLTP and OLAP environments with successful implementation of efficient design concepts.
Proficiency with the design and execution of NoSQL database to optimize BigData storage and retrieval.
Experience with API code integrations with external vendors to push/pull data between organizations.
Familiarity with data orchestration pipeline using Argo or Airflow.
Knowledge of analytic tools such as R, Tableau, Plotly, Python Pandas.
Financial services industry experience is a plus.
Powered by JazzHR",4.0,"Personal Capital
4.0","Redwood City, CA","Redwood City, CA",201 to 500 employees,2009,Company - Private,Investment Banking & Asset Management,Finance,Unknown / Non-Applicable,-1
Software Engineer,"$90K-$131K
(Glassdoor est.)","Software Engineer

OSBU | Denver, CO, United States

Why Join Rincon Research Corporation (RRC)?

At Rincon Research Corporation, our primary business is innovating, developing, and fielding digital signal processing (DSP) products and services for the United States Defense and Intelligence Communities in support of national security.

Rincon Research Corporation seeks a Software Engineer to create cutting edge signal processing, geolocation, and communication systems solutions to challenging national security and defense problems. You will work in a multi-disciplinary R&D environment with similarly skilled and motivated electrical engineers, mathematicians, and computer scientists/engineers in a highly rewarding personal and professional environment.

Come join the team that is creating cutting edge signal processing, geolocation, and communication systems for the future!

What are the primary responsibilities in the Software Engineer position?

Core responsibilities include designing real-time processing solutions, implementing advanced signal processing and geolocation algorithms in efficient software, testing with real data, and deploying to front-line customer facilities. You also create effective user interfaces and data visualization tools. A key responsibility is mastering and evolving framework capabilities as applications migrate to a cloud-based computing environment. RRC personnel can expect to work across all functional areas: systems engineering, development, integration and test, deployment and O&M, and experience the direct mission feedback from the customer and seeing your project provide real-world contributions that make a significant difference.

What required background will make you successful?
Degree (Bachelor’s, Master's, or PhD) in Computer Engineering or Computer Science
Competent in using C/C++/Python for engineering or scientific applications in the Linux environment
Facility with agile software development practices at all stages of the software life cycle
Good speaking skills with the ability to interact with customers and senior engineers
Able to assist in creation of cutting-edge solutions for customer issues
Ability to obtain and maintain a TS/SCI security clearance
(US CITIZENSHIP REQUIRED)
Technical Interest Areas:
High Performance Computing including parallel and distributed computation
Numerical algorithms
GPU acceleration using CUDA
Machine learning
Virtualization and Cloud computing
Visualization of large engineering data
HTML5 for real-time GUI engineering applications
Where is the position located?

This position is located at our Denver, CO office.

What benefits does RRC offer?
100% employer-paid premiums for family medical and dental insurance, employee life insurance, short-term and long-term disability (STD & LTD)
Flexible reimbursement spending accounts for medical expense and dependent care
Immediate participation and vesting in the company’s Employee Stock Ownership Plan (ESOP) and 401(k) Plan
Employer contributions to RRC’s ESOP
Employer matching contributions to the company’s 401( k) Plan
Employer discretionary contributions to the company’s 401(k) Plan
Rincon Research Corporation is an equal opportunity employer and considers qualified applicants for employment without regard to race, color, creed, religion, national origin, sex, sexual orientation, gender identity and expression, age, disability, veteran status, or any other protected factor.",4.3,"Rincon Research Corporation
4.3","Centennial, CO","Tucson, AZ",201 to 500 employees,1983,Company - Private,Aerospace & Defense,Aerospace & Defense,$50 to $100 million (USD),"Raytheon Technologies, General Dynamics, MIT Lincoln Laboratory"
Principal Software Engineer,-1,"Omniscience is seeking a Principal Software Engineer to build and scale our machine learning platform and deliver solutions to customers.

At Omniscience, we build software that will transform the insurance industry through automation and intelligence. We are a Machine Learning first company, building business systems from the ground up based on a broad range of AI and traditional technologies including Deep Learning, traditional Machine Learning, NLP, and Distributed Systems.
As a software engineer you will embrace the challenge of making machine learning systems intuitive and effective for our users. You will drive and build complex and deep technical solutions and take a lead role in defining and driving requirements, technical design, and long term direction.

You are a generalist who loves working on a variety of software and contributes across multiple areas. This is an opportunity to work with machine learning pipelines, large scale data processing, distributed systems & algorithms that are deployed in the cloud to solve real world problems.
You are smart, self-directed, and passionate about technology. You love learning and take pride in your ability to resolve ambiguity. You love new technology and understand the benefits of time tested tools. Above all you are an enjoy working with smart people, helping them do more than they ever imagined, and building software that will transform an industry.

Responsibilities
Build platforms, services and applications that power Machine Learning systems.
Design and build high quality code and systems that are scalable, secure, maintainable, extensible, and resilient.
Ship production level code to customers. Rapidly explore new ideas via prototypes and demo systems.
Partner with product managers, designers, data scientists, and other software engineers to deeply understand the needs of users and develop solutions that meet those needs.
Promote new or improved technologies that meet current and future needs.
Lead and Mentor senior and junior engineers.
Be a senior member of an agile team and with rapid iterations and continual improvement of product and process.
Skills & Experience
8+ years experience developing production software in Java, Python and/or Scala.
Experience developing and consuming internal and external API's.
Experience with SQL and NoSQL Databases, Message Brokers, OAuth/JWT.
Experience with AWS (EMR, EC2, S3, RDS, SageMaker)and other cloud providers, Terraform, Docker & Kubernetes, and a DevOps mindset.
Experience reviewing and improving code to ensure quality and to share knowledge.
Experience designing and implementing code and systems that are scalable, secure, maintainable, extensible, and resilient.
Exposure to Machine Learning, TensorFlow, Keras, Computer Vision, OpenCV, Distributed Computing, or Data Science (or the desire to learn) is a plus.
Experience with Machine Learning Pipelines or Spark is a plus.
Experience with Web or Mobile User Interfaces/SDK's is a plus.
Highly motivated with strong communication skills.
Omniscience is a fast-growing startup that is well funded by the venture community. We are a company building the next generation of business systems from the ground up with AI and traditional technologies. We are a team of experts, each in our respective specialty with a unified goal of creating the next generation of AI driven business systems.

As an equal opportunity employer, Omniscience does not discriminate against any applicant or employee based on race, color, sex, sexual orientation, gender identity, marital status, religion, national origin, ancestry, age, disability, military or veteran status, genetic information or any other basis protected by applicable federal, state, or local laws.
We do not accept resumes from head-hunters, placement agencies, or other suppliers that have not signed a formal agreement with us.",2.9,"Omniscience
2.9","Palo Alto, CA","Palo Alto, CA",1 to 50 employees,2014,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
"Sr. Distributed Systems Research Scientist/Engineer, Software","$82K-$164K
(Glassdoor est.)","This is a unique opportunity to join the applied research team at Real-Time Innovations (RTI). As a Senior Distributed Systems Research Engineer on our research team, you will be part of a team that is maintaining our strategic lead in technology and thought leadership for building software communications frameworks for smart machines and critical real-world systems like the Kennedy Space Center launch system and Hyperloop. The RTI Connext software enables 1000s of applications and devices to exchange data in a timely and reliable way. Our software features direct peer-to-peer connections, reliable multicast, automated application discovery, and unique, contractual quality-of-service control.

Our team values creativity, risk-taking, innovation, and open communication. Our research spans an ever-growing range of interesting topics, including for example, advanced compression, machine learning, edge communications and processing, software-defined networking, hardware and software cybersecurity, resiliency, simulation and gaming engines, fault tolerance, embedded computing, microkernels, flight safety and software verification, and much more. Our government customers span a wide array of organizations – and, we continue to have an excellent record of bringing in funding (millions per year).

Real-Time Innovations (RTI) is the largest software framework provider for smart machines and real-world systems. Our software runs the largest power plants on the continent, connects perception to control in over 200 autonomous vehicles, drives the new generation of medical robotics, controls hyperloop and flying cars, and provides 24x7 medical intelligence to hospital patients and emergency victims. We are the best positioned small company in the world to create the very real future of intelligent, distributed systems.

RTI leads the world market for software that connects real-world devices. Our diverse and global workforce believes in working hard and enjoying the journey. We recognize employees for their achievements, offer great opportunities for career growth and development, and provide the tools they need to succeed. We also offer great benefits and flexibility. We commit to making your life as satisfying as your career. And, RTI's team is unmatched; our collaborative, transparent, and creative culture truly sets us apart from the rest.

We solve some of the greatest challenges in technology. Our mission is to transform industries: automotive, medical, power, defense, and control. Our core values emphasize excellence, teamwork, and your potential. Few small companies can truly claim to make the world run better like RTI. Come help make a real difference.

Responsibilities


You will be part of a team of experts researching emerging technologies, coming up with solutions for the problems posed by our research sponsors, exploring new concepts for products, prototyping ideas, and leading small teams to develop and to enhance advanced features related to RTI's secure real-time middleware platform. This is an individual contributor role. Duties will include:
Innovate new solutions that will form the foundation of secure, adaptable, and fast distributed systems
Create and execute long-term strategic research activities
Work with the business development team to define research areas of interest and define interesting research proposal topics
Write research proposals and project reports
Execute and lead research contracts to push our technology forward. Serve in the role of Principal Investigator on externally-funded research projects.
Actively interface with research project sponsors, customers, research partners, and prospects
Participate in and drive industry standards
Communicate technical innovations through papers and presentations
Support the transition of promising technical innovations to product including customer trials, coordinating with product management, design, development, testing and support groups
Requirements
PhD in Computer Science/Engineering, Robotics, Autonomy, Smart Machines, Distributed Systems or related field.
New graduates are welcome; some experience preferred.
Experience in distributed systems research
Excellent written communications skills, and evidence of research publications
Experience writing and winning proposals, and research project management
Solid understanding of computer network protocols; network and system programming, and real-time and/or high-performance applications
Solid programming skills (e.g. C/C++, Java, scripting languages)
Ability to work successfully / actively engage with a highly distributed team
(Preferred, not required!) Experience using OMG Data-Distribution Service (DDS) middleware, including development of distributed applications using DDS
U.S. citizenship required. Work to be performed for this position relates to federal government contracts which require U.S. citizenship.
Job Location

This position could be located at our new office in the Denver Metropolitan Area, Colorado, remote, or at headquarters in Sunnyvale, California.

About RTI


We have a collaborative and inclusive environment where individuals strong on aptitude and attitude will have an opportunity to grow their professional careers. Our culture embraces transparency, learning, and fun. We offer an attractive compensation package consisting of competitive salary, benefits, vacation bonuses, and equity participation.

RTI is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, religion, color national origin, sex, age status as a protected veteran, or status as a qualified individual with disability.",4.9,"Real-Time Innovations
4.9","Denver, CO","Sunnyvale, CA",201 to 500 employees,1995,Company - Private,Computer Hardware & Software,Information Technology,$25 to $50 million (USD),"ADLINK Technology, Wind River, Green Hills Software"
Sr. Data Engineer - SRE,-1,"WHO WE ARE

Signal Sciences is the fastest growing web application security company in the world. Our award-winning next-gen WAF and RASP solution protects 40,000+ applications and APIs with over 2 trillion production requests per month. Signal Sciences' patented architecture allows our customers to embrace cloud and DevOps while bringing actionable security visibility to development, DevOps, and security teams.

We work with some of the world's most recognizable companies, like Datadog, DoorDash, Under Armour, Starbucks, Aflac, and many more across industries. We make web applications more secure. Simple as that. We do it by providing an unparalleled platform that teams actually want to use. It's flexible, exceptionally elastic, collaborativeand protects business initiatives like DevOps and cloud adoption without disrupting current workflows and processes already in place.

SUMMARY

We are looking for a Senior Data Engineer with a strong Site Reliability Engineer (SRE) background who can help on performance, enhancements, and operationally support our system.

You will be architecting highly scalable data integration and transformation platform processing a high volume of data under defined SLA. You will be creating and building the platform that includes ingestion and transformation of data, data governance, machine learning, analytics, and consumer insights.

Our tech stack includes Elasticsearch, Logstash, Kibana, ElastiCache/Redis, MongoDB Atlas, AWS S3, Datadog, Go, RPC

RESPONSIBILITIES
Developing sequencing data pipelines and/or data science platform
Responsible for building and managing end-to-end data pipelines and operations from ingestion and integration through delivery for the data products
Build cross-functional relationships with Business Stakeholders, Architects, Data Scientists, Product Managers and IT to understand data needs and deliver on those needs
Drive the design, building, and launching of new data models and data pipelines in production
Manage the development of data resources and support new product launches
Lead discussion of product-oriented analysis in meetings with clients and partners; comfortable speaking to executives
Primary data liaison for stakeholders to drive transformation and to democratize use of data
Consolidate the fragmented data across the company and provide simplified access to data for the stakeholders, internal users as well as external partners
Support compliance and auditing through a single gateway for data exchange
Stay abreast of technology development in retail and other industries
Act as a sounding board on testing, experimentation, target audience profiling and consumer insights that analyze the relationship between customers, products, partners, conversions, engagement and revenue, and drivers
Work with multiple complex and disparate datasets to enable data delivery through various means and APIs to evaluate performance and amalgamate information to derive strategic insights and recommendations
Establish the core data foundation and common data lake to enable data-driven decisions
Support delivery of scalable data products
QUALITIES / EXPERIENCE WE'RE SEEKING
Software development experience
Exceptional skills in at least one high-level programming language (Java, Scala, Go, Python or equivalent)
ETL and ELT pipelines
Data processing and job orchestration
Implementing analytics pipelines to assess machine learning model results
Setting up data and cloud environments to make data science more efficient
Quickly learning new tools
Strong understanding of ELK Stack
Database experience including MongoDB
Experience with Container technology and AWS services including S3, Amazon ECS
Excellent communication skills to collaborate with cross-functional partners and independently drive projects and decisions
WHY YOU SHOULD JOIN SIGNAL SCIENCES

We're not just rethinking what's possible with web application securitywe're revolutionizing it. At Signal Sciences, we engineer big ideas with an eye on the future, building sustainable and wide-reaching solutions that not only serve teams' immediate needs but also instinctively evolve along with them. We believe in simple, effective actions. We value teamwork.

Signal Sciences is disrupting the web security industry and was recently named one of the Next Billion-Dollar Startups by Forbes. As a team member, you'll enjoy 100% employer-sponsored medical, dental, and vision benefits, 401K retirement plan, and a flexible work environment. Most of all, you will have the opportunity to make a positive impact on improving security in the world's #1 most vulnerable part of technology infrastructure (the web) with the new industry leader in web application security. Join us and find out why we were named Best Place to Work in 2019 by LA Business Journal, and Best Work-Life Balance in 2019 by Comparably.",4.1,"Signal Sciences
4.1",Remote,"Culver City, CA",51 to 200 employees,2014,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Senior Software Engineer - Big Data,-1,"Job TITLE: Senior Software Engineer - Big Data

Location: Sunnyvale, CA

Term: Contract

Skill: - Build scalable, high- performance, and efficient pipelines and workflows that are capable of processing billions of transactions and real-time customer activities.
Work with big data and provide to our data scientists the right tools, data marts and rollups to build their machine learning models.
Fluent in Pig and/or Hive with experience in building UDFs, Pig and Hadoop streaming.
Build automated reports that can help the team to proactively identify quality and/or coverage problems in releases or new versions of our models.
Apply knowledge of Azkaban, Oozie or Hamake for workflow management and job scheduling.
Provide senior leadership and demonstrable, programming expertise and proficiency in Java, C/C++, or Python.
Work on Data Warehousing architecture and data modeling best practices.

Experience: We are seeking for an accomplished, enthusiastic Senior Big Data Software Engineer to join the Walmart eCommerce team. This exciting position involves many key engineering challenges as we deal with huge data sets (Billions of Transactions, Petabytes of data) to impact real-time customer activities.
Must have demonstrable, programming proficiency in one or more of the following: Java, C/C++, or Python.
Deep understanding of Map Reduce framework & Hadoop.
Fluent in Pig and/or Hive with experience in building UDFs, strong scripting ability.
Proven expertise and understanding of ETL techniques.
Knowledge of Azkaban, Oozie or Hamake for workflow management and job scheduling.
Must be team oriented and collaborative to interact with both managers and cross functional teams.
Ability to thrive in a fast paced environment on multiple projects in various phases and under tight deadlines

Education: Bachelor of Science degree or equivalent in Computer Science, Computer Engineering, Electrical Engineering or a related field plus 7-10 years of software engineering experience at a senior level; OR a Master’s degree or higher with 5-7 years of senior software engineering experience.",4.0,"Flexton
4.0","Sunnyvale, CA","San Jose, CA",51 to 200 employees,2007,Company - Private,IT Services,Information Technology,$10 to $25 million (USD),-1
VMWare Storage Engineer,-1,"Job Description
This is an exceptional opportunity to be creative and provide essential support to a prototyping environment that will push research and development forward. We are looking for emotionally intelligent professionals with a willingness to learn, a comfort with the unknown and drive to be creative. As a Storage / VMWare Engineer, You will build, install, configure, and troubleshoot VMWare based servers and systems as part of a full stack containerized microservices architecture. In this role you will participate in fostering a DevOps culture, building strong cross functional collaboration with all areas of development, product, and QA in a dynamic and fast paced environment. You will support the development of a data pipeline and machine learning (ML) services integration in support of intelligence community analysts whose mission is to solve unique and challenging problems

Responsibilities and Duties:

You will work closely with the chief architect, systems engineers, software and data engineers, and data scientists on the following key tasks:
Deploy, maintain and support VMWare storage-based system tools such as VMWare Site recovery Manager and Virtual Volumes
Develop and execute a multi-site recovery plan
Assist with phase-in activities including initial HW/SW configuration tests and network connectivity
Maintain the deployment environment according to the systems engineering specifications and baseline configuration at given points in time
Deploy, operate, diagnose, and maintain containerized (Docker) microservices across orchestrated (Kubernetes) environments
Maintain and orchestrate services and procedures for a big data pipeline which includes kafka, Elasticsearch, and several in house written python/java running on Kubernetes
Orchestrate staging and production deployment
Develop scripts to monitor and check health of the deployed pipeline
Maintain and develop DevOps automation using tools
Design, develop, and support scalable, redundant infrastructure to include physical and virtualized environments
Improve existing infrastructure to incorporate latest technology best practices and cross application integrations
Day-to-day collaboration with developers and QA teams, to influence design, and architect solutions in multi-tiered environments
Manage individual project priorities, deliverables, and deadlines
Produce clear documentation for delivered solutions
Required Skills:
BS in Computer Science, Systems Engineering, or related technical field or equivalent experience with at least 8+ years in systems engineering or administration or 4 additional years of experience in lieu of degree
Must have an active Top-Secret security clearance and able to obtain a TS/SCI with Polygraph
Experience with deployment and operations of containers as well as container orchestration tools
Experience orchestrating workflows to execute at predefined times, including workflows that have data dependencies
Proficiency in DevOps tools; scripting
4 years of experience with VMWare tools
4 years of experience in an operations role
2 years experience in a VMWare environment
2 years of patching servers, backups, permission management
2 years experience providing Tier II & III Windows and UNIX (Linux) support
Networking (TCP/UDP, ICMP, and DNS, etc.), infrastructure services, and security
Ability to work well with people from many different disciplines with varying degrees of technical experience
Ability to express complex technical concepts effectively, both verbally and in writing
CompTIA Security+
Specific experiences and skills Desired with the following (preferred):
Knowledge and some understanding of Kubernetes, Ansible, Puppet, Salt, Linux, Git, Python, Elasticsearch, Logstash, IPA, AWS, OpenStack, Java, Kafka, Hadoop, etc
Experience establishing large computer clusters- Experience in continuous configuration automation (CCA) methods for providing a flexible, programmatic platform for deploying and managing the configuration of infrastructure and application resources
Experience in applying both agent-based and agentless (e.g. SSH) methods to event-driven orchestration and remote execution for configuration management
Experience in applying automated configuration management and deployment tools (e.g. Puppet, Chef, Ansible, and Salt) for configuration automation, cloud control, and event-driven orchestration
Mount indie is an Equal Opportunity Employer. We celebrate diversity, respect and seek to empower each individual and support the diverse cultures, perspectives, skills and experiences within our company. Mount Indie's commitment is to create an inclusive environment for all employees",5.0,"Mount Indie
5.0","Reston, VA","San Diego, CA",1 to 50 employees,-1,Unknown,-1,-1,Unknown / Non-Applicable,-1
Senior Machine Learning Engineer,-1,"Job Description
We are looking for a strong Senior Data Scientist or Senior Machine Learning Engineer - a proven 'doer' to develop, implement and extend data-intensive machine learning software for real-time auctioning, ad inventory estimation, and audience segmentations.

You will design and implement core components of our algorithms, as well as model and monetize the large amounts of data that generates daily.

Working with our Data Science team, you will apply Machine Learning to help get things done.

As a Senior ML Engineer, you will need:
Development and implementation of data-intensive machine learning software for real-time auctioning, ad inventory estimation, audience segmentations, and other AdTech applications
Working with data scientists, product managers, and software engineers to develop and support the software for new Machine Learning products
Ensuring excellence in delivery to internal and external customers
For this role you will need:
3+ years hands-on industry work experience designing and building large-scale data, machine learning, and analytics applications and pipelines that are well-designed, cleanly coded, well-documented, operationally stable, and timely delivered
5+ years total Machine Learning experience, including years of academic research
Experience with R, Python data analysis libraries (pandas, sklearn, numpy, scipy, and matplotlib), and Spark MLlib
Proficiency with Spark, Hadoop, Kafka, Hive, and SQL
Solid software engineering skills, with proficiency in Python and experience with Scala, Java, C/C++
MS / PhD in Computer Science or related field
PROPRIUS is an AI Industry recruiting firm. We’re lucky enough to recruit the best candidates into the most exciting companies all over the United States. We deliver performance.",5.0,"PROPRIUS
5.0","San Francisco, CA","London, United Kingdom",1 to 50 employees,-1,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
"Senior Technical Program Manager, Deep Learning Software","$113K-$176K
(Glassdoor est.)","We are looking for an ambitious person to be our Sr. Technical Program Manager for Deep Learning Software! You will work with engineering and product leaders on the planning and execution of programs to develop and publish software to train and infer deep neural networks. You will drive process and coordinate work between multiple organizations, ecustomers, and researchers. Your work will enable NVIDIA’s customers to employ deep neural networks in their products across many industries.

NVIDIA’s invention of the GPU 1999 sparked the growth of the PC gaming market, redefined modern computer graphics, and revolutionized parallel computing. More recently, GPU deep learning ignited modern Artificial Intelligence — the next era of computing — with the GPU acting as the brain of computers, robots, and self-driving cars that can perceive and understand the world. Today, we are increasingly known as “the AI computing company”. We are looking to grow our teams with the smartest people in the world. If you're creative and autonomous, we want to hear from you!

What you'll be doing:
Define and drive process within the fast paced field of machine learning and deep learning
Develop critical metrics, program schedules to measure release health, predictability, and achievements
Identify failures, lead retrospective analysis, and help to develop improvement action plans
Lead and be viewed as a leader
Work closely with engineers on architectural discussions and challenge design choices that we make
Build best practices and persuade multiple business units of the advantages
Anticipate risks and develop risk management solutions as appropriate
Regularly communicate program status and key issues to senior management at NVIDIA’s headquarters
Build high level understanding of products, projects and goals and highlight domain specific / new market application possibilities
Coordinate efforts between development teams, product managers and solution architects
Work with development teams on test plans, execution, reviews, failure analysis and assessing overall quality and risk
Work with customer PMs on software issues including technical feedback from OEMs and CSPs.
Developing key KPIs to track execution and deploy process improvements to improve efficiency
What we need to see:
Strong technical background. Previous experience as a software engineer, data scientist or a software QA engineer.
Meaningful work experience in technical program, project or product management role
7+ years of experience managing global projects and readiness to work flexibly in multiple time zones
Excellent communication and effective presentation skills with a proven ability to articulate a value proposition to technical and non-technical audiences
Master’s degree in Engineering, Computer Science, or similar field
Ability to multitask, quickly switch context, and be thorough
Experience influencing decisions and leading teams in a matrix environment.
Enthusiastic, responsive and passionate about finding opportunities for
Ability to think strategically and tactically and to build consensus to make programs successful.
Strong problem solving skills, consistently successful implementing systematic solutions.
Ways to stand out from the crowd:
Experience with machine learning, deep learning, open source software, and/or GPU technology such as CUDA
5 years programming of a modern programming language is highly desired
Deep understanding of software engineering principles and enterprise system
architecture
Previous experience with productizing enterprise server systems
Solid understanding coordinating activities between HW / SW organizations
Experience with Open Source and 3rd Part Open Source SW suites such as Black Duck or Palamida
Previous experience in driving process and measuring for efficiency and effectiveness
Working knowledge with agile methodologies ( Scrum, Safe, Less, Business agility )
Previous experiences in IS026262 and ASPICE Standards
Natural inclination to improve what we build and how we build it
NVIDIA is widely considered to be one of the technology world’s most desirable employers. We have some of the most forward-thinking and hardworking people in the world working for us. If you're creative and passionate about developing cloud services we want to hear from you!

NVIDIA is committed to fostering a diverse work environment and proud to be an equal opportunity employer. As we highly value diversity in our current and future employees, we do not discriminate (including in our hiring and promotion practices) on the basis of race, religion, color, national origin, gender, gender expression , sexual orientation, age, marital status, veteran status, disability status or any other characteristic protected by law.#deeplearning",4.6,"NVIDIA
4.6","Santa Clara, CA","Santa Clara, CA",10000+ employees,1993,Company - Public,Computer Hardware & Software,Information Technology,$5 to $10 billion (USD),-1
"Sr Python Machine learning - Rosemont, MN or Wichita, KS - Fulltime",-1,"Role Sr Python Machine learning Location Rosemont, MN or Wichita, KS Duration FULLTIME 1) Senior Level Python Developer - 5+ yearsrsquo experience building Data Integrations andor Machine Learning models for analytics 2) Hands on experience with Object Oriented Programing - as this is what the application is built on 3) Will need to be self-sufficient and solution minded - not just a heads down coder. Really a borderline architect. + Any exposure to Manufacturing or logistics would be a huge plus + any work with AI applications also a big nice to have Bachelor's Degree - Proven professional experience with object oriented programming in a technology focused role (including but not limited to IT Roles such as Software Developer, Data Engineer, DevOpsCloud Engineer, Data Scientist) - 5+ years professional coding experience - 5+ yearsrsquo experience building Data Integrations andor Machine Learning models for analytics Thanks Regards Vijay Kumar Maragoni vijaymusmsystems.com 703-880-9819 469-900-2150571-250-7346",2.7,"USM Business Systems
2.7","Rosemount, MN","Chantilly, VA",51 to 200 employees,1999,Company - Private,Computer Hardware & Software,Information Technology,$25 to $50 million (USD),-1
Field Programmable Gate Array (FPGA) Software Engineer,-1,"Job Description
Company Description

IIA is currently looking for a Field Programmable Gate Array (FPGA) Software Engineer to work in either Herndon VA, McLean, VA, or Clarksburg, MD

Job Description

Overview:

As an FPGA Software Engineer you will be a key player in IIA’s innovation and growth efforts. You will support software and firmware design, development, and integration. You will support the porting and acceleration of machine learning and other algorithms from desktop to Field-Programmable Gate Arrays and other embedded devices. You will also participate in the corporate innovation laboratory, open source projects, and strategic business capture. This is a Full-Time position and work location is negotiable among locations in Herndon, VA, McLean, VA, and Clarksville, MD or remote.

Job Responsibilities:

• Work collaboratively in agile, mixed team environment with other FPGA engineers, software developers, data scientists and geospatial experts to port machine learning and other algorithms from CPU to FPGA with tight memory constraints and complex mission requirements

• Support testing, evaluation, installation and configuration of algorithms on FPGAs

• Support production maintenance activities that include the development of automated scripts and scheduled tasks, application/system monitoring, software/security updates and patching, archiving/disposition of system logs and/or data records

• Work with the Chief Technology Officer and Business Development teams to advance corporate capabilities, including the innovation laboratory and open source projects

• Support white paper development, strategic captures, and proposals in your areas of expertise and experience

• Envision and collaborate on open source or proprietary proof of concept pilots or projects

Required Skills:

• Highly skilled programmer in relevant languages, such as C/C++ and Java

• Ability to analyze existing code and rewrite and optimize for FPGA board, such as the Xilinx Kintex Ultrascale

• Ability to work in an Agile DevSecOps environment using tools like Jira, Confluence, Bitbucket, and Slack

• Ability to deploy applications in various on premise and public cloud environments

• Excellent written and verbal communication skills

• Ability to work independently and collaboratively

• Ability to identify and pursue opportunities for program growth



Desirable Skills:

As part of a multidisciplinary, cutting-edge team, the following optional experience is also viewed favorably:

• Development of machine learning inferencing engine

• FPGA in aerospace environments

• GPU and Internet of Things embedded systems programming experience

• Deep learning and machine learning frameworks, libraries, and models, like Caffe2, PyTorch, TensorFlow, and YOLO, and languages such as Python, Go, Julia, Javascript, and shell scripts

• Open source or proprietary geospatial software

• Signals and communications processing

• Hybrid multicloud containerization and serverless computing experience, such as Docker, Kubernetes, CI/CD.

• Interest in emerging computing architectures

• Business development

Education:

Bachelor’s Degree required, Master’s Degree preferred in electrical engineering, computer engineering, physics, mathematics or related field.

Clearance Requirements:

You do not need a current/active clearance to apply, but must be able to pass and hold a government Public Trust (SF-85) background investigation. You must either be a US Citizenship or Green Card Holder to be eligible.

IIA is proud to be an EEO/AA employer M/F/D/V.

Qualifications

Desirable Skills:

As part of a multidisciplinary, cutting-edge team, the following optional experience is also viewed favorably:

• Development of machine learning inferencing engine

• FPGA in aerospace environments

• GPU and Internet of Things embedded systems programming experience

• Deep learning and machine learning frameworks, libraries, and models, like Caffe2, PyTorch, TensorFlow, and YOLO, and languages such as Python, Go, Julia, Javascript, and shell scripts

• Open source or proprietary geospatial software

• Signals and communications processing

• Hybrid multicloud containerization and serverless computing experience, such as Docker, Kubernetes, CI/CD.

• Interest in emerging computing architectures

• Business development

Education:

Bachelor’s Degree required, Master’s Degree preferred in electrical engineering, computer engineering, physics, mathematics or related field.

Additional Information

You do not need a current/active clearance to apply, but must be able to pass and hold a government Public Trust (SF-85) background investigation. You must either be a US Citizenship or Green Card Holder to be eligible.

We are proud to be an EEO/AA employer M/F/D/V.",3.8,"Information International Associates, Inc.
3.8","McLean, VA","Red Bank, NJ",1 to 50 employees,-1,Company - Private,IT Services,Information Technology,Less than $1 million (USD),-1
Lead Data Scientist,"$117K-$186K
(Glassdoor est.)","Please note, this is a proactive search for a role that has been vetted by our leadership team for future hiring.  The recruiting team and hiring managers remain active in discussions with interested, qualified individuals and are committed to being transparent on timelines throughout the process. Thank you.

Who We Are:

Vistaprint’s Data and Analytics (DnA) organization is working to make our company one of the world’s most well-known and successful data-driven companies. The cross-functional team includes product owners, analysts, technologists, data engineers and more – all focused on providing Vistaprint with information and tools we can use to deliver jaw-dropping customer value. DnA team members are empowered to learn new skills, communicate openly and be active problem-solvers.

What You Will Do:

As the Lead Data Scientist, you will be a “go-to” domain specialist in data science and machine learning, leading the charge on ground breaking work, mentoring more junior data scientists, and guiding the organization on methodology and best practices. You will also drive high-profile projects - not just delivering solutions, but helping to seek out new opportunities and own the creation of innovative solutions. Your statistical, computer science and business domain expertise will have a significant impact to our business from day one.

You will join a core team of Data Scientists, working alongside Marketers, Analysts, Engineers and Product Owners to forge new paths and redefine how data is utilized to deliver value. You’ll seek ways to improve, communicate openly, and be an active problem-solver. Throughout the design, development, and delivery stages you will surprise yourself with new levels of professional and personal growth.
Engage with cross-functional business partners to identify analytical project requirements, discuss methodologies and determine deliverables.
Learn, practice, and lead others in using new tools in an ambitious technical environment that combines both coding skills, web technologies and real-time data.
Analyze pre-existing models and algorithms; provide suggestions on how to improve the efficiency and effectiveness, to drive value to the organization
Deliver a range of custom Data Science projects that may include Recommendation Systems, Price Optimization; Time Series Modeling; Customer Lifetime Value Customer, Propensity Modelling); Image Recognition, etc.
Act as a thought leader within the Data Science team, staying ahead of the latest trends and technologies
Your Qualifications:
5+ years machine learning and modeling experience, and have delivered multiple projects as a lead scientist or in a similar capacity
MSc or PhD in Statistics, Mathematics, Operational Research or similar field
Strong programming skills in Python and R
Hands on experience using “big data technologies”
Experience of software engineering techniques including version control, continuous integration, unit testing.
Experience of designing and building DS products for ecommerce like recommendation systems, forecasts, Customer Lifetime Value Models, etc.
Business partner management; ability to independently communicate technical and statistical concepts to non-practitioners, and influence the application.
Nice to Have:
Spark, Java, Scala
Bayesian Statistics
Experience using standard libraries (scikit-learn, MLlib, TensorFlow, MXNet, PyMC3)
Agile working methodology
Relevant work in an e-commerce environment
Why You’ll Love Working Here:

At Vistaprint, we put great importance into the wellbeing of our employees, which is why we offer perks that ensure a phenomenal work/life balance. Perks include flexible schedules, work from home capabilities, and very generous time off, including our unique sabbatical-like program, “Vistabreak”, to name a few! Here in Waltham, we offer a modern and collaborative office environment with a free on-site gym, fully stocked kitchens, and cold brew on tap.

About Us:

As an e-commerce powerhouse, Vistaprint is a dynamic organization that maintains an exciting, entrepreneurial culture. With founder Robert Keane’s return as CEO, we’ve renewed our focus on empowering and helping small businesses. To do this, we create customer value (and delight) through accessible, cutting-edge technology. We thrive on providing opportunities for exploration, collaboration, innovation and growth – for both our customers and our team.

Equal Opportunity Employer:

Vistaprint, a Cimpress company, is an Equal Employment Opportunity Employer. All qualified candidates will receive consideration for employment without regard to race, color, sex, national or ethnic origin, nationality, age, religion, citizenship, disability, medical condition, sexual orientation, gender identity, gender presentation, legal or preferred name, marital status, pregnancy, family structure, veteran status or any other basis protected by human rights laws or regulations. This list is not exhaustive and, in fact, in many cases, we strive to do more than the law requires.

#LI-AC1

Nearest Major Market: Waltham
Nearest Secondary Market: Boston
Job Segment:
Scientific, Database, Engineer, Scientist, Computer Science, Engineering, Technology, Science",3.5,"Vistaprint
3.5","Waltham, MA","Venlo, Netherlands",5001 to 10000 employees,1995,Company - Public,Other Retail Stores,Retail,$1 to $2 billion (USD),"Tripadvisor, Wayfair, Amazon"
Senior Software Development Engineer - Deep Learning Platform,"$135K-$210K
(Glassdoor est.)","Interested in machine learning and AI? Can you envision a future where technology is driven primarily by smarter machines?

The mission of AWS AI is to make machine learning easy, fast, and universal across all of our customers. Our world class platform provides the services that runs 85% of all on-cloud machine learning through performance optimizations, machine learning tools, and SDKs to democratize machine learning. Our customers include scientists, data analysts, and ML engineers all building and deploying models through either SageMaker or self-managed instances on EC2/EKS.

As a software development engineer in AWS AI, you will be at a rare intersection of AWS-scale software development, advanced machine learning topics, and innovative product development. The right candidate will possess a technical background with experience in both machine learning and cloud-based software engineering. Strong engineering skills and prior experience with machine learning frameworks and cloud platforms is a must. Our customers are deeply technical and the solutions we build for them are strongly coupled to technical feasibility. You must be able to thrive and succeed in an entrepreneurial environment, and not be hindered by ambiguity or competing priorities.

This means you are not only able to develop and drive high-level strategic initiatives, but can also roll up your sleeves, dig in and get the job done. Ownership, high judgment, negotiation skills, ability to influence, analytical talent and leadership are essential to success in this role.


Amazon is an Equal Opportunity Employer Minority / Women / Disability / Veteran / Gender Identity / Sexual Orientation / Age.





Basic Qualifications

· 4+ years of professional software development experience
· 3+ years of programming experience with at least one modern language such as Java, C++, or C# including object-oriented design
· 2+ years of experience contributing to the architecture and design (architecture, design patterns, reliability and scaling) of new and current systems
· Experience in python, distributed systems, and cloud services
· Experience with one or more machine learning technologies such as PyTorch or TensorFlow
· Experience with Apache Airflow, Argo Workflows, and Kubernetes
· Experience launching cutting edge science as features in existing products or as new products

Preferred Qualifications

· Experience participating in and leading open source projects, including community meetups
· Experience communicating with technical and non-technical stakeholders across multiple business units",3.9,"Amazon
3.9","East Palo Alto, CA","Seattle, WA",10000+ employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),"Google, Microsoft, Walmart"
Senior Software Engineer (Backend),"$152K-$231K
(Glassdoor est.)","About Opendoor:Are you intrigued by the thought of disrupting a trillion dollar industry through technology? At Opendoor, we're on a mission to make it simple to buy and sell homes. The traditional process is broken, with an average home taking over 90 days to sell and costing thousands of dollars. We empower everyone with the freedom to move by making buying and selling a home stress-free and instant. We've built an exceptional team, seen strong growth, served nearly 75,000 customers (with an annual run rate of $5 billion), and raised $1.3 billion in funding. With Covid-19, the world is changing, and real estate is no exception. The coming years present a tremendous opportunity for innovation as we explore new frontiers and scale nationwide.About the Role:The role of the Backend Engineering team is to form the foundation for data processing and exploration at Opendoor. One component is producing a world class data set for our pricing and machine learning algorithms. Real estate data is a complex and challenging data domain, and to put things into perspective, a single piece of inaccurate data can cause hundreds of thousands of dollars of swings in home value. Another component is building platforms and tools to allow our analysts and data scientists to iterate on state of the art machine learning and pricing algorithms, which are critical to serving our customers and ensuring Opendoor is a sustainable business. As Opendoor continues to transact on billions of dollars of homes, the Backend Engineering team continues to lie at the core of Opendoor's product and business strategy.Your responsibilities will include:* Processing large amounts of real estate and transactional data in batch and real time to generate a highly accurate world class real estate data set.* Understanding how to quantify uncertainty with our data.* Deriving fields from unstructured data (e.g. extracting data from home photos and satellite images with Computer vision algorithms, extracting data from MLS remarks with natural language processing).* Performing analysis to ensure our datasets are robust and reliable for machine learning and business use cases.* Applying deep understanding of data processing technologies to reason about engineering / design tradeoffs.* Working with data processing technologies such as Spark, Airflow, Pytorch, Jupyter, and PandasWe're looking for teammates who have:* Bachelor's degree in Computer Science, Engineering or related field, or equivalent training, fellowship, or work experience* 6+ years of track record in building and delivering production quality software systems* A deep understanding of data processing technologies such as SQL, Spark, Hadoop, and Kafka* Experience with Airflow, Luigi, or other ETL scheduling technologies* The ability to propose and test hypothesis to problems, and drive toward the best solution whilst starting with incomplete information* Experience with building resilient and reliable systems or data pipelines* A focus on rapid delivery without sacrificing technical excellence* Care for modular, performant and testable codeBonus points:* Love delighting customers with honest, transparent products and experiences* Experience working with AWS, microservice architecture, Python/Go/Scala, Kubernetes* Experience working with GIS DataMore About UsWant to learn more about us and how we are revolutionizing the home buying and selling process? Learn more about us on our website, check out our profile on The Muse to learn more about our culture from our team members, or read our blog posts to hear about the work we are doing.We Offer the Following Benefits and Perks:* Full medical, dental, and vision with optional 70% coverage for dependents* Flexible vacation policy* Commuter Benefit stipend* Generous parental leave* Paid time off to volunteerPlease note that these benefits and perks are available only to Full Time team members and do not apply to contract roles.Opendoor values OpennessOur team celebrates our diverse backgrounds. We believe that being open about who we are and what we do allows us to be better. Individuals seeking employment at Opendoor are considered without regards to race, color, religion, national origin, age, sex, marital status, ancestry, physical or mental disability, veteran status, sexual orientation, gender identity or other protected status under all applicable laws, regulations, and ordinances.",3.5,"Opendoor
3.5","San Francisco, CA","San Francisco, CA",501 to 1000 employees,2014,Company - Private,Real Estate,Real Estate,$2 to $5 billion (USD),-1
Machine Learning Engineer - SEAL with Security Clearance,-1,"Job Description The Sensors and Electromagnetic Applications Laboratory (SEAL) of the Georgia Tech Research Institute (GTRI) is seeking technical personnel to be part of an established software team that has multiple opportunities for software engineers within the Software Engineering and Architecture Division (SEAD) at Smyrna, GA. The SEAD group mission is to provide world-class software to be used in sensors, signal processing, electronic warfare, tracking, and intelligence surveillance reconnaissance (ISR) systems deployed on land, air and sea. Our software team employs a modern software engineering process to design, code, integrate and test capabilities on a continuous basis resulting in a mature and quality solution for our customers. We strive for technical excellence by drawing upon a diverse workforce whose knowledge base covers the complete spectrum of modern computing languages and platforms. Job Duties The successful candidates will be involved in the artificial intelligence (AI) software design, development, integration and testing of the systems. Our real-time machine learning software applications are developed using C++ and Python in a Linux environment. Our group utilizes productive modern (Agile) and industry-proven software development processes and environments. The candidate will get the opportunity to creatively solve problems, design features, and independently and work in a team environment to implement projects. The candidate will have the opportunity to leverage machine learning techniques to build processes to gather insights from a high volume of data from multiple sources. You will develop systems to efficiently process the data in our platform. The candidate will ultimately be responsible for developing powerful software systems that reinforce our place as a technical research leader in machine learning and deploying software. Travel Requirements 10% - 25% travel Education & Length of Experience Research Engineer/Scientist I * A Bachelor's degree in Computer Engineering, Computer Science, Electrical Engineering, Mathematics, Physics, or related field of study. Research Engineer/Scientist II * A Master's degree in Computer Engineering, Computer Science, Electrical Engineering, Mathematics, Physics, or related field of study and three (3) years of relevant full-time experience after completion of that degree, * A Master's degree in Computer Engineering, Computer Science, Electrical Engineering, Mathematics, Physics, or related field of study and five (5) years of relevant full-time experience after completion of a Bachelor's degree, or * A Doctoral degree in Computer Engineering, Computer Science, Electrical Engineering, Mathematics, Physics, or related field of study. Required Minimum Qualifications * Candidates currently enrolled in an accredited Bachelor's degree program relevant to this position will be considered. Candidate must have a graduation date of no later than May, 2020 * Artificial Intelligence algorithms utilized for applications * Knowledge of industry AI tools (e.g., TensorFlow, PyTorch, etc.) * Experience with C and C++ * Experience with Linux or Windows * Experience in software engineering and development * Knowledgeable in version control software such as GIT * Knowledgeable in JIRA, Bitbucket and Confluence * Good verbal and written communication skills * Self-starter and ability to work in a team environment Preferred Qualifications * Knowledge of computer architectures including multi-core environments * Familiarity with software applications requiring multi-threaded programming implementation * Experience in software engineering and development * Complex programs that involved hardware, software, communications and networking * Existing secret clearance, or the ability to obtain an interim clearance within 30 days and full clearance thereafter U.S. Citizenship Requirements Due to our research contracts with the US federal government, candidates for this position are required to be US Citizens. Clearance Type Required Ability to obtain Secret Clearance upon hire Diversity & Inclusion Diversity & Inclusion (D&I) at Georgia Tech Research Institute aims to enhance the Institute's mission of solving the world's most complex technical problems by creating a workforce with a shared appreciation for diversity, raising awareness around inclusiveness, and fostering a sense of belonging and appreciation for all members of our community. Equal Employment Opportunity Georgia Tech Research Institute is an Equal Opportunity Employer of individuals with disabilities and protected veterans and actively seeks diversity among its employees. Equal Employment Opportunity is the Law . Posted: 05/01/2020 Closes: 08/01/2020 Back Submit Resume",3.6,"The Georgia Tech Research Institute
3.6","Smyrna, GA","Atlanta, GA",1001 to 5000 employees,1943,Subsidiary or Business Segment,Research & Development,Business Services,$100 to $500 million (USD),"MIT Lincoln Laboratory, Johns Hopkins University Applied Physics Laboratory"
Semantic Engineer (Sr),"$82K-$106K
(Glassdoor est.)","Job Summary


The J. Paul Getty Trust is looking for an enthusiastic Senior Semantic Engineer, with the experience and passion to design and lead the execution of data oriented projects to support, connect, enrich and ensure the persistence of the institution's cultural heritage knowledge bases. Our aim is to provide a deeply connected and consistent experience for scholars, researchers, and enthusiasts as they explore the complex information held across the organization, and your participation is crucial for that to be successful.

You will report to the Enterprise Semantic Architect, and interact with software engineers, data engineers and content specialists in the cultural heritage programs. Your work will improve the quality, reliability, connectedness, and consistency of our data by designing ontologies and models to represent the institution's broad knowledge, configuring Linked Open Usable Data (LOUD) platforms. You will have a hands on role with both content specialists in the programs and with the wider community, and be responsible for working with both to understand data requirements and then ensure those requirements are correctly represented and able to be easily implemented.

The Getty is among the most prestigious cultural heritage organizations in the world, dedicated to furthering the study of the history of art. You will work on an amazing campus amongst fabulous art, architecture, and information systems, collaborating with world-class scientists, curators, librarians, archivists, and academics. We offer every other Friday off, excellent benefits, and a very strong commitment to balancing work and personal life.

Major Job Responsibilities
Work with technical and content stakeholders to understand data oriented project requirements
With the Semantic Architect, design and document the institution's data model and resulting APIs
With Data Engineers, to ensure the accuracy of data transformation pipelines to migrate legacy datasets into Linked Open Usable Data (LOUD) within our data engineering ecosystem
With Data Engineers, design and ensure the accuracy of validation services for LOUD models
Participate in standardization and adoption efforts for Linked Open Usable Data ontologies, profiles and implementations
Integrate external content services to enrich and reconcile our data
Participate in agile data management, with continuous integration and deployment
Configure institutional LOUD data management instances built on the Arches Platform
Assist software engineering teams by translating stakeholder requirements into feature requests
Disseminate results via appropriate academic and industry communication channels
Qualifications
Bachelor's degree in a related field or a combination of education and relevant experience; Master’s in Information Science, Philosophy or related, or PhD strongly preferred
5+ years of knowledge management/ontology engineering; semantic web experience strongly preferred
5+ years of software development, management or implementation experience
Knowledge, Skills and Abilities
Excellent verbal and written communication skills, especially when interacting with non-technical stakeholders
Attention to detail combined with a focus on product usability
Direct experience of standardization efforts relevant to the cultural heritage community
Expertise in data-oriented work within cultural heritage organizations
Expertise in cultural heritage data standards
Expertise with Linked Open Data standards and technologies
Proficiency in Python, or willingness to translate experience
Proficiency in relational and document oriented databases
Familiarity with technical productivity tools such as git, docker
Familiarity with agile software development methodologies
Familiarity with machine learning, data mining or similar concepts",3.6,"J. Paul Getty Trust
3.6","Los Angeles, CA","Los Angeles, CA",1001 to 5000 employees,1954,Nonprofit Organization,Grantmaking Foundations,Non-Profit,Unknown / Non-Applicable,-1
"Senior Data Scientist -San Jose, CA",-1,"Please note this posting is to advertise potential job opportunities. This exact role may not be open today, but could open in the near future. When you apply, a Cisco representative may contact you directly if a relevant position opens.

What You'll Do


Have you ever dreamt of joining a highly skilled team to build a ground breaking product with a start-up spirit, yet the power of the top networking company in the world? This is the mission of our team. We are actively hiring highly-skilled engineers, with a true passion for innovation. Our mission is to build a new generation of routing engine for the Internet deeply using Data Analytics, Machine Learning (ML), and Artificial Intelligence (AI). The size, diversity, and richness of our data are, simply unmatched. The Internet is changing fast, and we are too. The objective of this confidential product is to adopt a highly novel and ambitious approach for optimizing networks to better serve applications.

You thrive in dynamic environments that require a rare blend of innovation and speed of execution. You pride yourself on your communication and interpersonal skills, a keen eye for both aesthetic design and code and an ability to autonomously plan and organize your work assignments based on the objectives of the team.

Who You'll Work With


Our team is made of engineers with a very diverse skillset united by their passion for innovation and the excitement of turning wildly disruptive ideas into products that impact the industry at large. We are building Cisco’s next-generation technological innovation by combining machine learning and distributed software with networking technologies.

We love designing and implementing large-scale machine learning pipelines. Our technology stack includes Python, Scala, Go as well as a wide range of internal tools built on top of Apache Spark, TensorFlow, PostgreSQL and the Hadoop ecosystem.

Who You Are


An agile, pragmatic, and hardworking engineer with hands-on experience in providing simple and intuitive visualization of complex and intricate datasets for web and mobile applications. You love technology, innovation, and building products at scale.

You hold a Ph.D. or M.S. in computer science, Machine Learning, Statistics, or other data-science related field. You can demonstrate a strong track record in the following areas:
Strong background in statistics and machine learning is required, preferably with 5 to 10 years of industrial experience.
Ability to explore large datasets and find key descriptive and inferential properties in large and diverse datasets. Identify patterns and interactions in the data, and to clearly articulate impact of such data properties on proposed usecases.
Strong programming skills in Python, with an ability to manipulate large and complex datasets using distributed computing technologies (e.g., Apache Spark).
Expertise in time-series forecasting is appreciated.
Excellent quantitative, analytical, and communication skills; past experience working with other mathematicians, scientists, or engineers is required.
Software development methodologies and tools (unit and system testing, code reviews, Git).
Excellent English spoken and written skills (C1 level) is required.
We Are Cisco


#WeAreCisco, where each person is unique, but we bring our talents to work as a team and make a difference. Here’s how we do it.

We embrace digital, and help our customers implement change in their digital businesses. Some may think we’re “old” (30 years strong!) and only about hardware, but we’re also a software company. And a security company. An AI/Machine Learning company. We even invented an intuitive network that adapts, predicts, learns and protects. No other company can do what we do – you can’t put us in a box!

But “Digital Transformation” is an empty buzz phrase without a culture that allows for innovation, creativity, and yes, even failure (if you learn from it.)

Day to day, we focus on the give and take. We give our best, we give our egos a break and we give of ourselves (because giving back is built into our DNA.) We take accountability, we take bold steps, and we take difference to heart. Because without diversity of thought and a commitment to equality for all, there is no moving forward.

So, you have colorful hair? Don’t care. Tattoos? Show off your ink. Like polka dots? That’s cool.",4.1,"Cisco Systems - Engineering - Software
4.1","San Jose, CA","San Jose, CA",10000+ employees,1984,Company - Private,Computer Hardware & Software,Information Technology,$10+ billion (USD),"Alcatel-Lucent, Juniper Networks"
"Senior Machine Learning Engineer, Infrastructure",-1,"Company Description

Cash App is the fastest growing financial brand in the world. Initially built to take the pain out of peer-to-peer payments, Cash App has gone from a simple product with a single purpose to a dynamic app with over 24 million monthly active users. We are bringing a better way to send, spend, invest, and save to anyone who has ever sought an alternative to the traditional banking system.

Loved by customers and pop culture, we’ve consistently held the top spot for finance in the App Store for many years, seeing more engagement with millions of followers across social media in a day than most brands see in a year. We are building an ecosystem to redefine the world’s relationship with money by making it universally accessible.

We want to hire the best talent regardless of location. Our employment model is distributed, offering the opportunity to collaborate with teams across the world in San Francisco, New York, St. Louis, Portland, Toronto, Kitchener-Waterloo, Sydney, and Melbourne.

Interested in learning more?

Job Description

At Cash App we believe Machine Learning, especially Deep Learning powered Artificial Intelligence, is the future. Our mission is to make them available in the present. To achieve this we’re organized into three teams: ML Platform, Data Infrastructure & Risk.

We believe each Machine Learning Engineer has a diverse set of skills, regardless of what your strength is, we would love to talk to you.

Problems you’d be solving:
Prototype new approaches and productionize solutions at scale for our 24+ millions of active users
Help execute our long-term Machine Learning strategy across Cash App
Create a world class platform for training, hosting and maintaining ML models '
Identify opportunities for platformization by communicating with our applied ML team
Balance the needs of Product, Data Scientists, User Research, and other engineers in a small team to develop machine learning approaches that advance our mission to detect fraud
Qualifications

You have:
Demonstrated technical initiative and leadership on previous projects
The ability to work in a fast paced, autonomous and unpredictable environment
Desire to mentor & grow other machine learning engineers across the org to further these efforts
A deep understanding of software that allows you make the right trade offs
Natural curiosity & eagerness to learn (we have one day a week dedicated to Passion Projects)
Technologies we use:

We’re agnostic to what you know walking in the door. You’ll need to be happy working with:
Kotlin, Java, Go & Python
AWS
Kafka, Beam and Flink
Additional Information

Cash App treats all employees and job applicants equally. Every decision is based on merit, qualifications, and talent. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

We will consider for employment qualified applicants with criminal histories in a manner consistent with each office’s corresponding local guidelines.",-1,Cash App,"San Francisco, CA",-1,-1,-1,-1,-1,-1,-1,-1
Software Engineer - Android,-1,"AiCure is a VC-funded startup that leverages mobile technology by combining it with artificial intelligence (computer vision, machine learning, and big data) to bring better health, better drugs, and better treatment to everyone on the planet. We’re rapidly expanding and if you’re passionate about making a positive impact, we’d like to hear from you.

When participants in clinical trials, or patients use the AiCure apps, information on their medication intake is reported in various dashboard products, which allow stakeholders to gain insights and to take actions (patient alerts, etc.). Our apps use computer vision to identify the patient (face verification), verify that patients are taking the right medication (pill recognition), and that they are actually taking their medication (action recognition). We are also working on other novel therapeutic applications of computer vision.

Key responsibilities

• Develop android applications

• Work with computer vision team to integrate state of art algorithms into the mobile applications and deliver great user experiences

• Optimize the user interfaces and application code to ensure efficiency, reusability, and performance

• Develop end-user applications quickly

• Continuously learn and educate yourself on the latest mobile engineering techniques and best practices

As a mobile software engineer at AiCure you will be responsible for developing all patient-facing applications. You’ll work closely with our scientists and engineers to incorporate advanced AI technologies. Your work will be used at scale and will have significant impact on healthcare for everyone on the planet! Experience in healthcare is NOT required.

Requirements
Bachelor’s degree in computer science or equivalent experience
3+ years’ experience developing rich android applications
Strong experience with Java and Kotlin, familiar with RESTful API
Strong experience with algorithms and design patterns
Strong background in Object-Oriented Design and various design patterns
Strong background with multi-threaded programming
Experience in writing different levels of tests
Experience with well-architected apps published in Google Play is required
Good communication and collaborative skills
Excellent time and project management skills
Experience in Amazon Web Services is a plus
Experience in mobile CICD pipeline is a plus
Passionate about revolutionizing healthcare and having a positive impact on people around the world
Benefits

Philosophy

Our selection process is highly competitive because we only hire the best, most enthusiastic candidates. Openness, flexibility, creativity, ownership, and accountability are our main pillars. We love solving challenging problems and creating solutions that have real impact on people- at scale.

Impact

We're on a mission to revolutionize healthcare and when you join us, you'll have the opportunity of having real, tangible impact not only on individuals directly using our technology, but also on how drugs are tested and brought to market across the world. That means everyone on the planet will benefit from what you do. You'll be inspired every day because you'll be making a real difference and you'll see it happen. In real time and at scale.

People

You'll work with brilliant, positive people who thrive in an interdisciplinary, multi-cultural environment, and are curious, creative, and focused on executing our mission. You'll be up to speed in the the most recent advances in Artificial Intelligence (Machine Learning, Computer Vision, Big Data) while solving challenging problems that must take into account many fascinating aspects of human psychology and behavior. You'll work with Scientists, Engineers, Designers, and Medical Doctors, to create innovative products that scale in an environment that encourages learning, collaboration, and growth.",4.7,"AiCure
4.7","New York, NY","New York, NY",1 to 50 employees,-1,Company - Public,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,Proteus Digital Health
Software Engineer II,"$56K-$117K
(Glassdoor est.)","Mid/Senior Level Data Engineer- Remote due to COVID, but will be required to sit in Lincolnshire once restrictions are lifted. Start time would be 9AM Central
There is a possibility to move from Temp to FT Hire
Visa sponsorship is not available, now or in the near future, for this position
CTO AI services is a central group innovating new AI centric products, supporting Business Units on program acceleration and building an ecosystem that will allow Client to scale its AI components across the business and partners.
As a Data Engineer in computer vision you will have a unique opportunity to design and manage all of our data infrastructure used by our research team to solve real-world applications.
You will face a variety of challenges from automating data acquisition and annotation to evaluating our latest cutting-edge algorithms, and you will have access to the best hardware to do the job.
We are focusing on leveraging AI to help solve real-world problems on real-world data.
This means embracing noise and complexity, both at the data level and at the methodological level.
You will collaborate closely both with both software developers and research scientists to commercialise our products and manage data collection and management requirements.
You will have experience in machine learning and management, either through your studies or industrial R&D projects and will be equally adept at developing production-quality code.
Must haves in a Candidate:
Computer vision and applications of machine learning.
Collecting, QCing, and analyzing huge datasets.
Using the best tools to streamline data acquisition and processing.
Assisting research scientists achieve their goals
A getting-it-done attitude with a desire to both push the boundary of fundamental knowledge and turn it into great products.
A degree in computer science or a quantitative field and at least one year of industrial experience working with data.
Strong math skills, a problem-solving aptitude and desire to automate
Experience of scientific programming and libraries relevant to image and video processing and management, for example OpenCV.
Experience with at least one programming language such as Python, C++, etc.
Experience working in a diverse and international team.",3.9,"ApTask
3.9","Lincolnshire, IL","Iselin, NJ",201 to 500 employees,2010,Company - Private,IT Services,Information Technology,$50 to $100 million (USD),"Collabera, Mitchell Martin, The Judge Group"
Senior Software Engineer - Data Science Platform,"$161K-$190K
(Glassdoor est.)","Bloomberg runs on data. It's our business and our product. From the biggest banks to elite hedge funds, financial institutions need timely, accurate data to capture opportunities and evaluate risk in fast-moving markets. With petabytes of data available, a platform to transform and analyze the data is critical to our success.

Bloomberg's Data Science Platform was established to support development efforts around data-driven science, machine learning, and business analytics. The platform aims to provide scalable compute, specialized hardware and first-class support for a variety of workloads such as Spark, Tensorflow and Jupyter. The platform was developed to provide a standard set of tooling for addressing the Model Development Life Cycle from experimentation and training to inference. It provides advanced features such as Hyperparameter Tuning as a Service and is beginning to invest in Model Management and Governance. The platform is built leveraging containerization, container orchestration and cloud architecture and built on top of 100% open source foundations.

The platform is poised for enormous user growth this year and has an ambitious roadmap in terms of new features as well as improved user experience. That's where you come in. As a member of the multi-disciplinary Data Science Platform team, you'll have the opportunity to make key technical decisions to keep this platform moving forward.

Our team makes extensive use of open source (e.g. Kubernetes, Tensorflow, Spark and Jupyter) and is deeply involved in a number of communities. As part of that, we regularly upstream features we develop, present at conferences and collaborate with our peers in the industry. We are contributors to the Kubeflow project as well as founding members of the KFServing subproject to standardize ML Inference within the Kubernetes ecosystem. For Spark, we have implemented a scalable and resilient external shuffle service for dynamic resource allocation, a pluggable interface for secure worker creation, and a token renewal service that handles privacy and security across jobs, all in line with our effort to improve security and elasticity for Spark on Kubernetes. Open source is at the heart of our team. It's not just something we do in our free time, it is how we work.

We'll trust you to:
Interact with data scientists to understand their workflows and requirements to inform the next set of features for the platform
Design solutions for problems such as elastic load distribution, GPU sharing and guaranteed scheduling
Automate operation and improve telemetry of data science platform components in our infrastructure stack
You'll need to be able to:
Troubleshoot and debug run-time issues
Provide developer and operational documentation
Provide performance analysis and capacity planning for clusters
Be organized and multi-task in a fast paced environment
Have a passion for providing reliable and scalable infrastructure
You'll need to have:
Experience with distributed systems eg. Kubernetes, Kafka, Zookeeper, Spark
Proficiency in two or more languages (Python, Go, C++, Java, Scala, or JavaScript) and willingness to learn more as needed
Linux systems experience (Network, OS, Filesystems)
We'd love to see:


Experience building and scaling Docker-based systems using Kubernetes, Swarm, Rancher, Mesos
Experience working with authentication & authorization systems such as Kerberos and LDAP
Experience working with GPU compute software and hardware
Ability to identify and perform OS and hardware-level optimizations
Open source involvement such as a well-curated blog, accepted contribution, or community presence
Experience with cloud providers such as AWS, GCP or Azure
Experience with configuration management systems (Chef, Puppet, Ansible, or Salt)
Experience with continuous integration tools and technologies (Jenkins, Git, Chat-ops)
If this sounds like you, apply! You can also learn more about our work using the links below:
Machine Learning the Kubernetes Way -https://www.youtube.com/watch?v=ncED2EMcxZ8
Inference with KFServing -https://www.youtube.com/watch?v=saMkA4fIOH8
ML at Bloomberg -https://on-demand-gtc.gputechconf.com/gtcnew/sessionview.php?sessionName=s9810-machine+learning+%40+bloomberg%3a+building+on+kubernetes
Scaling Spark on Kubernetes -https://www.youtube.com/watch?v=GbpMOaSlMJ4
Bloomberg is an equal opportunities employer, and we value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.",3.8,"Bloomberg
3.8","New York, NY","New York, NY",10000+ employees,1981,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,"Google, Goldman Sachs, Thomson Reuters"
"Principal Software Engineer, MLOps & Inferencing","$61K-$127K
(Glassdoor est.)","Requisition Number: 41082

Corning is one of the world’s leading innovators in materials science. For more than 160 years, Corning has applied its unparalleled expertise in specialty glass, ceramics, and optical physics to develop products that have created new industries and transformed people’s lives.

Corning succeeds through sustained investment in R&D, a unique combination of material and process innovation, and close collaboration with customers to solve tough technology challenges.

The global Information Technology (IT) Function is leading efforts to align IT and Business Strategy, leverage IT investments, and optimize end to end business processes and associated information integration technologies. Through these efforts, IT helps to improve the competitive position of Corning's businesses through IT enabled processes. IT also delivers Information Technology applications, infrastructure, and project services in a cost efficient manner to Corning worldwide.

Data, automation and advanced analytics technologies are drastically transforming industrial manufacturers beyond point process automation to systemic, highly contextualized and data driven systems. Corning is building the foundational digital infrastructure for these company-wide efforts, and are looking for passionate, hard-working, and talented staff-level software engineering architects that will design that foundation for reuse, velocity and scale.

Overview: The MLOps and Inference Domain Architect will be part of a core platform development team working with domain experts, application developers, controls engineers, data engineers and data scientists. Their primary responsibility will be to architect outbound data engineering, integration and machine learning deployment pipelines, including their associated lifecycle management systems and practices, in coordination with their architecture peers and communities of practice throughout the company. These systems will span both cloud and on-premise environments and will require close collaboration with many technical teams to ensure success. Responsibilities as an MLOps & Inferencing architect, your main responsibilities will be:
Designing and implementing portable, modular, instrumented and highly performant model deployment pipelines for many types of machine learning including supervised and unsupervised learning as well as CNNs, RNNs or other deep learning algorithms
Working closely with data scientists, domain experts and controls engineers, both within and outside the company to understand model performance management requirements and design suitable inferencing instrumentation systems and practices that meet them
Designing and implementing outbound data engineering pipelines that serve curated datasets to business intelligence, reporting and HMI systems
Designing integration solutions including applications as needed to deliver inferencing outcomes or curated data sets for consumption and action
Ensuring your model deployment, outbound data engineering and integration pipelines are architecturally and operationally integrated with inbound ingestion and contextualization pipelines designed by your peer domain architects
Delivering and presenting proofs of concept implementations that explain the key technologies you have selected for your design and the recommended patterns of practice for ongoing development and lifecycle management. The target audience for these efforts span the company and include project stakeholders, data scientists, process experts, other domain architects and relevant technical communities of practice interested in leveraging your code for their own projects
Working with your fellow developers using agile development practices, and continually improving development methods with the goal of automating the build, integration, deployment and monitoring of production inferencing and dataset delivery systems
Working with the relevant communities of practice on component roadmaps, and serving as a trusted committer for your code for inner sourcing efforts with other development teams in the company
Education & Experience:
Advanced degrees in computer science and data science strongly preferred, though an equivalent level engineering, data science or mathematics degree, a technical undergraduate degree and relevant experience will also be considered
10 plus years of relevant work experience
3+ years of experience working with data scientists in a large-scale data engineering or production machine learning inferencing capacity, working with various types of supervised and unsupervised learning algorithms for classification, recommendation, anomaly detection, clustering and segmentation, as well as CNNs, RNNs or other deep learning algorithms
5+ years of full-stack experience developing large scale distributed systems and multi-tier applications
5+ years of programming proficiency in, at least, one modern JVM language (e.g. Java, Kotlin, Scala) and at least one other high-level programming language such as Python
2+ years of production DevOps experience
3+ years of programming on the Apache Spark platform, leveraging both low level RDD and MLlib APIs and the higher-level APIs (SparkContext, DataFrames, DataSets, GraphFrames, SparkSQL, SparkML).
Demonstrated deep understanding of Spark core architecture including physical plans, DAGs, UDFs, job management and resource management
At least 1 year of implementation experience with Apache Airflow, and a demonstrated expert level understanding of both segmented and unsegmented Directed Acyclic Graphs and their operationalization
Experience working with MLflow and a demonstrated ability to lead architecture efforts for its implementation
Demonstrated experience working with inner sourcing initiatives, serving both as a trusted committer and contributor
Strong technical collaboration and communication skills
Unwavering commitment to coding best practice and a strong proponent of code review
Cultural bias towards continual learning, sharing best practice, encouraging and elevating less experienced colleagues as they learn
Additional Technical Qualifications:
Proficiency with functional programming methods and their appropriate use in distributed systems
Expert proficiency with AWS foundational compute services, including S3 and EC2, ECS and EKS, IAM and CloudWatch
Expert proficiency with Kubernetes and Docker
Expert proficiency with continuous integration and continuous deployment methodologies
Other Qualifications:
Strong relationship building skills
Proven success working in highly matrix environment.
Excellent analytical and decision-making abilities.
Must demonstrate a proven willingness to go the extra mile, to take on the things that need to be done and maintain a positive attitude that can adapt to change.
Strong leadership and excellent verbal and written communications skills, with the ability to develop and sell ideas.
This position does not support immigration sponsorship.

We prohibit discrimination on the basis of race, color, gender, age, religion, national origin, sexual orientation, gender identity or expression, disability, or veteran status or any other legally protected status.",3.8,"Corning
3.8","Painted Post, NY","Corning, NY",10000+ employees,1851,Company - Public,Electrical & Electronic Manufacturing,Manufacturing,$10+ billion (USD),-1
"Senior Frontend Engineer, Amazon SageMaker","$109K-$245K
(Glassdoor est.)","Interested in Machine Learning? As the SDE on the SageMaker UI team, youll get to work on:

1. The SageMaker Management Console (https://console.aws.amazon.com/sagemaker )
This is one of AWS' largest consoles, and we're not slowing down! The baseline requirement is to keeps parity with SageMaker's rapidly expanding HTTP API's, but we'll push to also develop unique experiences for SageMaker metadata that are only possible in a browser or mobile device. You own our webservers and the bytes they vend, including the design, testing, continuous deployment, operations, usage analytics, and customer support.

2. Custom UI/widgets for AWS ML's Notebook authoring and data scientist IDE experience
From a browser, we're making a highly scalable and collaborative data science workbench so a data scientist, developer, or student can launch a wholly configured and sharable workspace in the cloud.

Key Responsibilities:
· Work closely with senior engineers, UX designers, and product managers to develop friendly UI experiences.
· Work closely with engineers to architect and develop the best technical design.
· Develop/maintain operational rigor for the frontend of a fast-growing AWS service.
· Develop the engineers of an existing two pizza scrum team.
· Collaborate with other SageMaker SDE's for features that cut across SageMaker.
· Engage with customers and other AWS partners.
· Help with hiring.
You'll be well supported with by a group with deep technical chops, including multiple senior and principal engineers.

What is SageMaker?
Amazon SageMaker (https://aws.amazon.com/sagemaker/) is a fully-managed Machine Learning platform that makes it easy to build ML models, manage them, and integrate them with custom applications for batch or online predictions. SageMaker takes away the heavy-lifting normally associated with large-scale Machine Learning implementations so that developers and scientists can focus on the truly creative work of modeling and solving the business problem at hand.

Amazon.com is an Equal Opportunity-Affirmative Action Employer Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation.


Basic Qualifications

· Bachelors Degree in Computer Science or related field.
· Equivalent experience to a Bachelor's degree based on 3 years of work experience for every 1 year of education
· 5+ years professional experience in software development.
· Experience with modern programming languages (Java, C#, Python) and open-source technologies.
· Experience with web/mobile technologies (e.g., JavaScript/TypeScript, NodeJS, React, WebPack, HTTP mechanics/performance).

Preferred Qualifications

· Experience building tools for data scientists or developers.
· Attuned design sense so can collaborate with UX designers and hold a high bar with backend SDE's.
· Experience with with CI/CD in a frontend context.
· Experience establishing and leveraging web analytics.
· Machine learning knowledge and experience.
· Knowledge of professional software engineering practices & best practices for the full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations.
· Ability to take a project from scoping requirements through actual launch of the project.
· Experience in communicating with users, other technical teams, and management to collect requirements, describe software product features, and technical designs.
· Deep hands-on technical expertise in full-stack development.",3.9,"Amazon
3.9","East Palo Alto, CA","Seattle, WA",10000+ employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),"Google, Microsoft, Walmart"
Java Software Engineer,-1,"Java Software Engineer

BigBear, Inc. currently has an immediate position for a talented and passionate JAVA Software Engineer in the Charlottesville, VA area to build high-performing, scalable, enterprise-grade
applications. You will be responsible for server-side application development while providing expertise in the full software development lifecycle, from concept and design to testing. You will collaborate directly with customers to ensure our products meet and exceed operational requirements. The successful candidate will be a self-starter that demonstrates excellent communication and problem-solving skills with a focus on customer service.
SKILLS REQUIRED:
• 5+ years of hands-on experience with Java.
• 5+ years of experience developing applications on the JavaFX platform (Bonus)
• Object-Oriented Programming and Design skills are required.
• Experience working Java frameworks such as Spring.
• Familiarity with event-driven programming.
• Experience developing multi-threaded applications a plus.
• Working experience with Postgres/PostGIS, ElasticSearch, or Oracle database a plus.
• Hands-on experience with OpenStreetMap, OGC, or other GIS a plus.
• Experience with JavaScript, C# and .Net Framework a plus.
• Experience integrating applications with intelligence databases such as MIDB a plus.
• Strong communication and leadership skills required.
• Experience working in an Agile/Scrum development process.
• B.S./M.S. degree in Computer Science, Engineering, or equivalent experience.
• Must be a US Citizen.
• Must have a SECRET Clearance with the ability to obtain a TOP SECRET / SCI Clearance.
WHAT YOU'LL DO:
• Collaborate with Project Manager and engineering to implement innovative solutions.
• Design and develop high-volume, low-latency applications for mission-critical systems.
• Contribute in all phases of the development lifecycle.
• Write well designed, testable, efficient code and unit tests.
• Ensure designs are in compliance with specifications.
• Perform demonstrations and briefings to customers to ensure program success.
• Perform technical support for products at customer sites.
• Perform system monitoring, optimization, and high performance tuning.
• Perform requirements analysis, system design, and draft technical documentation.
• Participate in research and development for system engineering and product advancement.
• Domestic travel as needed.
Our Company:

BigBear, Inc. is an Information Technology enterprise with locations in Northern Virginia and Southern California. Our mission is to enable big data computing and analytics for our customers at a low cost. We leverage capabilities such as machine learning, crowdsourcing, geospatial image processing, and Extract-Transform-Load (ETL) data processing using our on-premise cloud computing technology stack. Our solutions provide a unique offering of products, custom-built software and services focused within Big Data Analytics, Geospatial Information Systems (GIS), Visualization and Cloud Computing to our Department of Defense, and Commercial customers. We currently have exciting and challenging career opportunities for talented, motivated individuals who want to be part of a fast-growing company.
Our Team:

Operating as a unified team, with employees who are creative, dynamic, and visionary, drives our mission to success. Each team member provides a unique set of advanced technical skills and trade that contributes to our overall success. We pride our team on having a burning desire to push our technology and solutions to the next level of innovation. To accomplish these goals, we advocate hard work, dedication, leadership, and a passion for excellence.

Why Us?

We are seeking to expand our top-notch team of forward-thinking engineers, data scientists, and innovators, to help our customers make sense of their data. We are experiencing rapid growth, with a mission to help our customers find new ways to discover, understand, and visualize information. We will provide you a competitive salary based on experience, 100% employer paid for medical, dental, and vision, FSA, 401(k) with match, life/disability insurance, education assistance, gym reimbursement, flexible hours, unlimited coffee and snacks, and an ownership opportunity in the company as we grow.
BigBear is an Equal Employment Opportunity Employer/Veterans/Disabled",4.4,"BigBear, Inc.
4.4","Charlottesville, VA","San Diego, CA",51 to 200 employees,2008,Company - Public,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Lead Machine Learning Engineer with Security Clearance,-1,"Company Information Octo Consulting Group (Octo) is an industry-leading, award-winning provider of digital services for the federal government. Octo specializes in providing agile software engineering, user experience design, cloud services, and digital strategy services that address government's most pressing missions. Octo delivers intelligent solutions and rapid results, yielding lower costs and measurable outcomes. Our team is what makes Octo great. At Octo you'll work beside some of the smartest and most accomplished staff you'll find in your career. Octo offers fantastic benefits and an amazing workplace culture where you will feel valued while you perform mission critical work for our government. Voted one of the region's best places to work multiple times, Octo is an employer of choice! Job Description You... As a Lead Machine Learning Engineer at Octo, you will help develop and expand Octo's AI capability. In this role you will have the opportunity to help chart our AI strategy while helping build core offerings. You will work closely with executives, business line stakeholders, and customers to help design, innovate and build our next generation AI/ML solutions and offerings. As a team lead you will provide mentorship/guidance to junior AI team and you will represent the team when participating in internal and external technology initiatives. In this role you will be driving the creation of innovative AI products from ideation, through MVP, Pilot, and production. You will help solve real world problems and challenges that our customers face. From a leadership standpoint, you will directly support the Octo's CTO office and help shape strategy, initiatives, solutions and investments in all things AI. As a team lead, you will work closely with your team to develop and productionize solutions and offerings. You will also be responsible for leading and reviewing the work of multiple engineers, data scientists, developing and testing Machine Learning algorithms. As a lead, you will also serve as a solution architect to help shape AI related proposals. Us... We were founded as a fresh alternative in the Government Consulting Community and are dedicated to the belief that results are a product of analytical thinking, agile design principles and that solutions are built in collaboration with, not for, our customers. This mantra drives us to succeed and act as true partners in advancing our client's missions. Specifics... * Develop an AI roadmap to align to strategic imperatives * Determine metrics of success and systematically track the impact of the program * Use AI to solve customer business problems and build internal solution offerings * Run AI projects/initiatives, build MVPs/prototypes, from beginning to end * Stay up-to-date on new AI products and develop solutions (prototypes, white papers, trainings) * Prototype and demonstrate AI related products and solutions for customers * Execute and drive Executive Management's AI strategy * Identify new business opportunities and prioritize pursuits for AI * Create customized offerings * Build a library of AI assets * Enable strategic partnerships with industry leaders * Create AI white papers * Align, mentor, and manage, team(s) around strategic initiatives Skills & Requirements Requirements... * Hands-on experience using deep learning and computer vision libraries such as PyTorch, TensorFlow, Caffe, MXNet, OpenCV, Keras, and scikit * Experience with containerization of machine learning applications (AWS DL Containers, Docker, Singularity, Apache Mesos Openshift, Kubernetes) * Experience with CUDA and NVIDIA GPU accelerated libraries for AI, ML, DL * Experience with embedded low SWaP GPU computing * Basic understanding of full motion video data formats * Basic understanding of 3D geospatial model formats (OBJ, 3D Tiles, GLTF) Years of Experience: Minimum 3 years building and deploying at scale Machine Learning and Deep Learning models and minimum 3 years of developing machine learning methods, including familiarity with techniques in clustering, regression, optimization, recommender engines, artificial neural networks. Education: Bachelor's dgeree in computer science, data science, physics, applied mathematics/statistics, operation research, or other physical science/engineering field. Clearance: Ability to obtain a DoD Secret Clearance Location: Reston, VA Octo Consulting Group is an Equal Opportunity/Affirmative Action employer. All qualified candidates will receive consideration for employment without regard to disability, protected veteran status, race, color, religious creed, national origin, citizenship, marital status, sex, sexual orientation/gender identity, age, or genetic information. Selected applicant will be subject to a background investigation.",3.9,"Octo Consulting Group
3.9","Reston, VA","Reston, VA",501 to 1000 employees,2006,Company - Private,Consulting,Business Services,$50 to $100 million (USD),"Attain, Deloitte, Booz Allen Hamilton"
Senior Frontend Engineer - Machine Learning,-1,"Are you intrigued or passionate about Machine Learning (ML) and ready to build a new customer-centric product? The Amazon SageMaker team is looking for talented front-end engineering leaders to help us build the next generation of ML tools.

With SageMaker, developers and data scientists have the ability to build, train, and deploy machine learning models quickly. As a fully-managed cloud service, SageMaker covers the entire data science workflow from data preparation and exploratory data analysis to model building and inference; our charter is to make data science and machine learning understandable, affordable, scalable, and accessible to everyone. The foundation of the SageMaker user experience is the industry standard, open-source Jupyter Notebook.

As an front end engineering leader on the SageMaker team, you'll be responsible for starting a new team to build out interactive data-driven ML applications.

Key Responsibilities:
Work closely with senior engineers, UX designers, and product managers to develop friendly UI experiences.
Work closely with engineers to architect and develop the best technical design.
Develop/maintain operational rigor for the frontend of a fast-growing AWS service.
Develop the engineers of an existing ""two pizza"" scrum team.
Collaborate with other SageMaker SDE's for features that cut across SageMaker.
Engage with customers and other AWS partners.
Help with hiring.
You'll be well supported with by a group with deep technical chops, including multiple senior and principal engineers and scientists.

Basic Qualifications
Bachelor's Degree in Computer Science or related field.
Equivalent experience to a Bachelor's degree based on 3 years of work experience for every 1 year of education
5+ years professional experience in software development.
Experience with modern programming languages (Java, C#, Python) and open-source technologies.
Experience with web/mobile technologies (e.g., JavaScript/TypeScript, NodeJS, React, WebPack, HTTP mechanics/performance).
Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.",-1,Amazon Corporate LLC,"Seattle, WA",-1,-1,-1,-1,-1,-1,-1,-1
Software Engineer - Natural Language Understanding,-1,"At SoundHound Inc., we believe every brand should have a voice. As the leading innovator of conversational technologies, we're trusted by top brands around the globe. Houndify, our independent Voice AI platform, with 70,000+ users, allows brands to create custom voice assistants that deliver results with unprecedented speed and accuracy.

Our mission is to enable humans to interact with the things around them in the same way we interact with each other: by speaking naturally. We're making that a reality through our SoundHound music discovery app and Hound voice assistant and through our strategic partnerships with brands like Mercedes-Benz, Hyundai, Deutsche Telekom, and Pandora. Today, our customized voice AI solutions allow people to talk to phones, cars, smart speakers, mobile apps, coffee machines, and every other part of the emerging 'voice-first' world.

Our diverse team of engineers, UX/UI designers, writers, data scientists and linguists are all passionate about creating a world with more conversations. With more than 14 years of expertise in voice technology, we have hundreds of millions of end users, and a worldwide team in six countries building solutions for a voice-first world.

About the Role:

In this role, you will be implementing functionality similar to what you see in these videos:

https://www.youtube.com/watch?v=yUbK1yeYzAI

https://www.youtube.com/watch?v=M1ONXea0mXg

You will be learning and using the most advanced technologies in the fields of Natural Language Understanding, Speech, Search, and AI, all built in-house here at SoundHound over the past 10 years.

We've worked hard to build a platform that enables individual developers to implement deep natural language user experiences very rapidly, often within days. These user experiences will be showcased within our Hound app, and made available to other developers via the Houndify platform, enabling them to power billions of devices and applications.

Your work will directly contribute to a revolution in the way people interact with the devices around them: by speaking naturally.

About You:
You are excited about being one of the first people to become proficient in a new programming paradigm.
Your dream job involves building/owning the systems that improve the lives of millions of users every day.
You view coding as an art form, and your love of coding is second only to your love of deprecating even more code.
You notice opportunities to improve the end user experience and are proactive about getting the details right.
You are a fast learner with strong software development skills, enabling you to meet aggressive deadlines while producing scalable and maintainable systems.
Requirements:
Proficient in C/C++ and at least one scripting language
Excellent algorithms skills, and ability to write efficient code
Strong English language communication skills
Experience with data conditioning and relevance algorithms
Experience manipulating and managing large amounts of data
Comfortable working in Linux environment
BS/MS in Computer Science or equivalent
Nice to Haves:
Experience working with third-party APIs or datasets
Experience working in a client-server Agile development environment.
Familiarity with web crawling and related concepts
Familiarity with text search and related systems
Fluent in additional languages such as:
Spanish, French, German, Russian, Mandarin, Japanese, Korean, etc.
How to Apply:
Please send us your resume and cover letter. Tell us why you would like a job at SoundHound in particular.",4.3,"SoundHound Inc.
4.3",United States,"Santa Clara, CA",201 to 500 employees,2005,Company - Private,Computer Hardware & Software,Information Technology,$25 to $50 million (USD),-1
Senior Software Engineer - Quant Developer Platform,"$126K-$237K
(Glassdoor est.)","Bloomberg is the global leader in business and financial data, news and insight. Using the power of technology, we connect the world's decision makers to accurate information on the financial markets and help them make faster, smarter decisions.

So where does BQuant fit in?


Finance is changing, and fast; new financial professionals are even learning python themselves. Here in our San Francisco office we've identified an opportunity to reach this tech savvy client base by building a product that opens our data, core products and visualizations to data scientists, ML researchers, and quantitative modelers.

Gone are the days of downloading raw CSV files! The BQuant platform allows users to bring their algorithms to our data, not the other way around. Our service provides a unified environment where users can develop their code and test, share, and deploy it easily. Our impact? Providing the entire industry with tools that are currently only available to large banks and hedge funds, through customer deployed installations in enterprise environments.

What will you be building?


The BQuant Platform team owns our users' development experience and development productivity on BQuant. We are responsible for their IDE, source code management, and collaboration, as well as tools to help them navigate learning resources, handle breaking changes in Python packages, and more. Our goal is to make our users as productive as possible as they learn how to interact with Bloomberg data and analytics in a much more powerful and flexible way than before.

BQuant is built on top of Project Jupyter, and Bloomberg has funded major initiatives in the Project Jupyter community, such as JupyterLab, Voil (a Jupyter dashboarding solution), and a Jupyter debugger. Two of your teammates will be ACM Software System Award-winning Project Jupyter members!

As part of the team, we'll trust you to:
Build search capabilities for resource navigation, collaborative code editing capabilities, application deployment infrastructure, linting tools, and more
Collaborate with other teams to seamlessly integrate advanced features into our users' workflows, such as running remote machine learning jobs, Git integration, and interacting with custom data sets
Develop and deploy robust software requiring minimal maintenance
Think critically about how our users interact with the platform and how we can continue to improve and enrich their experience
You need to have:


5+ years of production experience in JavaScript/TypeScript, Python, C++ or other programming languages
3+ years of production experience in JavaScript/TypeScript
Experience with React, HTML, CSS, and other web frontend technologies
Experience building and supporting production systems
An understanding that software should be kept as simple as possible
We'd love to see:


Experience building full-stack applications, including service APIs and database design
Experience contributing to open-source projects
An appreciation for how our data sets underpin the world's financial systems - if you don't know anything about finance, you'll pick it up by interacting with a world-class team of market experts.
For more information about our work, see our ACM award-winning engineers discussing their work:
http://bit.ly/2PIyndO
http://bit.ly/2PcLKBV
http://bit.ly/2MRFEtm

Bloomberg is an equal opportunities employer, and we value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.",3.8,"Bloomberg
3.8","San Francisco, CA","New York, NY",10000+ employees,1981,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,"Google, Goldman Sachs, Thomson Reuters"
"Computer Science Researcher in Data Science, Machine Learning, and High Performance Computing - ICL",-1,"ID: 495726
Type: Researchers
Location: Atlanta, GA
Categories: Image Processing, Machine Learning, Modeling/Simulation, Networking, Software Development/Design, Algorithm Development, Artificial Intelligence, Data Analytics/Science, Health Informatics
Job Description


Full-time, permanent position available in the Information and Communications Laboratory working on a wide variety of data science and computer science/engineering problems. Our team is looking for a data scientists and computer scientists with experience working on large datasets to extract meaningful insight. In particular, skillsets both in doing data science (statistical analysis and inference, machine learning, and graph analytics) as well as software engineering experience building tools and applications for data science (using Python, R, Julia, etc.) are required. Demonstrated experience working with multiple programming languages and development environments is preferred.

Preference will be given to candidates with strong fundamentals in computer science and/or computer engineering. Experience with managing business or scientific problems and working with customers is also needed. Prior work consulting for or working for Federal Government and/or Department of Defense agencies will be given preference.

Candidate needs to be able to communicate effectively their results both through documentation as well as through technical writing and reports. Candidate may also be asked to work on proposals for funding, thus proposal writing experience is preferred. Candidates should be adept in learning new programming languages and frameworks quickly, and should be able to demonstrate the ability to integrate large projects together that span multiple languages and problem domains.

The projects are based out of the Tech Square area in Atlanta on the Georgia Tech campus. Occasional travel may be required and is project dependent. The High Performance Computing and Data Analytics branch at GTRI works on problems ranging from low-level computer architecture design, to building scalable algorithms and data structures, to machine learning and statistical inference. Our team spans the full technology stack to bring cutting-edge research in data analytics to scale, and then apply those analytics to real-world problems to enable actionable insight. Our team works on a variety of projects ranging from data analytics in healthcare, predictive modeling, predictive maintenance, and large scale parallel and discrete scientific models and simulations. We are looking for candidates that are excited by working on a variety of problems always with an eye on sponsor value, performance, and scalability.

This position may additionally support the design, development, analysis, and implementation of parallel computing codes on medium- and large-scale clusters. Additional job functions may include creating parallel computing tools and frameworks to support mission applications, implementing security controls on HPC systems, and contributing to technical reports. Experience with image/signal processing or functional programming is beneficial.

Candidate must be a US citizen eligible for a security clearance. An active clearance is not required at time of application.

Travel Requirements

Education & Length of Experience


Research Engineer/Scientist I
A Bachelor's degree in Computer Science, Computer Engineering, Electrical Engineering, Applied Mathematics, Physics, Industrial Sciences and Engineering, Computational Sciences and Engineering or other majors with sufficient work in the field of data science or computer science.
Research Engineer/Scientist II
A Master’s degree in Computer Science, Computer Engineering, Electrical Engineering, Applied Mathematics, Physics, Industrial Sciences and Engineering, Computational Sciences and Engineering or other majors with sufficient work in the field of data science or computer science and three (3) years of relevant full-time experience after completion of that degree,
A Master’s degree in Computer Science, Computer Engineering, Electrical Engineering, Applied Mathematics, Physics, Industrial Sciences and Engineering, Computational Sciences and Engineering or other majors with sufficient work in the field of data science or computer science and five (5) years of relevant full-time experience after completion of a Bachelor’s degree, or
A Doctoral degree in Computer Science, Computer Engineering, Electrical Engineering, Applied Mathematics, Physics, Industrial Sciences and Engineering, Computational Sciences and Engineering or other majors with sufficient work in the field of data science or computer science.
U.S. Citizenship Requirements


Due to our research contracts with the US federal government, candidates for this position are required to be US Citizens.

Clearance Type Required


Ability to obtain Secret Clearance upon hire

Diversity & Inclusion


Diversity & Inclusion (D&I) at Georgia Tech Research Institute aims to enhance the Institute’s mission of solving the world’s most complex technical problems by creating a workforce with a shared appreciation for diversity, raising awareness around inclusiveness, and fostering a sense of belonging and appreciation for all members of our community.

Equal Employment Opportunity


Georgia Tech Research Institute is an Equal Opportunity Employer of individuals with disabilities and protected veterans and actively seeks diversity among its employees. Equal Employment Opportunity is the Law.

Posted: 05/28/2020
Closes: 08/28/2020",3.6,"Georgia Tech Research Institute
3.6","Atlanta, GA","Atlanta, GA",1001 to 5000 employees,1943,Subsidiary or Business Segment,Research & Development,Business Services,$100 to $500 million (USD),"MIT Lincoln Laboratory, Johns Hopkins University Applied Physics Laboratory"
Data Engineer,-1,"This position is located in the ALLENTOWN, PA Area.

W-2 Candidates Only - NO AGENCIES

Interested? Please send resumes to James Derrick, 973-805-7008,

James Derrick

973-805-7008

jderrick@galentechsolutions.com

As a Data Engineer, you will work closely with a multidisciplinary Agile team to build high quality data pipelines driving analytic solutions. These solutions will generate insights from our connected data, to advance the data-driven decision-making capabilities of our enterprise. This role requires deep understanding of data architecture, data engineering, data analysis, reporting, and a basic understanding of data science techniques and workflows. The ideal candidate is a skilled data / software engineer with experience creating data products supporting analytic solutions. The ideal candidate is a skilled data / software engineer with experience creating data products supporting analytic solutions. They are an Agile learner, possess strong problem-solving skills, work as part of a technical, cross functional analytics team, and want to Solve complex data problems and deliver the insights to enable analytics strategy.

Responsibilities
Design, develop, optimize, and maintain data architecture and pipelines that adhere to ETL principles and business goals
Solve complex data problems to deliver insights that helps our business to achieve their goals
Create data products for analytics and data scientist team members to improve their productivity
Advise, consult, mentor and coach other data and analytic professionals on data standards and practices
Foster a culture of sharing, re-use, design for scale stability, and operational efficiency of data and analytical solutions
Lead the evaluation, implementation and deployment of emerging tools and process for analytic data engineering in order to improve our productivity as a team
Develop and deliver communication and education plans on analytic data engineering capabilities, standards, and processes
Partner with business analysts and solutions architects to develop technical architectures for strategic enterprise projects and initiatives.
Learn about machine learning, data science, computer vision, artificial intelligence, statistics, and/or applied mathematics
Skills
Bachelor’s degree required; Computer Science, MIS, or Engineering preferred
5 years of experience working in data engineering or architecture role, 7+ preferred
Expertise in SQL and data analysis and experience with at least one programming language (Python/PySpark or Scala preferred)
Experience developing and maintaining data warehouses in big data solutions
Experience with developing solutions on cloud computing services and infrastructure in the data and analytics space (preferred)
Database development experience using Hadoop or BigQuery and experience with a variety of relational, NoSQL, and cloud data lake technologies
Worked with BI tools such as Tableau, Power BI, Looker, Shiny
Conceptual knowledge of data and analytics, such as dimensional modeling, ETL, reporting tools, data governance, data warehousing, structured and unstructured data.
Big Data Development experience using Hive, Impala, Spark and familiarity with Kafka (Preferred)
Familiarity with the Linux operating system (Preferred)
Exposure to machine learning, data science, computer vision, artificial intelligence, statistics, and/or applied mathematics
Passionate about Agile software processes, data-driven development, reliability, and experimentation
Experience working on a collaborative Agile product team
Self-motivated with strong problem-solving and learning skills
Flexibility to changes in work direction as the project develops
Excellent communication, listening, and influencing skills
Demonstrated strong number sense, intellectually curious and willing to adjust position based on additional information
Strong work ethic; ability to work at an abstract level and gain consensus",3.0,"Galen Technology Solutions
3.0","Allentown, PA","Florham Park, NJ",1 to 50 employees,-1,Company - Private,"Health, Beauty, & Fitness",Consumer Services,$1 to $5 million (USD),-1
Sr. Software Engineer - Platform,-1,"LeapYear's secure machine learning platform is deployed by some of the largest enterprises in the world across finance, healthcare, and technology.

Our technology ensures differential privacy, a widely recognized standard of data privacy that enables all data - including sensitive information - to be utilized for analytics, while providing mathematically proven privacy protection.

The LeapYear system is composed of a core set of components that allow private machine learning on data sets that can scale to petabytes. The system includes private algorithms for relational operations, statistical methods and machine learning. A data scientist accesses private data using a Python API. Administration is provided via a web-based GUI or an API.

LeapYear's platform team builds the services that allow our product to integrate with complex enterprise environments and operate effectively on our customers’ most sensitive data.
The platform includes services for authentication, access control, logging, auditing and support for integration of data from a variety of data sources including SQL/NoSQL Databases, HDFS and S3. Queries are processed using Spark to support to enable fast, distributed processing of massive data sets. The services are primarily written in Haskell, with Python, Scala, and Java used as additional supporting languages.

We are looking for platform engineers that have a track record of developing enterprise-ready features for technical end users, including enterprise integrations, rigorous security, flexible deployment, and support for diverse data sources.

Recent technical challenges we've been working on
Developing a Spark-based query engine with strong typechecking.
Achieving terabyte and petabyte scale on Spark.
Refactoring our persistence layer.
Using Haskell to implement enterprise-ready subsystems for authentication, permissioning, job management, and logging.
Extending the platform to support automated daily data updates.

For details on the specific responsibilities and requirements of this role, please see below.
Responsibilities
Develop greenfield systems and scale existing services to support internet-scale deployments.
Own the full software development lifecycle - problem definition, design, development, testing, demoing, and supporting production use of the features you own.
Partner with product management to define problems and identify iterative solutions
Balance immediate business objectives against long-term architectural vision
Contribute to an engineering-wide culture of code quality and shared responsibility for testing
Requirements
7+ years of professional experience writing production code
Acquainted with and interested in functional programming (Haskell, OCaml, Clojure, Erlang, Scala)
Track record of delivering high-quality product features on schedule
Preferred
Experience developing for on-premise enterprise deployments
Professional experience with functional programming
Prior experience developing production-level Spark applications or machine learning platforms
Experience with ODBC/JDBC databases, AWS, CircleCI
Lifelong learners and mentors
A Few of the Perks
Culture of teaching and learning
Competitive compensation package of salary and equity
Catered lunch every day
Company outings
Build your ideal work station
Generous health insurance plan
Relocation support and visa sponsorship",4.2,"LeapYear
4.2","San Francisco, CA","San Francisco, CA",1 to 50 employees,2015,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Senior Data Engineer,"$67K-$127K
(Glassdoor est.)","Join our team dedicated to developing and executing innovative solutions in support of customer mission success.
Job Description:

Novetta has an immediate need for a Senior Data Engineer to join a fast-paced program in support of a government customer with a very critical national security mission. This is a multi-year program, where the successful candidate will work on an interdisciplinary project team of more than 30 highly qualified individuals with a wide array of skills that include client (reactjs), server (spring java), QA Automation Engineers, UI/UX Designers, and DevOps engineers. The team is responsible for building a next generation Mission Information System and is performing greenfield Software Development using modern technologies via an Agile DevOps approach.

This Senior Data Engineer will play a vital role collaborating as part of this cross-functional Agile team to create and enhance data ingestion pipelines and address big data challenges. The Senior Data Engineer will work closely with the Chief Architect, systems engineers, software engineers, and data scientists on the following key tasks:
Provide Extraction, Transformation, and Load (ETL) experience coupled with enterprise search capabilities to solve Big Data challenges
Design and implement high-volume data ingestion and streaming pipelines using Open Source frameworks like Apache Spark, Flink, Nifi, and Kafka on AWS Cloud
Leverage strategic and analytical skills to understand and solve customer and business centric questions
Create prototypes and proofs of concept for iterative development
Learn new technologies and apply the knowledge in production systems
Monitor and troubleshoot performance issues on the enterprise data pipelines and the data lake
Partner with various teams to define and execute data acquisition, transformation, processing and make data actionable for operational and analytics initiatives

Required Qualifications / Experience:
BS in Computer Science, Systems Engineering, or a related technical field or equivalent experience with at least 8+ years in systems engineering or administration (6+ years with a MS/MIS Degree).
Must have an active Top Secret security clearance and able to obtain a TS/SCI with Polygraph.
3 years of experience with big data tools: Hadoop, Spark, Kafka, NiFi.
3 years of experience with object-oriented/object function scripting languages: Python (preferred) and/or Java.
3 years of experience with and managing data across relational SQL and NoSQL databases like MySQL, Postgres, Cassandra, HDFS, Redis, and Elasticsearch.
3 years of experience working in a Linux environment.
2 years of experience working with and designing REST APIs.
Experience in designing/developing platform components like caching, messaging, event processing, automation, transformation and tooling frameworks.
Experience developing data ingest workflows with stream-processing systems: Spark-Streaming, Kafka Streams and/or Flink.
Experience transforming data in various formats, including JSON, XML, CSV, and zipped files.
Experience with performance tuning of ETL jobs.
Experience developing flexible ontologies to fit data from multiple sources and implementing the ontology in the form of database mappings / schemas.
Strong interpersonal and communication skills necessary to work effectively with customers and other team members.
Preferred Qualifications / Experience:
Data engineering experience in the Intelligence Community or other government agencies.
Experience with Microservices architecture components, including Docker and Kubernetes.
Experience developing microservices to fit data cleansing, transformation and enrichment needs.
Experience with AWS cloud services: EC2, S3, EMR, RDS, Redshift, Athena and/or Glue.
Experience with Jira, Confluence and extensive experience with Agile methodologies.
Knowledge about security and best practices.
Experience developing flexible data ingest and enrichment pipelines, to easily accommodate new and existing data sources.
Experience with software configuration management tools such as Git/Gitlab, Salt, Confluence, etc.
Experience with continuous integration and deployment (CI/CD) pipelines and their enabling tools such as Jenkins, Nexus, etc.
Detailed oriented/self-motivated with the ability to learn and deploy new technology quickly.
Clearance Level: TS/SCI with Poly


Novetta, from complexity to clarity.

Novetta delivers highly scalable advanced analytics and secure technology solutions to address challenges of national and global significance. Focused on mission success, Novetta pioneers disruptive technologies in machine learning, data analytics, full-spectrum cyber, cloud engineering, open source analytics, and multi-INT fusion for Defense, Intelligence Community, and Federal Law Enforcement customers. Novetta is headquartered in McLean, VA with over 1,000 employees across the U.S.


Our culture is shaped by a commitment to our core values:

Integrity • We hold ourselves accountable to the highest standards of integrity and ethics.

Customer Success • We strive daily to exceed expectations and achieve customer mission success.

Employee Focus • We invest in our employees' professional development and training, respecting individuality and fostering a culture of diversity and inclusion.

Innovation • We know that discovering new and innovative ways to solve problems is critical to our success and makes us a great company.

Excellence in Execution • We take pride in flawless execution as we build a company that is best in class.


Earn a REFERRAL BONUS for the qualified people you know.
For more details or to submit a referral, visit bit.ly/NovettaReferrals.

Novetta is an equal opportunity/affirmative action employer.
All qualified applicants will receive consideration for employment without regard to sex, gender identity, sexual orientation, race, color, religion, national origin, disability, protected veteran status, age, or any other characteristic protected by law.",4.5,"Novetta
4.5","Reston, VA","Mc Lean, VA",501 to 1000 employees,2012,Company - Private,Enterprise Software & Network Solutions,Information Technology,$100 to $500 million (USD),"Leidos, CACI International, Booz Allen Hamilton"
Azure Data Engineer,-1,"The candidate will be responsible for meeting with business and technical staff, end users, and senior management to define requirements. The candidate must also be able to develop, deploy, and support Data Engineering. The ideal candidate will possess effective communication and interpersonal skills to build and maintain working relationships with clients. The developer will also be expected to prepare and maintain related technical documentation.
RESPONSIBILITIES:
Work with clients to elicit, refine, and document requirements.
Data modeling, process modeling, and rapid prototyping.
Develop/maintain ETL packages.
Develop/maintain Power BI data models and visualizations.
Assist in the design and implementation of a data lake to store structured and unstructured data.
Plan, prioritize, and execute in a rapidly changing, fast-paced environment.
Use version management and issue tracking software to document all changes.
Conduct tuning in Power BI to improve performance.
REQUIRED:
Bachelors Degree in computer science, engineering, mathematics, statistics, data science, analytics bioinformatics, or related program.
3-5 years proven experience with Power BI and/or SSAS/SSIS.
Experience with TSQL.
Experience with programming language such as JavaScript, Python or R.
Application architecture experience.
Excellent interpersonal and organizational skills.
Strong leadership, verbal and written communication skills.
U.S. Citizenship Required
Project management understanding.
Consulting experience a plus.
Ability to obtain a security clearance
DESIRED:


Experience with Power Query/M functions.
ETL experience and/or ML experience with Apache Spark or Apache Hadoop
Azure Data Engineer, Azure Data Scientist, Azure Data Analyst Associate or MCSA: Machine Learning Certification
1+ years of experience with data science, econometrics, statistics, machine learning, or analytics in professional or academic environments
1+ years of experience with managing and manipulating large data sets, developing data science approaches, and executing data science tasks
Experience with machine learning models and applications
Ability to leverage a wide variety of data science capabilities and languages
Ability to communicate results effectively to both technical and nontechnical audiences",4.4,"Definitive Logic
4.4","Arlington, VA","Arlington, VA",201 to 500 employees,1999,Company - Private,Consulting,Business Services,$25 to $50 million (USD),-1
Senior Software Engineer - Machine Learning,"$135K-$210K
(Glassdoor est.)","Amazon is investing heavily in building a world class advertising business and we are responsible for defining and delivering a collection of self-service performance advertising products that drive discovery and sales. Our products are strategically important to our Retail and Marketplace businesses driving long term growth. We deliver billions of ad impressions and millions of clicks daily and are breaking fresh ground to create world-class products. We are highly motivated, collaborative and fun-loving with an entrepreneurial spirit and bias for action. With a broad mandate to experiment and innovate, we are growing at an unprecedented rate with a seemingly endless range of new opportunities.

Our systems and algorithms operate on one of the world's largest product catalogs, matching shoppers with advertised products with a high relevance bar and strict latency constraints. We work hand-in-hand with Machine Learning scientists to come up with novel solutions that deliver highly relevant ads. We consistently strive to improve the customer search and detail page experiences. You will drive appropriate technology choices for the business, lead the way for continuous innovation, and shape the future of e-commerce. This is an opportunity to make a significant impact on the future of the Amazon vision.

As a Senior Software Development Engineer in Machine Learning at Amazon, you will drive the technical direction of our offerings and solutions, working with many different technologies across the sponsored products organization. You will design, code, troubleshoot, and support scalable machine-learning pipelines and online serving systems. You will work closely with applied scientists to optimize the performance of machine-learning models and infrastructure, and implement end-to-end solutions. What you create is also what you own. In addition to being a strongly motivated individual contributor, you will also be responsible for mentoring junior engineers and guiding them to deliver to the full potential.

The team is open to hiring this engineering into the Palo Alto office or with a flexibile schedule of coming into the office or as a full remote/virutal employee.


Basic Qualifications

· 4+ years of professional software development experience
· 3+ years of programming experience with at least one modern language such as Java, C++, or C# including object-oriented design
· 2+ years of experience contributing to the architecture and design (architecture, design patterns, reliability and scaling) of new and current systems
· Bachelor or Master's Degree in Computer Science, Applied Mathematics, or related discipline
· 5+ years professional experience in software development with experience in working on low latency, high volume distributed systems.
· 5+ years experience with computer science fundamentals data structures, algorithm design, problem solving, and complexity analysis
· Exposure to Machine Learning basics (will train for more advanced skills in ML)

Preferred Qualifications

· Experience in building large-scale machine-learning infrastructure for online recommendation, ads ranking, personalization, or search, etc.
· Experience with Big Data technologies such as AWS, Hadoop, Spark, Pig, Hive, etc.
· Strong proficiency with Java, Python, Scala or C++
· Advanced knowledge of performance, scalability, enterprise system architecture, and engineering best practices
· Strong written and verbal communication
Amazon is an Equal Opportunity-Affirmative Action Employer Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation/Age
#PABDSDE3ADS
#PABDSDE3
#VIRBDSDE3

#VIRBDSDE3ADS",3.9,"Amazon
3.9","Palo Alto, CA","Seattle, WA",10000+ employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),"Google, Microsoft, Walmart"
Senior Machine Learning Engineer - SEAL,-1,"ID: 495319
Type: Researchers
Location: Smyrna, GA
Categories: Algorithm Development, Artificial Intelligence, Electronic Warfare, Embedded Systems, High Performance Computing, ISR & Tactical Systems, Software Development/Design, System Architecture, Testing, Machine Learning, Modeling/Simulation, Radar, Sensors Integration, Sensors/Optics, Signal Processing
Job Description


The Sensors and Electromagnetic Applications Laboratory (SEAL) of the Georgia Tech Research Institute (GTRI) is seeking technical personnel to be part of an established software team that has multiple opportunities for software engineers within the Software Engineering and Architecture Division (SEAD) at Smyrna, GA. The SEAD group mission is to provide world-class software to be used in sensors, signal processing, electronic warfare, tracking, and intelligence surveillance reconnaissance (ISR) systems deployed on land, air and sea.

Our software team employs a modern software engineering process to design, code, integrate and test capabilities on a continuous basis resulting in a mature and quality solution for our customers. We strive for technical excellence by drawing upon a diverse workforce whose knowledge base covers the complete spectrum of modern computing languages and platforms.

Job Duties


The successful candidates will be involved in the artificial intelligence (AI) software design, development, integration and testing of the systems. Our real-time machine learning software applications are developed using C++ and Python in a Linux environment. Our group utilizes productive modern (Agile) and industry-proven software development processes and environments. The candidate will get the opportunity to creatively solve problems, design features, and independently and work in a team environment to implement projects.

The candidate will have the opportunity to leverage machine learning techniques to build processes to gather insights from a high volume of data from multiple sources. You will develop systems to efficiently process the data in our platform. The candidate will ultimately be responsible for developing powerful software systems that reinforce our place as a technical research leader in machine learning and deploying software. The candidate will also lead and mentor junior engineers in the development of our quality, efficient and open software products.

Travel Requirements


10% - 25% travel

Education & Length of Experience


Senior Research Engineer/Scientist
A Master’s degree in Computer Engineering, Computer Science, Electrical Engineering, Mathematics, Physics, or related field of study and seven (7) years of relevant full-time experience after completion of that degree,
A Master’s degree in Computer Engineering, Computer Science, Electrical Engineering, Mathematics, Physics, or related field of study and nine (9) years of relevant full-time experience after completion of a Bachelor’s degree, or
A Doctoral degree in Computer Engineering, Computer Science, Electrical Engineering, Mathematics, Physics, or related field of study and four (4) years of relevant full time experience after completion of a Bachelor's degree.
Required Minimum Qualifications
Candidates currently enrolled in an accredited Master's or Doctoral degree program relevant to this position will be considered. Candidate must have a graduation date of no later than May, 2020
Artificial Intelligence algorithms utilized for applications
Knowledge of industry AI tools (e.g., TensorFlow, PyTorch, etc.)
Experience with C and C++
Experience with Linux or Windows
Experience in software engineering and development
Knowledgeable in version control software such as GIT
Knowledgeable in JIRA, Bitbucket and Confluence
Experience in the technical management of software engineers
Good verbal and written communication skills
Self-starter and ability to work in a team environment
Preferred Qualifications
Knowledge of computer architectures including multi-core environments
Familiarity with software applications requiring multi-threaded programming implementation
Complex programs that involved hardware, software, communications and networking
Experience with Object-Oriented Design Knowledge
Existing secret clearance, or the ability to obtain an interim clearance within 30 days and full clearance thereafter
U.S. Citizenship Requirements


Due to our research contracts with the US federal government, candidates for this position are required to be US Citizens.

Clearance Type Required


Ability to obtain Secret Clearance upon hire

Diversity & Inclusion


Diversity & Inclusion (D&I) at Georgia Tech Research Institute aims to enhance the Institute’s mission of solving the world’s most complex technical problems by creating a workforce with a shared appreciation for diversity, raising awareness around inclusiveness, and fostering a sense of belonging and appreciation for all members of our community.

Equal Employment Opportunity


Georgia Tech Research Institute is an Equal Opportunity Employer of individuals with disabilities and protected veterans and actively seeks diversity among its employees. Equal Employment Opportunity is the Law.

Posted: 02/18/2020
Closes: 08/18/2020",3.6,"Georgia Tech Research Institute
3.6","Smyrna, GA","Atlanta, GA",1001 to 5000 employees,1943,Subsidiary or Business Segment,Research & Development,Business Services,$100 to $500 million (USD),"MIT Lincoln Laboratory, Johns Hopkins University Applied Physics Laboratory"
Sr. Machine Learning Engineer,"$75K-$134K
(Glassdoor est.)","IQVIA is the leading human data science company focused on helping healthcare clients find unparalleled insights and better solutions for patients. Formed through the merger of IMS Health and Quintiles, IQVIA offers a broad range of solutions that harness the power of healthcare data, domain expertise, transformative technology, and advanced analytics to drive healthcare forward.

Title: Machine Learning Engineer

Technology Solutions division of IQVIA develops and markets healthcare-focused enterprise software applications including Master Data Management, CRM, Multi-channel Marketing, Content Management, Social and Compliance solutions. The Digital Office leads the transformation of the Technology Solutions product portfolio and is developing a cloud-based micro-intelligence platform bringing a layer of smart services to Technology Solutions software offering called Ada. Adas algorithms use machine learning, natural language processing and deep learning techniques as appropriate.

Role Purpose:

As an Ada Machine learning engineer, you will develop algorithms that enhance the daily life and professional outcomes of our end-users. You will join a team of other ML engineers / data scientists, big data and software engineers, all responsible for the delivery of Ada from the ground up. You will work with product and business stakeholders to deliver algorithms with very clear business objectives, including requirements gathering, model development, prototyping, and interfacing with the software engineering team. Ideal candidates will bring a well-rounded skillset capable of spanning customer-focus, data science and software development disciplines to shape early stage ideas into fully assessed, designed, and implemented machine learning solutions.

The Ada team is looking for a Machine Learning Engineer.

Do you have a passion for building great products? Do you believe in customer-centricity? Do you have strong analytical, interpretative and problem-solving skills? Do you want to work in a positive, can-do environment where collaboration and growth mindset are valued?
Join us!

Our teams values:
We focus on building software that adds value for our customers
We believe that the best idea or opinion precedes the title of its author
We are respectful of everybodys think time, optimizing meetings and limiting interruptions as much as possible
We value ownership, accountability, openness in collaboration and feedback
We test our code before handing it off: unit tests, ML tests, (continuous) integration tests, etc
We believe in reusing existing solutions over reinventing the wheel, and automating where possible
We seek continuous improvement, individually and as a team
Principle Accountabilities:
Build production-grade algorithms, utilizing machine learning & deep learning models and/or NLP processes to create actionable insights and recommendations for end-users
Work closely with technical stakeholders to optimize and integrate machine learning models and algorithms into the Ada platform, to productize models and algorithms
Interface with software engineering team for the development of the product
Design and develop proof-of-concept solutions as needed
Minimum Education, Experience, & Specialized Knowledge Required:
MS or PhD degree in Computer Science, Artificial Intelligence, Machine Learning, or related technical field or 3+ years relevant experience in data science (Machine learning or NLP solution development)
Creative problem solver with a strong knowledge of statistics/data analytics, text analytics/natural language processing and machine learning methods and strategies
Advanced proficiency with at least one statistical computing language for data analysis, such as Python or Scala
Good scripting and programming skills, including object-oriented programming
Experience with software engineering best practices (programming, testing, version control, agile development, etc)
Experience with source control (GitHub) and working in a Linux/Unix environment
Experience with Spark, Hadoop and MLib is a plus
Experience with SQL (MySQL, Redshift/Postgres)
Experience distilling and presenting complex concepts to a business audience
Excellent communication (written and oral) and interpersonal skills
To be successful as a member of the Digital Office Team, the candidate must also:
Work well in a collaborative, team-based environment (both work autonomously and as part of a team)
Be a self-starter who enjoys collaborating
Is flexible and able to work in a fast-paced, dynamic environment
Is fast and efficient and able to juggle multiple projects
#LI-TJ1

Join Us

Making a positive impact on human health takes insight, curiosity, and intellectual courage. It takes brave minds, pushing the boundaries to transform healthcare. Regardless of your role, you will have the opportunity to play an important part in helping our clients drive healthcare forward and ultimately improve outcomes for patients.

Forge a career with greater purpose, make an impact, and never stop learning.

IQVIA is an EEO Employer - Minorities/Females/Protected Veterans/Disabled

IQVIA, Inc. provides reasonable accommodations for applicants with disabilities. Applicants who require reasonable accommodation to submit an application for employment or otherwise participate in the application process should contact IQVIAs Talent Acquisition team at workday_recruiting@iqvia.com to arrange for such an accommodation.",3.6,"IQVIA
3.6","Plymouth Meeting, PA","Durham, NC",10000+ employees,2017,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,$2 to $5 billion (USD),"PPD, INC Research, PRA Health Sciences"
Data Engineer Senior,"$93K-$160K
(Glassdoor est.)","DescriptionJob Description:Leidos is seeking a Data Engineer who wants to work on a new agile DevSecOp project in an IC DoD customer space. Leidos is building a new team to develop new structure and applications for our customer. We are looking for a collaborative and forward leaning individual who wants to tackle challenges and be a part of creating innovative solutions. In return, Leidos will invest in you with a new enhanced leave plan, generous 401k, and training to name just a few great benefits. Ready to tackle your next challenge - then we want you on our team.This role ensures high quality data is available for use by other team members. This role designs, implements, and maintains standard data interfaces for data ingest including Extract/Transform/Load (ETL) methodology and implementation, Application Programming Interfaces (APIs), RESTful Web Services, data quality, and data cleansing.Primary Responsibilities* Ensure high quality data is available for use by other team members.* Design, implement, and maintain standard data interfaces for data ingest including Extract/Transform/Load (ETL) methodology and implementation, Application Programming Interfaces (APIs), RESTful Web Services, data quality, and data cleansing.* Develop methods, processes, and systems to consolidate and analyze structured and unstructured data, diverse sources including ""big data"" sources.* Develop and use advanced software programs, algorithms, query techniques, modeling complex business problems, and automated processes to cleanse, integrate, and evaluate data sets.* Collaborate across a team of Data Scientists, Data Engineers, and Data Administrators to produce work products.* Analyze requirements and evaluate technologies for data science capabilities including Natural Language Processing (NLP), Machine Learning (ML), predictive modeling, statistical analysis and hypothesis testing.* Work with cross-discipline teams to ensure connectivity between various data sources and business functions.* Identify meaningful insights related to data interfaces, data ingest and data quality; interpret and communicate findings and recommendations.* Develop information tools, algorithms, dashboards, and queries to monitor and improve business performance.* Maintain awareness of emerging analytics and big-data technologies.* Plan and lead major technology assignments related to data interfaces, data ingest and maintaining data quality.* Evaluate data related performance results and recommend major changes affecting short-term project growth and success.* Function as a technical expert for providing high quality data to business and mission users across multiple project assignments.* May mentor or supervise others.Basic Qualifications* Ability to apply a comprehensive knowledge of data technologies, data interfaces, data ingest, and data security across key tasks and high impact assignments.* Expert technical knowledge of data science technologies including Natural Language Processing (NLP), Machine Learning (ML), predictive modeling, statistical analysis, hypothesis testing, emerging analytics, and big-data technologies.* Ability to use advanced software programs, algorithms, and query techniques as well as model complex business problems, and automated processes to cleanse, integrate, and evaluate data set* Ability to analyze data interface, data ingest, and data security requirements and evaluate technologies for data science capabilities and applications.* Ability to evaluate performance results and recommend major changes affecting short-term project growth and success.* Ability to lead major technology assignments/project for data interfaces, data ingest, and providing data quality.* Ability to communicate finding and recommendations based on insight and knowledge of data related issues.* Experience reviewing other people's work.* Experience in mentoring, supervising, and managing team members.* The candidate must have a Bachelor's degree with 8-12 years of experience; or a Master's degree with 6-10 years of experience. Years of experience may be used in lieu of degree.US Citizenship is required.TS/SCI with Poly required.Preferred Qualifications* May possess a Doctorate in a technical field.External Referral Bonus:EligiblePotential for Telework:NoClearance Level Required:Top Secret/SCI with PolygraphTravel:NoScheduled Weekly Hours:40Shift:DayRequisition Category:ProfessionalJob Family:Data ScientistLeidosLeidos is a Fortune 500® information technology, engineering, and science solutions and services leader working to solve the world's toughest challenges in the defense, intelligence, homeland security, civil, and health markets. The company's 33,000 employees support vital missions for government and commercial customers. Headquartered in Reston, Virginia, Leidos reported annual revenues of approximately $10.19 billion for the fiscal year ended December 28, 2018. For more information, visit www.Leidos.com.Pay and BenefitsPay and benefits are fundamental to any career decision. That's why we craft compensation packages that reflect the importance of the work we do for our customers. Employment benefits include competitive compensation, Health and Wellness programs, Income Protection, Paid Leave and Retirement. More details are available here.Securing Your DataLeidos will never ask you to provide payment-related information at any part of the employment application process. And Leidos will communicate with you only through emails that are sent from a Leidos.com email address. If you receive an email purporting to be from Leidos that asks for payment-related information or any other personal information, please report the email to [email protected].Commitment to DiversityAll qualified applicants will receive consideration for employment without regard to sex, race, ethnicity, age, national origin, citizenship, religion, physical or mental disability, medical condition, genetic information, pregnancy, family structure, marital status, ancestry, domestic partner status, sexual orientation, gender identity or expression, veteran or military status, or any other basis prohibited by law. Leidos will also consider for employment qualified applicants with criminal histories consistent with relevant laws.",3.5,"Leidos Holdings Inc.
3.5","Washington, DC","Reston, VA",10000+ employees,1969,Company - Public,Aerospace & Defense,Aerospace & Defense,$10+ billion (USD),-1
Senior Data Scientist,"$120K-$135K
(Glassdoor est.)","Thank you for your interest in joining the Centauri team. Together, we can leverage the next generation of advanced technologies to deliver industry-leading capabilities across land, air, sea, space, and cyberspace. Our goal is to deliver innovative solutions using an agile, mission-first approach to address the most difficult technical challenges facing our customers. The only way that we can tackle these challenges is by recruiting the brightest minds in the industry to join our team.
Description
Centauri is seeking a Data Scientist for long term employment to develop breakthrough products and innovative software applications for government and commercial customers. As a software engineer you work individually or on a small team. Many of our projects have immediate impact on national security leader decision making options. Projects may vary in duration offering you the opportunity to take on new challenges. We need engineers who are versatile, enjoy working in a fast-paced environment, like to consistently tackle new problems, and exceed customers’ expectations.

Responsibilities:
Work with team lead to define software requirements
Design & develop system software for our customers
Explore new areas or program in new languages to deliver a complete product
Support on-site meetings and deliveries to customers
Analyze, troubleshoot, and optimize deployed web app/database systems
Minimum Qualifications:
Minimum of 5 years’ experience with data analysis, database federation, or data quality projects
Minimum of 5 years software development, and object-oriented design and programming, including design, coding, and testing experience
Experience with Postgres, NoSQL, and REST APIs
Experience with Web Services and JavaScript (e.g., ReactJS)
Bachelor’s degree in Computer Science, Engineering, or related discipline
Strong communication and interpersonal skills
Ability to work independently as well as part of a team to achieve customer and company goals
Preferred Qualifications:
Hands-on Experience with PeopleSoft HCM
Hands-on Experience with Java, C/C++, C#, and/or Python
Experience using machine learning for anomaly detection, data clustering, or NLP
MS/PhD in Computer Science, Engineering, or related discipline
Azure, AWS, Security+ certifications
Security Requirements: Must meet eligibility requirements for a security clearance.

Travel: up to 25%
Centauri is an Equal Opportunity / Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, protected veteran status or any other factor protected by law.

Are you a returning applicant?
Previous Applicants:


Email:


Password:
If you do not remember your password click here.
Back to Search Results

New Search",4.6,"Centauri
4.6","Carlsbad, CA","Chantilly, VA",501 to 1000 employees,1999,Company - Private,Aerospace & Defense,Aerospace & Defense,$100 to $500 million (USD),"TASC, Vencore, Booz Allen Hamilton"
Senior AI Researcher/Engineer - CV,"$143K-$246K
(Glassdoor est.)","Title: Senior AI Researcher/Engineer CV

Company: Samsung Research America

Lab: Artificial Intelligence Lab

Location: Mountain View, CA

Position Summary:

Samsung Research America (SRA), located in Mountain View, CA, is looking for an outstanding and highly self-motivated researcher/engineer. We are looking for candidates with machine learning and deep learning background, in the field of computer vision.You will work with a team of research scientists and engineers tackling real-world problems involving Samsung's Artificial Intelligence initiatives. The AI research center is a key part of Samsung's global R&D effort and aims to have influence on future Samsung products reaching hundreds of millions of users worldwide.

Common Essential Duties & Responsibilities:
Design, develop and implement novel deep learning/machine learning algorithms for visual understanding, visual generation, visual quality enhancement, etc.
Conduct exploratory research on deep learning, especially efficient on-device computing
Develop proof-of-concept demonstration on advanced computer vision technologies
Generate creative solutions (patents) and publish research results in top conferences (papers).
Background / Experience:

Experience in one or more of the following areas:
Experience in efficient machine learning model/architecture design for edge devices (e.g., MobileNet, ShuffleNet, etc.)
7+ years of experience in computer vision, especially in image synthesis, super resolution, object detection, etc.
7+ years of experience in deep learning technologies on computer vision (CNN, RNN/LSTM/GRU, R-CNN, fast R-CNN, Mask RCNN, GAN, etc.)
7+ years of experience in machine learning (generative model, discriminative model, transfer learning, GAN, one-shot or few shot learning, unsupervised learning, semi-supervised learning, weakly supervised learning, meta-learning, outlier detection, etc.)
Experience in multi-modal data deep learning is welcome
Proficiency in a neural network library (e.g., TensorFlow, PyTorch, etc.)
7+ years of experience in developing software in computer vision, machine learning or computer graphics, including low-level system development and development on various platforms, especially on mobile edge devices
Proven track record of research/publications and patents on machine learning and artificial intelligence field (CVPR, ICCV, ECCV, NeurIPS, ICML, ICLR, AAAI, IJCAI, etc.)
Necessary Skills / Attributes:
Team work and communication skills are required
PhD. degree in CS, EE, or related field is required
Samsung is an EEO/Veterans/Disabled/LGBT employer. We welcome and encourage diversity as we strive to create an inclusive workplace.",3.5,"Samsung Research America
3.5","Mountain View, CA","Mountain View, CA",1001 to 5000 employees,1988,Subsidiary or Business Segment,Computer Hardware & Software,Information Technology,$50 to $100 million (USD),"Sony, LG Electronics, Nokia"
Lead Software Engineer for Medical Software,-1,"Job Description
Interested in developing leading edge medical device technology in a small company with a history of success? Join our team and have the opportunity to work on several exciting projects at once in an R&D environment that leads to success, not excessive meetings and paperwork. You’ll have the opportunity to lead efforts to commercialize the technology you develop or continue focusing on early stage efforts.

Minimum requirement:
Bachelor’s degree in Computer Engineering, Electrical Engineering, or equivalent
Full stack development experience
5+ years of medical device, secure database implementation, and/or embedded software development experience.
Preferred:
Masters or PhD in Computer Engineering or Electrical Engineering
DSP and machine intelligence experience
This position is in a small team developing medical device hardware and software. Multiple projects will be developed each year and the desire and ability to learn new skills quickly is required. Initial primary task is developing software system that supports respiratory therapists in taking care of ventilated patients. This involves acquiring data from medical equipment, uploading to an online database, and creating application interfaces to display combined data for the clinician.

Self-starter, independent worker able to work in inter-disciplinary teams of engineers, scientists, and clinicians.

Required Skills:
Full stack development
Medical device software design and quality
Use of industry standard source/revision control with clear/concise engineering documentation
Secure back-end database design
Mobile applications including Java, C++
Desired Skills (or willing to learn):
Microcontroller experience such as ARM, arduino, ATTiny
Embedded software including C
Code optimization for limited resources and multi-threaded applications
Experience using Matlab for algorithm design, development, and test
Physiologic/biomedical signal analysis (plethysmography, ECG, ventilator waveforms, etc)
Machine intelligence
Android and/or Linux kernel drivers
Real time operating systems
Experience with Bluetooth LE
Experience with inter-hardware communication such as I2C and SPI bus

Company Description
Convergent Engineering is a biomedical research engineering firm near Gainesville, FL specializing in creating better, more intelligent medical devices. We have licensed many of our technologies to large companies such as Philips Healthcare and successfully spun off two companies that are commercializing: (1) a more comfortable and accurate fetal monitoring technology, and (2) a proof-positive medication compliance technology (electronic pills). Convergent Engineering currently has 4 employees and is growing towards 6-8. We offer health and dental insurance and a retirement account. Cost of living in the Gainesville area is low and quality of life is high.",5.0,"Convergent Engineering
5.0","Gainesville, FL","Newberry, FL",1 to 50 employees,2004,Company - Private,Health Care Services & Hospitals,Health Care,$1 to $5 million (USD),-1
DevOps Engineer - Top Secret Clearance Required,-1,"Job Description
DevOps Engineer

Top Secret security clearance with an SCI required (TS/SCI)

BigBear, Inc. is a leading provider of big data computing and analytic solutions. We help people make sense of their data using our cloud-based platform and big data processing algorithms. Each day, we crunch massive volumes of structured and unstructured data into usable and actionable information for our customers.

We currently have an opening for a talented and passionate DevOps Engineer to join our top-notch team of forward-thinking engineers, data scientists, analysts, and innovators. The successful candidate will be a self-starter that demonstrates excellent communication and problem-solving skills with a strong drive for innovation.

Required Experience:

Solid experience with Linux

Amazon Web Services such as EC2, S3, SQS, RDS

Deployment automation with tools such as Terraform, CloudFormation, Jenkins, Ansible, or Chef

Advanced scripting skills with Python or Bash.

Bachelor’s or Master’s degree in Computer Science, Engineering, a related field, or equivalent work experience

Preferred Experience:

Experience with ELK Stack (ElasticSearch, Logstash, Kibana, Beats)

AWS Certification

Security+ or CISSP Certification

Current Top Secret security clearance with SCI (TS/SCI)

Technology We Use:

ElasticSearch

PostgreSQL

Python - Django

AWS

Docker

Git

Angular

React

Jenkins

Our Company:

BigBear, Inc. is a software development company with locations in San Diego, Washington DC, Charlottesville, and Reston, VA. Our mission is to enable big data computing and analytics for our customers at a low cost. We leverage capabilities such as machine learning, crowdsourcing, geospatial image processing, and Extract-Transform-Load (ETL) data processing using our on-premise cloud computing technology stack. Our solutions provide a unique offering of products, custom-built software, and services focused within Big Data Analytics, Geospatial Information Systems (GIS), Visualization and Cloud Computing to our Department of Defense, and Commercial customers. We currently have exciting and challenging career opportunities for talented, motivated individuals who want to be part of a fast-growing company.

Our Team:

We like to play with new toys and technologies. We like to break things to see if we can put them back together again in a better way. Our tails wag when we hear the words Big Data, Geospatial or Machine Learning. Each team member provides a unique set of advanced technical skills and trade that contributes to our overall success.

Perks/Benefits:

· 100% employer-paid for Medical, Dental, and Vision insurance (PPO)

· A competitive salary based on experience

· Flexible Spending Account (FSA) - optional

· 401(k) with dollar-for-dollar match up to 6%

· A warm, cozy office with actual chairs and tables

· Life and Disability Insurance 100% paid for by the company

· Education Assistance

· 529 College Savings Plan - optional

· Healthy Rewards Program

· Pre-paid Legal & Identity Theft Protection - optional

· Gym Reimbursement

· Pet Insurance - optional

· A shiny magical machine that does wonderful things

· Flexible Hours

· Unlimited Coffee, Drinks and Snacks

· 6 WEEKS of Paid Time Off (PTO) on top of 11 Paid Holidays!

BigBear is an Equal Employment Opportunity Employer/Veterans/Disabled
Company Description
BigBear, Inc. is an industry-leading provider of big data computing and analytics solutions. We help people make sense of their data using our cloud-based platform and big data processing algorithms. Each day, we crunch massive volumes of structured and unstructured data into usable and actionable information for our customers. We currently have offices in Reston, VA., Charlottesville, VA., and San Diego, CA.",4.4,"BigBear Inc.
4.4","Reston, VA","San Diego, CA",51 to 200 employees,2008,Company - Public,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Software Engineer (Python/Spark),-1,"TVision is the leader in TV engagement metrics. We measure what was previously unmeasurable - how people actually watch TV. We enable the media industry - advertisers, networks, and technology partners alike - to reduce waste and drive greater and more efficient marketing results.

Utilizing cutting edge technology, TVision goes beyond traditional TV data to include measurement of presence in room, co-viewing and attention, producing best-in-class TV data. This allows us to provide critical data to inform the decision making of a $100B/year industry.

Our growth and innovation have been recognized by The New York Times, Advertising Age, AdWeek, Business Insider, MediaPost, and Forbes. We were selected as a Best Place to Work 2019 by Built in Boston, and were named one of the top companies to watch in advertising technology by Business Insider in December 2019.

The Role

Measurement and data analysis lie at the foundation of TVision's data products. As an engineer working on TVision's data pipeline, you might find yourself working on
the framework for training and tracking changes to our computer vision models;
the data collection software that runs on our measurement devices;
the error correction and statistical analyses in our back end that help us extract meaning from the raw measurements;
or the compute and data storage infrastructure that makes all of this possible.
Because we believe strongly in working together with domain experts to build our software, our data analysis pipeline is built in the common language of data science, which is Python. Together with state of the art machine learning frameworks such as Tensorflow and OpenVINO, our primary tool for organizing computation is Apache Spark. The successful candidate for this position will be an experienced and confident developer with both Python and Spark.

But this role is not just about data science and data analysis; we expect you to be a generalist software engineer first. This is a centrally located, interdisciplinary role. You will be working closely with colleagues from all parts of our engineering and data science organizations, from customer-facing data analysts to systems and devops engineers.

In addition, because we also believe in the value of statically proven correctness, the back end services that manage our device and data ecosystem are built in Haskell. If you have experience or are interested in statically typed functional programming, so much the better.

The Candidate

You are a software engineer first, with experience working in an agile development environment following sound engineering practices. You are thoroughly familiar with Python and Spark, and some related technologies (machine learning frameworks, relational databases, other big data ecosystem tools). If you are primarily a data scientist, and your expertise with these tools is purely using them rather than developing with and integrating with them, this is not the role for you.

The specific requirements are as follows:
3 - 7 years of industry experience
BS/MS in Computer Science or closely related discipline (math, computer engineering).
Substantial experience with Python and Spark, including enough confidence in Scala to understand what's going on in Spark under the hood.
Experience with at least one relational database (we use Postgres). If you are also familiar with columnar databases (Redshift, Vertica, etc) even better.
Engineering experience with at least one deep learning framework (Tensorflow, PyTorch, etc) is desirable. You don't need to know how to build and train models, though it certainly doesn't hurt.
Knowledge of Haskell is a plus, but not a requirement.
Strong communications skills with both technical and non-technical team members.
Collaborative and enthusiastic approach to software development.
Strong sense of project ownership and personal responsibility.
Benefits
Competitive pay and stock options
Your choice of comprehensive health benefits for you and your family (health, dental, vision)
Short and long-term disability, Life and AD&D insurance
FSA/HSA accounts
401(k) retirement plan options
Pre-tax commuter benefits
Monthly phone reimbursement
Unlimited PTO and paid holidays
Gym membership discounts
Financial support for ongoing professional development
Casual dress and fun atmosphere",4.4,"TVision Insights
4.4","Boston, MA","New York, NY",1 to 50 employees,2014,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Senior Machine Learning,-1,"Job Description
Title: Senior Machine Learning

Location: Remote in continental U.S. or Richmond, VA; must be available 8am-5pm EST

Type: Contract ( 6 months +) Potential Contract to Hire

Key Skills: Python, C#, APIs, Azure and Databricks (In between Data Scientist and Data Engineer)

Essential Responsibilities:

Work collaboratively and creatively with other developers to productionize and operationalize models using the latest Microsoft Azure technologies and leading industry practices
Develop scalable model-as-a-service patterns and enterprise capabilities
Build scalable online/offline feature stores and streaming capabilities
Partner with Data Scientists, Product Managers, and Data Engineers to deliver creative, cutting-edge, high-quality engineering solutions, enhancing the iconic CarMax experience for our customers

Qualifications:

5+ years software development experience using Python and C# including strong understanding of software engineering principles
2 years experience developing REST APIs and deploying microservices in Azure
2 years experience with Databricks
1-year experience deploying and managing containerized applications, preferably using Azure Kubernetes Services
1-year experience developing streaming capabilities
1-year experience with Azure Machine Learning Services and MLflow
Exposure to machine-learning libraries and tools, such as PyTorch, Tensorflow, or scikit-learn.
2 years experience working on Agile teams implementing DevOps/DataOps/MLOps practices
Excellent communication skills, adapting to various audience types
Passionate about innovation and loves solving complex problems in a highly- collaborative, fast-paced team environment

MINIMUM QUALIFICATIONS

Bachelor's Degree or master's degree in the field of Computer Science or Information Systems or a related field.",5.0,"IKCON Technologies Inc
5.0","Richmond, VA","South Plainfield, NJ",1 to 50 employees,-1,Company - Public,-1,-1,Unknown / Non-Applicable,-1
Mid-Level Engineer (Electrical/Software/Computer),-1,"The Position


EngeniusMicro is looking for an Engineer to join our multi-disciplinary staff of engineers and scientists. We seek a candidate able to work in a fast-paced, small team environment through all phases of the product life cycle from conceptual development and detailed design through manufacturing, testing, delivery, and support.

Primary work duties include the development, troubleshooting, maintenance and improvement of control and application software used in 3D printer operation and automation including the interface, integration and testing of software with various hardware systems.

Basic Qualifications


This position requires a bachelor's degree from an ABET School in Software, Electrical, Robotic, Mechatronics, or Computer Engineering with aminimum of 3+ yearsof experience in the development and implementation of control and electro-mechanical systems software including demonstrated project experience.

Experience both embedded system programming and UI development is required.

*This position requires the ability to obtain a US Security Clearance for which the US Government requires US Citizenship

Required Skills / Experience


Strong knowledge and demonstrated experience is required in:
UI programming (Python, Javascript, React, Vue, HTML, CSS, QT)
Experience with Git
Control system programming (C, C++, Java, Spin)
Firmware for various MCU families
Computer vision (OpenCV)
Embedded microcontroller-based hardware design
Interfacing to sensors and mixed-signal components
Strong written and verbal communication skills
Test equipment and debug/test methods
Preferred Skills / Experience


Familiarity or experience is preferred in:
Experience with 3D Printing or automated systems
Electronics packaging design
Data processing and machine learning principles
Computational geometry and path planning algorithms
Circuit design and schematic capture
PCB layout
Why should you apply?
You like solving problems and developing new technology in a fast-paced team driven environment
You're interested in building hardware and prototypes
You enjoy strong technical challenges in a collaborative environment
Job Posted by ApplicantPro",5.0,"EngeniusMicro, LLC.
5.0","Huntsville, AL","Huntsville, AL",1 to 50 employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
"Engineer in Virtualization and Container Orchestration, Pittsburgh Supercomputing Center (PSC)",-1,"Job Function:The Pittsburgh Supercomputing Center, a joint research center Carnegie Mellon University and the University of Pittsburgh, was established in 1986, and for over 30 years has provided university, government and industrial researchers with access to several of the most powerful systems for advanced computational research, communications and data storage available to scientists, engineers and scholars nationwide for unclassified research. PSC advances science across the spectrum including artificial intelligence / machine learning, medical imaging, weather modeling, and genomics. The Advanced Systems and Operations group within PSC is responsible for the integration and operations of computational assets central to this pursuit.We are seeking a creative and capable individual to join our highly-experienced Advanced Systems and Operations team as our new Virtualization Infrastructure Engineer. In this role, you will support the research community by developing and maintaining the infrastructure to deploy and maintain fleets of hosts (physical and virtual), containers and services for the variety of project-based resources PSC operates and have a hand in planning new directions. This is an opportunity to join a growing team at the nexus of technology, research, and software development dedicated to helping the scientific community solve challenging and complex problems. We are looking for creative and capable individuals to join our team and continue our part in pushing forward the boundaries of science.Your core responsibilities include:* Designing, implementing, and maintaining virtual hosting platforms at PSC* Designing, implementing, and maintaining container hosting and orchestration platforms for system operations and research computing* Designing, implementing and maintaining a microservice architecture for high performance computing orchestration and emerging (e.g. Functions as a Service) hosting resources* Designing and maintaining OS provisioning on bare-metal systemsMinimum Qualifications:* Bachelor's degree or equivalent in education and experience* A combination of 3 to 5 years of experience in the following areas:* Development, installation, and/or managing virtualization, orchestration, and/or container infrastructure: such as: OpenStack, Singularity, Kubernetes* Experience administering Linux and/or other Unix systems at scale, preferably in support of high-performance computing* Overall Systems Administration and Information Technology Experience* Scripting for systems automation with languages such as Python and BashPreferred Qualifications:* Ability to work in a team to automate systems tasks, stand up and maintain new and existing infrastructure infrastructure* 1-3 years experience using, deploying and maintaining virtualization and/or container hosting platforms* 1-3 years experience virtualization hosting platforms such as OpenStack, VMWare ESX, oVirt* 1-3 years' experience writing and/or extending systems software such as utilities, libraries, plugins* 1-3 years' Linux systems administration experience* Container experience with Singularity or Docker and Kubernetes (or similar)* Familiarity with cloud services such as AWS, GCP, or Azure* Familiarity with OS provisioning software such as OpenStack Ironic, Warewulf, or Puppet Razor.Requirements:* Background checkAre you interested in this opportunity with us? Please apply.More Information:Please visit ""Why Carnegie Mellon"" to learn more about becoming part of an institution inspiring innovations that change the world.A listing of employee benefits is available at: www.cmu.edu/jobs/benefits-at-a-glance/.Carnegie Mellon University is an Equal Opportunity Employer/Disability/Veteran.FT/PT Status: Full Time Salary: 104062 Description:The Pittsburgh Supercomputing Center, a joint research center Carnegie Mellon University and the University of Pittsburgh, was established in 1986, and for over 30 years has provided university, government and industrial researchers with access to several of the most powerful systems for advanced computational research, communications and data storage available to scientists, engineers and scholars nationwide for unclassified research. PSC advances science across the spectrum including artificial intelligence / machine learning, medical imaging, weather modeling, and genomics. The Advanced Systems and Operations group within PSC is responsible for the integration and operations of computational assets central to this pursuit.We are seeking a creative and capable individual to join our highly-experienced Advanced Systems and Operations team as our new Virtualization Infrastructure Engineer. In this role, you will support the research community by developing and maintaining the infrastructure to deploy and maintain fleets of hosts (physical and virtual), containers and services for the variety of project-based resources PSC operates and have a hand in planning new directions. This is an opportunity to join a growing team at the nexus of technology, research, and software development dedicated to helping the scientific community solve challenging and complex problems. We are looking for creative and capable individuals to join our team and continue our part in pushing forward the boundaries of science.Your core responsibilities include:* Designing, implementing, and maintaining virtual hosting platforms at PSC* Designing, implementing, and maintaining container hosting and orchestration platforms for system operations and research computing* Designing, implementing and maintaining a microservice architecture for high performance computing orchestration and emerging (e.g. Functions as a Service) hosting resources* Designing and maintaining OS provisioning on bare-metal systemsMinimum Qualifications:* Bachelor's degree or equivalent in education and experience* A combination of 3 to 5 years of experience in the following areas:* Development, installation, and/or managing virtualization, orchestration, and/or container infrastructure: such as: OpenStack, Singularity, Kubernetes* Experience administering Linux and/or other Unix systems at scale, preferably in support of high-performance computing* Overall Systems Administration and Information Technology Experience* Scripting for systems automation with languages such as Python and BashPreferred Qualifications:* Ability to work in a team to automate systems tasks, stand up and maintain new and existing infrastructure infrastructure* 1-3 years experience using, deploying and maintaining virtualization and/or container hosting platforms* 1-3 years experience virtualization hosting platforms such as OpenStack, VMWare ESX, oVirt* 1-3 years' experience writing and/or extending systems software such as utilities, libraries, plugins* 1-3 years' Linux systems administration experience* Container experience with Singularity or Docker and Kubernetes (or similar)* Familiarity with cloud services such as AWS, GCP, or Azure* Familiarity with OS provisioning software such as OpenStack Ironic, Warewulf, or Puppet Razor.Requirements:* Background checkAre you interested in this opportunity with us? Please apply.More Information:Please visit ""Why Carnegie Mellon"" to learn more about becoming part of an institution inspiring innovations that change the world.A listing of employee benefits is available at: www.cmu.edu/jobs/benefits-at-a-glance/.Carnegie Mellon University is an Equal Opportunity Employer/Disability/Veteran.",4.5,"Carnegie Mellon University
4.5","Pittsburgh, PA","Pittsburgh, PA",1001 to 5000 employees,1900,College / University,Colleges & Universities,Education,$1 to $2 billion (USD),-1
Sr. Data Science Innovation Engineer,-1,"Overview:
This is not your ordinary engineering job! Do you want a startup environment with the stability of large established company? Do you want to work with some of the world’s best data analytics leaders? Does your entrepreneurial mindset drive you to constantly level-up your technical skills? Then we want you!

Alteryx Venture Engineers work with the world’s leading companies every day to develop cutting edge data and analytic solutions to solve real world business problems. From financial services to communications, retail, to healthcare, you’ll work with business partners and data scientists that are on the leading edge of the analytic revolution to create innovative new vertical solutions leveraging Alteryx’s amazing platform of products.
***The company will not provide sponsorship for work visas or other employment authorization for this position***

Responsibilities:
Leverage the existing Alteryx Platform to create new businesses
Quickly code minimum viable products (MVPs) to fully harness and push the limits of existing frameworks
Implement data pipelines, machine learning, visualizations and deliver insights to businesses in an automated manner
Research, evaluate, and commercialize new technologies

Required qualifications:
Bachelor’s degree in Engineering, Computer Science or Data Science related field or equivalent experience
Programming fluency in a minimum of two languages as well as experience with at least one database technology (e.g. SQL, Server, Teradata, Hadoop, etc.)
3-5 years’ experience with HTML5, React / Redux, TypeScript, JavaScript
Experience with Python
Experience with C#/Java
Working knowledge of all Microsoft Windows operating systems and server platforms
Willingness to travel up to 25%
Top-notch interpersonal skills, with excellent written communication to match
Excellent troubleshooting skills (databases, environments, network communications, applications)
Ability to communicate technical concepts to non-technical users
Ability to work in a fast-paced environment, under pressure and prioritize multiple tasks
Proficient English written and verbal communication skills

Brownie Points For:
Experience with cloud based microservice solution architecture
Experience with data replication technology and managing curated data products
Experience with collaborative coding (paired programming, peer reviews, source control)
Experience with building customer facing front ends
Experience using SQL or similar technology, understanding of ODBC, Oracle’s OCI, APIs and connection strings
Experience troubleshooting database connections (SQL Server, Oracle, Teradata, PostgreSQL, and/or Hadoop)
Experience working with Linux environments
Experience maintaining and/or administrating computer hardware and software, file servers, firewalls and/or Active Directory
Demonstrated ability to use in-depth troubleshooting to resolve or workaround customer issues using troubleshooting tools i.e. Wireshark, Fiddler
Computer, Network, and Software certifications
Experience in Data Analysis
Experience with Alteryx Designer / Server Platform
Experience with Visualization Tools and Techniques
#LI-JE1",5.0,"ClearStory Data
5.0","Ann Arbor, MI","Menlo Park, CA",51 to 200 employees,2011,Company - Private,Enterprise Software & Network Solutions,Information Technology,$1 to $5 million (USD),-1
Electrical field Engineer (R&D Engineer 2),"$25K-$76K
(Glassdoor est.)","*What You Will Do****This position will be located at the Nevada National Security Site and requires living in the****Las Vegas, Nevada area.**Put your engineering talents to good use by joining our world-class R&D team! Los Alamos National Laboratory is looking for two exceptional Electrical Field Engineers (R&D Engineer 2) to join our Integrated Weapons Experiments Nevada Operations (J-NV) Group. Our diverse workforce enjoys a collegial work environment focused on creative problem solving, where everyone's opinions and ideas are considered. This is your chance to make a real difference while working on important research directly impacting national security.The Electrical Field Engineer (R&D Engineer 2) will report to the Nevada Operations Group Leader within the Integrated Weapons Experiments Division. The Group is the Nevada National Security Site (NNSS) on-site organization responsible for preparation, fielding, and execution of dynamic high explosive related experiments including sub-critical dynamic experiments involving special nuclear material for the LANL Weapons program as well as other national security customers.**In this position you will** work closely with a diverse group of scientists, engineers, technologists, and technicians on projects and programs for both internal and external customers. Responsibilities include: successful system design, fabrication, implementation, formal documentation and maintenance in the completion of computer-based process control, diagnostics, timing and firing instrumentation systems for high explosive and sub-critical experiments, additional tasks are broad based and include determination of experiment utility and diagnostics testbed requirements, subsystem control and instrumentation for high voltage systems, vacuum operations, personnel access control and safety systems, radiographic machine operations, High Explosive (HE) testing and firing site support.**_What You Need_****Minimum Job Requirements:****Electrical Engineering**Strong backgroundin the fundamentals of electrical engineering, including advanced knowledge of analog and digital electronics, ability to determine electrical power and grounding test bed requirements, experience selecting and integrating diagnostics instrumentation to field hardware and obtaining noise-free dynamic diagnostic data, with a demonstrated history of taking projects from concept to final testing and deployment in an experimental environment.**Tools and Systems**Familiarity with common electronic/electrical test equipment, strong knowledge and creative problem solving utilizing data acquisition systems in an experimental environment and interpreting data, familiarity with computer, HMI or PLC programming languages such as LabView, iFix, C/C++ etc., Operating Systems supporting Software: Word, Excel and Project etc.,**Safety**Demonstrated knowledge of safety issues or potential hazards relating to electrical systems and devices and the use of interlocks and design features to mitigate risks and hazards, including the demonstrated ability to define deliverable and/or lead projects related to safety.**Communication**Demonstrated ability to effectively interact and present technical issues, both verbally and in written form, to an audience with various technical backgrounds, as well as experience providing technical direction, mentoring and coordinating/monitoring the work of others.**Education**Requires a Bachelor's of Science Degree from an Accreditation Board for Engineering and Technology (ABET) accredited engineering college or university program in a relevant engineering program. Advanced degree in Engineering preferred. Focus on Electrical Engineering preferred.**Desired Qualifications:****High Explosive Experiments**Demonstrated knowledge and experience designing, planning and executing high explosives experiments or other complex experiments.**Nuclear Operations**Demonstrated knowledge operating under Device Safety Analyses and Technical Surveillance Requirements.**Management and Oversite**Demonstrated capability estimating project costs and work schedules, ensuring project milestones, and maintaining personnel and fiscal budgets under stringent time constraints.**Note to Applicants:** Along with your resume, please include a detailed cover letter explaining how you meet each of the minimum requirements and any of the desired qualifications.**_Additional Details_****_Directive 206.2_** _-_ _Employment with Triad requires a favorable decision by NNSA indicating employee is suitable under NNSA Supplemental_ _Directive 206.2_ _._ _Please note that this requirement applies only to citizens of the United States. Foreign nationals are subject to a similar requirement under DOE Order 142.3A._**Clearance: Q** (Position will be cleared to this level). Applicants selected will be subject to a Federal background investigation and must meet eligibility requirements* for access to classified matter.* Eligibility requirements: To obtain a clearance, an individual must be at least 18 years of age; U.S. citizenship is required except in very limited circumstances. See DOE Order 472.2 for additional information.**New-Employment Drug Test:** The Laboratory requires successful applicants to complete a new-employment drug test and maintains a substance abuse policy that includes random drug testing.**Regular position:** Term status Laboratory employees applying for regular-status positions are converted to regular status.**Internal Applicants:** Regular appointment employees who have served at least one year of continuous service in their current position are eligible to apply for posted jobs throughout the Laboratory. If an employee has not served the one year of continuous service, they may only apply for Laboratory jobs with the documented approval of their Division Leader.Please refer to Laboratory Policy P701 for applicant eligibility requirements.**Equal Opportunity:** Los Alamos National Laboratory is an equal opportunity employer and supports a diverse and inclusive workforce. All employment practices are based on qualification and merit, without regard to race, color, national origin, ancestry, religion, age, sex, gender identity, sexual orientation or preference, marital status or spousal affiliation, physical or mental disability, medical conditions, pregnancy, status as a protected veteran, genetic information, or citizenship within the limits imposed by federal laws and regulations. The Laboratory is also committed to making our workplace accessible to individuals with disabilities and will provide reasonable accommodations, upon request, for individuals to participate in the application and hiring process. To request such an accommodation, please send an email to applyhelp@lanl.gov or call 1-505-665-4444 option 1.**_Where You Will Work_****This position will be located at the Nevada National Security Site and requires living in the****Las Vegas, Nevada area.**Located in beautiful northern New Mexico, Los Alamos National Laboratory (LANL) is a multidisciplinary research institution engaged in strategic science on behalf of national security. Our generous benefits package includes:+ PPO or High Deductible medical insurance with the same large nationwide network+ Dental and vision insurance+ Free basic life and disability insurance+ Paid maternity and parental leave+ Award-winning 401(k) (6% matching plus 3.5% annually)+ Learning opportunities and tuition assistance+ Flexible schedules and time off (paid sick, vacation, and holidays)+ Onsite gyms and wellness programs+ Extensive relocation packages (outside a 50 mile radius)Appointment TypeRegularRegular**Vacancy Name:** IRC81211 **Organization Name** J-NV/Joint Division Nevada Operations **Minimum Salary** 91800 **Maximum Salary** 151400 **Req ID:** IRC81211 **Category:** Engineering",3.9,"Los Alamos National Laboratory
3.9","Las Vegas, NV","Los Alamos, NM",10000+ employees,1943,Government,Federal Agencies,Government,$500 million to $1 billion (USD),"Lawrence Livermore National Laboratory, Pacific Northwest National Laboratory, Sandia National Laboratories"
Senior Cyber RD Engineer/Scientist with Security Clearance,-1,"Technologies is an employee-owned company with benefits that are unmatched by
most companies in the Dayton OH area. Employee ownership, generous 401K, full
health/dental/life/vision insurance benefits, educational reimbursement,
competitive salaries, interesting assignments and a pleasant work environment
combine to make Radiance Technologies a great place to work and succeed. In
fact, Radiance was named by the Dayton Business Journal as one of the Best
Places to Work in Dayton in 2017, 2018, 2019 and 2020! Radiance Technologies,
supporting multiple technology development efforts, performs advanced research
and development using machine learning, program analysis, optimization,
artificial intelligence (AI), and formal methods for the cybersecurity and
resiliency of cyber-physical systems. Addressing the most urgent national
security challenges, Radiance Technologies is developing fundamentally new
capabilities in cyber-physical systems modeling, vulnerability analysis, and
attack detection and remediation. We are seeking engineers and scientists who
are passionate about technology and security, from the bare metal to the cloud,
and everywhere in between. We are growing rapidly and hiring at all levels and
across disciplines for new and exciting projects. Radiance Technologies is
committed to creating a collaborative learning environment that supports deep
technical understanding and recognizes the contributions and achievements of
all team members. We strive for excellence in technical work that addresses the
most important problems in national security. We believe that each employee has
a unique set of skills, experiences, and perspectives that are essential to
providing our customers with innovative solutions. The skills listed below are
intended to give you a sense for the position. If you see an overlap with your
skills, go ahead and apply! All applicants must be US citizens who are willing
and able to obtain and maintain a security clearance. Role
Work in small research teams to develop innovative software prototypes
Apply a diverse set of advanced technologies, e.g., program analysis (static,
dynamic, symbolic), formal methods, artificial intelligence, and machine
learning, to solve the most difficult cybersecurity challenges
Span the stack or find a niche: from developing tools for the automatic
instrumentation and modification of program binaries, to automation and
planning technologies to coordinate large-scale cyber operations, Radiance
Technologies'''' cyber programs cover a broad territory Required Skills
Strong analytical skills with demonstrated ability to understand and handle
concepts at a fundamental level
Strong programming background
Strong technical writing and oral communication skills
Motivated collaborator and effective communicator to both technical and non-
technical audiences
Ability to work independently or in a team environment
US citizenship with the ability to obtain and maintain security clearance
Required Experience
A BS in Computer Science, Computer Engineering, Electrical Engineering,
Physics, Mathematics, Cybersecurity or related field
Minimum of five (5) years of relevant experience, or minimum of three (3) years
of relevant experience and a higher technical degree (MS or PhD)
Demonstrated ability to design, develop, analyze, modify and evaluate
complicated and difficult technical problems
Demonstrated ability to direct technical efforts within projects or major
phases of significant projects Desired Qualifications The skills/qualifications
listed below are intended to give you a sense for the position. If you see an
overlap with your skills, please go ahead and apply.
Proficiency in programming languages (e.g., C/C++, C#, Java, Python, Assembly,
MATLAB)
Experience with the functional programming paradigm in one or more languages,
such as Rust, Scala, ML, Racket, Common Lisp, Haskell
Understanding of operating system internals, such as memory/process/thread
management
AI, machine learning or autonomy in the context of network operations and
security
Experience with software and hardware emulation tools such as QEMU
Experience with cyber vulnerability discovery
Virtualization software, virtual hardware device development, VHDL/Verilog
simulation
Knowledge of operating system internals including memory/process/thread
management
Linux and/or Windows development with kernel development and/or driver
development
Experience performing static/dynamic/symbolic program analysis
Experience with graph theory as applied to taint tracking and data flows
Compiler intermediate representations (e.g. LLVM) and virtualization
Reverse engineering of software using tools such as IDA, Binary Ninja, or
Ghidra
Mathematical analysis and optimization
Signal processing expertise
Performing research and development in an Agile environment using tools such as
JIRA, Confluence, and Bitbucket
Currently pursing or possesses a master''''s or PhD in relevant areas
TS/SCI Clearance Job Location Dayton, Ohio, United States Position Type Full-
Time/Regular US Citizenship Required Yes Ability to obtain a Security Clearance
Yes Polygraph Required Not Required",3.6,"Radiance Technologies
3.6","Dayton, OH","Huntsville, AL",501 to 1000 employees,1998,Company - Private,Aerospace & Defense,Aerospace & Defense,$100 to $500 million (USD),-1
Senior Software Engineer - iOS (Remote),"$104K-$198K
(Glassdoor est.)","ABOUT HOPPER

At Hopper, we’re on a mission to make booking travel faster, easier, and more transparent. We are leveraging the power that comes from combining massive amounts of data and machine learning to build the world’s fastest-growing travel app -- one that enables our customers to save money and travel more. With over $235M CAD in funding from leading investors in both Canada and the US, Hopper is primed to continue its path toward becoming the go-to way to book travel as the world continues its shift to mobile.

Recognized as the fastest-growing travel app by Forbes and one of the world’s most innovative companies by Fast Company two years in a row, Hopper has been downloaded over 40 million times and has helped travelers plan over 100 million trips and counting. The app has received high praise in the form of mobile accolades such as the Webby Award for Best Travel App of 2019, the Google Play Award for Standout Startup of 2016 and Apple’s App Store Best of 2015.

Take off with us!

THE ROLE
As a Senior Mobile Software Engineer, you will contribute to building a product that impacts millions of users. You will help drive the product direction, making sure we solve the right user problems and find new and innovative ways to delight our customers. You will collaborate with a team of talented engineers, product managers, and data scientists to break down complex problems, and experiment with new ideas very quickly. You will also help design and evolve the mobile architecture to enable teams to run experiments and iterate very quickly.
IN THIS ROLE, YOU WILL:
Collaborate with a team of talented engineers to develop innovative solutions to challenging, impactful technical problems
Quickly prototype new ideas and run experiments to identify features that users love
Create delightful user experiences in our app (iOS)
Help evolve our mobile architecture to consistently improve development efficiency
Influence the technical direction for the team
Influence the strategic direction of the product
A PERFECT CANDIDATE HAS:
4+ years professional experience in full-stack or mobile development
Thorough understanding of Swift and the iOS mobile API
A proven ability to build prototypes and take a data-driven approach to product development, testing and measuring new ideas very quickly
Passion for technical leadership and mentoring
BENEFITS

• Well-funded and proven startup with large ambitions, competitive salary and stock options
• Dynamic and entrepreneurial team where pushing limits is everyday business
• 100% employer paid medical, dental, vision, disability and life insurance plans
• Access to a 401k (US) or Retirement Savings Plan (Canada)",3.5,"Hopper
3.5","Boston, MA","Montreal, Canada",501 to 1000 employees,2007,Company - Private,Travel Agencies,Travel & Tourism,Unknown / Non-Applicable,-1
Sr Software Development Engineer-Fire OS,"$112K-$209K
(Glassdoor est.)","DESCRIPTION


Amazon Lab126 is an inventive research and development company that designs and engineers high-profile consumer electronics. Lab126 began in 2004 as a subsidiary of Amazon.com, Inc., originally creating the best-selling Kindle family of products. Since then, we have produced groundbreaking devices like Fire tablets, Fire TV, Fire phone, and Amazon Echo. What will you help us create?

Work hard. Have fun. Make history.

The Role:

We are looking for a passionate Sr. Software Development Engineer to help develop critical services and machine learning applications that drives the device health improvements release over release. You must be responsive, flexible and able to succeed within an open collaborative peer environment. You will take the lead in designing, prototyping, and building solutions to hard problems in the Amazon ecosystem. You will assist more junior engineers with designs and code structure to improve the functionality, quality, and maintainability of the team’s work. You will work closely with engineers, data scientists, product and project managers, and other service teams to drive development from the concept stage to launch.

We are looking for hard-working and talented Software Development Engineers who have experience building innovative, mission critical, highly optimized applications. You will have an enormous opportunity to make a large impact on the design and architecture of cutting-edge products used every day by people you know. In this role, you will:
· Design, implement and maintain a high-volume, highly available, distributed big data processing system in AWS.
· Work with Data Scientists to design and implement data analytics and machine learning solutions.
· Be a champion for engineering excellence, applying best practices to all stages of the software development process.
BASIC QUALIFICATIONS


· 7+ years of experience in software development of large-scale data infrastructure and distributed systems
· 7+ years of experience in data extraction, transformation, statistical analysis and data modeling
· 7+ years of experience developing enterprise software using Java or Python
PREFERRED QUALIFICATIONS


· Master’s degree in Computer Science, Computer Engineering, Machine Learning, or related field;
· Advanced knowledge in performance, scalability, numerical accuracy, enterprise system architecture
· Experience building solutions using AWS big data and machine learning services
· Experience in applying Data Mining and Machine Learning techniques to solve business problems
· Working knowledge of major database systems and a statistical modeling tools such as R, SAS, SciKit-learn, or TensorFlow
· Ability to communicate complex technical concepts and solutions to all levels of the organization
· Excellent communication and consensus building

Lab126 is part of the Amazon.com, Inc. group of companies and is an Equal Opportunity Employer – Minority / Women / Disability / Veteran / Gender Identity / Sexual Orientation / Age.",3.4,"Lab126
3.4","Sunnyvale, CA","Sunnyvale, CA",1001 to 5000 employees,2004,Subsidiary or Business Segment,Computer Hardware & Software,Information Technology,$50 to $100 million (USD),-1
Automated Test Engineer (QA),"$48K-$84K
(Glassdoor est.)","About the Role
We are seeking a talented and creative Quality Assurance (QA) Engineer to join our Baton Rouge team to design, innovate, and support one of FiscalNote’s range of applications and technology stacks.

In this role you will collaborate closely with a dedicated, cross-functional team - engineers, interaction and product designers, product managers, and scrum masters - working on FiscalNote’s advocacy applications. Utilizing Agile methodologies and incorporating data and user research, you and your team will design, build, and deliver high quality products, features, and services to serve your end-users. Regardless of level, you will be called upon to present your work, communicate with technical and non-technical teammates and executives, and guide and mentor members of your team.

About FiscalNote Engineering
Our team has a wealth of diverse life and career experiences that allow us to think outside of the box and ahead of the curve. You'll get the opportunity to work at an institution pushing the boundaries of open data transparency while collaborating with some of the industry’s brightest engineers and data scientists to devise, nurture, and implement cutting-edge solutions to continuously evolving engineering challenges.

About You:
A successful Automated Test Engineer is:
-Curious
-Ego-less
-Leadership Mindset
-Tenacious
-Adaptable
-Transparent

Success In This Role Includes:
- Creating and executing test plans/cases in multiple environments and cross-browser
- Testing web applications in a series of web browsers and environments
- Designing and creating test conditions and scripts to address business and technical use cases
- Working with scrum team(s) to design, develop, and execute scripts which validate test cases defined within the project’s test plan
- Collaborating with our product, engineering, and client support teams
- Participating in troubleshooting and triaging of issues with different teams to drive towards resolution
- Ensuring the appropriate testing and monitoring tools/technologies are configured accordingly with the test objectives/project team requirements
- Ensuring the test execution results fulfill the defined test objectives
- Tracking and communicating task progress, status, and key performance metrics

What Sets You Apart:
-A working knowledge of manual and automated testing techniques and strategies
-Strong hands-on experience with test automation tools (ex. Selenium, Appium, Postman, etc.)
-Experience with Agile methodologies and practices
-An ability to communicate to technical and non-technical audiences
-Empathy for your peers, stakeholders, and our customers
About Us
FiscalNote is a technology-powered global software data and media company that uses powerful machine learning to provide clients with the right policy information and insights, and at the right time so that they can better navigate market risk and uncertainty and maximize new opportunities.

As the premier hub of domestic and global information for more than 5,000 clients worldwide, FiscalNote’s tools, analysis, news, and award-winning journalism delivers context, clarity, and a competitive edge in a rapidly changing world.

If your background and experience align with the competencies above, we encourage you to apply so that we can review your experience and learn more about how you can add to FiscalNote’s growth and success.

Company Benefits
FiscalNote offers competitive salaries, equity packages, and retirement accounts to ensure we’re all FN owners. We work hard, so our open vacation policy helps us ensure you’re getting the R&R you need. We offer comprehensive health, vision, and dental insurance options supplemented by a flexible spending account (FSA). We have a slew of other benefits which you can check out at careers.FiscalNote.com.

FiscalNote values diversity. We are committed to equal opportunities and creating an inclusive environment for all our employees. We welcome applicants regardless of ethnic origin, national origin, gender, race, religious beliefs, disability, sexual orientation or age. FiscalNote is an EEOC employer.

FiscalNote uses E-Verify to confirm the employment eligibility of all new employees. To learn more about E-Verify, including your rights and responsibilities, please visit www.DHS.gov/E-Verify.",3.9,"FiscalNote
3.9","Baton Rouge, LA","Washington, DC",201 to 500 employees,2013,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Senior Software Engineer,"$99K-$124K
(Glassdoor est.)","About Us

Ready to write the best chapter of your career? XSELL Technologies is an artificial intelligence company focused on increasing sales. Our cloud-based machine learning engine uses predictive analytics and natural language processing to equip sales professionals with the best real-time responses, driving improved conversion rates and customer experiences. We pride ourselves on our high performing, collaborative culture. We are passionate about our product, our clients, and our industry leading results.

XSELL is currently seeking a Sr. Software Engineer to serve as a key member of our development team.. This role will work within the SAFe Agile framework of continuous delivery, provide leadership and guidance to junior developers, and be a critical resource for our growing development staff.

Job Description
Design and implement full stack applications/services/tools/script for pipelines running in AWS and other cloud services
Work closely with technical product managers and data scientists to design, implement, test highly scalable automated solutions.
Participate in design reviews, code reviews of your work and the work of your peer engineers.
Participate in architecture and design efforts with the team members and/or across multiple teams.
Automate deployment processes and provide adequate test coverage by utilizing test framework
Mentor junior engineers to develop quality code and review the design/code
Respond to internal customers issue requests
Background & Qualifications

In order to be successful, you will need the following:
Bachelor’s Degree
5+ years of software development experience
2+ years of development experience with Ruby on Rails
IT Project and Management principles and techniques (SAFe Agile)
Backend: Ruby on Rails, Sidekiq, Python and Flask
Frontend: VueJS, jQuery
Database: PostgreSQL, Redis
Infrastructure: AWS, Linux
Deployment: Capistrano, Ansible
Capable of working in a fast-paced environment
Ability to lead the development of a product or large project
Ability to create project specs and identify roadblocks before writing code
Set coding standards and creates standard processes
Focused on writing clean, readable, and testable code
We provide competitive compensation, generous benefits, and a professional atmosphere. XSELL fosters an entrepreneurial, results driven work environment where you will have the opportunity to be part of a collaborative, inclusive team and be able to grow and develop your professional career.

XSELL Technologies is an Equal Employment Opportunity Employer and all employment decisions shall be made without regard to age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status or any other basis as protected by federal, state, or local law.",3.8,"XSELL Technologies
3.8","Chicago, IL","Chicago, IL",51 to 200 employees,2014,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Senior Product Engineer,-1,"Job Description
Our technologists design, code, test and deploy software core to business operations. These include software for building predictive models, deploying them into production and delivering their results to clients.

We are looking for teammates who have strong experience in shipping scalable software solutions working with large data and throughput volumes. Our expectation is for you to be able to contribute for the full development lifecycle from data to pipelines to core system functions and to support our colleagues in Data Science and Research teams. Supporting and working with Machine Learning and Quantitative Research teams or products is a strong plus

We’re cloud-native and are seeking a fantastic developer with 5+ years in developing large-scale systems. This role will give you ample visibility across the whole organization and expose you to a vast range of projects, from building and maintaining core technologies, migrating data with the research platform, producing and delivering research model results to clients. You’re a naturally curious, detail-oriented person who enjoys working in a highly collaborative environment. You’re also able to communicate complex concepts using effective and simple terms and are open to the possibility of helping build the rest of the software development team as well as mentoring them, if the chance arises.

Senior Product Engineer will support one or more of our products using data ingestion and manipulation (ETL, SQL, No-SQL, Spark, Airflow, Python, etc), BI and Dashboarding, use of our platform and products, and whatever else Product and Research need to be successful. This is a key new role to support us as we go to market with our predictive models.

In this role, you will primarily be using Python and SQL with hiring manager happy to speak with candidates who have experience with Python, or other languages.
Quick Facts
HQ in NYC with office in Budapest Hungary and co-workers worldwide
Founded in 2018
Talented team & creative environment
Skill Requirements (TLDR):

5+ years of professional work experience in data analytics related functions. You will be experienced in writing features and production-level code but feel that there is so much more to learn. We hope to be the place where you learn from our senior architects and we learn together all the new things the industry is throwing at us.
Strong working knowledge of handling large amount of data (structured / unstructured) through SQL, T-SQL or P-SQL or NoSQL. This position requires being comfortable working with data and if you have not been doing some sort of SQL before, it is probably not for you.
Hands on experience with data warehousing / data lake procedures with proven ability for ETL scripting, including integration of data from multiple data sources and automation of data processes. Your role will be responsible for making sure data for one or more of our products is in good shape - automation and coding the workflows will be key.
Experience in data wrangling using python. Python is our shared language. We use others as well, but it will be hard to fit in without python to start.
Experience working with Data Scientists and facilitating production-grade Machine Learning models through ETL procedures and other data preparation tasks. This role is the technical counterpart to product owners and researchers so working with Research and Product as business customers is expected.
Some experience with cloud architecture including Amazon Web Services (AWS) is strongly desired. We are a cloud-native shop and cloud experience is necessary although cloud vendor is not.
Some experience with UI driven data blending tools (e.g. Alteryx, SAS Enterprise Guide, Knime, Pentaho). We need to prototype a lot and these tools help us get there quickly.
Some experience with BI tools (e.g. Tableau, Power BI, Qlik, Spotfire). Our internal and external clients
Knowledge of basic concepts and approaches in Machine Learning. The result of our work are predictive models using ML. Knowing how the sausage is made is very helpful.
Experience in any of the following industries is an advantage: Retail, FMCG, Healthcare
Confident communicator, comfortable leading discussions with non-technical team members and clients
Intellectually curious and enjoys creative problem-solving
Ability to thrive in a flexible, non-hierarchical and collaborative environment
Comfort with ambiguity associated with fast paced project work",4.9,"ubergig
4.9","New York, NY","New York, NY",1 to 50 employees,2009,Company - Private,Building & Personnel Services,Business Services,$5 to $10 million (USD),-1
Signal Processing and Machine Learning Engineer - ATAS with Security Clearance,-1,"Job Description The Aerospace Transportation and Advanced Systems Laboratory (ATAS), Aerospace and Acoustics Technologies Division (AATD) is searching for a Signal Processing and Machine Learning engineer who can think outside of the box and is looking for a dynamic and challenging work environment. The candidate will support multiple opportunities in the Biosensing and Signal Analytics Branch (BSAB), as it relates to physiological sensing, biomedical signal processing, and machine learning, communications, tactical sensing, and related tactical applications. The role of this position is to apply technical skills to support the development of software and hardware in support of ongoing projects and support the development of new research opportunities. Job Duties The ideal candidate will display skills and an educational background in electrical engineering and in one or more of the following areas: signal processing, statistical signal processing, machine learning, data processing, array processing, and beamforming, acoustics, and related topics. The desired candidate should be familiar with the application of digital signal processing and machine learning to data analysis and exploration and algorithm development using modern programming techniques. Moreover, candidates should also possess familiarity with data measurement techniques, data acquisition systems and transducers, have familiarity with a laboratory environment, have excellent communication skills and be familiar with the peer-review publishing and review process. Travel Requirements 10% - 25% travel Education & Length of Experience Research Engineer/Scientist I * A Bachelor's degree in Electrical and Computer Engineering, Electronic Engineering, Computer Science, Mechanical Engineering, Aerospace Engineering, or a related field of study. Research Engineer/Scientist II * A Master's degree in Electrical and Computer Engineering, Electronic Engineering, Computer Science, Mechanical Engineering, Aerospace Engineering, or a related field of study and three (3) years of relevant full-time experience after completion of that degree, * A Master's degree in Electrical and Computer Engineering, Electronic Engineering, Computer Science, Mechanical Engineering, Aerospace Engineering, or a related field of study and five (5) years of relevant full-time experience after completion of a Bachelor's degree, or * A Doctoral degree in Electrical and Computer Engineering, Electronic Engineering, Computer Science, Mechanical Engineering, Aerospace Engineering, or a related field of study. Required Minimum Qualifications * Candidates currently enrolled in an accredited Bachelor's degree program relevant to this position will be considered. Candidate must have a graduation date of no later than December 2020 * Experience in signal processing and machine learning algorithms utilized for applications * Programming experience in Matlab, Python, C, and C++ * Experience with Linux and Windows and open-source software tools * Knowledgeable in version control software such as GIT * Experience with the acquisition and analysis of measured data * Good verbal and written communication skills * Self-starter and ability to work in a team environment Preferred Qualifications * A Master or Ph.D. in Electrical Engineering or related fields * Active Secret Clearance * Record of publications and technical seminar presentations * Experience in applied ML to time series analysis and development of predictive models * Knowledge of array signal processing with emphasis on acoustic applications and infrasound * Experience in time-frequency analysis and wavelets * Experience with one or more of the following Matlab Toolboxes: Signal Processing, Statistics and Machine Learning, Phased Array, Wavelets * Experience managing research projects, making technical presentations, and report writing U.S. Citizenship Requirements Due to our research contracts with the US federal government, candidates for this position are required to be US Citizens. Clearance Type Required Ability to obtain Secret Clearance upon hire Diversity & Inclusion Diversity & Inclusion (D&I) at Georgia Tech Research Institute aims to enhance the Institute's mission of solving the world's most complex technical problems by creating a workforce with a shared appreciation for diversity, raising awareness around inclusiveness, and fostering a sense of belonging and appreciation for all members of our community. Equal Employment Opportunity Georgia Tech Research Institute is an Equal Opportunity Employer of individuals with disabilities and protected veterans and actively seeks diversity among its employees. Equal Employment Opportunity is the Law . Posted: 06/15/2020 Closes: 09/15/2020 Back Submit Resume",3.6,"The Georgia Tech Research Institute
3.6","Smyrna, GA","Atlanta, GA",1001 to 5000 employees,1943,Subsidiary or Business Segment,Research & Development,Business Services,$100 to $500 million (USD),"MIT Lincoln Laboratory, Johns Hopkins University Applied Physics Laboratory"
"Senior Software Engineer, Data (Remote)","$91K-$178K
(Glassdoor est.)","Develop a state-of-the-art product. Make sense of the future. Use data to grow your business.

If you are a coding fanatic and passionate about programming, we want you to help us make a huge impact. Our clients love our product and are thirsty for more!

At CB Insights we build products that help clients make sense of the future and drive their businesses forward using data. Our system retrieves large amounts of structured and unstructured data and uses scientific methods to extract knowledge and insights from that data. We present those analytics through a sophisticated, dynamic user interface which enables our clients to find answers to their most important questions.

Your main tasks:

Senior Data Engineer will be the main engineering resource within our data science team. Reporting to the R&D Team Lead, you will work alongside data scientists on cutting-edge problems. The goal is to build efficient and reusable data and machine learning pipelines to enable rapid R&D work, make it easy to productionize the research, quickly adopt new data sources, and maintain the best software engineering practices. The data engineer will collaborate with software engineers from other teams and influence the company's engineering strategy.

You will join a small and very motivated team doing interesting and unique work in NLP and knowledge discovery. You'll get access to rich and interesting data and a chance to build cutting-edge data processing pipelines. Here is your chance to be all you can be. This position is critical to scaling the data science team. You'll be responsible for enabling data science in a truly data-centric company.

What you bring to the table:
4+ years professional experience in Python. Familiarity with Go is a plus
Relational database proficiency (e.g. Redshift, MySQL, Aurora)
Experience using Spark, Sqoop, AWS services (Spectrum, Glue) and other related tools in the big data ecosystem
Knowledgeable of data modeling, data storage techniques, data warehousing and general data architecture
Experience with engineering data pipelines to capture, store and process unstructured data
Proficiency developing in a Mac/Linux environment
Professional experience working remote or telecommuting
The Perks:
Amazing culture: Happy, Helpful, Humble, Hungry. Learn more here
A newsletter that 600k people follow: Sign up here.
Be Healthy: Health with HSA and FSA options, dental, and vision insurance along with unlimited/take what you need sick day policy
Plan for the future: 401k with up to 4% match
Continued Learning: $1,000 yearly continuing education stipend
Rest and Relax: Competitive vacation and holiday plans
Refuel: Daily lunch stipend, unlimited snacks/coffee
We are dedicated to adding new perspectives to the team and encourage everyone to apply if your experience is close to what we are looking for.

Equal Opportunity Employer: CB Insights is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status.

If you know someone who'd be perfect for the role,
submit here and you'll be eligible for $5,000!

#LI-FR1",4.1,"CB Insights
4.1","New York, NY","New York, NY",201 to 500 employees,2009,Company - Private,Enterprise Software & Network Solutions,Information Technology,$25 to $50 million (USD),-1
Enterprise Data Engineer,-1,"Data Engineers are the architects of the next generation platforms that control how we interact with and consumes information. They own the entire data pipeline starting with how we ingest data from the outside world, through the transformation of data into actionable insights, and finally the interfaces and APIs that our analysts and portfolio managers use to monetize that information. Throughout that process our data engineers work closely with investment professionals and researchers to design systems that answer some of the most challenging questions in the hedge fund industry.

Enterprise Data Engineers build pipelines that support datasets used by all investment teams and strategies across the company. They manage the firms most critical data sets and focus on applying software development best practices to solve complex data challenges. The expectation is that the data engineer has sound programming skills, strong business acumen, and a strong interest in finance.

Key Responsibilities
Develop solutions that enable internal analysts to efficiently extract insights from data. This includes owning the ingestion (web scrapes, S3/FTP sync, bespoke processes), transformations (Python, Perl) and interface (API, schema design, events, etc.)
Build tooling and automation around data pipelines that improve the efficiency, quality and resiliency of our data platform
Partner with internal analysts, quants and data scientists to design, develop, test and deploy solutions that answer fundamental questions about financial markets.
Take on an entrepreneurial mentality by building and selling your own ideas. We work in an evolving space and we expect you to help design our evolution by challenging the status quo and independently identifying opportunities to improve the entire data organization.
Required Skills
A passion for working with data and developing software to address data processing challenges
Proficiency with Python, C++, Java or equivalent
Proficiency with RDBMS, NoSQL, distributed compute platforms such as Spark, Dask or Hadoop
Prior experience building data pipelines from structured or unstructured data preferably including web crawlers
Prior work developing BI tooling and/or application development for data analytics
Advanced technical communication skills
Working knowledge of statistics, predictive analytics or machine learning techniques
Strong business acumen with prior experience in investment research or direct exposure to product or data science teams AND passionate about using data for investment decisions",3.2,"Q Systems
3.2","New York, NY","Iselin, NJ",1 to 50 employees,-1,Company - Private,"Health, Beauty, & Fitness",Consumer Services,Less than $1 million (USD),-1
"Senior Software Engineer (AI - Human interfaces), Machine Assisted Cognition",-1,"At Toyota Research Institute (TRI), we’re working to build a future where everyone has the freedom to move, engage, and explore with a focus on reducing vehicle collisions, injuries, and fatalities. Join us in our mission to improve the quality of human life through advances in artificial intelligence, automated driving, robotics, and materials science. We’re dedicated to building a world of “mobility for all” where everyone, regardless of age or ability, can live in harmony with technology to enjoy a better life. Through innovations in AI, we’ll help…

- Develop vehicles incapable of causing a crash, regardless of the actions of the driver.
- Develop technology for vehicles and robots to help people enjoy new levels of independence, access, and mobility.
- Bring advanced mobility technology to market faster.
- Discover new materials that will make batteries and hydrogen fuel cells smaller, lighter, less expensive and more powerful.
- Develop human-centered AI systems to augment (not replace) human decision making to increase the quality of decisions (e.g. mitigate cognitive biases) and/or to facilitate faster innovation cycles.

Our work is guided by a dedication to safety – in both what we research and how we perform our research our goal is to benefit society. As a subsidiary of Toyota, TRI is fueled by a diverse and inclusive community of people who carry invaluable leadership, experience, and ideas from industry-leading companies. Over half of our technical team carries PhD degrees. We’re continually searching for the world’s best talent ‒ people who are ready to define the new world of mobility with us!

We strive to build a company that helps our people thrive, achieve work-life balance, and bring their best selves to work. At TRI, you will have the opportunity to enjoy the best of both worlds ‒ a fun environment with forward-thinking people who enjoy solving tough problems and the financial backing to successfully achieve our goals. Come work with TRI if you’re interested in transforming mobility through designing technology for safer cars, enabling the elderly to age in place, or designing alternative fuel sources. Start your impossible with us.

TRI’s Machine Assisted Cognition team is developing AI systems to augment (not replace) human decision making. In particular, we are interested in advancing the intersection between behavioral science, machine learning and causal inference to increase the quality of human decisions (e.g. mitigate cognitive biases) and / or to facilitate faster innovation cycles. We are looking for a Senior Software Engineer with deep expertise in UI and UX development to join this exciting new endeavor to collaborate cross-functionally with machine learning and causal inference experts, behavioral scientists, designers, and user researchers.
Responsibilities:
Lead the UI / UX design and Human - AI interface software development for the machine-assisted cognition (MAC) team.
Collaborate cross-functionally with machine learning and causal inference experts, behavioral scientists, user researchers, and university partners to design and build novel AIs to augment human decision making.
Increasing quality of predictions, judgments, and decisions by (a) reducing/neutralizing cognitive biases, (b) ensuring fitness, (c) ensuring ethics
Speeding up predictions, judgments, and decisions
Scaling up to more complex cognitive tasks and larger groups while countering the tendency of groups to be risk-averse.
Promote UI / UX and software engineering best practices. Mentor and advise others.
Qualifications:
Deep expertise in UI development, user experience design and data visualization.
Advanced knowledge of front-end development (JavaScript, CSS, HTML5). Experience with visualization frameworks such as Angular.js, WebGL, d3.js, React.
Proficiency developing in a general-purpose software programming language (e.g. Python, Go, or Java).
Experience in providing technical leadership and mentorship.
Strong track record of driving and executing complex, open-ended, multi-functional projects.
Strong interpersonal skills. Phenomenal teammate.
Appetite to learn across functions.
Please reference this Candidate Privacy Notice to inform you of the categories of personal information that we collect from individuals who inquire about and/or apply to work for Toyota Research Institute, Inc. or its subsidiaries, including Toyota A.I. Ventures GP, L.P., and the purposes for which we use such personal information.

TRI provides Equal Employment Opportunity without regard to the applicant's race, color, creed, gender, gender identity or expression, sexual orientation, national origin, age, physical or mental disability, medical condition, religion, marital status, genetic information, veteran status, or any other status protected under federal, state or local laws.",3.5,"Toyota Research Institute
3.5","Los Altos, CA","Los Altos, CA",201 to 500 employees,2016,Subsidiary or Business Segment,Research & Development,Business Services,Unknown / Non-Applicable,Waymo
Senior Machine Learning Engineer,"$147K-$169K
(Glassdoor est.)","The machine learning engineering team is developing the brain of the BounceX communication and personalization platform. As a Senior Machine Learning Engineer, you will be working with a team of Data Engineers and Data Scientists in order to build out our next-generation platform. You will be utilizing cutting edge technologies such as Spark MLLib, Tensorflow, Google AI Platform, and Cloud Dataproc to build the required ML pipelines to enhance our customer's experience.

Responsibilities:
Build & maintain production ready ML pipelines
Build & maintain a production-ready experimentation platform to run models in parallel and A/B test
Prepare and preprocess data in collaboration with the data engineering team
Qualifications:
Deep understanding of ML problems such as classification, clustering, anomaly detection, association rules, deep learning, and recommendation
Deep understanding of test analysis
Previous work with Spark MLlib
Previous work with TensorFlow
B.S. or M.S in Computer Science
Nice to have:
Experience with Google Cloud BigQuery
Experience with Google Cloud BigTable
BounceX is proud to be an equal opportunity workplace. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status.

JOIN US ON OUR MISSION
BounceX is an international marketing technology solution that brings a ""logged-in"" experience to logged-out website visitors across all their devices. A category leader in device identity resolution, BounceX helps companies like Uniqlo, HelloFresh and Tribune Interactive orchestrate real-time, multichannel marketing programs customized for the individual behind each device. They're best known for their impact on triggered email performance and website personalization.

Having raised over $44.9 million in funding from proven firms like Battery Ventures, Cross Creek Advisors and Primary Ventures, BounceX was named the Fastest Growing Software Company in America by Inc Magazine. With headquarters in New York and London, BounceX has been recognized by Glassdoor and Crain's for its exceptional culture and being one of the top places to work in the country. The company recently signed both the White House Equal Pay Pledge and the United Nations Women's Empowerment Pledge and continues to set the bar as a pioneer in technology innovation and workplace inclusion initiatives.

What bonds our community together is our commitment to 5 Core Values:
Come Hungry
Carry Each Other
Drive Undeniable Performance
Respect People, Privacy, Ideas
Bounce Back
Come join us on our mission.",4.1,"Bounce Exchange
4.1","New York, NY","New York, NY",201 to 500 employees,2012,Company - Private,Advertising & Marketing,Business Services,Unknown / Non-Applicable,-1
Data Engineer,-1,"Title Data Engineer
Location - Allentown, PA 18101 (The ideal candidate will be able to be onsite after COVID)
Duration 1+ Year

As a Data Engineer, you will work closely with a multidisciplinary Agile team to build high quality data pipelines driving analytic solutions. These solutions will generate insights from our connected data, enabling advance the data-driven decision-making capabilities of our enterprise. This role requires deep understanding of data architecture, data engineering, data analysis, reporting, and a basic understanding of data science techniques and workflows. The ideal candidate is a skilled data / software engineer with experience creating data products supporting analytic solutions. The ideal candidate is a skilled data / software engineer with experience creating data products supporting analytic solutions. They are an Agile learner, possess strong problem-solving skills, work as part of a technical, cross functional analytics team, and want to Solve complex data problems and deliver the insights to enable analytics strategy.
Responsibilities
Design, develop, optimize, and maintain data architecture and pipelines that adhere to ETL principles and business goals
Solve complex data problems to deliver insights that helps our business to achieve their goals
Create data products for analytics and data scientist team members to improve their productivity
Advise, consult, mentor and coach other data and analytic professionals on data standards and practices
Foster a culture of sharing, re-use, design for scale stability, and operational efficiency of data and analytical solutions
Lead the evaluation, implementation and deployment of emerging tools and process for analytic data engineering in order to improve our productivity as a team
Develop and deliver communication and education plans on analytic data engineering capabilities, standards, and processes
Partner with business analysts and solutions architects to develop technical architectures for strategic enterprise projects and initiatives.
Learn about machine learning, data science, computer vision, artificial intelligence, statistics, and/or applied mathematics
Skills
Bachelor's degree required; Computer Science, MIS, or Engineering preferred
5 years of experience working in data engineering or architecture role, 7+ preferred
Expertise in SQL and data analysis and experience with at least one programming language (Python/PySpark or Scala preferred)
Experience developing and maintaining data warehouses in big data solutions
Experience with developing solutions on cloud computing services and infrastructure in the data and analytics space (preferred)
Database development experience using Hadoop or BigQuery and experience with a variety of relational, NoSQL, and cloud data lake technologies
Worked with BI tools such as Tableau, Power BI, Looker, Shiny
Conceptual knowledge of data and analytics, such as dimensional modeling, ETL, reporting tools, data governance, data warehousing, structured and unstructured data.
Big Data Development experience using Hive, Impala, Spark and familiarity with Kafka (Preferred)
Familiarity with the Linux operating system (Preferred)
Exposure to machine learning, data science, computer vision, artificial intelligence, statistics, and/or applied mathematics
Passionate about Agile software processes, data-driven development, reliability, and experimentation
Experience working on a collaborative Agile product team
Self-motivated with strong problem-solving and learning skills
Flexibility to changes in work direction as the project develops
Excellent communication, listening, and influencing skills
Demonstrated strong number sense, intellectually curious and willing to adjust position based on additional information
Strong work ethic; ability to work at an abstract level and gain consensus
#LI-FRESH",3.9,"TalentBurst, Inc.
3.9","Allentown, PA","Natick, MA",501 to 1000 employees,2002,Company - Private,IT Services,Information Technology,$50 to $100 million (USD),"TEKsystems, Collabera, Artech Information Systems"
Senior Computer Vision & Deep Learning Engineer - Autonomous Vehicles,"$169K-$286K
(Glassdoor est.)","We are now looking for a Senior Computer Vision & Deep Learning Engineer with an emphasis in light source detection/automatic high-beam application.

Intelligent machines powered by Artificial Intelligence computers that can learn, reason and interact with people are no longer science fiction. Today, a self-driving car powered by AI can meander through a country road at night and find its way. An AI-powered robot can learn motor skills through trial and error — this is truly an extraordinary time and the era of AI has begun. Image recognition and speech recognition — GPU Deep Learning has provided the foundation for machines to learn, perceive, reason and solve problems. The GPU started out as the engine for simulating human creativity, conjuring up the amazing virtual worlds of video games and Hollywood films.

Now, NVIDIA's GPU runs Deep Learning algorithms, simulating human intelligence, and acts as the brain of computers, robots and self-driving cars that can perceive and understand the world. Just as human imagination and intelligence are linked, computer graphics and AI come together in our architecture. Two modes of the human brain, two modes of the GPU. This may explain why NVIDIA GPUs are used broadly for Deep Learning, and NVIDIA is increasingly known as “the AI computing company.” Come, join our Deep Learning team, where you can help build the real-time, cost-effective computing platform driving our success in this exciting and quickly growing field. We are seeking the best Computer Vision Scientists with background in the following, to partner with system software engineers to build the next generation of vision algorithms.

What you’ll be doing:
Develop computer vision, visual geometry and Deep Learning algorithms for autonomous cars, mapping and localization - Focused on light source detection/classification/automatic high-beam applications
Experiment with new or early stage algorithms
Solidify existing algorithms working with large amounts of real data
Maximize the quality of algorithmic results
Partner with system software engineering specialists to build shipping industrial strength codes
Minimize inefficiencies and latency to maximize performance
What we need to see:
BS or MS in Computer Science, Computer Engineering or Electrical Engineering
8+ years of relevant experience
Experience in light source detection/classification/automatic high-beam applications
Experience in embedded Computer Vision, SIMD and parallel computing, with a deep understanding of CV algorithms and multimedia image formats
Fluent in C & C++, as well as experience in CUDA
Efficient in SW development in Linux, with a deep understanding about mobile operating system e.g. Linux, Android
Good knowledge in SoCs e.g. Tegra, with efficient use of Software development tools like debuggers
Outstanding written and verbal interpersonal skills in English, as well as dedication to the work
Good organization skills, with a logical approach to problem solving, good time management and task prioritization skills
Ways to stand out from the crowd:
Experience with visual geometry and Deep Learning in a shipping product context
Background in light source detection/classification/automatic high-beam applications in a shipping product context
Experience developing real-time Image Processing and/or Computer Vision systems
Software development on embedded platforms or large scale cloud services
Experience with GPGPU programming (CUDA and OpenGL)
NVIDIA is committed to fostering a diverse work environment and proud to be an equal opportunity employer. As we highly value diversity in our current and future employees, we do not discriminate (including in our hiring and promotion practices) on the basis of race, religion, color, national origin, gender, gender expression , sexual orientation, age, marital status, veteran status, disability status or any other characteristic protected by law.#deeplearning",4.6,"NVIDIA
4.6","Santa Clara, CA","Santa Clara, CA",10000+ employees,1993,Company - Public,Computer Hardware & Software,Information Technology,$5 to $10 billion (USD),-1
Senior Software Engineer,"$107K-$209K
(Glassdoor est.)","Bluecore is a marketing technology company that's reimagining how the world's fastest growing retail brands transform casual shoppers into lifetime customers. Through our patented retail data model and the recent release of Bluecore Communicate and Bluecore Site, we replace manual processes with an intelligent, AI-driven workflow. We are credited with doubling email revenue, and increasing customer retention for more than 400 brands, including Express, Tommy Hilfiger, The North Face, Teleflora, and Bass Pro Shops. We have been recognized as one of the Best Places to Work by Glassdoor and ranked No. 241 on the Inc. 500 List, the most prestigious ranking of the nation's fastest-growing private companies.We are looking for Senior Software Engineers to work across our engineering teams to build web applications and backend systems that perform at scale. The ideal candidate is adept at writing robust, extensible, and efficient code and has a knack for solving complex problems with simple solutions. Our stack consists primarily of Python and Golang on the backend and React on the frontend. We see technology as a means to solving problems and getting things done and thus prioritize talent over existing skill set. We use Google Cloud hosted infrastructure services including Google App Engine, Kubernetes, BigQuery, and Cloud SQL. Our culture emphasizes making good tradeoffs, working as a team, and leaving your ego at the door.Responsibilities* Design, architect, and build performant, reliable, high-quality systems at scale.* Own projects end-to-end, including gathering requirements, designing, implementing, testing, deploying, and maintaining systems.* Work cross-functionally with product managers, data scientists, and engineers to deliver high quality products.* Coaching and growing junior developers through mentorship and leading by exampleRequirements* 5-8 years of relevant professional experience* B.E./B.S. in one of the following departments (i) Computer Science, (ii) Computer Engineering, (iii) Information Sciences, (iv) Electronics, (v) Mathematics or relevant field/equivalent work experience* Significant programming expertise.* Experience with languages such as Python, C++, Java, or Go is a plus.* Track record of delivering high quality products* Passion for learning new technologies and developing skills* Knack for getting things done, whether it be independently or in a team* Experience/Passion for exploring diverse fields such as Machine Learning, AI, microservice architectureBenefits:Highly competitive compensation package including salary and equity as well as the opportunity to work for one of the fastest growing marketing technology companies.* Comprehensive medical, dental, and vision insurance* 401(k) plan* Monthly discretionary reimbursement towards fitness, home office and/or Learning and Development opportunities* Generous Parental Leave & flexible vacation policyAt Bluecore we believe in fostering an inclusive environment in which employees feel encouraged to share their unique perspectives, leverage their strengths, and act authentically. We know that diverse teams are strong teams, and welcome those from all backgrounds and varying experiences.Bluecore is a proud equal opportunity employer. We are committed to fair hiring practices and to creating a welcoming environment for all team members. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, disability, age, familial status or veteran status.",4.3,"Bluecore
4.3","New York, NY","New York, NY",51 to 200 employees,2013,Company - Private,Internet,Information Technology,$25 to $50 million (USD),-1
Data Engineer â All Levels,-1,"At DataSync Technologies, our data engineering professionals touch every area of our company. Their insights drive our decisions and their innovations fuel projects. When you join our team of data experts, youâre helping DataSyncâs customers make better, smarter and faster decisions every day. See how you can help us solve some our customerâs most challenging data problems while you grow your skills and build your own future.

Job Description

DataSync Technologies is seeking Data Engineers to support a mission critical program within the Intelligence Community.

ONLY CANDIDATES WITH ACTIVE GOVERNMENT SECURITY CLEARANCES AND APPROPRIATE POLY WILL BE CONSIDERED. MUST BE A U.S. CITIZEN.

Responsibilities will vary by specific data engineer role â Data Architect, Data Scientist, Database Engineer, Data Governance to include the following:
Design and develop methods, processes, and systems to consolidate and analyze structured and unstructured data from diverse sources including âœbig dataâ sources.
Develop and use advanced software programs, algorithms, query techniques, model complex business problems, and automated processes to cleanse, integrate, and evaluate datasets.
Analyze the requirements and evaluate technologies for data science capabilities including one or more of the following: Natural Language Processing, Machine Learning, predictive modeling, statistical analysis and hypothesis testing.
Develop information tools, algorithms, dashboards, and queries to monitor and improve business performance. Maintain awareness of emerging analytics and big-data technologies.
Designs, implement, and maintain standard data interfaces for data ingest including Extract/Transform/Load (ETL) methodology and implementation, APIs, RESTful Web Services, data quality, and data cleansing.
Provide data services, data administration, data management, and âœBig Dataâ support in client/server, virtual machine, Hadoop, and cloud infrastructure environment and/or migrations between these environments.
Database installation, configuration, and the upgrading of database server software and related products, backup and recovery policies and procedures, database implementation, security, optimization, multi-domain operation, and performance management.
Hadoop, cloud, and other technologies associated with data storage, processing, management, and use.
The migration/transition of database capability into cloud based technologies and/or creation of interfaces between classic relational databases and key indexes to cloud based columnar databases and map reduce index capabilities.
Preferred Qualifications (All not required):
Databases/Data Stores: Oracle, MySQL, HIVE, HBASE, and HDFS
Frameworks: Hadoop, Rails, JavaScript Frameworks, SOA/WebServices, JSP
Indexing: SOLR and Lucine
Development/Scripting Languages: JAVA (J2EE), Python, Ruby, JavaScript, MapReduce, Pig, XML, SQL, JAQL, HTML, CSS, XML, BASH, ANT, and Perl
________________________

What makes DataSync Technologies different?

Leadership Training: We provide employees with a variety of learning opportunities, including access to exclusive classes, professional growth training and more.

Feedback & Mentoring: We believe in talkingâoften. So we have one-on-one feedback sessions for every employee.

Community Service: We believe in helping the community where we work. DataSync and its employees donate time and services on a regular basis to local military charities. We believe in helping, both inside and outside of the office.

Social Events: We plan social events on a regular basis to help our employees relax and socialize so we get to know one another outside of our job titles.

Equal Employment Opportunity
DataSync is an EEO and Affirmative Action Employer of Female/Minorities/Veterans/Individuals with Disabilities. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.

Information about Equal Employment Opportunity (EEO) and Employee Polygraph Act (EPPA) provisions in addition to other Federal labor laws can be found at the Department of Labor's Website.

DataSync is committed to providing veteran employment opportunities to our service men and women.

Find out more about DataSync on Social Media.
www.datasynctech.com
www.facebook.com/DatasyncTechnologies
www.twitter.com/Jobs at DataSync (@DatasyncJobs)
www.twitter.com/datasynctech
#datasynctech on Instagram
Interested in Joining Our Team? - Check out this YouTube video!
#CJ

Powered by JazzHR",5.0,"DataSync Technologies, Inc
5.0","Reston, VA","Reston, VA",1 to 50 employees,2003,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Software Engineer - Defense & Intelligence,"$46K-$100K
(Glassdoor est.)","Software Engineer

Work Location is Springfield, VA

Home Base office is Arlington, VA

Elder Research Inc. is a recognized leader in predictive analytics and machine learning. We pride ourselves in our ability to find creative, cutting edge solutions to real-world problems. We are looking for innovative and inquisitive self-starters who enjoy translating complex models into actionable solutions that deliver real value for our clients. We have multiple openings in the Baltimore-Washington Metropolitan area for Software Engineers to support our Defense& Intelligence business.

As a Software Engineer in the Defense& Intelligence Business Unit, you will join a functional team of accomplished Data Scientists and Software Engineers that delivers data science solutions to address the toughest national security challenges. You will work closely with data scientists, business consultants, other software engineers, and the system users to create and deploy applications that help the customer make actionable, data-driven decisions. Candidates should have the ability and the willingness to tailor applications to a client’s specific business goals using an iterative methodology.

The Software Engineer designs, develops, tests, deploys, documents, maintains and enhances complex and diverse software systems based upon documented requirements. These systems might include, but are not limited to, processing, intensive analytics, novel algorithm development, manipulation of extremely large data sets, and real-time systems.

Required Qualifications
1-6 years of technical experience working with data and deploying analytical solutions.
BS in Computer Science or related field, or equivalent experience. (Master’s degree and Phd’s preferred)
All applicants for cleared contracts must be a US citizen and have an active TS within the past 2 years.
Software development experience with Java and Python
Experience with ELK (ElasticSearch, Logstash, Kibana) stack, and NiFi
Software development using languages such a C++, Ruby, Perl, Javascript is a plus.
Experience with Agile Development processes
Experience developing and implementing algorithms to meet or exceed system performance and functional standards
Excellent written and verbal communication skills to evaluate and describe complex technical solutions for management, non-technical users and team members
Experience in any of the following areas preferred: Data Visualization, User Experience Design and Implementation, Data Structures, Database Administration and Manipulation, DevOps (Infrastructure, Continuous Integration and Automation, Packaging and Deployment), Operationalizing Algorithms, Web Development, Cloud Platforms and SaaS, Scientific Computing, Storage and Retrieval
Must be willing and able to travel to and work on client site. Some travel may be required
About Elder Research, Inc.

Elder Research is a fast growing consulting firm specializing in predictive analytics. Elder Research has been in the data science business over 20 years providing analytic solutions to hundreds of companies and organizations across numerous industries. At Elder Research, you’ll be part of a fun, friendly community. In keeping with our entrepreneurial spirit, we want candidates that are self-motivated with an innate curiosity and strong team work ethic. We work hard to provide the best value to our clients and allow each person to contribute their ideas and put their skills to use immediately.

Achieving success on defense, intelligence and security projects requires a data science team with broad experience, critical thinking, a proven ability to solve complex problems, and the ability to effectively communicate results. Our team relies on well-trained technical personnel who have experience with tools, algorithms, best practices, and custom software development to navigate the frontier of unsolved problems we typically encounter. Our team enjoys great variety in the type of work they do and exposure to a wide range of analytic techniques and tools.

Elder Research, Inc. is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, or protected veteran status and will not be discriminated against on the basis of disability.",3.8,"Elder Research
3.8","Springfield, VA","Charlottesville, VA",51 to 200 employees,1995,Company - Private,Consulting,Business Services,$5 to $10 million (USD),-1
CMR Software Engineer,-1,"A talented software engineer is needed in Riverdale, Maryland to join Raytheons EED-2 (EOSDIS Evolution and Development) team which supports NASA in its mission to provide scientists and other users access to data from NASAs Earth science missions. As a member of the EED-2 team, software engineers will build innovative tools allowing scientists and students alike to discover, transform, update and improve the quality of earth science data in the pursuit of solving a wide range of environmental and socio-economic issues. Specifically, this opening is for a software engineer on EED-2s Common Metadata Repository (CMR) team. The CMR is an AWS hosted scalable repository for ~500M earth science metadata records from around the world. It receives approximately 3M queries per week and is envied for its speed and reliability. The CMR team is an established and high performing agile team working in the Scaled Agile Framework methodology.
Primary Responsibilities:
Participate in all aspects of the software development lifecycle from user story generation, through design, development, automated testing and operational support
Develop new feature ideas to meet the ever evolving needs of our end-users
Continually help the team grow by sharing new ideas and industry best practices
Suggest improvements to processes and tools to help the team be more efficient
Other duties as assigned
Required Skills:

2+ years of experience as a Software Engineer
Experience with a functional programming language, such as Clojure
Experience with Amazon Web Services (AWS)
Experience with the Atlassian tool suite (JIRA, Confluence, Bamboo)
Experience as a member of small team using Agile/Scrum methodologies
Firm commitment to automated testing and continuous integration
Proponent of continuous improvement and willingness to bring new ideas to the team
Desired Skills:

Experience with machine learning
Experience with algorithm optimization
Experience with Elasticsearch
Experience developing in Clojure
Experience with Geographic information systems (GIS)
Experience developing on MacOS X and deploying to Red Hat Enterprise Linux
Experience with the Scaled Agile Framework (SAFe)
Experience presenting at technical conferences
Required Education:

Must have a BS degree in a technical major, such as engineering or computer science, and 2 years direct experience.
U.S. citizenship is required. All candidates must be able to pass a National Agency Clearance with Inquires (NACI) screening
162284

Raytheon is an Equal Opportunity/Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to race, age, color, religion, creed, sex, sexual orientation, gender identity, national origin, disability, or protected Veteran status.",3.5,"Raytheon Intelligence & Space
3.5","East Riverdale, MD","Arlington, VA",10000+ employees,2020,Subsidiary or Business Segment,Aerospace & Defense,Aerospace & Defense,$10+ billion (USD),-1
Enterprise Data Engineer,"$99K-$121K
(Glassdoor est.)","Job title: Enterprise Data Engineer
Job type: Permanent
Emp type: Full-time
Salary:
Negotiable
Location: New York, NY
Job published: 2019-12-16
Job ID: 41913

Job Description


Our client is searching for an experienced Enterprise Data Engineer to join their team in Chicago. Enterprise Data Engineers build pipelines that support datasets used by all investment teams and strategies across the firm. They manage the firm’s most critical data sets and focus on applying software development best practices to solve complex data challenges. The expectation is that the data engineer has sound programming skills, strong business acumen, and a strong interest in finance.

Responsibilities:
Develop solutions that enable internal analysts to efficiently extract insights from data. This includes owning the ingestion (web scrapes, S3/FTP sync, bespoke processes), transformations (Python, Perl) and interface (API, schema design, events, etc.)
Build tooling and automation around data pipelines that improve the efficiency, quality and resiliency of the data platform
Partner with internal analysts, quants and data scientists to design, develop, test and deploy solutions that answer fundamental questions about financial markets.
Take on an entrepreneurial mentality by building and selling your own ideas. The company works in an evolving space and they expect you to help design their evolution by challenging the status quo and independently identifying opportunities to improve the entire data organization.


Requirements:
A passion for working with data and developing software to address data processing challenges
Proficiency with Python, C++, Java or equivalent
Proficiency with RDBMS, NoSQL, distributed compute platforms such as Spark, Dask or Hadoop
Prior experience building data pipelines from structured or unstructured data preferably including web crawlers
Prior work developing BI tooling and/or application development for data analytics
Advanced technical communication skills
Working knowledge of statistics, predictive analytics or machine learning techniques
Strong business acumen with prior experience in investment research or direct exposure to product or data science teams AND passionate about using data for investment decisions
If you would like to be considered for the position of Enterprise Data Engineer or wish to discuss the role further then please leave your details below. Your resume will be held in confidence until you connect with a member of our team

Email: info@njf.com or call London (0207 604 4444,) New York (212 400 4845) or Chicago (312 204 72176) to speak to a member of our team. Thank you",4.2,"NJF Global Holdings
4.2","New York, NY","London, United Kingdom",51 to 200 employees,2003,Company - Private,Staffing & Outsourcing,Business Services,$10 to $25 million (USD),-1
Senior Machine Learning Engineer,-1,"About ConcertAI

ConcertAI is the leading provider of precision oncology solutions for biopharma and healthcare, leveraging the largest collection of research-grade Real-world Data and the only broadly deployed oncology-specific AI solutions. Our mission is to improve translational sciences; accelerate therapeutic clinical development; and provide new capabilities for post-approval studies to accelerate needed new medical innovations to patients and to improve patient outcomes.
ConcertAI has emerged as one of the highest growth technology companies in Real-world Data and AI, backed by industry leading private equity companies: SymphonyAI, Declaration Partners, Maverick Ventures, and Alliance|Bernstein.

ConcertAI is looking for a talented Senior Machine Learning Engineer to build advanced AI and Machine solutions as part of our eurekaHealth solution team engaging in projects and programs of high priority. You should have a good mix of programming/CS skills and data science experience. You will be responsible for designing, implementing and maintaining software that powers the company’s data operations, production analytics (AI/ML/DS) and products. You will collaborate with data scientists on prototypes and work on productization, focusing on scalability and robustness (tests, documentation, etc).This role reports to the Vice President of Data Science.
Responsibilities
Lead, design, develop, and implement AI production software to address client’s needs.
Collaborate on software projects with data scientists, and provide technical guidance.
Develop ML/AI algorithms using high level libraries and high performing implementation.
Stay current on the most recent AI/ML algorithms, design principles, and programming paradigms.
Write documentation and test suites, and help maintain several codebases.
Requirements
PhD in computer science, math, physics, or engineering and 3+ years of relevant work experience.
Experience with Python or another high level programming language (e.g. Java, C++).
Production software development experience.
Expertience with advanced data science and machine learning concepts and libraries.
Experience with data munging with Spark/Scala/Sq.
Experiece with cloud technologies (AWS, Docker, Git).
Experience with healthcare data (Electronic Health Records, claims data) is preferred.
Strong communication, project management and technical leadership skills with an enthusiasm for working in an interdisciplinary environment.
Learn More About ConcertAI

ConcertAI is transforming how healthcare is delivered and dedicated to improving patient outcomes in oncology by offering innovative solutions on how data and intelligence is used to solve healthcare problems. We are creating something special in our culture, by building a collaborative, engaged, patient focused, team approach to our mission. Our high-performance teams are looking to add great talent to the mix and we are hiring for the right mix of new skills and diverse mindset. Learn more about ConcertAI at www.concertai.com or on LinkedIn .",3.4,"Concerto HealthAI
3.4","Boston, MA","Boston, MA",501 to 1000 employees,2018,Company - Private,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,Unknown / Non-Applicable,-1
"Senior Software Engineer, Reasoning",-1,"OpenAI’s mission is to discover and enact the path to safe, beneficial AGI. On this path, the Reasoning team aims to develop machine learning systems that achieve high performance on tasks that require reasoning for humans, such as answering questions about the world, understanding logic puzzles and games, solving math problems, and proving theorems. To do this, we believe that we will need to develop systems for acquiring data of unprecedented scale and quality.

We are looking for an experienced full-stack software engineer to develop systems that enable us to procure and process data for a wide variety of research projects. This includes maintaining and scaling a web application for collecting data from human annotators, harvesting datasets from the web, and building new tools that use machine learning to clean and prepare data. This is a core role integrated within a team of research scientists and engineers working on pushing the limits of reasoning capabilities.
You will:
Work at all levels of the web application stack, using HTML and CSS, VueJS or React, NodeJS, Python (Django), as well as Heroku, AWS, or another cloud platform
Own the process of finding large-scale datasets and acquiring them via crawling and scraping
Develop and implement new deep learning-based methods for getting feedback from humans and for cleaning and curating datasets, in order to make them accessible for research within OpenAI
Partner with researchers across OpenAI to understand their research and data needs
Design reusable, scalable data infrastructure that can be applied across multiple teams
You’ll be a good fit for this role if you are:
Excited to work closely with a fast-paced results-oriented research team with dynamic requirements
An expert in Javascript, Python, and Linux, and comfortable with large Python and Javascript codebases
Experienced in maintaining and scaling performant web applications
Experienced in developing web crawlers and scrapers, and processing web-sourced data
Comfortable with the fundamentals of machine learning and excited to develop expertise in deep learning
Excited to use machine learning to develop tools for filtering, balancing, and deduplicating data
Engaged with OpenAI’s mission of building safe and beneficial artificial general intelligence
About OpenAI
We’re building safe Artificial General Intelligence (AGI), and ensuring it leads to a good outcome for humans. We believe that unreasonably great results are best delivered by a highly creative group working in concert. We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

This position is subject to a background check for any convictions directly related to its duties and responsibilities. Only job-related convictions will be considered and will not automatically disqualify the candidate. Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.

Benefits
Health, dental, and vision insurance for you and your family
Unlimited time off (we encourage 4+ weeks per year)
Parental leave
Flexible work hours
Lunch and dinner each day
401(k) plan",5.0,"OpenAI
5.0","San Francisco, CA",-1,51 to 200 employees,-1,Nonprofit Organization,-1,-1,Unknown / Non-Applicable,-1
Sr. Software Engineer - AI/Machine Learning,"$133K-$160K
(Glassdoor est.)","C3.ai is a leading enterprise AI software provider for accelerating digital transformation. The comprehensive and proven C3 AI Suite uses a model-driven abstraction layer to enable organizations to develop, deploy, and operate enterprise scale AI applications 40x to 100x faster than alternative approaches. www.c3.ai

We are looking for a seasoned software engineer to build the next generation AI platform scaling to petabyte level data volumes.

As a member of C3.ai's platform engineering team, you will be responsible for the entire software engineering lifecyle, i.e design, document, build, test, maintain. As one of the core teams, this role is integral to the success of the company. A successful candidate will thrive in a fast-paced, highly collaborative environment and demonstrate an ability to execute precisely and quickly. The ideal candidate will have in-depth experience with Data Science workflows and built scalable machine learning systems.

- Build systems and tools that enable data scientists to create machine learning applications using the C3.ai Platform.
Enable scalable, end-to-end machine learning pipelines in a distributed system.
Work with other platform engineering teams to enable streaming, batch, or ad-hoc data analysis.
Collaborate with and support data scientists to understand the utility of the C3.ai Platform and define new requirements.
Define and lead the development of longer-term C3.ai Platform capabilities.
Mentor junior members of the team.

Requirements:

- Advanced degree in computer science, math, or similar field.
Excellent programming and algorithmic skills and a taste for DRY code.
In-depth understanding of supervised and unsupervised machine learning algorithms.
Proven track record of applying learning algorithms in a production system.
Strong programming skills in Java, Python and JavaScript.
Demonstrated end-to-end ownership of projects.
Stellar listening and explanation skills.
Thorough knowledge of data structures, algorithms, profiling/optimization, and Object-Oriented and Functional Programming.
A minimum of 3 years of work experience in a fast-paced software company.

C3.ai provides a competitive compensation package and excellent benefits including:
Competitive salary, generous stock options, 401K, medical, dental, and vision benefits. At the office, we offer a fully stocked kitchen with catered breakfast and lunch, table tennis and pool table, free membership at our on-site gym, Friday evening social hours with food, drink and music and a fun team of great people.
C3.ai is proud to be an Equal Opportunity and Affirmative Action Employer. We do not discriminate on the basis of any legally protected characteristics, including disabled and veteran status.",4.7,"C3.ai
4.7","Redwood City, CA","Redwood City, CA",201 to 500 employees,2009,Company - Private,Enterprise Software & Network Solutions,Information Technology,$100 to $500 million (USD),"GE Digital, Palantir Technologies, Uptake"
IoT Cloud Engineer,-1,"SharkNinja is a relentless innovator with 550+ patents in consumer technologies. We obsess about consumer satisfaction. We build up our company by building up our people. We seize opportunities—individually and collectively—to be competitive with our products and attract the most talented people in the world.

SharkNinja Robotics Organization is a unique group of Robotics, Software/Hardware Engineers, Analysts and Data Scientists who work on cutting edge technologies in IoT, Cloud, Artificial Intelligence, Machine Learning and Cleaning Technologies to create delightful consumer products. Through an unrelenting focus on solving for consumer’s pain points, we have built a loyal and passionate following that continues to garner us 5‑star ratings on our products.
The IoT Cloud Engineer will provide technical leadership to develop processes, build and scale our cloud infrastructure and tools used to connect our software (Application, Firmware and Cloud) to our customer devices (Robots/IoT).
Responsibilities:
Oversee and support cloud implementation and migration for Connected Robots services, internationally
Collaborate with internal support groups to vet and implement necessary changes to support cloud deployment of connected products
Collaborate with internal clients and vendors to evaluate solutions and articulate technical, cost and architectural value of various options
Design of solutions for high availability and disaster recovery for cloud-based applications
Ensure delivered solutions meet/perform to technical and functional requirements
Provide technical expertise and ownership in the diagnosis and resolution of an issue, including the determination and provision of workaround solution or escalation to service owners
Demonstrate forward thinking around where the organization is going and how technology can support these efforts
Advocate and help define cloud architecture vision from a strategic perspective, including internal and external platforms, tools, and systems
Research, document, and devise solutions for customer use cases
Identify issues on OTA updates and document corrections and improvements in the Knowledge Base (KB)
Work with tech writers to enhance documentation and training materials
Partner with Product and IoT team to become the subject matter expert (SME) on IoT systems and features.
Qualifications:
Solid foundation in software with strong systems knowledge
Good communication skills and desire to help customers and coworkers
Demonstratable experience with creating and modeling digital twins
Significant knowledge of systems and cloud architecture principles
Significant experience with RESTful APIs and MQTT
Knowledgeable of change management processes and a deep understanding of the impact changes can have on production systems
Familiar with developing software for wireless technologies: Wi-Fi, TCP/IP, Bluetooth/BLE
Considerable experience with AWS and/or other cloud-based environments
Experience with mobile applications and development platforms for iOS and Android operating systems
Experience with AWS Greengrass, Ayla Networks, PTC ThingWorx, or Azure IoT Edge
Ready to work in dynamic, fast-paced startup environment
8+ years relevant work experience
Education: BS/MS in Engineering or Computer Science (or equivalent)
At SharkNinja, our purpose is to positively impact people’s lives every day in every home around the world. We work very hard to provide our consumers with high quality, exciting 5-star products that make life easier. We thrive on passion and innovation, and are looking for great people, with great ideas, who want to create the next big thing. We take a team approach to our projects, where everyone has a voice. We want individuals to push limits, look outside the box and think the unthinkable. With the explosive growth we have been experiencing, we’re looking for motivated individuals to join us on our exciting journey. People need to think big, move fast and want to make a significant impact. Are you ready?",3.1,"SharkNinja
3.1","Needham, MA","Needham, MA",1001 to 5000 employees,1993,Company - Private,Consumer Products Manufacturing,Manufacturing,$1 to $2 billion (USD),"Dyson, Keurig Green Mountain"
"Senior Software Engineer, Knowledge Platform (Data Infrastructure)","$106K-$201K
(Glassdoor est.)","Company Description

Square builds common business tools in unconventional ways so more people can start, run, and grow their businesses. When Square started, it was difficult and expensive (or just plain impossible) for some businesses to take credit cards. Square made credit card payments possible for all by turning a mobile phone into a credit card reader. Since then Square has been building an entire business toolkit of both hardware and software products including Square Capital, Square Terminal, Square Payroll, and more. We’re working to find new and better ways to help businesses succeed on their own terms—and we’re looking for people like you to help shape tomorrow at Square.
Job Description

Square's Knowledge Platform team has two goals:
Make machine learning at Square easy. Square has over 100 engineers and data scientists building machine learning solutions; our team’ supports these efforts. We build model development tools, feature computation infrastructure, and high scale serving systems to ensure that those trying to use machine learning can spend less time on infrastructure and more time delivering value.
Provide ecosystem expertise to all of Square's products. We provide systems and models that help teams transform their idiosyncratic data into reusable knowledge, so that each new ML system starts with access to a large set of observations and features.
You Will:
Build tools and systems that make data scientists happier and more productive. As an infrastructure team that supports data scientists, we have a tight connection with the DS community and need people who enjoy working on tools and building reusable, maintainable systems. Two tools we’ve open-sourced are Bionic and pydocker.
Build scalable systems that can do the heavy lifting of feature processing. Our team maintains the infrastructure to compute real-time features used in the decision flows of all payments at square and the historical store that allows models to be trained.
Build fault tolerant serving systems. The main job of the team is to evaluate models to make the Data Scientist’s job easy in production. You will build flexible systems that support the vast array of ML requirements that can serve models built through any DS tool.
Qualifications

You have:
4+ years of software development experience.
Experience producing scalable production-quality code incorporating testing, evaluation, and monitoring.
Experience designing and productionizing large-scale distributed systems built around machine-learned models and big data.
Technologies we use and teach:
Java, Python, Google Cloud Platform, AWS, Snowflake, JanusGraph, and Docker
Python ML tech (pandas, scikit-learn, Jupyter)
MySQL, Redis, Hibernate, jOOQ, Bigtable
Additional Information

At Square, we value diversity and always treat all employees and job applicants based on merit, qualifications, competence, and talent. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. We will consider for employment qualified applicants with criminal histories in a manner consistent with the requirements of the San Francisco Fair Chance Ordinance. Applicants in need of special assistance or accommodation during the interview process or in accessing our website may contact us by sending an email to assistance(at)squareup.com. We will treat your request as confidentially as possible. In your email, please include your name and preferred method of contact, and we will respond as soon as possible.

Perks

At Square, we want you to be well and thrive. Our global benefits package includes:
Healthcare coverage
Retirement Plans
Employee Stock Purchase Program
Wellness perks
Paid parental leave
Flexible time off
Learning and Development resources",4.0,"Square
4.0","San Francisco, CA","San Francisco, CA",1001 to 5000 employees,2009,Company - Public,Computer Hardware & Software,Information Technology,$1 to $2 billion (USD),-1
"Senior Data Engineer (San Francisco, CA)","$98K-$175K
(Glassdoor est.)","Earnest empowers people with the financial capital they need to live better lives.

We're an accomplished team of technology, finance, and design geeks who believe consumer lending can be radically improved and are doing something about it. We are disrupting the trillion dollar student loan industry by redefining what it means to be creditworthy. We created a company that combines data science, streamlined design, and technology to:
Build products that simplify the lending process
Personalize loans to suit the needs of our customers
Engage with our customers through more human experiences
Our culture is one that values transparency and blameless problem solving. Earnest has a strong track record of employee growth and career progression. Earnies are empathetic, product-focused, proactive, and curious.

As a Senior Data Engineer, you will report to the Head of Data and work with members of the Data team to maintain and improve data pipelines, deploy predictive models as a service, and build our nextgen data infrastructure. Expect an environment where you will always learn and be encouraged to work with tools, languages, frameworks that are outside the area of your expertise.

We believe data engineers should spend time writing tooling and creating abstractions to empower and support the work of analysts and data scientists in the team. It enables team members to write and maintain their own ETL.

Tools, Frameworks, and Languages you will work with:
Languages: Python, Scala, and occasionally R and Node.js
Storage: Postgres, Redshift, S3
Compute: Spark, Athena, EC2
Workflow Management: Airflow
Infrastructure: Terraform, Kubernetes
What you'll do:
Work with Data Scientists to deploy trained machine learning models as a Python microservice.
Create abstractions and tools for running ETL and non-ETL jobs.
Manage overall data pipeline orchestration including Airflow.
Create databases and access controls in data warehouses.
Ideal background and expertise:
5+ years of experience building and managing data pipelines, data warehouses, and backend services
3+ years of experience with Python or Scala
Experience with server-side concepts (e.g. microservices, database, caching, performance, monitoring and scalability)
Experience with OLTP databases such as Postgres, MySQL
Experience making data available in data lakes such as S3
Experience with orchestration tools such as Airflow (preferred), Luigi, Ooozie
Familiarity with Business Intelligence tools such as Tableau, Looker, Superset is a plus
Domain experience developing software for Fintech, Banking, or related Consumer Financial Services companies is a plus
Nice to Have:
Familiarity with Business Intelligence tools such as Tableau, Looker, Superset
Domain experience developing software for Fintech, Banking, or related Consumer Financial Services companies
Earnest Perks & Benefits:
Great culture and an awesome team
Health, Dental, & Vision benefits plus savings plans
Employee Stock Purchase Plan
401(k) plan to help you save for retirement plus a company match
Tuition reimbursement program
$1000 flight on each Earnie-versary to anywhere in the world and 25 days of annual PTO
Earnest provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability or genetics. Qualified applicants with criminal histories will be considered for the position in a manner consistent with the Fair Chance Ordinance

#LI-KO1",3.9,"Earnest
3.9","San Francisco, CA","San Francisco, CA",51 to 200 employees,2013,Subsidiary or Business Segment,Lending,Finance,Unknown / Non-Applicable,"SoFi, CommonBond, Organic"
Connected Instruments Workflow Engineer,-1,"Requisition Id 2674

Overview:

Oak Ridge National Lab (ORNL) is a home to several hundred of the brightest scientists working on internationally relevant, diverse problems ranging from advanced materials to supercomputing. The Advanced Data and Workflow Group (ADWG) in the Oak Ridge Leadership Computing Facility (OLCF) supports artificial intelligence, visualization, and data handling requirements for the world’s fastest supercomputers such as Summit. The ADWG is looking for a self-motivated and creative engineer who can develop software, tools and infrastructure to help the definition and implementation of workflows that enable edge devices and instruments to connect to scalable computing resources. We are an inclusive environment that welcomes a diversity of creative, spunky scientists and engineers with an eagerness to learn.

Job Duties / Responsibilities:
Enabling edge computing - (near)-real-time analytics in close proximity to an instrument for rapid iteration of experiments towards intelligent or self-driving instruments
Applying data analytics (machine learning / deep learning) in multiple phases of the lifecycle of scientific data, starting from generation to archival in an effort to accelerate scientific discovery
Connect two or more modalities of scientific discovery (experiments / observations, numerical modelling / simulations, data analytics) via software infrastructure and/or algorithms to accelerate the discovery process. For example – using deep learning models as surrogates for computationally intensive simulation kernels.
Write peer-reviewed papers, technical reports, give technical presentations at international conferences or other large public forums
Basic Requirements:
MS in computer science, computational science, mathematics, statistics, or any relevant domain sciences such physics, material science, chemistry, biology and 1 year relevant experience
Background in computational science and software development
Preferred Qualifications:
PhD in the domain sciences such as in physics, material science, chemistry, biology, etc.
Strong programming skills in one or more of the following languages: Python, C/C++, Fortran
Experience in parallel computing and high-performance computing
Experience in data science – machine learning and/or deep learning
Experience in software development and deployment
Experience or background in simulations as well as observational and experimental sciences
Experience in controlling and acquiring data from scientific instruments
Excellent verbal and written communication skills
Ability to work effectively as a team-member and collaborate with scientists, engineers, and sponsors
Self-motivated to lead projects
Interest in mentoring students
This position will remain open for a minimum of 5 days after which it will close when a qualified candidate is identified and/or hired.

We accept Word (.doc, .docx), Adobe (unsecured .pdf), Rich Text Format (.rtf), and HTML (.htm, .html) up to 5MB in size. Resumes from third party vendors will not be accepted; these resumes will be deleted and the candidates submitted will not be considered for employment.

If you have trouble applying for a position, please email ORNLRecruiting@ornl.gov.

ORNL is an equal opportunity employer. All qualified applicants, including individuals with disabilities and protected veterans, are encouraged to apply. UT-Battelle is an E-Verify employer.",4.3,"Oak Ridge National Laboratory
4.3","Oak Ridge, TN","Oak Ridge, TN",1001 to 5000 employees,1943,Government,Federal Agencies,Government,Unknown / Non-Applicable,"Pacific Northwest National Laboratory, Sandia National Laboratories, Argonne National Laboratory"
Senior Data Engineer,-1,"The Data Team at ReSci is in a new phase of its evolution. We've scaled our predictive models to 350M+ users and we are looking for a Senior Machine Learning Engineer to help us innovate new models and improve our existing algorithms, to take our predictions to the next level! On our Data Team, you will work closely with other Data Scientists and Data Engineers to create the Machine learning backbone that powers our marketing automation platform (""Cortex"") for commerce brands. Your expertise at algorithms will be paired closely with the software expertise of Data Engineers, and you will jointly own these ML systems.

We are looking for an experienced data engineer who is passionate about writing clean, well-tested code. You should want to make a huge impact in a fast-paced and cutting-edge start-up environment. You should have great experience with scala/spark or python/serverless and working closely with ML algorithms and data scientist. You’ll be building robust real-time data pipelines that process billions of events per day and sitting on the team that builds end-to-end ML algorithms. You'll help our data scientists productionize our ML models.

In addition to having meaningful responsibilities and gaining experience in product development, you will also receive comprehensive exposure to all aspects of our business. The code and ideas that you contribute will have a tangible impact on the business as a whole. Your code will touch millions of end-users. You will have full responsibility for your projects and have a real sense of product ownership. You will also have the opportunity to learn tremendously from our awesome team of humble yet super engineers. You'll work with and learn the latest technologies and apply them across our distributed systems.


About You:
5+ years experience working on production data products in Python, Scala, or similar
Proficient in at least one statically typed language
Experience designing and implementing large, scalable services
Passionate about enforcing software engineering principles, production code quality, and regular use of design patterns
Experience interfacing with APIs - SOAP, REST, etc.
Comfortable using Git, Bitbucket/Github
Strong belief that tests and code go hand-in-hand
Deep understanding of SQL, query optimizations, joins etc.
Excellent CS foundation: data structures, time complexities, algorithms, etc.
Startup work experience a major plus!
About Us:

ReSci's mission is to make artificial intelligence accessible and usable for brands.

Our values:
- Inspire with passion.
- Persevere with determination.
- Collaborate with unity.
- Grow without bounds.
- Create with impact.
- Lead with character.

Based out of Santa Monica, CA, our team consists of serial entrepreneurs who have all made Retention Science a leader in AI marketing. Our SaaS platform, “Cortex” helps online businesses target, engage, and retain customers. The Cortex marketing platform uses machine-learning algorithms to predict customer behavior by analyzing massive sets of demographic, social, and behavioral data to generate 1-to-1 retention campaigns personalized to each customer. Cortex makes 3.5+ billion predictions per day and processes 5k+ events per second.

Our founders have been recognized as the Ernst & Young Entrepreneurs of the Year, and our company was awarded Top 10 Big Data Startup of the Year by CRN, one of Fast Company's €œInnovation Agents€, Top 10 Software Company in Southern California from SocalTech, and identified by Inc. Magazine as one of the most innovative startups. Retention Science has also been featured in Forbes, the Wall Street Journal, TechCrunch, Bloomberg, and Reuters, among other notable publications. In addition, the most prestigious startup accelerator in LA (part of the TechStar Network), as well as many reputable angel investors and Venture Capital firms have provided their support and backing for our business.

We're passionate about what we do and we put our people first! We are a close-knit family whose members drink too much coffee, work hard, and never cease to brainstorm creative new ways to improve our solutions. We foster a dynamic and exciting start-up environment that is conducive for innovative thought; join us if you are interested in working with our world-class team!",4.4,"Retention Science
4.4","Santa Monica, CA","Santa Monica, CA",51 to 200 employees,2013,Company - Private,Enterprise Software & Network Solutions,Information Technology,$5 to $10 million (USD),"AgilOne, IBM"
"Senior Software Engineer, Cheminformatics",-1,"We are seeking an experienced software engineer with a degree in Chemistry to join our Cheminformatics team. Your expertise will guide decisions on appropriate representations of chemicals and their properties, selection of existing tools to incorporate, and evaluation of public data sets. You will work side-by-side with computational chemists, data scientists and other scientists to build the foundation on which key scientific and business decisions are made. This role provides an opportunity to make a significant impact on Zymergen in a high-priority project.The ideal candidate thrives in a fast-paced, multi-disciplinary, collaborative environment; values clear communication; balances pragmatism and idealism; and is not afraid of ambiguity and incompletely specified requirements. As a team member, there will be opportunities to hone your knowledge in software engineering, Machine Learning, chemistry, and more in the company of experts and expand your skills into a variety of new technologies.The software engineering team is responsible for building the tools that our scientists use on a daily basis and the computational infrastructure powers the Zymergen platform. You will apply your Python expertise to large-scale resilient distributed systems, analysis pipelines, and high performance data processing. Our primary projects in this team involve:* Ongoing development of a large-scale chemicals/molecules database, ETL process, and API's to support a UI and other programmatic interactions. This has been developed primarily utilizing AWS tools and capabilities. Integration of that DB and many other chemistry related tools (Electronic Lab Notebook, computational material modeling tools, ML tools, etc), together and interfacing with the existing software infrastructure at Zymergen* Cheminformatics analysis on groups of chemicals/molecules that are accessible through our biology and genetic engineering processes and fully managed and searchable through the core database.* Being a trusted partner, bridging communication between chemists and other software engineers, with the ability to deeply understand the user needs and grasp the science they are attempting to accomplish on the tools and platforms that we are building.Qualifications/Experience* BS + 5yrs or MS + 3 yrs* 4+ years of experience in software engineering. Specifically building infrastructure for data processing and retrieval* Experience working in distributed systems and/or systems programming. Python experience a plus* Database development + ORM experience (MySQL, Postgres, Oracle + SQLAlchemy)* Penchant for big data and related technologies* Mastery of software engineering principles and experience with git, unit and integration testing, and CI/CD pipelines.* Excellent written and verbal communication skills.* Demonstrated ability to work with a team of highly-motivated engineers* Ability to collaborate with research scientists, understand their challenges, and design software solutions to address challenges.* Strong communication, explanatory, and exploratory skills, including technical writing and ad hoc analysis with tools like Jupyter.Preferred* Full stack development* RESTful API and microservice development* Knowledge of chemical toolkits and various structure formats (RDKit, OpenEye, InChI, SMILES, SD File)* Experience with AWS services, Docker/K8s, and infrastructure as code (e.g. Terraform)* BSc. or higher in chemistry or related subject matter, especially polymer chemistry* Experience with chemical prediction and simulation, such as MD, DFT, or ML methods and descriptors* Knowledge of electronic lab notebooks and experiment data capture* Advanced python skills and working knowledge of asynchronous programming, generators, and multithreading techniques* Experience with NoSQL technologies, e.g. graph databases is a plusResponsibilities:* Design, development and deployment of a chemical database for Zymergen.* Collaborating with chemists and other scientists to understand their problem domain and how software tools can help.* Studying existing Zymergen systems to understand the overall ecosystem and how new projects / services should integrate into it.* Defining and building data models to represent chemicals and their properties; designing data transformation processes to populate the database(s).* Creating APIs to make the chemicals data queryable. Queries in question may need to be significantly more complex than simple boolean keyword searches or sql-like statements; search-by-example, probabilistic queries, and other approaches may come into play.* Evaluating and integrating 3rd-party and open-source tools as needed.* Working with computational chemists to enhance the design of the database which enables the management, storage and analysis of large-scale computational chemistry data.* Working with a front-end engineer to make sure the overall tool makes sense, and possibly contributing some front-end code.Legal authorization to work in the U.S. is required. Zymergen may agree to sponsor an individual for an employment visa now or in the future if there is a shortage of individuals with particular skills for this job.In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification form upon hire.Founded in 2013 and based in the San Francisco Bay Area, Zymergen is a technology company unlocking the power of biology. We deliver better economics for products made from biology that are used across industries, bring new products to market faster, and develop novel products. Our proprietary platform uses robots and machine learning to engineer microbes faster, more predictably, and to a level of performance previously unattainable. These microbes, and the products they produce, have broad applications across industries such as chemicals and materials, agriculture, and healthcare. For more information visit www.zymergen.com.",2.6,"Zymergen
2.6","Emeryville, CA","Emeryville, CA",201 to 500 employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Senior Data Engineer,-1,"Job Description
Our leading marketing technology company provides the infrastructure for the industry's first and only ecosystem of advertising exchanges for native search and metasearch media. We connect buyers and sellers to create efficient marketplaces for performance media across leading brand, metasearch, and comparison sites. Our technology platforms power over 50 million high-value transactions annually, representing more than $400 million in annual media spent across the insurance, travel, personal finance, education, and home service verticals. Our team of talented and passionate professionals work together to identify new solutions that keep our company and our partners one step ahead in the industry. Headquartered in Redmond, Washington and Los Angeles, California, our offices extend from Seminole, Florida and Carson City, Nevada to our international location in London.

We are currently seeking a seasoned, analytical, and creative Senior Data Engineer/Scientist to join our dynamic team! We are looking for someone with previous experience building and deploying models that can make real-time low-latency predictions. The ideal candidate will possess stellar problem-solving skills and be highly organized and self-motivated. They will enjoy designing and implementing production-ready solutions that process and analyze many ad transactions everyday!

The Senior Data Engineer/Scientist will participate in the entire software development lifecycle. They will work with stakeholders to identify any issues and provide solutions, run statistical analysis on large data sets, and prepare and deploy predictive models at scale.

While the company is open to relocating a candidate, we are seeking someone with ties in Seattle or a real desire to move to Seattle. For the right candidate, the company is willing to pay reasonable relocation fees.

Only seeking candidates with professional experience. No recent graduates need apply.

Responsibilities:
Own the full development lifecycle (implement high-performance real-time predictive engines that enable ad serving decisioning from data management to model training and evaluation to deployment and monitoring).
Run statistical analysis on large data sets.
Prepare and deploy predictive models at scale.
Participate in the software development lifecycle.
Implement high-performance ad serving software.
Create code to analyze ad performance data for optimization.
Direct specific ad-hoc projects across our five product verticals.
Work within a Perl development environment on a Linux platform.
Collaborate with the team to maintain and support our company’s platform.
Requirements:
Bachelor’s degree in Computer Science or other technical discipline.
Previous experience implementing statistical models, machine learning, and analysis using R or Python.
Previous experience working with engineers and non-technical stakeholders.
Strong knowledge of relational data modeling and SQL.
Strong programming skills, including software engineering methodologies and best practices.
Experience using web APIs.
Experience with Hadoop v2, MapReduce, and HDFS.
Previous experience with Perl, a plus!
Previous experience working with engineers and non-technical stakeholders.
Excellent communication and analytical skills.
Able to work on multiple tasks simultaneously and meet deadlines.
Highly detail-oriented with strong problem-solving skills.
Compensation:
Competitive salary and bonus program participation.
401K company contribution program after 1 year.
High quality health and dental care plans with no employee contributions and zero deductibles (in network). Flexible spending account.
Unlimited PTO.
Professional training and education reimbursements.
Employee perks, including mobile phone program and gym membership.
Powered by JazzHR

og9EOewBd7",-1,EvolvInc,"Redmond, WA","Los Angeles, CA",1 to 50 employees,2005,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
"Senior Software Engineer, Data",-1,"The Company You'll Join


At Carta we create owners and make private markets liquid.

We live in a world where some people live on the equity stack and enjoy exponential wealth growth and preferential tax treatment; others live on the debt stack and may work their entire lives for a company and retire only with the cash they've managed to save from their paychecks. Our contribution to solving the wealth inequality problem is moving people from the debt stack (payroll) to the equity stack. By making it as easy to issue equity to employees as it is to put them on payroll, we can create more owners.

At Carta, we are helpful, transparent, fair, and kind. We are relentless executors, unconventional thinkers, and masters of our craft.

To learn more, here is what one of our investors wrote about leading our Series F.

The Team You'll Work With


The Data team at Carta is transforming what decision making looks like at the company. We believe that our data is what is key to setting us apart and will help us succeed as a data driven company. Members of the data team are working on understanding and making sense of data while partnering with product and business teams on helping drive direction with data. The team is currently composed of professionals in Data Science/ Machine Learning space, advanced Data Analytics space, and Data engineering. We like to partner with each other and with Cartans across the company to get our work done, and we like to constantly think about how we can improve. We also like to come up with new product ideas based on data.

The Problems You'll Solve


As a member of this team, you will be responsible for building and scaling our pipelines to make data accurate, accessible and secure. You will build systems that will allow the rest of the company answer questions they need in a self-service manner, and allow analysts and data scientists to quickly analyze and prototype new ideas. You will partner with the rest of the team on prototyping those new ideas and build scalable products. Examples of responsibilities will include:
Build resilient data pipelines based on internal and external data sources
Implement data security practices to support CartaX, compliance & legal, and other areas of the company that require additional safeguards
Build or evaluate tooling for data accuracy detection and alerting
Partner with the rest of the team on prototyping and building scalable products driven by the data team
Partner with teams throughout Carta on identifying opportunities and building solutions to help in simplifying operations while producing rich and accurate data sets for us to use
Constantly identify opportunities for providing self-service tooling to our internal partners
The Impact You'll Have


By building scalable self-service solutions you will enable easier and faster decision making. In addition, you will be able to increase productivity and accuracy of our data team, and operations and product teams as well

About You


Successful candidates in this role will always look for a balance between fast delivery and building for scale. You don't follow the status quo but look for ways to improve how we do things. You are able to talk to technical and business users and explain your work, and are able to be a good partner to your team and to your customers. Building relationships is a priority. Even though our toolstack (Airflow, DBT, Redshift & Looker) are a good start, you will always be in the know on the latest and greatest technology we could utilize. You concentrate on automation and self service. You are also excited to build new products, starting with ideas and all the way to execution. Example of problems you will solve include:
Building tools to automate data anomaly detection and alerting
Scaling our data infrastructure and developing software that allows for improved data processing and automation
Evaluating build vs buy tooling
Scaling Looker as a platform to solve operational use cases as well as increase self service adoption around the company
Evaluating and rearchitecting our data model to support existing and future products
Partnering with external teams to help in data modeling requirements to support analytics
Understanding the needs of external teams, identify pain points and opportunities, and come back with proposals on how data engineering practice can help
Rearchitecting solutions such as Amplitude to allow for faster and more accurate reporting
Partner with the rest of data team to develop best in class software solutions to stand up products based on our data
Carta is a Series E company and is backed by top-tier VCs like Andreessen Horowitz, Lightspeed Venture Partners, Meritech Capital, and more.

We are an equal opportunity employer. As a company, we value fairness, helpfulness, transparency, leadership and build our teams around these values. Check out our careers page to get to know us better as you think about your next step at Carta.

Please read about our candidate privacy policy here.",3.9,"Carta
3.9",Remote,"San Francisco, CA",501 to 1000 employees,2012,Company - Private,Venture Capital & Private Equity,Finance,Unknown / Non-Applicable,-1
"Software Engineer (Data Scientist, C,C++,Linux,Unix) - SISW - MG","$72K-$142K
(Glassdoor est.)","During the current global health crisis, the priority for Siemens Digital Industries Software is the health and well-being of our entire community including current and future employees, which may add time to our hiring processes. We appreciate your patience and invite you to visit our website to learn more about how Siemens is responding to the pandemic.
Company: SISW - MG
Job Title: Software Engineer (Data Scientist, C,C++,Linux) - 189288
Job Location: USA - CA - Fremont
Job Category: R&D SW Engineering

Job Description:

We are looking for a highly motivated engineer to work in the RET team in the Calibre business unit. In this role you will be responsible for analyzing modeling data (experimental and synthetic/simulated) and coming up with novel ways to organize it, while deriving meaningful operations and extracting maximum information from this data.

You will also be expected to develop supporting software that will be properly integrated in the modeling suite of tools that are used specifically in modeling of semiconductor manufacturing.

You will be teaming up with a group of senior software engineers contributing to final production-level quality of new components and algorithms and to support existing components.

This is a unique role that will challenge you and allow you to grow in interdisciplinary areas of software engineering and data analysis.

Knowledge and experience in the area of data science/data analysis is preferred.

Some familiarity with physical modeling of any discipline (e.g. from fields in electrical or mechanical engineering) will be very useful for the suitable candidate.

Job
Qualifications:

The successful candidate will possess the following
combination of education and experience:
BS or
MS in Data Sciences, Computer Science, Electrical Engineering, Physics or
Applied Mathematics.
Working
knowledge in development of C and C++ on UNIX and/or LINUX platforms.
Excellent
programming skills in at least one mainstream scripting language, preferably
Python.
Experience/knowledge
in data analysis.
Experience/knowledge
in machine learning technology.
Experience
with Python, Keras and Tensorflow.
Demonstrated
ability to learn and explore new technologies.
Excellent
analysis and problem-solving skills.
Must
have the ability to collaborate closely with other members of the team and
develop critical components consistently and in a timely manner.
Experience
with MATLAB/R or equivalent mathematical package is expected.
This position may require access to export-controlled technology. If an export license is required and Mentor Graphics elects to apply for such a license, then candidates must be approved and licensed by the applicable government authorities as a condition of employment.

#LI-MGRP
#LI-JE1

Organization: Digital Industries

Company: Mentor Graphics Corporation

Experience Level: Recent College Graduate

Job Type: Full-time

Equal Employment Opportunity Statement
Siemens is an Equal Opportunity and Affirmative Action Employer encouraging diversity in the workplace. All qualified applicants will receive consideration for employment without regard to their race, color, creed, religion, national origin, citizenship status, ancestry, sex, age, physical or mental disability unrelated to ability, marital status, family responsibilities, pregnancy, genetic information, sexual orientation, gender expression, gender identity, transgender, sex stereotyping, order of protection status, protected veteran or military status, or an unfavorable discharge from military service, and other categories protected by federal, state or local law.

EEO is the Law
Applicants and employees are protected under Federal law from discrimination. To learn more, Click here.

Pay Transparency Non-Discrimination Provision
Siemens follows Executive Order 11246, including the Pay Transparency Nondiscrimination Provision. To learn more, Click here.

California Privacy Notice
California residents have the right to receive additional notices about their personal information. To learn more, click here.",4.2,"Mentor Graphics
4.2","Fremont, CA","Wilsonville, OR",5001 to 10000 employees,1981,Company - Public,Computer Hardware & Software,Information Technology,$1 to $2 billion (USD),"Cadence Design Systems, Synopsys, Altium Limited"
Sr. Software Engineer,-1,"Where good people build rewarding careers.

Think that working in the insurance field cant be exciting, rewarding and challenging? Think again. Youll help us reinvent protection and retirement to improve customers lives. Well help you make an impact with our training and mentoring offerings. Here, youll have the opportunity to expand and apply your skills in ways you never thought possible. And youll have fun doing it. Join a company of individuals with hopes, plans and passions, all using and developing our talents for good, at work and in life.
Job Description
We are looking for an engaged and enthusiastic Software Engineer to join our growing Data Science and Engineering team and build out the next generation of our platform. Our team is innovating the tools, technologies, and techniques that enable Allstate to stay on the leading edge of analytics, bring the best data-driven solutions to the enterprise.

We can hire mid and senior level engineers depending on your experience. The ideal candidate is a hands-on Java developer with significant experience in backend applications. Were looking for someone with experience in developing scalable and highly available enterprise-level applications. The candidate must have strong, first-hand technical expertise in a variety of configuration management and web technologies and the proven ability to fashion robust scalable solutions that can manage large data sets. They must be at ease working in an agile environment with little supervision. This person should embody a passion for continuous improvement and test-driven development.

Here's more on what the role entails:
Passion to develop products that people love to use.
Analyze, design and develop enterprise level applications.
Participate in product development in an agile environment.
Collaborate cross-functionally with data scientists, business users, project managers and other engineers to achieve elegant solutions.
Work alongside other engineers on the team to elevate technology and consistently apply best practices.
Identify new technologies to continuously enhance the existing products.
Job Qualifications
Were looking for a Java Engineer with a minimum of 3+ years of experience in B2B. As noted above, we can hire mid and senior level Engineers depending on experience. Candidates need a BS degree in computer science or similar, and the following qualifications:
Solid hands-on experience in Java Development is a must.
Good understanding of building APIs and services using REST.
Experience with test-driven development and automated testing frameworks.
Experience with Scrum/Agile development methodologies.
Capable of delivering on multiple competing priorities with little supervision.
Excellent verbal and written communication skills.
Experience in using build automation technologies like Gradle, Maven, Jenkins.
Following qualifications are a plus
Experience working with Python, R,
Machine Learning knowledge and exposure.
Familiarity with Spring Framework.
Exposure to Cloud Technologies: Pivotal Cloud Foundry, AWS, Docker, and Kubernetes
Exposure to Big Data and Streaming technologies such as: Hadoop, Spark, and Kafka

The candidate(s) offered this position will be required to submit to a background investigation, which includes a drug screen.

Good Work. Good Life. Good Hands®.

As a Fortune 100 company and industry leader, we provide a competitive salary but thats just the beginning. Our Total Rewards package also offers benefits like tuition assistance, medical and dental insurance, as well as a robust pension and 401(k). Plus, youll have access to a wide variety of programs to help you balance your work and personal life -- including a generous paid time off policy.

Learn more about life at Allstate. Connect with us on Twitter, Facebook, Instagram and LinkedIn or watch a video.

Allstate generally does not sponsor individuals for employment-based visas for this position.

Effective July 1, 2014, under Indiana House Enrolled Act (HEA) 1242, it is against public policy of the State of Indiana and a discriminatory practice for an employer to discriminate against a prospective employee on the basis of status as a veteran by refusing to employ an applicant on the basis that they are a veteran of the armed forces of the United States, a member of the Indiana National Guard or a member of a reserve component.

For jobs in San Francisco, please click here for information regarding the San Francisco Fair Chance Ordinance.
For jobs in Los Angeles, please click here for information regarding the Los Angeles Fair Chance Initiative for Hiring Ordinance.

To view the EEO is the Law poster click here. This poster provides information concerning the laws and procedures for filing complaints of violations of the laws with the Office of Federal Contract Compliance Programs

To view the FMLA poster, click here. This poster summarizing the major provisions of the Family and Medical Leave Act (FMLA) and telling employees how to file a complaint.

It is the Companys policy to employ the best qualified individuals available for all jobs. Therefore, any discriminatory action taken on account of an employees ancestry, age, color, disability, genetic information, gender, gender identity, gender expression, sexual and reproductive health decision, marital status, medical condition, military or veteran status, national origin, race (include traits historically associated with race, including, but not limited to, hair texture and protective hairstyles), religion (including religious dress), sex, or sexual orientation that adversely affects an employee's terms or conditions of employment is prohibited. This policy applies to all aspects of the employment relationship, including, but not limited to, hiring, training, salary administration, promotion, job assignment, benefits, discipline, and separation of employment.",3.4,"Allstate
3.4","Charlotte, NC","Northbrook, IL",10000+ employees,1931,Company - Public,Insurance Agencies & Brokerages,Insurance,$10+ billion (USD),"Progressive Insurance, State Farm, Farmers Insurance Group"
Data Engineer,-1,"As a Data Engineer, you'll join our growing team of data scientists and engineers, reporting into Operations organization but working across multiple teams throughout the company. In this role, you(TM)ll be responsible for handling the design and construction of scalable data management systems "" ensuring that all data systems meet our company requirements "" and will also research and recommend new uses for data acquisition. As a Data Engineer, you will implement the data models and data structures needed for each use case, in the most convenient format to be used by the Data Science and Business Intelligence teams. Through regular interactions with stakeholders and functional business unit leaders, you will build high-performance algorithms, predictive models, and prototypes that influence data storage, piping, and usage. Additionally, you will participate in data requirements, modeling and testing activities. Each day will be unique, requiring an ability to think strategically and on your feet, be creative, take initiative, and employ a diverse set of skills.

WHO YOU ARE

Knowledgeable, Analytical, and Solution-Oriented. Without a doubt, you(TM)ve got strong quantitative skills and are comfortable analyzing large data set, spotting trends and patterns, and synthesizing relevant observations. You use a hypothesis-driven approach to engage in analysis that will deliver on your client questions. You like thinking outside the box to come up with innovative points of view on new challenges, relying on your previous analytic work and experience to help guide you along the way.

Results-Oriented. You demonstrate an inherent sense of urgency to drive great results, while being precise in executing your work. You are facile with creating and communicating a clear project plan, tracking progress, and keeping your business partners in the loop along the way.

Intellectually Curious. You're inherently interested in the ""why"" so that you can identify opportunities that represent unconventional solutions to the problems you are trying to solve.

Strong Communicator. Your writing and speaking skills are concise, articulate, and effective, providing an ability to interact with all levels/various teams across the organization, be understood, and develop trust and rapport within the organization.

Technologically Savvy. Microsoft Excel is a basic tool to you that you know like the back of your hand. You also have a strong skill set in R, Python, ArcGIS, machine learning, neural networks and/or other advanced analytics tools and techniques.

A Trusted Team Player. You enjoy partnering with others and build constructive working relationships that foster the collaboration necessary to deliver great results. You are accountable to your teammates and follow through on commitments.

Organized and Confident. You are flexible, composed, and able to prioritize multiple tasks and deadlines simultaneously, while confidently interacting with a variety of individuals, across all levels of the organization. You handle pressure well and do so with confidence.

WHAT YOU(TM)LL DO

Create data models and data processes, providing the right format and structure for use case solutions.

Participate in early data modeling and testing for use case development, providing input on how to improve proposed solutions and implement necessary changes.

Help to build, document, and maintain best practices, including but not limited to codebase management, work and issue tracking, testing and quality control/assurance measures, data dictionaries, and a documentation hub for both production level code and ad hoc analyses.

Interact with stakeholders and functional subject matter experts to understand all data requirements in order to develop effective business insights and translate them into actionable data structures and data models.

Assemble large, complex data sets that meet both functional and non-functional business requirements.

Extract relevant data to solve analytical challenges the organization and/or functional business units may face.

Work closely with IT teams on internal data acquisition (e.g., CRM, ERP, etc.).

Partner with stakeholders to provide technical support related to data structures, data models, data management and data infrastructure needs.

Work with data and analytics experts to strive for greater functionality in our data systems. Recommend different ways to constantly improve data reliability and quality.

Research new uses for existing data.

Create data tools for Business Intelligence, Analytics and Data Scientist team members that assist them in building and optimizing our Company use of data.

Collaborate regularly with key stakeholders to support and enhance the day-to-day operations of our business.

Produce various reports for stakeholders, as requested, to highlight areas of opportunity; works with teams to develop and implement changes, as needed.

Develop and maintain formal documentation that describes data and data structures, including data modeling.

PREVIOUS EXPERIENCE & REQUIREMENTS

Bachelor's Degree required, preferably in computer science, software/computer engineering, applied mathematics, or physics statistics.

Minimum 2 years data modeling experience and working with data management systems; deep expertise in data modeling and structuring required.

2+ years experience in high volume data environments and core data engineering activities (i.e. familiarity with cloud database set up, automation scheduling using directed acyclic graph (such as Airflow) and database optimization, including but not limited to partitioning, group and sort keys, and indexes).

Familiarity with a broad base of analytical methods e.g. data modeling (variable transformation and summarization) and processing (i.e. Spark, SQL Server, Hadoop/Hive, neo4j, etc).

Strong attention to detail and ability to think critically/conceptually.

Team oriented and flexible with proven track record in collaborating with multiple stakeholders.

Effective written and verbal communication skills required. Demonstrated ability to quickly learn new technologies a must.

Ability to think creatively when problem solving for new solutions and to work on numerous projects concurrently while effectively prioritizing workload. Tolerance for ambiguity required.

Tools/software:

Familiarity with data loading and management tools (i.e. Azure Storage""BlockBlob and relational and NoSQL databases and tools such as SQL Server, MongoDB, Data Stax, etc) required.

Must have programming and/or scripting experience (Python, Java) as well as experience with version control systems (Git/GitHub), continuous integration (circleCI) and other programming frameworks/approaches.

Proficiency in MS and Google application suites.

Must be available for overnight travel (approximately 10%)

Authorization to work in the US (without need for Visa sponsorship from employer) is required.",5.0,"CultureFit Technology Staffing
5.0","Chicago, IL","Deerfield, IL",1 to 50 employees,1997,Company - Private,Advertising & Marketing,Business Services,$1 to $5 million (USD),-1
Senior React UI Engineer,"$88K-$199K
(Glassdoor est.)","About us;

LogRhythm, a Thoma Bravo company is a world leader in NextGen SIEM, empowering thousands of enterprises on six continents to successfully reduce cyber and operational risk by rapidly detecting, responding to and neutralizing damaging cyberthreats. LogRhythm's technology serves as the foundation for the world's most modern enterprise security operations centers (SOCs), helping customers measurably secure their cloud, physical, and virtual infrastructures for both IT and OT environments. Built for security professionals by security professionals, the LogRhythm NextGen SIEM Platform has won countless customer and industry accolades.

Who we are looking for;

We are looking to add a Senior React UI Engineer to our team for development on our next generation greenfield project. Our product is designed to significantly reduce the time required to detect and respond to threats, enabling organizations to neutralize these threats before they cause a damaging cyber incident or data breach

We have pioneered a holistic approach to security intelligence that sits at the intersection of advanced cyber-security and Big Data analytics. Our highly scalable, purpose-built platform collects, classifies and contextualizes petabytes of machine and forensic data from across the extended IT and operational environment. We use correlation-based as well as Machine Learning technology to continuously and in real-time analyze this contextualized data to detect cyber-threats, including those that Big Data analytics are best positioned to detect. We also provide robust forensic analytics and centralized search capabilities that enable security and operational personnel to rapidly investigate and respond to threats.

You'll have the opportunity to work with a talented team of professionals, including software developers, UX researchers, designers, QA engineers, and data scientists. As a Senior Software Engineer, take pride in delivering an award-winning user experience to our customers and believe that a challenging and fun work environment is essential to this goal.

Here's an overview of the responsibilities & challenges ahead;
Development of front-end client application code in React, utilizing micro front-end architecture
Foster a collaborative, team-oriented, agile environment.
Evaluate new tools and technologies, and influence adoption across the broader Engineering organization.
Improve Engineering delivery through all phases of the software development lifecycle (build, test, and release).
Ability to successfully mentor other team members in growing their skills/careers.
Understand the product, our customers, and their needs.
Have a passion for beautiful, usable interfaces.
Required Skills:
Five (5) or more years of professional experience writing large, scalable and performant business applications in JavaScript.
Demonstrable experience and fluency with React.
Work well in a close-knit, ego-free team environment.
Outstanding attention to detail and software quality.
Solid written and verbal communication skills.
B.S. degree in Computer Science, a related field, or equivalent experience.
Workplace equality & inclusion are not just words or topics for LogRhythm, they are part of our core values, beliefs, and integral to our company culture. We hire the best of the best and do not discriminate based on race, gender, age, religion, sexual orientation, identity, or other personal factors. LogRhythm was built on the principals of innovation, dedication, creativity, and commitment. It is through these key areas we were able to grow as an equal and inclusive workplace, one where our employees feel respected and safe in.",3.5,"LogRhythm
3.5","Boulder, CO","Boulder, CO",501 to 1000 employees,2003,Company - Private,Computer Hardware & Software,Information Technology,$100 to $500 million (USD),"IBM, McAfee, Splunk"
"Lead Data Scientist - NLP, Machine Learning",-1,"Lead Data Scientist - NLP, Machine Learning We are disrupting enterprise analytics and business intelligence by killing dashboards. We transform enterprise data into actionable natural language insights for business leaders. Our mission is to empower all businesses to tell their own data story. Top Reasons to Work with Us Based in Santa Monica, we have successfully closed our seed funding and are looking for our first hires. Our founders have led teams at Facebook and PayPal and have built core technologies at several startups that have had successful exits. What You Will Be Doing As a Sr. Data Scientist, you will be working closely with the clients and our engineering team to build our product that auto-generates actionable business insights. You will be creating algorithms that analyze business data at scale for several different kinds of businesses. You must have an expertise in end-to-end data analytics processes from ETL to executive level presentations. -Business / Performance Forecasting -Designing and evaluating experiments -Identifying new levers to help move key metrics -Monitoring key product metrics -Evaluating and defining metrics -Understanding root causes of changes in metrics -Building and analyzing dashboards and reports -Building key data sets to empower operational and exploratory analysis -Understanding ecosystems, user behaviors, and long-term trends -Building models of user behaviors for analysis or to power production systems -Influencing product teams through presentation of data-based recommendations -Communicating state of business, experiment results, etc to product teams -Spreading best practices to analytics and product teams What You Need for this Position -2+ years' experience doing quantitative analysis at a top-tier tech company -BA/BS in Computer Science, Math, Physics, Engineering, Statistics or another technical field from top-tier institution (Graduate degrees preferred) -Experience in SQL. -Development experience in Python or R -Ability to communicate the results of analyses with product and leadership teams -Understanding of statistics (e.g., hypothesis testing, regressions) -Experience manipulating data sets through statistical software (ex. R, Pandas) or other methods -Experience with distributed computing Spark/Hadoop -Experience with Amazon Redshift and Athena is a plus What's In It for You -Competitive benefits package (including Healthcare, Dental, Vision) -Help shape and grow a venture-backed tech company from the ground floor -Life Insurance -15 days of PTO per year -unlimited sick days -paid holidays -401k Retirement Savings Plan -Free snacks and drinks -Professional Development -Performance Bonuses -Equity Package -Relocation costs (if applicable) So, if you are a Senior Data Engineer with experience, please apply today! - Applicants must be authorized to work in the U.S.
CyberCoders, Inc is proud to be an Equal Opportunity Employer

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, protected veteran status, or any other characteristic protected by law.

Your Right to Work In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification document form upon hire.

CyberCoders will consider for Employment in the City of Los Angeles qualified Applicants with Criminal Histories in a manner consistent with the requirements of the Los Angeles Fair Chance Initiative for Hiring (Ban the Box) Ordinance.",4.2,"CyberCoders
4.2","Santa Monica, CA","Irvine, CA",201 to 500 employees,1999,Subsidiary or Business Segment,Staffing & Outsourcing,Business Services,$100 to $500 million (USD),-1
Senior Software Engineer - Backend,-1,"Freenome is hiring a Senior Software Engineer - Backend to develop software to combat cancer and other age-related diseases. You will work as part of an interdisciplinary team of engineers and scientists building end-to-end solutions for our ML team and clinical and R&D labs.

At Freenome, we're building a multi-omics platform that ingests clinical-grade, high-dimensional, biological data for early cancer detection. We're a diverse group of Engineers building tools and services which enable our Molecular and ML Scientists to turn great research into even better products. We will create actionable insights for health systems and will guide change for the way doctors think about early detection of colon cancer.

As a member of a fast-growing team, you'll take the lead on major projects and collaborate actively with our world-class team of engineers, scientists, designers, and product managers. You'll build reliable, maintainable, scalable, and fault-tolerant backend services that enable the rapid growth of our business and our mission to save lives.

Depending on your skills and our needs you'll be working on projects including ML platform development, job scheduler development, EMR system integration, and data CRUD operations and ETL. Our systems are built using the latest web software development technologies and methodologies.

Responsibilities:
Design, develop, and deploy reliable, maintainable, scalable, and fault-tolerant backend services that power both our internal and external systems
Collaborate with team members for code and design review
Work with scientists, designers, product managers, and other engineers to solve complex problems in the face of lots of dynamism and uncertainty
Take a mindful, transparent, and humane approach to your work and your interactions with others
Guide and champion engineering hygiene and culture as a core part of the engineering backbone
What We're Looking For:
5+ years of experience as a part of a software development team successfully shipping a software product
BS, MS, or PhD in Computer Science, Engineering or related field, or equivalent training, fellowship, and/or work experience
Experience with Python or similar scripting language
Excellent written and verbal communication skills
Direct experience with web service development
The ability to thrive in an environment where collaboration, communication, and compromise are an expected part of your day-to-day work
A mindful, transparent, and humane approach to your work and your interactions with others
Nice to Haves:
Expertise with Python
Experience with SQLAlchemy, Flask, or Django frameworks
Experience in Kubernetes, Docker, PostgreSQL, Google Cloud Platform
Previous experience leading teams or managing projects
Understanding of, and practical experience with, statistical and machine learning methods
Domain-specific experience in computational biology, genomics or a related field
Direct experience with clinical interoperability standards such as FHIR, IHE ITI Profiles or HL7v2
About Freenome

Freenome is on a mission to empower everyone with the tools they need to detect, treat, and ultimately prevent diseases.

By applying advanced machine learning techniques to recent breakthroughs in genomic science, Freenome is developing simple blood tests to detect early-stage cancer and make treatments more effective. The company has raised $238 million from investors such as RA Capital, Polaris Partners, Perceptive Advisors, Andreessen Horowitz, funds and accounts advised by T. Rowe Price Associates, Inc., GV (formerly Google Ventures), Roche Venture Fund, Kaiser Permanente Ventures, American Cancer Society's BrightEdge Ventures, Data Collective Venture Capital, Novartis and Verily Life Sciences (formerly Google Life Sciences).

Our Science

Freenome is building technology to gain an understanding of the body through several analytes derived from blood. These signals include cell-free DNA, methylation of cell-free DNA, cell-free RNA, circulating proteins, and immune profiling derived from thousands of prospective samples. By developing novel statistical learning methods and applying them to integrate various -omics datasets, Freenome is a leader in modeling specific biological mechanisms to capture disease dependent signatures such as gene expression, immune response, tumor burden, the tissue of origin, and 3D chromatin structure.

By building comprehensive discovery datasets and modeling critical biological systems, Freenome is learning what biological changes are present within the blood between a variety of different disease states including cancer, autoimmune disorders, infections, drug response, and aging. With the combination of Freenome's datasets, cross-functional technical expertise, and mission to uncover the biological truth, we seek to positively change the lives of millions through the early detection and early treatment of disease.

Our Culture

Freenomers are technical and creative, visionary and grounded, empathetic and passionate. We build teams around divergent expertise, which allows us to solve problems and uncover opportunities in unique ways. Freenomers are some of the most talented experts in their fields, coming together to advance healthcare one breakthrough at a time.

We value empathy, integrity, and trust in one another. That means embracing other's perspectives, those of our coworkers and those of the patients and communities we serve. It means knowing when to push, and when to listen. At Freenome, we give each other the benefit of the doubt in the belief that we're all working as a team toward the same goals, and empower others to grow in a collaborative environment.

What does a successful person look like at Freenome?

Those who thrive at Freenome prioritize, manage, and execute their own goals in alignment with those of the company. They embrace our values of empathy, integrity, and trust, and hold themselves and their team accountable. They crave collaboration with brilliant minds from unfamiliar fields of study and believe that hiring and mentorship are fundamental to our success. Above all, they welcome and provide constructive feedback and criticism, trusting in the good intentions of others, and secure in the knowledge that embracing mistakes is the best way to learn and move on. For those who crave challenges, understudied problems, and the chance to see their work impact the lives of millions of people affected by cancer every year, there's no better place to be.

Freenome is proud to be an equal opportunity employer, we value diversity in every way. Freenome does not discriminate on the basis of race, religion, color, sex, gender identity, sexual orientation, age, non-disqualifying physical or mental disability, national origin, veteran status or any other basis covered by appropriate law.",5.0,"Freenome
5.0","South San Francisco, CA","South San Francisco, CA",51 to 200 employees,2014,Company - Private,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,Unknown / Non-Applicable,-1
Senior Software Engineer - DevOps,-1,"Position Overview

Beyond Limits product organization is seeking a high-energy, creative and passionate Sr DevOps Engineer to join our team. This position is a hybrid of DevOps and CloudOps, and entails working with product engineering to build out efficient development and cloud infrastructure systems interfacing with cutting-edge A.I. (Artificial Intelligence) technologies. This role has exposure to many different technologies and business verticals creating huge room for learning and professional growth.

Job Duties/Responsibilities
Build the development pipeline for efficiently & regularly deploying code to production
Design, administer, deploy and manage systems and services on the AWS cloud
Develop highly repeatable processes and have a keen interest in automation
Collaborate in an agile manner with engineers, data scientists, and other cross-functional teams to improve maintainability and reliability of services. Enhance team’s technical capabilities as it pertains to the DevOps culture.
Build effective monitoring, alerts, logging and metrics for production services
Serve as a technical SME for cloud services, providers, and platforms
Ensure compliance with appropriate security standards
Minimum Qualifications
BS or MS in Computer Science or a related degree
8 or more years of experience in DevOps and/or Cloud engineering, or in software engineering with strong exposure to DevOps and CloudOps practices
Passionate about Continuous Build, Integration, Test, and Delivery systems
Strong knowledge of infrastructure and automation of CI/CD pipelines using tools such as Jenkins, Harness, Maven, Nexus/Artifactory or equivalent
Be well versed in administration tasks of managing Docker images, container orchestration on Docker and Kubernetes or equivalent
Deep knowledge of major cloud technologies & concepts such as virtualization, containers, networking, etc.
Strong programming and scripting fundamentals – Python, Terraform, Shell or equivalent
Demonstrated work with one or more Cloud providers (AWS, Azure, Google)
Preferred Requirements
Experience using configuration management tools such as Chef, Ansible, Puppet, etc.
Familiarity with Security Ops topics in the cloud such as intrusion, penetration, and vulnerability scanning
Understanding of Network & Switches, VPN, Direct Connect, Routing, Firewalls
Experience in cloud technology architecture & service management as it pertains to resiliency and disaster recovery is a plus
About Beyond Limits

Beyond Limits is a pioneering Artificial Intelligence engineering company creating advanced software solutions that go beyond conventional AI. Founded in 2014 with a legacy in space exploration, Beyond Limits is transforming proven technologies from Caltech and NASA’s Jet Propulsion Laboratory into advanced AI solutions, hardened to industrial strength, and put to work for forward-looking companies on earth. We leverage this unparalleled innovation portfolio, along with proprietary cognitive technologies, to help companies solve tough, complex, mission-critical problems and transform their business. We apply a unique hybrid approach to AI, combining numeric AI techniques like machine learning with higher order symbolic AI and expert human knowledge to deliver intuitive cognitive reasoning and information. Our cognitive computing technology mimics human thought processes and provides explainable reasoning to aid human-like decision-making.

Beyond Limits provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability or genetics. In addition to federal law requirements, Beyond Limits complies with applicable state and local laws governing nondiscrimination in employment in every location in which the company has facilities. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.

Beyond Limits expressly prohibits any form of workplace harassment based on race, color, religion, gender, sexual orientation, gender identity or expression, national origin, age, genetic information, disability, or veteran status. Improper interference with the ability of Beyond Limit’s employees to perform their job duties may result in discipline up to and including discharge.",4.2,"Beyond Limits
4.2","Glendale, CA","Glendale, CA",51 to 200 employees,2014,Company - Private,Research & Development,Business Services,Unknown / Non-Applicable,-1
Software Engineer,"$71K-$146K
(Glassdoor est.)","Feedzai is the market leader in managing financial risk with AI. We're coding the future of commerce with today's most advanced risk management platform powered by big data and machine learning. Founded and developed by data scientists and aerospace engineers, Feedzai has one mission: to make banking and commerce safe. The world's largest banks, processors, and retailers use Feedzai's fraud prevention and anti-money laundering products to manage risk, while improving customer Experience.

The Customer Success team ensures our global customers achieve their business goals using our product. Everything you do matters: all your code, machine learning models, advisory, management, and other actions/roles will have a material impact on the way our clients run their business and how effectively we fight fraud and protect people from wrongdoing. You will be able to interact and meet many people from widely different cultures around the world and understand the business like few others. You will be able to say you protect people on a daily basis. You will be challenged with new technology, new processes, and new mindsets and will be asked to contribute to ensure continuous improvement. Come and change the world with us.

Responsibilities:
Execute full software development life cycle
Develop flowcharts, layouts and documentation to identify requirements and solutions
Write well-designed, testable code
Integrate software components into a fully functional software system
Troubleshoot, debug and upgrade existing systems
Deploy and support systems in production
Comply with best practices and industry standards
Requirements:
7+ years of professional experience in Java software development
BS or MS in computer science, or a comparable field, or equivalent experience
Project/ team leading experience
Excellent English communication skills, both verbal and written
Availability to travel up to 10%
Experience with Zookeeper, RabbitMQ, Cassandra, Ansible or Docker
Experience in the financial services, payments industry or e-commerce is a plus!
Feedzai is an equal opportunity Employer

Feedzai does not accept unsolicited resumes from recruiters or employment agencies",3.6,"Feedzai
3.6","Atlanta, GA","San Mateo, CA",201 to 500 employees,2009,Company - Private,Computer Hardware & Software,Information Technology,$50 to $100 million (USD),-1
Senior Software Engineer - DevOps,-1,"Position Overview

Beyond Limits product organization is seeking a high-energy, creative and passionate Sr DevOps Engineer to join our team. This position is a hybrid of DevOps and CloudOps, and entails working with product engineering to build out efficient development and cloud infrastructure systems interfacing with cutting-edge A.I. (Artificial Intelligence) technologies. This role has exposure to many different technologies and business verticals creating huge room for learning and professional growth.

Job Duties/Responsibilities
Build the development pipeline for efficiently & regularly deploying code to production
Design, administer, deploy and manage systems and services on the AWS cloud
Develop highly repeatable processes and have a keen interest in automation
Collaborate in an agile manner with engineers, data scientists, and other cross-functional teams to improve maintainability and reliability of services. Enhance team’s technical capabilities as it pertains to the DevOps culture.
Build effective monitoring, alerts, logging and metrics for production services
Serve as a technical SME for cloud services, providers, and platforms
Ensure compliance with appropriate security standards
Minimum Qualifications
BS or MS in Computer Science or a related degree
8 or more years of experience in DevOps and/or Cloud engineering, or in software engineering with strong exposure to DevOps and CloudOps practices
Passionate about Continuous Build, Integration, Test, and Delivery systems
Strong knowledge of infrastructure and automation of CI/CD pipelines using tools such as Jenkins, Harness, Maven, Nexus/Artifactory or equivalent
Be well versed in administration tasks of managing Docker images, container orchestration on Docker and Kubernetes or equivalent
Deep knowledge of major cloud technologies & concepts such as virtualization, containers, networking, etc.
Strong programming and scripting fundamentals – Python, Terraform, Shell or equivalent
Demonstrated work with one or more Cloud providers (AWS, Azure, Google)
Preferred Requirements
Experience using configuration management tools such as Chef, Ansible, Puppet, etc.
Familiarity with Security Ops topics in the cloud such as intrusion, penetration, and vulnerability scanning
Understanding of Network & Switches, VPN, Direct Connect, Routing, Firewalls
Experience in cloud technology architecture & service management as it pertains to resiliency and disaster recovery is a plus
About Beyond Limits

Beyond Limits is a pioneering Artificial Intelligence engineering company creating advanced software solutions that go beyond conventional AI. Founded in 2014 with a legacy in space exploration, Beyond Limits is transforming proven technologies from Caltech and NASA’s Jet Propulsion Laboratory into advanced AI solutions, hardened to industrial strength, and put to work for forward-looking companies on earth. We leverage this unparalleled innovation portfolio, along with proprietary cognitive technologies, to help companies solve tough, complex, mission-critical problems and transform their business. We apply a unique hybrid approach to AI, combining numeric AI techniques like machine learning with higher order symbolic AI and expert human knowledge to deliver intuitive cognitive reasoning and information. Our cognitive computing technology mimics human thought processes and provides explainable reasoning to aid human-like decision-making.

Beyond Limits provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability or genetics. In addition to federal law requirements, Beyond Limits complies with applicable state and local laws governing nondiscrimination in employment in every location in which the company has facilities. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.

Beyond Limits expressly prohibits any form of workplace harassment based on race, color, religion, gender, sexual orientation, gender identity or expression, national origin, age, genetic information, disability, or veteran status. Improper interference with the ability of Beyond Limit’s employees to perform their job duties may result in discipline up to and including discharge.",4.2,"Beyond Limits
4.2","Glendale, CA","Glendale, CA",51 to 200 employees,2014,Company - Private,Research & Development,Business Services,Unknown / Non-Applicable,-1
Senior Front-End Engineer,-1,"Join our team of leading engineers, researchers, and data scientists who are building the next generation AI-assisted customer analytics technology. Syntasa leverages proven streaming, machine learning, visualization, and big data technologies to process billions of records in real-time, resulting in actionable intelligence that improves acquisition, conversion, and retention. This provides a unique opportunity to be a part of a growing team in a fast-paced and evolving environment that delivers business impacts from data-driven recommendations.

As a Senior Front-End Engineer, you will develop new features and improvements across the Syntasa application. You will work closely with the UX design team to build and design browser-based experiences that are easy to understand and use. Every day you will be coding in TypeScript using Angular and writing tests in Jest. You will be performing code reviews for your peers and leading the development effort for the front end. As the team grows, you'll have an opportunity to take on a management role if you so desire. You'll also have the opportunity to work on the back-end in a Node.js environment.

IN THIS ROLE, YOU WILL:
Take features from design to implementation
Build reusable code and libraries
Review pull requests and mentor junior engineers
Collaborate with other team members and stakeholders
Work with data scientists and back-end engineers to build and design new features
Build efficient and reusable front-end systems and abstractions
Find and address performance issues
Participate in design and code reviews
Identify and communicate front-end best practices
REQUIRED QUALIFICATIONS:
5+ years of industry front-end experience
2+ years’ experience with modern front-end frameworks like Angular, React, Vue, etc
Proficiency in JavaScript/Typescript, and JavaScript design patterns
Advanced knowledge of HTML and CSS (SCSS) and the features in the latest versions
Awareness of cross-browser compatibility issues and client-side performance considerations
Demonstrated design and UX sensibilities
Version control experience of Git, Unit
Unit testing using Jest or similar
PREFERRED QUALIFICATIONS:
Demonstrated expertise in Angular, React or Vue
Bachelor’s in Computer Science or relevant experience
Working experience with various JavaScript environments, such as Node.js
Strong communication abilities with team members as well as clients (i.e. software features and issues)
Strong sense of ownership and drive
Syntasa provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability or genetics.",4.7,"Syntasa US
4.7","Herndon, VA","Herndon, VA",1 to 50 employees,2014,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Federal - Big Data Engineer,-1,"Organization: Accenture Federal Services
Location: Arlington, VA - Washington, DC

Accenture Federal Services, a wholly owned subsidiary of Accenture LLP, is a U.S. company with offices in Arlington, Virginia. Accenture's federal business has served every cabinet-level department and 30 of the largest federal organizations. Accenture Federal Services transforms bold ideas into breakthrough outcomes for clients at defense, intelligence, public safety, civilian and military health organizations.
We believe that great outcomes are everything. Its what drives us to turn bold ideas into breakthrough solutions. By combining digital technologies with what works across the worlds leading businesses, we use agile approaches to help clients solve their toughest problems fastthe first time. So, you can deliver what matters most.
Count on us to help you embrace new ways of working, building for change and put customers at the core. A wholly owned subsidiary of Accenture, we bring over 30 years of experience serving the federal government, including every cabinet-level department. Our 7,200 dedicated colleagues and change makers work with our clients at the heart of the nations priorities in defense, intel, public safety, health and civilian to help you make a difference for the people you employ, serve and protect.

AFS is seeking a Big Data Engineer to support our Federal portfolio. This role involves supporting the full software development lifecycle, utilizing emerging technologies and big data design principles in developing data pipelines, interfaces, and architecture to support big data and analytics initiatives. The candidate will work with other engineers, data analysts, data scientists, and data visualizers to bring powerful analytical solutions and insights to our clients.
Basic Skills and Qualifications:
Experience with Data Engineering or Big Data Technologies, or Data Transformation, and modeling
Experience in architecting and building scalable data platforms
Experience with Cloud Technologies (Data Lake, Azure, Google, AWS etc.) or experience with open source technologies (Spark, Kafka, Presto, Hive, Cassandra etc.)
Experience with SQL and/or NOSQL databases
Must be a US Citizen; no dual citizens

Preferred Skills and Qualifications:
Production implementation experience for all qualifications listed
Production experience in building real-time analytics applications
Experience in both batch and stream processing technologies
Experience with 2 of 3 - Java, Scala, and Python programming languages
Machine learning experience with Spark or similar
Ability to manage numerous requests concurrently and be able to prioritize and deliver
Good communication skills
Dynamic team player
Bachelors Degree

An active security clearance or the ability to obtain one may be required for this role.
Candidates who are currently employed by a client of Accenture or an affiliated Accenture business may not be eligible for consideration.
Applicants for employment in the US must have work authorization that does not now or in the future require sponsorship of a visa for employment authorization in the United States and with Accenture (i.e., H1-B visa, F-1 visa (OPT), TN visa or any other non-immigrant status).
Accenture is a Federal Contractor and an EEO and Affirmative Action Employer of Females/Minorities/Veterans/Individuals with Disabilities.
Equal Employment Opportunity
All employment decisions shall be made without regard to age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status or any other basis as protected by federal, state, or local law.
Job candidates will not be obligated to disclose sealed or expunged records of conviction or arrest as part of the hiring process.
Accenture is committed to providing veteran employment opportunities to our service men and women.",3.9,"Accenture
3.9","Multiple Locations, USA","Dublin, Ireland",10000+ employees,1989,Company - Public,Consulting,Business Services,$10+ billion (USD),"Cognizant Technology Solutions, EY, McKinsey & Company"
Computer Vision Systems Engineer,-1,"CURRENT EMPLOYEES OR STUDENTS:If you are a current employee (faculty, staff, technical service, or student) at Penn State, please login to Workday to complete the internal application process. If you are a current student at Penn State and seeking employment with Penn State, please login to Workday to complete the student application process.JOB DESCRIPTION AND POSITION REQUIREMENTS:The Electro-Optics Center (EOC), located in Freeport, PA, a Division of The Applied Research Laboratory (ARL) at Penn State University, is seeking an experienced Computer Vision Systems Engineer. This position works closely with a multi-disciplinary team of engineers and scientists to design computer vision and imaging systems supporting various military and intelligence community customers.Responsibilities include:* Lead and contribute to key technical efforts in the development of broad range of novel electro-optical sensor systems, and software and algorithm development for computer vision, image processing, machine learning, data fusion, automated test systems, control systems, and custom graphical user interfaces to push the state of the art of these systems* Guide system development from desk/bench-top and field-testable prototype to transitioned, field-deployable product, and support operationalization of techniques through field integration and testing activities, data analysis, and lab experimentation* Document work in memoranda, sponsor briefs, conference proceedings, and journal articles, and brief senior leadership and sponsors* Work with leadership to develop project/staffing plans, participate in strategic business planning, new business development and internal research and development efforts.This job will be filled as a level 3, level 4, or level 5, depending upon the successful candidate's competencies, education, and experience. Typically requires a Bachelor's degree or higher in an Engineering or Science discipline (Master's degree preferred) or higher plus five years of related experience, or an equivalent combination of education and experience for a level 3. Additional experience and/or education and competencies are required for higher level jobs. A Master's degree in Electrical Engineering, Computer Science or Physics/Optics is desired.Preferred experience areas include:* Fifteen years in a computer vision-related industry, consulting, or academia with some experience building products for Department of Defense or Intelligence Community customers* Real time/embedded application development and control systems theory* CUDA and/or GPGPU computing libraries* Writing software design documents and ICDs* Three dimensional data processing and visualization* GPS and positioning systems* Simultaneous location and mapping (SLAM)* Active or passive remote sensing systems* Distributed Aperture Systems, Visual Augmentation Systems, and EO System Modeling tools* Current Secret clearance with eligibility for TS/SCIRequired experience:* In developing computer vision, imaging systems, or machine learning systems for military or intelligence community customers* Familiarity with remote sensing physics and theory, detection, and estimation theory, image processing, active or passive camera systems, photogrammetry/stereo imaging, metrology and inspection, image display technologies, multispectral and hyperspectral systems, and augmented reality technology;* C and C++, Java, C#, MATLAB or CUDA* Windows, Linux, and real-time operating environments* OpenCV* Interfacing with hardware via an ICDAttributes to be successful in this position include:* Excellent written (including technical writing), verbal, and interpersonal skills, including a comfort level briefing to very senior and large audiences* Strong organizational and planning skills, with a demonstrated ability to effectively lead and inspire high performance teams of technical staff in solving complex problems* A demonstrated ability to collaborate in technical activities, as evidenced by co-authorship of technical papers, presentations, proposals, and white papers with authors from other organizations* Identify as a self-starter in practical initiation and execution of research projects* Holds the ability to work independently or as part of a multidisciplinary team and adapt to changing requirementsCandidate selected will be subject to a government security investigation. You must be a U.S. citizen to apply. Employment with the ARL will require successful completion of a pre-employment drug screen. This is a one-year, fixed-term renewable appointment.ARL is committed to diversity, equity, and inclusion; we believe this is central to our success as a Department of Defense designated University Affiliated Research Center (UARC). We are at our best when we draw on the talents of all parts of society, and our greatest accomplishments are achieved when diverse perspectives are part of our workforce.CAMPUS SECURITY CRIME STATISTICS:Pursuant to the Jeanne Clery Disclosure of Campus Security Policy and Campus Crime Statistics Act and the Pennsylvania Act of 1988, Penn State publishes a combined Annual Security and Annual Fire Safety Report (ASR). The ASR includes crime statistics and institutional policies concerning campus security, such as those concerning alcohol and drug use, crime prevention, the reporting of crimes, sexual assault, and other matters. The ASR is available for review here.EEO is the LawPenn State is an equal opportunity, affirmative action employer, and is committed to providing employment opportunities to all qualified applications without regards to race, color, religion, age, sex, sexual orientation, gender identify, national origin, disability or protected veteran status. If you are unable to use our online application process due to an impairment or disability, please contact 814-865-1473.Affirmative ActionPenn State PoliciesCopyright InformationHotlinesFreeport, PA",4.2,"Penn State University
4.2","University Park, PA","University Park, PA",10000+ employees,1855,College / University,Colleges & Universities,Education,$5 to $10 billion (USD),-1
"Software Engineer (Data Scientist, C,C++,Linux,Unix) - SISW - MG","$57K-$119K
(Glassdoor est.)","During the current global health crisis, the priority for Siemens Digital Industries Software is the health and well-being of our entire community including current and future employees, which may add time to our hiring processes. We appreciate your patience and invite you to visit our website to learn more about how Siemens is responding to the pandemic.
Company: SISW - MG
Job Title: Software Engineer (Data Scientist, C,C++,Linux) - 189288
Job Location: USA - CA - Fremont
Job Category: R&D SW Engineering

Job Description:

We are looking for a highly motivated engineer to work in the RET team in the Calibre business unit. In this role you will be responsible for analyzing modeling data (experimental and synthetic/simulated) and coming up with novel ways to organize it, while deriving meaningful operations and extracting maximum information from this data.

You will also be expected to develop supporting software that will be properly integrated in the modeling suite of tools that are used specifically in modeling of semiconductor manufacturing.

You will be teaming up with a group of senior software engineers contributing to final production-level quality of new components and algorithms and to support existing components.

This is a unique role that will challenge you and allow you to grow in interdisciplinary areas of software engineering and data analysis.

Knowledge and experience in the area of data science/data analysis is preferred.

Some familiarity with physical modeling of any discipline (e.g. from fields in electrical or mechanical engineering) will be very useful for the suitable candidate.

Job
Qualifications:

The successful candidate will possess the following
combination of education and experience:
BS or
MS in Data Sciences, Computer Science, Electrical Engineering, Physics or
Applied Mathematics.
Working
knowledge in development of C and C++ on UNIX and/or LINUX platforms.
Excellent
programming skills in at least one mainstream scripting language, preferably
Python.
Experience/knowledge
in data analysis.
Experience/knowledge
in machine learning technology.
Experience
with Python, Keras and Tensorflow.
Demonstrated
ability to learn and explore new technologies.
Excellent
analysis and problem-solving skills.
Must
have the ability to collaborate closely with other members of the team and
develop critical components consistently and in a timely manner.
Experience
with MATLAB/R or equivalent mathematical package is expected.
This position may require access to export-controlled technology. If an export license is required and Mentor Graphics elects to apply for such a license, then candidates must be approved and licensed by the applicable government authorities as a condition of employment.

#LI-MGRP
#LI-JE1

Organization: Digital Industries

Company: Mentor Graphics Corporation

Experience Level: Recent College Graduate

Job Type: Full-time

Equal Employment Opportunity Statement
Siemens is an Equal Opportunity and Affirmative Action Employer encouraging diversity in the workplace. All qualified applicants will receive consideration for employment without regard to their race, color, creed, religion, national origin, citizenship status, ancestry, sex, age, physical or mental disability unrelated to ability, marital status, family responsibilities, pregnancy, genetic information, sexual orientation, gender expression, gender identity, transgender, sex stereotyping, order of protection status, protected veteran or military status, or an unfavorable discharge from military service, and other categories protected by federal, state or local law.

EEO is the Law
Applicants and employees are protected under Federal law from discrimination. To learn more, Click here.

Pay Transparency Non-Discrimination Provision
Siemens follows Executive Order 11246, including the Pay Transparency Nondiscrimination Provision. To learn more, Click here.

California Privacy Notice
California residents have the right to receive additional notices about their personal information. To learn more, click here.",3.9,"Siemens Healthineers
3.9","Fremont, CA","Erlangen, Germany",10000+ employees,1847,Company - Public,Health Care Services & Hospitals,Health Care,$10+ billion (USD),"GE Healthcare, Roche"
"Advanced Algorithm Engineer, 3D Maps",-1,"Vision

Hivemapper is modern mapping infrastructure. Our machine vision powered mapping tools help forward thinking teams build smarter maps. Maps that see changes. Maps that understand. Some of the world’s most important organizations trust Hivemapper to build their maps that can see.

Who We Are

With just under 20 employees, we are proud to have multiple PhD’s, and alum from top schools like Stanford, UC Berkeley, Cal Poly, lending their expertise to our product and business. Hivemapper is a team of mathematicians, designers, programmers, and scientists from well-known companies like Palantir, Mapbox, and Yahoo, working together to create a modern mapping platform fed by a network of videos. Our work is fast-paced, collaborative, and cross-disciplinary as we focus on solving truly challenging problems. Our team and tech are growing rapidly, we encourage skill development and learning new things, and we love to promote leaders from within.

What We Need

As we improve our technologies in speed, accuracy, information content, flexibility, and many other ways, we only have room for smart, ambitious people with at least some entrepreneurial blood running through their veins.

As a developer of advanced algorithms you will collaborate with teammates across the company to design, develop, test, and deploy sophisticated solutions to a wide variety of challenging problems. The ideal candidate for this role not only has strong technical implementation skills, but a demonstrated fluency in flexible mathematical and algorithmic thinking. We are open to hiring varying levels of experience for this role.
What You'll Do
Research, develop and prototype advanced hardware and software technologies related to 3D reconstruction, photometric stereo, object detection, and point cloud registration.
Develop algorithms for refining and denoising 3D maps and removing dynamic objects
Develop evaluation tools for ensuring the quality of large scale 3D maps
Design and implement 3D scene segmentation algorithms to intelligently map environments using a mix of geometric and deep learning approaches.
What We're Looking For
2+ years of experience, and Masters and above degree in Applied Maths or related field
C++ proficiency
Robust experience in mathematics and algorithms
Proficiency with probabilistic inference and 3D geometry
Nice To Haves
Experience in machine learning, AI, 3D data, high performance computing or other relevant domains.
Strong systems design sense",5.0,"Hivemapper
5.0","San Francisco, CA","Burlingame, CA",1 to 50 employees,2012,Company - Private,Computer Hardware & Software,Information Technology,$5 to $10 million (USD),-1
Sr. Machine Learning Engineer,-1,"Every day our employees make their mark by helping clients better
manage and service their financial assets around the world.
Whether providing financial services for institutions,
corporations or individual investors, clients count on us across
time zones and in 35 countries and more than 100 markets. It's
the collective ambition, innovative thinking and exceptionally
focused client service paired with a commitment to doing what is
right that continues to set us apart.

Client Technology Solutions provides our business partners with
client-focused, technology-based solutions. These enhance their
ability to be successful through world-class software solutions
and leading-edge infrastructure. Client Technology Solutions
provides employees with the tools and resources to enhance their
professional qualifications and careers.

Description
Our Innovation Center is currently seeking Senior Data Scientists
to join our rapidly growing team. We are a startup within an
enterprise, focused on applied research that can be quickly
brought to market as production services and new financial
services products. We are the worlds leading provider of
financial services technology, and current business operations
provide a wealth of fascinating business opportunities and
requirements, as well as terabytes of the worlds most
interesting data science challenges. Help us revolutionize global
financial services!

Responsibilities
You will lead the development and enhancement of the relevance
engine in our new enterprise search platform.

Experience and Skills:
Advanced degree in Computer Science or related field (Masters
required, Ph.D. preferred) with a solid understanding of
Information Retrieval, Learning to Rank, Text Mining and Machine
Learning.
Experience with search engine log analysis and applying Machine
Learning to improve search engine relevance.
Experience in Text Mining, Information Extraction and Document
Classification.
Software development experience with Java.
Experience programming for a search platform like Lucene.
Experience with a scripting language like Python, Perl.
Strong communication and presentation skills; experience in
communicating results of machine learning and statistical
analysis to a broad audience

Make your mark!",-1,Stride Search,"Palo Alto, CA","Westlake Village, CA",1 to 50 employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
"Senior Application Engineer, Backend",-1,"Job Description
Come work alongside some of the most talented minds in the agtech industry. We are a team of innovators who want to make an immediate and significant impact. You will be given the opportunity to work with an amazing group of people who care about each other and their work.

What we are looking for:

At Arable we operate at the intersection of innovative connected hardware, data science, and recommendation systems; and at the center of all of these are the data systems that run our IoT, ML, and application systems. We're building a backend system for our specialized hardware which provides in-field monitoring for agricultural solutions. Our fleet is expanding and we're pushing new technologies like NB-IoT and edge-based machine learning. If you’re motivated by working on complex technical problems, and driven to create a better, more sustainable future, then this is the right place for you.

Come help build the future of agriculture!

What we do:

At Arable, our goal is to connect all the world’s farms and provide the highest-quality data to power predictive analytics that will help optimize the global food system. This is an ambitious goal, but the need has never been greater to rethink how we will feed an ever-growing population and reduce our impact on natural resources. We believe the heart of the solution is digitizing the analog world with high-fidelity data to help food producers optimize their operations. If successful, we hope the impact of our work will improve the lives of farmers everywhere and be a major contribution to securing the global food supply for decades to come.

A few examples of the work we’re doing today:
Helping farmers in India and China through improved insights into crop development
Giving produce growers in California the tools to optimize production with less waste
Helping irrigated farmers in Nebraska manage water more efficiently and sustainably to protect our water supply

What you will do:
Build features and implement robust scalable software in Python and Postgres
Work closely with the backend team to develop new features and APIs
Work closely with QA, Firmware, Data Scientists, and Product management
Be your own DevOps and deploy code to the cloud
What you bring:

Qualifications:

4+ years in cloud-based backend application development
Experience in web services development in Python (Pandas is a plus)
Experience with relational databases and SQL
Experience implementing web-based APIs
Team player with excellent verbal and written communication skills
BSCS, MSCS, or Ph.D. in CS or equivalent experience

Preferred Qualifications:

Experience with cloud infrastructure (AWS a plus)
Experience with Docker and/or Linux environments
Experience with CI/CD
Understanding of REST protocols
Experience with Business Intelligence/Analytics tools

What we offer:

At Arable you will be joining a company of dedicated team players who bring together diverse expertise and a passion for building a more sustainable future. We are a fast-moving startup committed to providing a rewarding employee experience through the work we do, the team, compensation, and benefits including:
Excellent medical, dental, vision, life, disability benefits, and a 401k program
Flexible PTO
A focus on community involvement and career development
Being an intricate part of creating an excellent IoT product in the Agtech space and having a positive impact on the world we live in.

At Arable, we don't just accept difference—we celebrate and support it. Not only because it's the right thing to do, but because we draw on the differences in who we are, what we've experienced, and how we think to make Arable thrive. Arable is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity, gender expression, protected veteran status, and any other characteristic protected under applicable State or Federal laws and regulations.",5.0,"Arable Labs, Inc.
5.0","San Francisco, CA","San Francisco, CA",1 to 50 employees,2014,Company - Private,Farm Support Services,Agriculture & Forestry,Less than $1 million (USD),-1
Big Data Engineer,-1,"Description Robert Half Technology is looking for an experienced Big DataETL Developer in the Great Pennsylvania area. Responsibilities bull Design, develop, optimize, and maintain data architecture and pipelines that adhere to ETL principles and business goals bull Solve complex data problems to deliver insights that helps our business to achieve their goals bull Create data products for analytics and data scientist team members to improve their productivity bull Advise, consult, mentor and coach other data and analytic professionals on data standards and practices bull Foster a culture of sharing, re-use, design for scale stability, and operational efficiency of data and analytical solutions bull Lead the evaluation, implementation and deployment of emerging tools and process for analytic data engineering in order to improve our productivity as a team bull Develop and deliver communication and education plans on analytic data engineering capabilities, standards, and processes bull Partner with business analysts and solutions architects to develop technical architectures for strategic enterprise projects and initiatives. bull Learn about machine learning, data science, computer vision, artificial intelligence, statistics, andor applied mathematics Skills bull Bachelors degree required Computer Science, MIS, or Engineering preferred bull 5 years of experience working in data engineering or architecture role, 7+ preferred bull Expertise in SQL and data analysis and experience with at least one programming language (PythonPySpark or Scala preferred) bull Exposure to machine learning, data science, computer vision, artificial intelligence, statistics, andor applied mathematics Requirements ETL, Python, Hadoop, BigQuery, Tableau, Power BI, Apache Hive, Impala, Apache Spark Robert Half Technology matches IT professionals with some of the best companies on a temporary, project or full-time basis. From roles in software and applications to IT infrastructure and operations, we provide you unparalleled access to exciting career opportunities. Our personalized approach, innovative matching technology and global network with local market expertise help you find the technology jobs that match your skills and priorities - fast. By working with us, you have access to challenging opportunities, competitive compensation and benefits, and training to enhance your skill sets. From philanthropy to environmental stewardship to employee programs, Robert Half is proud to have an active role in the communities in which we live and work. Our company has appeared on FORTUNE's ""Most Admired Companies"" list every year since 1998. Download our mobile app to take your job search on the go! Contact your local Robert Half Technology office at 888.490.4429 or visit www.roberthalf.comjobstechnology to apply for this job now or find out more about other job opportunities. All applicants applying for U.S. job openings must be authorized to work in the United States. All applicants applying for Canadian job openings must be authorized to work in Canada. 2020 Robert Half Technology. An Equal Opportunity Employer MFDisabilityVeterans. By clicking 'Apply Now' you are agreeing to Robert Half Terms of Use httpswww.roberthalf.comterms-of-use .",3.5,"Robert Half
3.5","Allentown, PA","Menlo Park, CA",10000+ employees,1948,Company - Public,Staffing & Outsourcing,Business Services,$2 to $5 billion (USD),"Adecco, Manpower"
Sr. Software Development Engineer,"$107K-$162K
(Glassdoor est.)","Alexa is the groundbreaking cloud-based intelligent agent that powers Echo and other devices designed around your voice. Our mission is to push the envelope in Artificial Intelligence (AI), Natural Language Understanding (NLU), Machine Learning (ML), Dialog Management, Automatic Speech Recognition (ASR), and Audio Signal Processing, in order to provide the best-possible experience for our customers. Were looking for a Software Development Engineer to help build industry-leading conversational technologies that customers love.

As a Software Development Engineer for the Alexa team, you will be responsible for translating business and functional requirements into concrete deliverables with the design, development, testing, and deployment of highly scalable distributed services. You will also partner with scientists and platform engineers to help invent, implement, and connect sophisticated algorithms to our cloud based engines. A successful candidate should have knowledge of research domains including AI, NLU, ML, and Dialog Management. They should also be very agile in developing flexible software with respect to scientific, experimentation methods and usage patterns. Additional responsibilities include:

· Developing and maintaining core system features
· Helping define product features, drive the system architecture, and spearhead the best practices that enable a quality product
· Working with scientists and other engineers to investigate design approaches, prototype new technology, and evaluate technical feasibility
· Operate in an Agile/Scrum environment to deliver high quality software against aggressive schedules.


Basic Qualifications

· 3+ years of programming experience with at least one modern language such as Java, C++, or C# including object-oriented design
· 2+ years of experience contributing to the architecture and design (architecture, design patterns, reliability and scaling) of new and current systems
· 4+ years of professional software development experience
· Bachelor's degree in Electrical Engineering, Computer Sciences, Mathematics, or related technical field
· Knowledge of programming languages such as C/C++, Java, Perl or Python and open-source technologies (Apache, Hadoop)
· Experience with OO design and common design pattern
· Knowledge with data structures, algorithm design, problem solving, and complexity analysis
· Experience defining system architectures and exploring technical feasibility trade-offs

Preferred Qualifications

· MS in Computer Science
· Experience developing cloud software services and an understanding of design for scalability, performance and reliability.
· Development experience defining, developing and maintaining REST based interfaces.
· Excellence in technical communication with peers and non-technical cohorts.
· Sharp analytical abilities and proven design skills.
· Strong sense of ownership, urgency, and drive.
· Demonstrated leadership abilities in an engineering environment in driving operational excellence and best practices.
· Demonstrated ability to achieve stretch goals in a highly innovative and fast paced environment.

Amazon is an Equal Opportunity Employer Minority / Women / Disability / Veteran / Gender Identity / Sexual Orientation / Age",3.9,"Amazon
3.9","Sunnyvale, CA","Seattle, WA",10000+ employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),"Google, Microsoft, Walmart"
"Senior Software Engineer, Backend","$126K-$193K
(Glassdoor est.)","Mercari is the selling app. We make it super easy to sell (or buy) almost anything. We all have things we don't use, never used or simply outgrew. But that stuff still has value. Mercari gives you the power to simply sell it, ship it, and earn some cash for it. Fashion to toys. Sporting goods to electronics. All the brands you know and love. Our mission is simple: to make selling easier than buying. And with 45M+ downloads in the U.S. and 225k new listings every day, we're just getting started.

We are aggressively growing our Backend team to develop large-scale systems with the latest technology.

What you'll be doing:
Coding in Go and PHP
Design, develop, test, deploy, maintain, and improve the backend system for our product
Design distributed systems with microservices architecture running on Kubernetes
Work with Product Managers and Designers for the design and specification of our product
Collaborate with iOS, Android, Web, Machine Learning, and Data engineers to develop new features on our product
Collaborate with QA Engineers to test and deliver the feature with high-quality and high-speed
Solve complex performance problems and architectural challenges
Write and maintain technical documentation
Manage own project requirements, deadlines, and qualities
Mentor software engineers in the same team or project
Requirements:
6+ years of experience in software engineering
Full-time working experience as software engineer with consumer applications
Excellent knowledge of data structures and algorithms
Experience with developing complex software systems scaling to millions of users with production quality deployment, monitoring, and reliability
Experience designing, developing, and managing microservices
Knowledge of software testing and the ability to write testable code and proper tests
An insatiable desire and ability to learn with a positive attitude
Ability to collaborate with team members including Product Managers, Data Scientists, Designer, Engineers, and QA Engineers to solve complex business problems
Ability to mentor engineers in an open, respectful, flexible, and empathetic manner
Nice-to-haves:
Deep knowledge of Go or PHP
Proficient computer science background such as a bachelor's, master's, or Ph.D. degree
Strong knowledge of container and orchestration technologies like Docker and Kubernetes
Experience working on cloud infrastructures like GCP or AWS
Technologies We Use:
Databases: Cloud Spanner & MySQL
Programming Language: Go & PHP
Containers & Orchestration: Docker, Kubernetes
Web Services & Hosting: Google Cloud Platform (GCP) & Amazon Web Services (AWS)
Perks:
Competitive medical, dental, and vision insurance options
401k match
Life & disability insurance
Employee Assistance Program
New parent paid leave
Rocket Lawyer legal services
Fond perks and rewards
Commuter reimbursement
Time when you need it - flexible vacation days
Catered lunches everyday
Team outings and events",2.7,"Mercari
2.7","Palo Alto, CA","Tokyo, Japan",1001 to 5000 employees,2013,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Senior Software Engineer - Data Platform,-1,"About Wellio


We're a growing software FoodTech company with a mission to help you nurture your family with home-cooked meals. Our AI-based Food Intelligence Platform powers Meal Hero, our native and web app that helps people discover, plan, shop, prepare, and enjoy meals at home with ease. This proprietary technology is based on millions of recipes and thousands of ingredients, and it's always improving.

To achieve our goal we have assembled a team of smart, empirically motivated, disagreeable givers who care about making a difference in the world. We believe that using technology, collaboration, innovation and diversity we can transform the way people eat, cook, and share meals. Wellio was acquired during the summer of 2018 by the Kraft Heinz Company.

Learn more at about.mealhero.com

Try Meal Hero on the web or download the app from the Apple App Store or Google Play Store

As a member of our data pipeline and operations team, you'll work with other engineers, data scientists, and product managers to enable the highest quality data products in our Food Intelligence Platform.

What you will do
Collaborate with a team of data scientists, data engineers, and product managers to develop food-related data products
Design, build, maintain, and improve a performant and highly scalable data platform to support both internal and external use cases. We give broad leeway to implement your best architectural decisions. Use cases for this core data include:
two-way flow of data to user-facing apps via microservices
structuring both core data and data exhaust for training machine learning models
Work with our data scientists to design and build a models platform that leverages and supports online learning and machine teaching to develop industry-leading models in the food and health space
Work with data scientists and engineers to build a CI/CD system for our ever-improving models that allows their performance to be monitored and improved in an automated manner
Basic qualifications
You are proficient in writing production-quality code (preferably in Python) and in software design best practices (minimum 3 years experience)
You are familiar with the software development lifecycle and interested in helping to maintain high quality software through CI/CD, TDD, and code reviews
Experience designing, building, and maintaining RESTful APIs
You previously worked with GCP, AWS, or another PaaS
Experience with relational and non-relational databases
Experience in system design and architecture
Preferred qualifications
Experience building both streaming and scheduled data pipelines (experience with Airflow/Cloud Composer is a plus)
Experience with containers and orchestration (e.g. Docker, Kubernetes)
Experience with industry-standard storage systems (e.g. Elasticsearch, Redis)
About you
You enjoy collaborating as part of a small, agile, and dynamic team where everyone is valued
You believe ""done is better than perfect"" and enjoy helping to ship features and quantify the right areas for iterative improvement
You enjoy both learning and teaching, and enjoy working with others from whom you can learn and who can learn from you
You have a passion for food and nutrition, and are excited to use your skills to help our customers nourish themselves
You believe that work should be fun and enjoy working with others
You like to try new things and believe in failing fast
If you got this far, perhaps you're the person we're looking for. We look forward to your application.",-1,Wellio,"San Francisco, CA","San Francisco, CA",1 to 50 employees,2017,Company - Public,Internet,Information Technology,Unknown / Non-Applicable,-1
Senior Software Engineer/Cloud,-1,"At Atomwise, we invented the first deep learning neural networks for structure-based small molecule drug discovery, and we're currently deploying it in one of the largest applications of machine learning for life sciences. We work on Alzheimer's, cancer, diabetes, drug-resistant antibiotics, and other diseases. We've partnered with 4 of the top-10 US pharma companies, raised over $50M from top VCs, and have 100+ diverse projects currently running.

You should think about joining us if you care about enabling the application of machine learning to essential problems. For example, we are not constrained by latency or uptime but by scaling and parallelization. Today we can analyze more than 1 billion molecules per day, but there are about 10^24 synthetically-accessible molecules. Come help us pick up a couple of orders-of-magnitude.

Our team has over 35 Ph.D. scientists who contribute to a collaborative academic-like culture that fosters robust scientific and technical discussion. We strongly believe that data wins over opinions, and aim for as little dogma as possible in our decision making. Our team members have expertise in a wide range of disciplines--from computational chemistry and structural biology to cloud-native best practices--and we regularly have internal seminars open to anyone interested in learning about these topics.

Our Engineering team is small and growing quickly. As a result, there's plenty of opportunities for career growth and to have a significant impact on our success.

You will
Have the opportunity to learn and improve how we run machine learning at scale to deliver new drugs.
Play an essential role in designing and building cloud-based solutions consisting of 500+ CPU and GPU instances in a highly dynamic scaling environment.
Foster high-quality and adaptable software using engineering and Agile best practices.
Interact closely with our scientists (your users) to scope, design and implement software to tackle cheminformatic and machine learning problems.
Required Qualifications
Bachelor's degree in Computer Science with 4+ years of software engineering experience.
High proficiency in Python and a compiled language (e.g., C++, golang, Java, etc).
A record of designing and implementing cloud software using docker containers.
High proficiency with the Linux command-line environment.
Preferred Qualifications
Experience building and deploying batch computing workloads or microservices onto Kubernetes.
Experience implementing machine learning architectures in PyTorch or TensorFlow
Background in Biology or a related field.
Compensation & benefits
Competitive salary, commensurate with experience
Stock compensation plan you'll be an Atomwise co-owner
Platinum health, dental, and vision benefits
401k with 4% match
Flexible work schedule
Generous parental leave
Strong emphasis on collaborative learning and career development
Atomwise is not currently offering visa sponsorships for any position. Please only apply if eligible to work in the U.S.

Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.",5.0,"Atomwise
5.0",Remote,"San Francisco, CA",1 to 50 employees,2012,Company - Private,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,Unknown / Non-Applicable,-1
Algorithm & Signal Processing Engineer II,"$68K-$119K
(Glassdoor est.)","Search by Keyword
More Options

Search by Location

Clear

Loading...

Department

All

State

All

×

Send me alerts every days
alert frequency in every certain days
Create Alert

form.emailsubscribe-form {
display: none;
}
×

Send me alerts every days
alert frequency in every certain days

Share this Job

AddThis
Email
Facebook
Twitter
LinkedIn
Pinterest

Apply now »



Algorithm & Signal Processing Engineer II

Date:

Jul 15, 2020

Location:

Danvers, MA, US

#job-location.job-location-inline {
display: inline;
}

Abiomed is a pioneer and global leader in healthcare technology and innovation, with a mission of Recovering Hearts & Saving Lives. With corporate headquarters in Danvers, Massachusetts, offices in Aachen & Berlin, Germany and Tokyo, Japan, Abiomed’s 1,400 employees form one of the fastest growing medical device companies in the world. We attract and retain exceptional talent with our collaborative culture, passion for our work, and a strong commitment to employee professional development.

Patients First | Innovation | Winning Culture | Heart Recovery

We are currently hiring for an Engineer who has at least 2 years of experience in digital signal processing and algorithm development. This role will be responsible for designing and implementing a new generation of advanced signal processing algorithms used in ABIOMED’s family of Impella heart pumps. These new algorithms will play a central role in the pursuit of ABIOMED’s mission of recovering hearts and saving lives. We are looking for a creative self-starter who welcomes ambitious challenges and thrives in a fast-paced, dynamic environment.

Responsibilities
Design robust yet lightweight algorithms to process physiological signals in real-time
Evaluate algorithm performance in offline (in silico) and live (in vitro, in vivo) environments
Collaborate with software teams to implement algorithms on embedded hardware
Work with data scientists to create and deploy advanced machine learning algorithms
Prepare and maintain programs and documentation for analytic models
Maintain concise descriptions of algorithm design specifications and performance evaluations
Perform variability analyses and error stack-up simulations to inform algorithm features
Interpret and align algorithm specifications to industry performance standards
Conduct independent quantitative and qualitative research in new signal processing features
Communicate algorithm designs and performance results to cross-functional stakeholders
Core Team and/or Project Team role
Qualifications
MS in computer science, mathematics, or an engineering field, or equivalent work experience; PhD preferred.
2+ years of professional experience in time- and frequency-domain digital signal processing algorithm development for medical device industry
Modeling and analyzing large data sets using Python, MATLAB or equivalent tools
Strong knowledge of C/C++ real-time programming or equivalent tools
Willing to travel
General Requirements
Superb communication and collaboration skills – comfortable operating within and outside a core team and presenting progress to company leadership
Demonstrated excellence of analytical thinking in one or more technical fields
Self-motivated and good team player
Willing to learn and explore new technologies
Independent, efficient, and able to manage several concurrent projects

Abiomed is an Equal Opportunity Employer committed to a diverse workforce. Abiomed will not discriminate against any worker or job applicant on the basis of race, color, religion, gender, gender identity, national origin, ancestry, age, sexual orientation, gender identity, marital or civil partnership status, pregnancy, gender reassignment, non-job related mental or physical disability, genetic information, veteran status, military service, application for military service, or membership in any other category protected under law.

Nearest Major Market: Boston

Apply now »

Find similar jobs:
Engineering & R&D

Apply now »



Algorithm & Signal Processing Engineer II

Date:

Jul 15, 2020

Location:

Danvers, MA, US

#job-location.job-location-inline {
display: inline;
}

Abiomed is a pioneer and global leader in healthcare technology and innovation, with a mission of Recovering Hearts & Saving Lives. With corporate headquarters in Danvers, Massachusetts, offices in Aachen & Berlin, Germany and Tokyo, Japan, Abiomed’s 1,400 employees form one of the fastest growing medical device companies in the world. We attract and retain exceptional talent with our collaborative culture, passion for our work, and a strong commitment to employee professional development.

Patients First | Innovation | Winning Culture | Heart Recovery

We are currently hiring for an Engineer who has at least 2 years of experience in digital signal processing and algorithm development. This role will be responsible for designing and implementing a new generation of advanced signal processing algorithms used in ABIOMED’s family of Impella heart pumps. These new algorithms will play a central role in the pursuit of ABIOMED’s mission of recovering hearts and saving lives. We are looking for a creative self-starter who welcomes ambitious challenges and thrives in a fast-paced, dynamic environment.

Responsibilities
Design robust yet lightweight algorithms to process physiological signals in real-time
Evaluate algorithm performance in offline (in silico) and live (in vitro, in vivo) environments
Collaborate with software teams to implement algorithms on embedded hardware
Work with data scientists to create and deploy advanced machine learning algorithms
Prepare and maintain programs and documentation for analytic models
Maintain concise descriptions of algorithm design specifications and performance evaluations
Perform variability analyses and error stack-up simulations to inform algorithm features
Interpret and align algorithm specifications to industry performance standards
Conduct independent quantitative and qualitative research in new signal processing features
Communicate algorithm designs and performance results to cross-functional stakeholders
Core Team and/or Project Team role
Qualifications
MS in computer science, mathematics, or an engineering field, or equivalent work experience; PhD preferred.
2+ years of professional experience in time- and frequency-domain digital signal processing algorithm development for medical device industry
Modeling and analyzing large data sets using Python, MATLAB or equivalent tools
Strong knowledge of C/C++ real-time programming or equivalent tools
Willing to travel
General Requirements
Superb communication and collaboration skills – comfortable operating within and outside a core team and presenting progress to company leadership
Demonstrated excellence of analytical thinking in one or more technical fields
Self-motivated and good team player
Willing to learn and explore new technologies
Independent, efficient, and able to manage several concurrent projects

Abiomed is an Equal Opportunity Employer committed to a diverse workforce. Abiomed will not discriminate against any worker or job applicant on the basis of race, color, religion, gender, gender identity, national origin, ancestry, age, sexual orientation, gender identity, marital or civil partnership status, pregnancy, gender reassignment, non-job related mental or physical disability, genetic information, veteran status, military service, application for military service, or membership in any other category protected under law.

Nearest Major Market: Boston

Apply now »",4.0,"ABIOMED
4.0","Danvers, MA","Danvers, MA",1001 to 5000 employees,1981,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,$100 to $500 million (USD),"Covidien, Boston Scientific"
Principal Software Engineer,-1,"Job Description
Principal Software Engineer, Clearance Required – TS/SCI w/Polygraph

Please note, this position requires all candidates to currently possess an active Top-Secret SCI Clearance with a Polygraph. This position is not an opportunity to be sponsored or nominated for a government security clearance.
The Challenge:

We encode mission critical software for our partners who analyze more than 25 petabytes of data a day. We ingest millions of signals confidentially utilizing our sensible solutions that identify and respond to attacks before they are even executed. We incorporate automated tools and cutting-edge technology that saves lives and protects property of everyday people. With our technology we are looking to refine our software to more securely protect, analyze, and increase the number of petabytes we work with.
How We Meet the Challenge:

A combination of utilizing the right people and giving them the tools, resources, support, and freedom to develop effective signal processing algorithms, excellent software, and use strong intuition on what works for a scalable system.
Minimum Qualifications:
A current Top-Secret/SCI government security clearance with polygraph is required.
At least sixteen years of general experience in computer science, computer engineering, mathematics, or a related discipline.
At least five years of experience in software-intensive projects and programs for government or industry customers.
At least five years of the experience must have been as a software engineer supporting software architecture development, requirement analysis, process execution and evaluation, selection and evaluation of COTS/GOTS tools, and integration (with both new and existing systems).
Experience in Cybersecurity and/or Cyber Defense is required.
Experience with Scripting languages (Python, Perl, Bash, Jupyter Notebook) experience is required.
Bonus Points:
Must be able to work in a team environment and collaborate well with others.
Experience in providing analytic support to operations is desired.
Experience utilizing Splunk is highly desired.
Experience utilizing containers such as Docker is desired.
Experience in software development is desired.
Experience in data science and machine learning is desired.
As a Principal Software Engineer, You Will:
Provide Analytic and Software Engineering support to CyberSecurity Operation missions by designing and implementing cybersecurity analytical solutions and developing prototype solutions using a variety of tools, APIs, frameworks and programming languages.
Be part of a robust Cybersecurity Defense development team and assist with utilizing Cybersecurity Analysis techniques to rapidly develop solutions to support emerging mission requirements.
Work closely with mission operators to identify the requirements and implement solutions for both the short and the long term.
Work in collaboration with a highly skilled development team consisting of software engineers and data scientists in DevOps/agile development environment.
Work Site: Greater Ft. Meade, MD area.

To Learn More About Our Team and Solutions, Check Out the Following:
Corporate Website: www.ssati.com
GlassDoor Page: https://www.glassdoor.com/Overview/Working-at-SSATI-EI_IE1260475.11,16.htm
Indeed Page: https://www.indeed.com/cmp/Ssati/reviews
LinkedIn Page: https://www.linkedin.com/company/ssati/
Facebook Page: https://www.facebook.com/ssati2003/
Twitter Page: https://twitter.com/ssati2003?lang=en
At Sensible Solutions and Technologies, Inc. (SSATI), we don’t just accept difference—we celebrate it, we support it, and we thrive on it for the benefit of our employees, our services, and our community. SSATI is honored to be an equal opportunity workplace. We are committed to equal employment opportunity regardless of race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or veteran status.",5.0,"SSATI
5.0","Annapolis Junction, MD","Annapolis Junction, MD",1 to 50 employees,2003,Company - Private,Computer Hardware & Software,Information Technology,$10 to $25 million (USD),-1
Senior Machine Learning Engineer,-1,"We are looking for a Data Scientist - Algorithms and Software Developer - to build new and amazing data products and algorithms. Bring data science into Human Resources: Extract knowledge about people, companies and positions, understand data and build learning engines to match the right person to the right position.

You Are:

Experienced in development and research of Machine Learning and/or NLP
(Natural Language Processing) algorithms in the industry (3+ Years)
Experienced in software development in the industry (3+ Years)
M.Sc. or above in Computer Science or other quantitative field (Mathematics, Statistics, Physics etc.)
Able to take product requirements and turn them into working software using advanced algorithms - from research to production
A motivated, self-thinker, explorer, passionate, always learning data enthusiast
Startup experience - an advantage

Your Skill Set:

Experience in Machine learning / Deep Learning / Prediction models and NLP techniques
Strong coding skills using big data tools and languages (Python / Java / Hadoop / Spark / Mongo DB etc.)
Agile person - getting things done – really wants to make products happen fast
Working with databases and large, complex data sets
Deep understanding of data

Your Responsibilities:

Creating algorithms and software to solve hard problems related people and jobs (HR-tech)
Extracting knowledge from texts and learning prediction models for matching the best candidates to positions
Analyzing complex data sets that few people in the world have access to
Working in a team to find unique solutions to unsolved universal problems using different data analysis techniques",3.3,"Cadre Inc
3.3","Santa Monica, CA","Santa Monica, CA",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Development/Operations Engineer,"$60K-$108K
(Glassdoor est.)","Responsibilities

The newly formed Cancer Data
Sciences group at the UCLA David Geffen School of Medicine and UCLA Jonsson
Cancer Center is seeking a Programmer/Analyst with extensive research and
development experience. The successful candidate will be working with a diverse
team of Data Scientists, developing new quantitative strategies to improve our
understanding and ability to treat cancer. Programmer/Analysts in our team are
passionate about applying their knowledge of software development and design to
improve scientific research. They develop scalable and distributed software
solutions that maximize utilization of both local high-performance computer
infrastructure and a growing set of cloud-based assets. Our datasets comprise
several petabytes, and are growing rapidly, creating fascinating problems in
storage, access, parallelization, distributability, optimization,
containerization and core algorithm design. This requires a strong background
in computer science, providing a platform for technical leadership, but linked
to strong personal communication and leadership skills, to help ensure insights
are broadly adopted. The successful candidate will be helping us perform
research that will transform the lives of cancer patients.

Your responsibilities will be
wide-ranging, and include an emphasis on using design, analysis and programming
skills to create systems that improve code quality and boost productivity of
the entire team. You will help drive professional level design and development
practices throughout the entire team, and serve as a local point of expertise
for workflow optimization and containerization. You will typically have one or
two major and several minor projects at any point in time, making appropriate
prioritization, time management and reporting across these. We are in a rapid
growth phase, and the successful candidate will be involved in hiring,
recruiting, onboarding and mentoring junior data scientists and software
engineers. You will have experience in either data-intensive research and
software engineering, or in a large-scale professional software engineering
environment.
Qualifications
Extensive applied software-engineering experience (5 years minimum, 10 years preferred)
Bachelor's degree in Software Engineering or Computer Science (highly desired)
Detailed working knowledge of C++, Perl or Python programming/scripting design
Working knowledge of software development tools and CASE tools
Strong verbal, interpersonal, and written communication skills
Experience with the full software development process including gathering requirements, turning them into a design, implementing the design, and validating the implementation against the original requirements.
Knowledge of LINUX/Unix operating system, and source-code versioning systems
Strong computer science knowledge, including software design patterns
Knowledge of SQL and data modeling
Working knowledge of containerization (e.g. Docker, Singularity)
Experience developing R-based code
Experience with machine-learning, bioinformatics and cancer or molecular biology
Knowledge of relational database software (e.g. Oracle, Postgres)
Familiarity with distributed programming
Understanding of core LAN networking protocols including ethernet, IP, TCP, UDP, ICMP

UCLA is an Equal Opportunity/Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or protected Veteran status.",4.0,"UCLA Health
4.0","Los Angeles, CA","Los Angeles, CA",5001 to 10000 employees,1919,Company - Public,Health Care Services & Hospitals,Health Care,Unknown / Non-Applicable,"Cedars-Sinai Medical Center, Loma Linda University Health, Harbor Hospital"
Senior Data Scientist,-1,"Job Description
Title: Senior Data Scientist
Location: Washington, DC
Salary: $140,000 - 180,000
Contact: Paul Chatlos, pchatlos@smithhanley.com

Senior Data Scientist The Position

We are seeking a data scientist to participate as a key team member in envisioning, designing, coding, testing and improving the algorithms that are central to our mission as a company.

Some key challenges will include:

-Identifying external datasets and developing API or other methods for accessing them
-Fluidly self-educating on existing methods for modeling end-user behavior in a variety of contexts, or developing new methods for doing this when necessary
-Designing experiments to answer targeted questions
-Teaming with developers to embed algorithms in applications
-Understanding business economics, user motivation and other contextual information in order to guide analytical trade-offs, with a focus on ""minimum viable algorithm"" followed by intensive, iterative improvement

Senior Data Scientist The Successful Candidate

A successful candidate will be comfortable in a fluid, entrepreneurial environment, but one that is focused on developing reusable software applications, not bespoke analytical solutions.
He or she will likely have many of the following characteristics:
-8+ years professional experience using statistical software (R, S-Plus, SAS, or similar), relational and NoSQL databases and scripting languages (such as Python). Ideally, R and Python
-Familiar with general-purpose machine learning methods, such as neural networks, Bayesian networks, regression, decision trees and so on. Capable of self-teaching new algorithmic methods easily
-Passionate about using data to drive strategy and business recommendations.
-Well-rounded top performer who is able to ""crunch the numbers"" one minute, and critically think through strategic issues the next
-Self-starter with a high degree of rigor, organization, and discipline to get things done
-Able to communicate as effectively in delivering complex data-driven findings with businesspeople, as in discussing machine-learning specifications with engineer

Senior Data Scientist Academic Qualifications
-Very strong math, physics, CS or similar degree from a leading program
-Extremely high SAT or similar standardized test scores",4.5,"Smith Hanley Associates
4.5","Washington, DC","New York, 061",1 to 50 employees,1980,Company - Private,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,"Kforce, PageGroup, Robert Half"
Big Data Software Engineer,-1,"The Amazon e-commerce platform supports hundreds of thousands of sellers who fuel the rich buying experience that Amazon is today. From artisans selling handmade goods to some of the world's largest retailers, Amazon's merchants are quickly becoming the heart of the Amazon shopping experience. Join Amazon Services, the fastest growing division of Amazon.com, in creating the next evolution of the internet's finest selling experience.
The team builds Self-Service analytic solutions for Selling Partner and Seller Experience teams that enables business users to make quick and data driven business decisions. Our tools are strategically important to our leadership, finance, economists, analysts, machine learning scientists, SDEs and BI partners to drive long-term growth. We are highly motivated, collaborative, and fun loving with an entrepreneurial spirit and bias for action. With a broad mandate to experiment and innovate, we are growing at an unprecedented rate with a seemingly endless range of new opportunities.
As an experienced member of the team, in this role, you will:
Contribute to evolving the technical direction of SPS analytical Systems and play a critical role their design and development
Build and support billing pipeline responsible for handling all impacting events in Selling partners domain in real-time.
You will research, design and code, troubleshoot and support. What you create is also what you own.
Develop the next generation of automation tools for monitoring and measuring data quality, with associated user interfaces.
Have the satisfaction of seeing your work impact thousands of Amazon selling partners world-wide.
Be able to broaden your technical skills and work in an environment that thrives on creativity, efficient execution, and product innovation.Basic Qualifications
Bachelors (BS/BE) in Computer Science or related field
3+ years of experience in software development and full product life-cycles
Excellent coding skills in Java, Python, C++, or equivalent object-oriented programming language
Understanding of relational and non-relational databases and basic SQL
Proficiency with at least one of these scripting languages: Perl / Python / Ruby / shell script
Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.",-1,Amazon Corporate LLC,"Seattle, WA",-1,-1,-1,-1,-1,-1,-1,-1
Senior Machine Learning Engineer,"$130K-$211K
(Glassdoor est.)","Leading the future of luxury mobility

Lucid’s mission is to inspire the adoption of sustainable energy by creating the most captivating luxury electric vehicles, centered around the human experience. Working at Lucid Motors means having a shared vision to power the future in revolutionary ways. Be part of a once-in-a-lifetime opportunity to transform the automotive industry.

We are looking for a Senior Machine Learning Engineer who enjoys thinking big and looking to make their mark on an incredibly fast-growing company. If building large and building fast, working with a very talented team of engineers, and collaborating with the brightest mind in the Automotive industry is what you like, Lucid is the best to experience it.
The Role
Work on state-of-the-art large-scale machine learning projects
Perform advanced platform research and lead the architecture design for efficient ML model training and deployment in scale
Adapt machine learning and data mining algorithms to solve problems across several teams
Develop new machine learning models using structured and unstructured data.
Perform model training, hyper parameter tuning and model parallelization and distributed training to achieve top performance for accuracy and latency.
Perform research and utilize state-of-the-art and best practices for model compression, quantization and optimization for deployment
Perform and streamline continuous model performance monitoring and debugging in production
Research and develop ML computing paradigm such as in-memory on-device or in the cloud distributed learning and employ concepts such as online learning, etc.
Articulate business questions and use mathematical techniques to translate ideas to actionable projects to arrive at an answer.
Partner with internal stakeholders on projects to identify and articulate opportunities, see beyond the data to identify solutions that will raise the bar for decision making.
Use quantitative analysis and the presentation of data to see beyond the numbers and understand what can improve our processes.
Engage broadly with the organization to identify, prioritize, frame, and structure complex and ambiguous challenges, where advanced AI projects or tools can have the biggest impact.
Qualifications
Bachelor’s or advanced degree (Masters/PhD) in computer science or STEM field.
2+ years of deploying machine learning solutions in the cloud or edge devices.
Or 4+ years of experience working as Machine learning scientist or Data Scientist collaborating on implementing end-to-end ML pipelines
Programming experience with at least one modern language such as Java, Scala, C++, C# or Python including object-oriented design
Proficiency with machine/deep learning frameworks such as TensorFlow, Keras, Pytorch, Caffe, MXNet, etc
Experience in creating production level ML models for training, validation, and inference leveraging real-time systems
Experience working with cloud-based accelerated computing, GPU/TPU, CUDA, parallel computing
Experience with major cloud computing services for model training and hyper-parameter tuning
Experience deploying containers, scaling machine learning algorithms and monitoring programmatically, using open source ML platforms or managed services.
Software development skills; unit testing, integration testing, monitoring and debugging
Critical Thinking and good communication skills
Nice to Haves
Ph.D. or Masters in Computer Science, Statistics, Operations Research or related field.
Technical expertise and in-depth knowledge in one or more of the following areas:
-- 1-Anomaly detection and signal processing
-- 2-Advanced machine learning and unsupervised learning
-- 3-Deep learning, convolutional neural networks. RNN, LSTM or Machine Vision
-- 4-Bayesian inference
-- 5-Natural Language Processing (NLP), text mining, sentiment analysis, information retrieval, etc.
Experience with model compression, quantization and optimization is a huge plus
In-depth theoretical knowledge of Statistics, traditional ML, Deep Learning, CNNs and optimization algorithms.
Experience with RESTful API design and Web based application development (e.g. ASP .NET, Javascript or C#)
Experience with analytics and big data tools (Spark, SQL, Presto, Hive) to create horizontally scalable solutions.
Technical expertise and in-depth knowledge in one or more of the following areas:

1-Anomaly detection and signal processing
2-Advanced machine learning and unsupervised learning
3-Deep learning, convolutional neural networks. RNN, LSTM or Machine Vision
4-Bayesian inference
5-Natural Language Processing (NLP), text mining, sentiment analysis, information retrieval, etc.


Be part of something amazing

Come work alongside some of the most accomplished minds in the industry. Beyond providing competitive salaries, we’re providing a community for innovators who want to make an immediate and significant impact. If you are driven to create a better, more sustainable future, then this is the right place for you.

At Lucid, we don’t just welcome diversity - we celebrate it! Lucid Motors is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, national or ethnic origin, age, religion, disability, sexual orientation, gender, gender identity and expression, marital status, and any other characteristic protected under applicable State or Federal laws and regulations.

To all recruitment agencies: Lucid Motors does not accept agency resumes. Please do not forward resumes to our careers alias or other Lucid Motors employees. Lucid Motors is not responsible for any fees related to unsolicited resumes.",3.9,"Lucid Motors
3.9","Newark, CA","Newark, CA",1001 to 5000 employees,2007,Company - Private,Transportation Equipment Manufacturing,Manufacturing,Unknown / Non-Applicable,-1
Senior Software Engineer / Team Lead,"$112K-$220K
(Glassdoor est.)","Join our team dedicated to developing and executing innovative solutions in support of customer mission success.

Job Description:

Novetta has an exciting opportunity for a self-motivated and accomplished Computer Scientist to lead our entity analytics team. You will work on complex projects involving data analysis, software engineering, and deploying software in a cloud computing environment. The team combines data from disparate sources to visualize the complex relationships between entities. This effort involves large scale data integration and entity resolution leveraging a best in class Novetta product. We are looking for a flexible problem solver with significant technical experience to lead a team providing unique solutions for our customers and stakeholders.

Responsibilities include:
Lead a technical team of software engineers and computer scientists, working within a larger ecosystem delivering an Enterprise capability.
Navigate customer and prime environment, manage resources within and across team, and assist team with professional and technical growth.
Deploy applications on a large-scale data processing cluster using AWS technologies.
Design and implement entity correlation strategies that are tailored to mission needs and unique data qualities.
Develop algorithms and visualization tools to help stakeholders understand their data and prioritize new data sources.
Develop and integrate applications to automate ingestion, processing and monitoring of data
Develop and maintain tools to support operations and maintenance of production and development computing clusters.
Basic Qualifications:
Experience leading a team of software engineers.
A Bachelor's degree in computer science or related field and a minimum of 5 years of experience; or a Master's degree in computer science or related field and a minimum of 3 years of experience.
Experience in software development/engineering including requirements analysis, software development, installation, integration, evaluation, enhancement, maintenance, testing and problem diagnosis/resolution.
Software development experience on Linux-based systems in Python or shell scripting or JavaScript.
Experience developing against full-featured REST APIs and using a command line interface
Desired Skills:

Should meet a minimum of 3:
Software development experience with JavaScript, Python, or other modern programming languages.
Hands-on experience with Spark.
Experience working with Databricks
Interest in statistical analysis, machine learning, or data science.
Experience with entity resolution products or a background in data matching theory and technologies.
Experience developing applications in AWS.
Security Clearance:
The candidate must have a TS/SCI with Poly.
Novetta, from complexity to clarity.

Novetta delivers highly scalable advanced analytics and secure technology solutions to address challenges of national and global significance. Focused on mission success, Novetta pioneers disruptive technologies in machine learning, data analytics, full-spectrum cyber, cloud engineering, open source analytics, and multi-INT fusion for Defense, Intelligence Community, and Federal Law Enforcement customers. Novetta is headquartered in McLean, VA with over 1,000 employees across the U.S.

Our culture is shaped by a commitment to our core values:

Integrity • We hold ourselves accountable to the highest standards of integrity and ethics.

Customer Success • We strive daily to exceed expectations and achieve customer mission success.

Employee Focus • We invest in our employees' professional development and training, respecting individuality and fostering a culture of diversity and inclusion.

Innovation • We know that discovering new and innovative ways to solve problems is critical to our success and makes us a great company.

Excellence in Execution • We take pride in flawless execution as we build a company that is best in class.

Earn a REFERRAL BONUS for the qualified people you know.

For more details, or to submit a referral: bit.ly/NovettaReferrals

Novetta is an equal opportunity/affirmative action employer.

All qualified applicants will receive consideration for employment without regard to sex, gender identity, sexual orientation, race, color, religion, national origin, disability, protected veteran status, age, or any other characteristic protected by law.",4.5,"Novetta
4.5","Chantilly, VA","Mc Lean, VA",501 to 1000 employees,2012,Company - Private,Enterprise Software & Network Solutions,Information Technology,$100 to $500 million (USD),"Leidos, CACI International, Booz Allen Hamilton"
Software Engineer,"$64K-$132K
(Glassdoor est.)","Every Analyst a Scientist - One of our primary goals is to empower intelligence analysts to be able to study their data like scientists. The tools we develop focus on streamlining intelligence analysis through integrated algorithms and software that provide insight into the geopolitical landscape for use in operational intelligence missions around the world.

The Role:
As a Software Engineer, you will be part of a team that transforms large and complex customer data into real-world, high-impact solutions. You will work with researchers and engineers to design and implement solutions to challenging national security problems. You will be responsible for building the software infrastructure to clean, ingest, and expose datasets and algorithms to both developers and end users. You will deploy algorithms, generate workflows, create engineer-facing tools, and design customer-facing prototype systems. You will occasionally travel to customer sites to engage with end users, demonstrate prototypes, and integrate analytics into customer systems.

If you would like to help intelligence and defense analysts keep pace with technology-driven innovation, then this role is for you!

Who you are:
A U.S. Citizen with the ability to obtain a Security Clearance
A degree in a scientific or engineering field, such as Computer Science, Mathematics, Physics, or Software Engineering
Proficiency with a scientific programming language such as Python, Java, or C++
Experience with database management and common query syntax
Motivated collaborator and excellent communicator of ideas to both technical and non-technical audiences
Knowledge of AWS, Spark, Dask, and/or similar technologies for working with data at scale
Even better:
Active Security Clearance
Track record of architecting, developing, deploying, or maintaining enterprise software
Experience with software development best practices and tools
Understanding of web development and visualization technologies, such as d3, Leaflet, Bootstrap, or others
Familiarity with machine learning or statistical modeling techniques",4.5,"Systems & Technology Research
4.5","Woburn, MA","Woburn, MA",201 to 500 employees,2010,Company - Private,Aerospace & Defense,Aerospace & Defense,$100 to $500 million (USD),-1
Full Stack Software Engineer (Python/Vue),-1,"Position Summary Full Stack Software Engineer (Python VueJS) Company Overview Our client is an automated underwriting platform for real estate professionals that was built to disrupt the commercial real estate industry. The software allows investors, brokers, and lenders to analyze rent, operating expenses and returns for multifamily properties by applying machine learning to a database of live multifamily transaction data from every U.S. market. Our client has a creative and entrepreneurial culture ndash everyone on the team interacts directly with customers each day, and we all contribute to the product and planning. If you have an idea to improve something, there is no red tapehellip just build what needs to be built! Innovation and passion for transforming the old-fashioned real estate industry are our highest priorities. Job Description As a full-stack (Python, PostgreSQL and HTMLCSSJavaScript) developer, you'll work on the interface and backend infrastructure of products and features used by hundreds of underwriters and real estate analysts every day. The work is challenging, fast-paced, and always changing. You must have demonstrated analytical skills, an unwavering commitment to quality, a collaborative work ethic, and cutting-edge coding skills. You must display solid proficiency in the fundamentals of Python, PostgreSQL, JavaScript, HTMLCSS, and popular front-end frameworks like Vue.js. The role will include the delivery of reliable, scalable new features to users, developed in Python, interacting with a PostgreSQL database and using the Vue.js frontend framework. You will work with the development team to develop, test and deliver finished, high quality, compelling features and products. Our team includes designers, engineers and data scientists who are passionate about quality, usability, and simplicity. If you are ready to join a company that fosters learning, growth, experimentation and innovation, our client's team is for you. Requirements Qualifications 3-5 years of experience in full stack Python development 1-3 years of experience with PostgreSQL 1-3 years of experience with JavaScript frameworks such as React, Angular or Vue.js (Vue.js is preferred, this is what our client uses), and CSS pre-processing frameworks (Sass or Less) 1-2 years of experience integrating with VBA and Excel integration preferred Experience using GitHub and solid understanding of software version control Familiarity with JIRA or equivalent product management software Familiarity with agile development best practices Driven self-starter able to work on a small team and take initiative on new tasks Familiarity with real estate or finance is a plus Responsibilities Collaborate with interdisciplinary team of data scientists, software engineers and real estate professionals Strive for high quality and rapid output utilizing agile development best practices Support, maintain, and document software functionality Maintain industry standard coding, compliance, security practices Proactively learn product frameworks and code base Our client is a startup company, and as such the responsibilities outlined above may change and evolve over time. Flexibility, curiosity, an entrepreneurial mindset, and strong work ethic are essential for this role. It is encouraged that everyone on the team continually research new technologies and analytical opportunities to improve the platform.",5.0,"CultureFit
5.0","Chicago, IL","Deerfield, IL",1 to 50 employees,1997,Company - Private,Advertising & Marketing,Business Services,$1 to $5 million (USD),-1
"Aviation Software Engineer - Huntsville, AL - ASL with Security Clearance",-1,"Job Description The Aviation Systems Division of the Applied Systems Laboratory in Huntsville, AL is looking for several entry- to mid-level software developers. We are looking for a software engineer interested in supporting the development of simulations for rotorcraft systems. You will analyze, design, and develop software used to simulate aircraft, sensors, and the 3-D world. As part of a team, you will participate in the development of simulations to support hardware-in-the-loop testing of avionics components. As part of the effort, you will also be responsible for specifying, implementing (C++, Python), and testing your SW components. Effort will be in support of system design and analysis for the Army Aviation platforms, handling aviation-based interfaces. Travel Requirements Education & Length of Experience Research Engineer/Scientist I * A Bachelor's degree in Computer Engineering, Software Engineering, or Computer Science. Research Engineer/Scientist II * A Master's degree in Computer Engineering, Software Engineering, or Computer Science and three (3) years of relevant full-time experience after completion of that degree, * A Master's degree in Computer Engineering, Software Engineering, or Computer Science and five (5) years of relevant full-time experience after completion of a Bachelor's degree, or * A Doctoral degree in Computer Engineering, Software Engineering, or Computer Science. Required Minimum Qualifications * Excellent skills and practice in programming with one or more software languages; C, C++, Python * Experience with software interfaces like Ethernet, I2C, SATA, SPI, UART, USB * Debugging skills and practice in the use of debugging tools * Experience in software integration and test, including unit test development * Very good communication skills in written and spoken English Preferred Qualifications * Active DoD Secret Clearance * Master's degree in Computer Engineering, Software Engineering, or Computer Science * Experience with avionics interfaces e.g., ARINC-429, MIL-STD-1553 * Experience with graphics libraries (OpenGL) * Experience with Data Distribution Service (DDS) interfaces * Experience with machine learning * Experience with 3D world simulation tools or flight simulators * Working knowledge of Agile SW development methodologies * Experience with test equipment and tools (oscilloscopes, wireshark, logic/bus analyzers) * Interest in publishing papers in professional conferences and journals U.S. Citizenship Requirements Due to our research contracts with the US federal government, candidates for this position are required to be US Citizens. Clearance Type Required Ability to obtain Secret Clearance upon hire Diversity & Inclusion Diversity & Inclusion (D&I) at Georgia Tech Research Institute aims to enhance the Institute's mission of solving the world's most complex technical problems by creating a workforce with a shared appreciation for diversity, raising awareness around inclusiveness, and fostering a sense of belonging and appreciation for all members of our community. Equal Employment Opportunity Georgia Tech Research Institute is an Equal Opportunity Employer of individuals with disabilities and protected veterans and actively seeks diversity among its employees. Equal Employment Opportunity is the Law . Posted: 02/19/2020 Closes: 08/14/2020 Back Submit Resume",3.6,"The Georgia Tech Research Institute
3.6","Huntsville, AL","Atlanta, GA",1001 to 5000 employees,1943,Subsidiary or Business Segment,Research & Development,Business Services,$100 to $500 million (USD),"MIT Lincoln Laboratory, Johns Hopkins University Applied Physics Laboratory"
AWS Data Engineer,-1,"About Infinitive:

At Infinitive, we do mission-critical work for great companies. We specialize in digital marketing and digital advertising solutions, customer data & analytics, digital & business transformation, and Technology solutions. Our Technology solutions focus on Managed Cloud Services, Cloud Enablement, Digital Operations, Application Development, DevOps, Product Development, Cloud Security, Data Science and Analytics, AI/ML, IoT, and everything in between.

Our experts are results-obsessed, focused and flexible, highly engaged and hugely experienced having sat in our clients seats. Those qualities are what make us different than old-school consulting shops. And surely, they are why clients and partners describe us as the gold standard in client experience.

Infinitive has been named a Best Small Firms to Work For by Consulting Magazine seven times, a Washington Post Top Workplace three times, a Washington Business Journal Best

About this Role:

Infinitive is growing its team in the Northern Virginia area and is currently seeking an Data Scientist to join our growing Technology practice. This person will utilize their experience in analytics, IoT, machine learning, and artificial intelligence advances to create value from structured and unstructured data. The ideal candidate has experience designing novel data analytic methods and workflows, including full data pipelines from raw data through analysis results. They must also have exposure to a variety of data mining/data analysis methods, data tools, building and implementing models, using/creating algorithms, and creating/running simulations.

We are looking for candidates who are accountable, passionate, assertive, proactive, open & honest, results oriented, and adaptable. Each project engagement represents a new challenge that will give you exposure to new clients, business issues, technologies, and people and will involve a range of responsibilities to include:
Developing in Java, Python, R, or other high-level languages.
Managing disparate data sources with varying data structures of content and preparing these for data science and machine learning applications.
Working with distributed scalable Big Data storage, processing, and computation, including AWS EMR, Spark, etc.
Implementation knowledge of, or desire to learn AWS / Azure data science capabilities.
Developing solutions and integrating and extending free and Open-source software (FOSS) or COTS products.
Conduct MapReduce programming with Apache Hadoop, the Hadoop Distributed File System (HDFS), and processing large data stores.
Knowledge of SQL and query languages.
Utilize real-time, large-scale data processing engine, including Apache Spark.
Lead and create Data Science and Analytics methodologies and frameworks for implementation.
Ability to build and develop Data Science demonstrations for clients
Qualifications:
4+ years of development experience (Java, Python, R, SQL)
3+ years of experience with distributed scalable Big Data storage, including AWS EMR, Spark, etc.
Desire to become AWS / Azure Certified architect / engineer.
Experience performing data Management, modeling, and warehousing.
Hands on experience with Amazon analytic tools (preferred)
Interest in being involved internally and growing a small business (entrepreneurial spirit)
Ability to travel (up to 20%) and to work independently
Experience using Agile software development methods in a DevOps environment.
Excellent leadership, peer management, and communication skills
Management consulting experience (preferred)
Bachelor's degree in related field (preferred)
Applicants for employment in the U.S. must possess work authorization which does not require sponsorship by the employer for a visa.

Infinitive is an Equal Opportunity Employer.

Powered by JazzHR",3.4,"Infinitive Inc
3.4","Arlington, VA","Cedar Rapids, IA",201 to 500 employees,1997,Company - Private,Enterprise Software & Network Solutions,Information Technology,$10 to $25 million (USD),-1
"Senior/Staff Software Engineer, Data Infrastructure","$116K-$227K
(Glassdoor est.)","Senior/Staff Software Engineer, Data Infrastructure job posting

Every year, while Americans wait for their paychecks, more than $1 trillion of their hard-earned money is held up in the pay cycle. As a result, we accumulate over $50 billion in late and overdraft fees and turn to high-interest loans. Overdraft charges and bank fees often trap people in a cycle of debt that can lead to unhealthy decisions and falling victim to predatory businesses disguised as helpful services. We don't accept that.

Earnin is an app that creates products that help people gain control of their finances. Cash Out lets people get paid as soon as they leave work, with no fees, interest, or hidden costs. With Health Aid, Earnin negotiates on behalf of community members to lower their total unpaid medical bill and work out a budget-friendly payment plan. Cash Back Rewards is a way for members to earn up to 10% cash back on purchases from over a thousand local and national businesses without needing a credit card or having to reach spend thresholds to earn cash rewards — and they can withdraw the money at any time. We also offer free tools to help avoid overdrafts, to remind people when recurring bills are due, and we're working on more! There is never any required cost to use any of these products or services, users can choose to tip what they think is fair to support the service and pay it forward to keep the movement going.

Earnin is supported by funding partners including Andreessen Horowitz, Matrix Partners, Ribbit Capital, Felicis Venture, Thrive Capital, and others. Join us and help build a new financial system focused on fairness and people's needs.

You can help make a difference.

About the Team:

We are a data driven mobile financial tech company. The Data Infrastructure team builds the data services and data infrastructure that powers data science, analytics, and product development throughout Earnin. We are looking for a product-minded, self-driven Senior Software Engineer to own multiple large-scale projects that advance our mission of enabling people to gain access to their paycheck on demand.

What sets us apart:
High impact roles at a relatively small company that's aggressively growing our user base.
We are a collaborative team and genuinely enjoy working with each other.
We believe in empowering our people to be successful.
We're building a product that inspires fairness across the financial world and helps people not get taken advantage of.
As a Senior Engineer you will:
Break down complex problems into their bare essentials, translate this complexity into elegant design and create high quality, maintainable code.
Build massively scalable, production-grade data services.
Champion data quality and governance throughout the organization.
Build a world class data lake and data warehouse.
Design and develop new systems and tools to enable all of Earnin to consume and understand data faster.
Own the end to end design, build, and maintenance of platform services, data pipelines, and data products.
Implement comprehensive monitoring, logging, and alerting across our data infrastructure.
Work cross functionally with other teams (data science, design, product, marketing, and analytics) in high visibility roles as an engineering leader.
Build and deploy the data architecture that supports machine learning model development and actionable analytics.
Work with product engineering and data science teams to design scalable, performance model deployment architectures.
Communicate the tradeoffs of technical decisions to multiple stakeholders, including non-technical audiences.
Collaborate with and mentor other engineers and provide engineering direction to data scientists and analysts.
Actively engage and drive design reviews and code reviews.
Some skills we consider critical to being a Senior Engineer:
BS or MS degree in Computer Science, Engineering, or a related technical field.
8+ years of development experience in a fast-paced environment, especially startups.
5+ years of experience working with data systems.
Strong Python and SQL skills.
Strong programming and architecture skills.
Excellent written and verbal communication skills, including the ability to identify and communicate data driven insight.
Taking pride in your code quality and helping others elevate their own code quality.
Substantial experience with testing, data validation, and data quality assurance.
You can articulate the tradeoffs of different deployment architectures (e.g. streaming vs. batch vs. service-based).
Experience designing data platforms and services on cloud infrastructure, preferably AWS.
Hands-on experience designing and building large-scale solutions with the Hadoop stack and/or Spark.
Experience tuning and optimizing Spark-based applications.
Experience deploying and/or using query engines like AWS Athena, Presto, and Impala.
Experience with AWS analytical services like Redshift.
Hands-on experience working with a varied set of data storage technologies (e.g. Mysql, Postgres, DynamoDB, S3, etc.). You know where and when to use each.
Extensive experience with data modeling for multiple use cases and application styles, including NoSQL data modeling.
Experience working with data formats such as Avro and Parquet.
Experience working with alerting and monitoring tools like DataDog and PagerDuty.
Nice to haves:
You have experience building and deploying machine learning models.
You have experience using Terraform.
You have substantial experience working at a startup.
You have experience with data modeling in Redshift.
Experience with streaming infrastructure like Kafka.
Experience working with Kubernetes.
Experience building and deploying AWS Lambda applications.",3.1,"Earnin
3.1","Palo Alto, CA","Palo Alto, CA",201 to 500 employees,2012,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Engineer (open level),"$43K-$69K
(Glassdoor est.)","Title
Data Engineer (open level)

07/08/2020

What you'll do...
At H&R Block, your contributions will go far beyond any job description. When you join our team, you'll add to the momentum of a forward-thinking company - one that defined an industry and is now leading its transformation.

H&R Block is transforming tax preparation through data to ensure that every client we serve gets the best tax outcome possible.

We are building a new Data Engineering Team in the Data Science & Analytics organization. This new team will own the technology and data capabilities of the end-to-end data-and-analytics function. It will take responsibility for building and maintaining the analytical technologies that the data science teams use, managing data at an enterprise scale, leveraging relationships with IT teams throughout the enterprise, and leading information architecture.

We are looking for talented, curious, and creative data engineers of all levels to help launch this team. You will be a good match for our organization if you are:
Motivated by the idea of building something innovative, transformative, and impactful.
Committed to the idea that data can drive experiences and products that wow our business partners and clients
Obsessed with defying expectations and raising the bar
Driven by an innate sense of ownership for the products you create.
Day to day, you'll...
Design and deploy architecture, solutions, and software to capture, manage, store, and use structured and unstructured data from internal and external sources in both on-prem and cloud environments.
Deploy machine-learning models and other data-science products across the enterprise.
Navigate the balance between business needs, data governance best practices, and technical requirements.
Select or develop tools to cleanse, organize, and transform data and to maintain, defend, and update data structures and integrity on an automated basis.
Develop data products to facilitate self-service capabilities and assist the data teams to increase their efficiency and effectiveness.
Collaborate and communicate effectively within cross-functional teams that span internal Data Science & Analytics teams, IT, business groups, and executive stakeholders.
Be a positive force to cultivate a culture that is passionate about developing data tools as a business driver.
Job ID
368348BR

Address1
ONE H&R BLOCK WAY

City
KANSAS CITY

State
Missouri

Employee Type
Regular

What you'll bring to the team...
Education / work experience should include most of these, depending on level:
Bachelor’s degree in Computer Science or a related technical field (or equivalent work experience and technical skills)
Data warehousing and ETL solutions
APIs in a microservices architecture
Big-data technologies and the Hadoop stack (MapReduce, Hive, Pig, Hbase
NoSQL implementations (MongoDB)
Developing Java-based software solution
At least one scripting language (Python, Perl, JavaScript, Shell
Developing software solutions to solve complex business problems
Working with data scientists and other data users
Posting Title
Data Engineer (open level)

Sponsored Job
#hrbjob

Job Family
Corporate Analytics",3.6,"H&R Block
3.6","Kansas City, MO","Kansas City, MO",10000+ employees,1955,Company - Public,Other Retail Stores,Retail,$2 to $5 billion (USD),"Intuit, Jackson Hewitt, Liberty Tax Service"
Senior Data Engineer,-1,"This is a Data Engineer position for supporting a Navy program located in Quantico, Virginia.

We are seeking a Data Engineer to join our team of committed technical professionals to protect those who serve against criminal, terrorism and emerging threats. Are you passionate about analytics and innovation? Our employees enjoy a fast-paced, collaborative culture and the ability to directly impact our business. You will identify technical issues and opportunities for efficiency and provide technical insights through system design and configuration perspectives. This role is both challenging and rewarding.

You will support the mission through the implementation of a modern, integrated internal data infrastructure with a focus primarily on exploiting the established data foundation to make internal and customer-centric business processes as effective and efficient as possible, laying the foundation for cognitive capabilities that can sense and respond to both internal and external customer data needs. The candidate will also focus on expanding the organization’s data ecosystem to include context-rich data while maintaining the agility needed to spark innovation.

How you will make a difference:
Establish shared operational data and integrated enterprise data, all while managing and/or improving data quality and security through the creation of business-driven governance structures and culture change management.
Establish data policies, standards, and procedures that improve data quality, availability, accessibility, security, usability, and enforcement of enterprise information management (EIM) program requirements.
Establish enterprise standards – including a uniform and repeatable system development lifecycle methodology for Reference Data and Master Data (e.g., a common set of standards for data naming, abbreviations, and acronyms).
Develop a Master Data Management (MDM) Plan that focuses on the technology, tools, and processes ensuring master data is coordinated across the enterprise. MDM is a method used to define and manage the critical data of an organization to provide, with data integration, a single point of reference. The data that is mastered may include reference data – the set of permissible values, and the analytical data supporting decision making. MDM provides a unified master data service intended to provide accurate, consistent and complete master data across the enterprise and to business partners.
Recommend solutions based on performing industry-specific analysis, such as case studies describing data management best practices, identifying trends across the industry.
Make recommendations to improve the efficiency and effectiveness in how the agency acquires, stores, manages, shares and applies its data.
Engage business users and stakeholders for the increased release of actionable high-quality data on key operational and tactical activities at NCIS.
Develop technology solutions to provide the platform, training, and standardized tools enabling querying, data mining, statistical analysis, reporting, scenario modeling, data visualization, and dash-boarding, and processes for a centralized, or analytics as a service model, allowing for the sharing of data across the enterprise from a common hub, facilitates cross-organizational data initiatives due to its enterprise-wide view of data assets and needs.
Basic Qualifications
Required: A bachelor’s or master’s degree in computer science, data science, operations research, statistics, applied mathematics, or a related quantitative field [or equivalent work experience such as, economics, engineering and physics] is [preferred/required]. Alternate experience and education in equivalent areas such as economics, engineering or physics, is acceptable. Experience in more than one area is strongly preferred.
Required: Three to six (midlevel) of relevant project experience in successfully launching, planning, and executing data science projects. Preferably in the domains of risk modelling and quality assessment.
Preferred: Specialization in text analytics, image recognition, graph analysis or other specialized ML techniques such as deep learning, etc.
Preferred: the candidates are adept in agile methodologies and well-versed in applying DevOps/MLOps methods to the construction of ML and data science pipelines.
Coding knowledge and experience in several languages: for example, R, Python, Java, C++, Excel, MATLAB, etc.
Experience with popular database programming languages including SQL, PL/SQL, others for relational databases and upcoming non-relational databases such as NoSQL/Hadoop-oriented databases such as MongoDB, Cassandra, others.
Preferred: Specialized/operational data scientists may need further high-performance computing (HPC)/compute skills; larger data science teams, in particular, may require further degrees of specialization such as:
Experience with distributed data/computing tools such as MapReduce, Hadoop, Hive, Kafka, and MySQL
Experience of working across multiple deployment environments including cloud, on-premises and hybrid environments, multiple operating systems and through containerization techniques such as Docker, Kubernetes, AWS Elastic Container Service, and others.
Experience in one or more of the following commercial/open-source data discovery/analysis platforms: RStudio, Spark, KNIME, RapidMiner, Alteryx, Dataiku, H2O, SAS Enterprise Miner (SAS EM) and/or SAS Visual Data Mining and Machine Learning, Microsoft AzureML, IBM Watson Studio or SPSS Modeler, Amazon SageMaker, Google Cloud ML, SAP Predictive Analytics.
Preferred: Expertise in solving vision, text analytics, credit scoring, and failure prediction problems.
Knowledge and experience in statistical and data mining techniques such as generalized linear model (GLM)/regression, random forest, boosting, trees, text mining, hierarchical clustering, deep learning, convolutional neural network (CNN), recurrent neural network (RNN), T-distributed Stochastic Neighbor Embedding (t-SNE), graph analysis, etc.
Strong documentation skills. Required: Certifications as per Cybersecurity Workforce Management and Qualification Manual, SECNAV M-5239.2.
Required: Eligible AND adjudicated to the Top Secret (TS SCI) clearance level is required to start.
About Inventium.io:

Inventium.io LLC is a technical consulting and software development services company dedicated to protecting and advancing our national defense and scientific capabilities. Based out of the Washington DC area, we rely on innovation to continually advance our employees' skills and provide digital transformation solutions to our customers.

With proven records of successfully delivering quality services and solutions to multiple federal agencies, our technical competencies include Emerging Technology Solutions, DevSecOps, Cloud Migration, Machine Learning, System Modernization, and Technology Management.

Benefits and Perks
Employer paid Health Benefits (Medical, Dental and Vision)
Retirement Plan
Paid Time Off and Federal Holidays
Training and Development
Employee Referral Program
Awards and Recognition",5.0,"inventium.io LLC
5.0","Quantico, VA","Washington, DC",1 to 50 employees,2016,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Senior Software Engineer,-1,"At Pacific Biosciences, our R&D team is committed to developing innovative products that enable scientists to excel in a wide variety of life science research fields, including human biomedical, plant and animal sciences, and microbiology and infectious disease. Our unique Single Molecule, Real-Time (SMRT) sequencing platforms generate true high-quality long reads, giving researchers a more comprehensive view of genomes, transcriptomes, and epigenomes from any organism.

The Primary Analysis group, as part of the larger software engineering team at PacBio, develops algorithms and HPC solutions for decoding the raw data streams, generated through high-speed optical detection of the SMRT sequencing reactions, into DNA sequence reads. We operate at the intersection of cutting-edge nanotechnology and state-of-the-art bioinformatics tools, and our responsibilities span the full product development life cycle in an aggressive time-to-market environment. These include analysis and algorithm development in coordination with chemistry and systems R&D; the development of real-time analysis pipelines; and the development of validation and support infrastructure geared towards product system reliability and internal R&D support. We are seeking a talented algorithm engineer with a strong background in the physical or machine-learning/data sciences who also has a passion for designing and developing performance-critical data analysis solutions.

Responsibilities:

Design, develop, and test signal- and sequence-analysis algorithms that will drive fundamental improvements in basecalling accuracy and yield.
Work collaboratively in a team environment to solve challenging problems in software architecture and scalability of real-time analysis pipelines for our next-generation sequencing platforms.
All listed tasks and responsibilities are deemed as essential functions to this position; however, business conditions may require reasonable accommodations for additional tasks and responsibilities.

Key Skills and Background:

3+ years of experience shipping product software in a scientific or quantitative domain.
Demonstrated skills applying numerical methods, statistical signal processing, or machine-learning techniques to high-throughput, performance-critical analysis applications.
Linux-based systems programming experience with knowledge of OS, toolchain and hardware constraints.
Strong C++ programming experience in applications geared towards performance and scalability; previous experience in CUDA programming for GPU is a plus.
MS, PhD or equivalent experience in a quantitative field (physics, CS, etc.), preferably with an applied math or algorithmic focus.
Engineering instincts to efficiently investigate and solve the problem at hand, from prototype development (Python, R, MATLAB, etc.) to production designs.
Team player, with strong communication skills, and comfortable as a self-starter in an agile, fast-paced development environment.
All qualified applicants will receive consideration for employment without regard to race, sex, color, religion, national origin, protected veteran status, or on the basis of disability, gender identity, and sexual orientation.",3.7,"Pacific Biosciences
3.7","Menlo Park, CA","Menlo Park, CA",201 to 500 employees,2000,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,$50 to $100 million (USD),Illumina
Sr Innovation Engineer,"$75K-$134K
(Glassdoor est.)","Company Information

Solid reputation, passionate people and endless opportunities. Thats Travelers. Our superior financial strength and consistent record of strong operating returns mean security for our customers and opportunities for our employees. You will find Travelers to be full of energy and a workplace in which you truly can make a difference.

Target Openings

1

Job Description Summary

Innovation is at the core of everything we do. We continue to ask ourselves, whats next? as we navigate the ever-changing insurance landscape. Continuing our customer journey toward the cutting-edge, we are looking for a forward-thinking individual that thrives in ambiguity, who believes that with every challenge comes a new opportunity for solutions.

As a member of the Innovation Technology team, you will partner with research scientists and product managers to discover, invent, and build solutions at scale. As a team, you will work on challenges in machine perception, data mining, machine learning, and natural language understanding.

We are looking for a hands-on individual with strong foundational knowledge highly scalable architectures and platforms. If you like using a variety of skills in technology and solving complex problems, work collaboratively in a small agile team environment, you might just be the person we need on our team!

Primary Job Duties & Responsibilities
Work closely with Cloud Engineering to build an innovation platform; a collection of reusable and extensible containers and tools specific to developing insurance products and platforms.
Recommend integration strategies, enterprise architectures, platforms and application infrastructure required to successfully implement a complete solution using best practices.
Produce quality output for highly visible IT products, services and future business development.
Assist in hands-on remediation of application stability and performance.
Adopt and communicate new concepts, ideas, techniques.
Manage multiple projects simultaneously.
Provide 'Shrink Wrap' solutions to solve business and technical needs. As part of our innovation process, be able to scale Minimum Viable Product to production systems.
Design and lead integration of analytic data products, including pilots and proof of concepts.
Frequently present and translate complex information in relevant business terms.
Constantly learn new skills within small teams.
No direct HR people management but will lead teams in project & program contexts.
Education, Work Experience, & Knowledge
Bachelors Degree in STEM (Science, Technology, Engineering, Mathematics) related field and 3+ years of experience or 10+ years of experience building highly scalable platforms and reusable components
Job Specific Technical Skills & Competencies
2+ years of experience working with Amazon Web Services (AWS) or equivalent cloud. Must be recent experience.
5+ years of designing and developing on-premise and cloud solutions.
3+ years of experience as a technical lead.
Experience in software engineering with relevant technologies (Java, JavaScript, Python etc.).
Experience with the application delivery process.
End-to-end experience with data, including querying, aggregation, analysis, and visualization.
Preferred Qualifications
AWS certified developer and/or architect
Proven ability to work creatively and analytically in a continuously evolving environment.
Exhibits high levels of learning agility in which they seek out and learn from unfamiliar experiences and then apply those lessons to succeed in the next new situation.
Ability to leverage business knowledge to determine approaches to execution.
Strong communication and presentation skills with the ability to present and translate complex information to leadership and non-technical teams in relevant business terms.
Uses effective listening skills and communication to build relationships across the organization.
Ability to Influence with experience working with matrixed staff to complete tasks in a timely manner.
Environmental / Work Schedules / Other
Travel Required
Equal Employment Opportunity Statement

Travelers is an equal opportunity employer.",4.1,"Travelers
4.1","Hartford, CT","Hartford, CT",10000+ employees,1853,Company - Public,Insurance Carriers,Insurance,$10+ billion (USD),-1
Senior Data Scientist,-1,"At CCRi, our clients look to us to solve their hardest problems, and we have a long history of exceeding their expectations. With clients in both the private sector and the US government, we provide a variety of advanced analytical techniques, and we render our solutions in software that our clients can apply immediately.

We are currently not expecting openings until after August 2020. However, we are always interested in experienced data scientists, especially those with some management experience.

The Role

You'll help create machine learning analytics that will be integrated into streaming data processing pipelines and appealing user interfaces that provide real-time situational awareness and expose advanced analytics to end users. As a senior data scientist, you will be expected to balance technical responsibilities (design and development) with team responsibilities (technical planning, roadmaps, ticket creation and delegation, mentorship). You’ll likely conduct demos and give presentations, and will be expected to contribute to the data science culture and ecosystem at CCRi through opportunities like design reviews and shared learning opportunities.

Who You Are
Curious: You enjoy peeling apart a problem and examining the interrelationships between data and how they can be used to form a solution.
Creative: You try new approaches to solving problems, looking for ways to apply techniques across domains and in new contexts.
Practical: You explore theories with an eye to their real world applications and their potential for improving performance for clients.
Collaborative: You work well on a team and understand how to lead a group of bright, technical coworkers. You can explain your work to your peers and source ideas and improvements from them.
Determined: You enjoy the challenge of finding solutions to difficult problems, testing them to discover what is successful and what should be optimized further, to develop industry-leading tools. You learn from failure and trying again.
Organized: You know how to keep track of both high-level goals and the tasks required to meet those goals. You take personal ownership of your team’s success.
Our Senior Data Scientists will have some combination of the following:
Understanding of structure and theory of common machine learning models
Familiarity with common machine learning libraries for implementation (sklearn, weka, tensorflow, torch, …)
Proficiency in one or more of: Python, Scala, Java, R, Julia, Matlab
Expertise in a sub-field of machine learning (computer vision, natural language processing, ...)
Ability to understand and implement new models from the literature
Project team leadership
Experience presenting team progress and results
Technical writing experience, including reports and proposals
Experience with distributed analytics and processing (Spark, Hadoop, …)
Experience with geospatial data and analytics
Active TS security clearance
Familiarity with Agile development
Requirements
US citizenship required. We do not offer sponsorships.
Multiple years of experience as a data scientist, machine learning engineer, or similar role.
Benefits

CCRi is a small engineering firm located in Charlottesville, Virginia. We develop and deploy novel machine-learning approaches to real problems at massive scale. Since 1992, we’ve been stopping bombs, predicting piracy, and guiding disaster relief.
Intellectually Challenging Work
Health Insurance
Short Term Disability Insurance
Generous Defined Benefit Retirement
Very Flexible Vacation Policy
Want to know more? Check out our recruitment video and blog.

The job description above is not intended to be comprehensive list. Responsibilities, activities, duties, and/or tasks may change or be assigned at any time.

CCRi is committed to a diverse and inclusive workforce because we know that our differences benefit our employees, our customers, and our community. We are proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, color, religion, age, sex, sexual orientation, gender identity, national origin, status as a an individual with a disability, status as a protected veteran, or any other applicable legally protected characteristics.",4.5,"CCRi
4.5","Charlottesville, VA","Charlottesville, VA",51 to 200 employees,1989,Company - Private,Aerospace & Defense,Aerospace & Defense,$10 to $25 million (USD),-1
SENIOR SOFTWARE ENGINEER & SOFTWARE ARCHITECT,-1,"Job Description
Senior Software Engineer, Software Architect
JOB SUMMARY

The Senior Software Engineer, Software Architect will develop software for Company innovative semiconductor X-Ray inspection system. The Senior Software Engineer will collaborate with Applications, QA, and Algo teams for high performance solutions and optimization per customer issues. It will be important to be comfortable working in a small company environment and a typical startup with engineers and scientists.

ABOUT THE CLIENT

Based in San Jose, California, client was founded in 2013 expressly to bring high speed inspection and metrology technology to the semiconductor packaging industry. Client founders anticipated the need to deploy inline 100% transmissive inspection into the semiconductor packaging manufacturing process and developed the company’s technology with this end in mind. The results, Client’s HR-AXI technology suite brings together the company’s unique data acquisition architecture with proprietary machine learning analysis techniques to provide customers with process monitoring and defect detection capabilities not found on any other products in the market. This job description can be updated at any time.

RESPONSIBILITIES
Designs, develops, troubleshoots, and debugs software programs for enhancements and new products, focused on creating high quality and high-performance solutions while maintaining high-level coding standards.
Develops software and tools in support of design, infrastructure, and technology platforms. Develops software solutions by studying information needs, conferring with users, and studying systems flow, data usage, and work processes
Supports hardware compatibility and/or influences hardware design based on software needs; work as part of cross-functional team to solve and implement system level problems.
Monitor application stability, performance, and availability. Promptly resolve issues impacting operations.
Work with engineering, documentation, and applications departments to ensure successful development and delivery of overall product.
Provide appropriate project feedback to management in a timely and appropriate format.
QUALIFICATIONS AND REQUIRED SKILLS
Education requirement: Bachelor’s degree in Computer Science, Electrical Engineering, or similar technical field required. Master’s or PhD strongly preferred.
Experience requirement: Minimum of 8 years of related experience working in software development.
Strong expertise in C# .NET. WCF, WPF, Database development. In addition, Python experience a plus.
Experience with Image processing algorithms implementations is a plus
Experience with software development for Factory Automation for Semiconductor equipment, a plus.
Self-starter able to think and act independently to translate general objectives into tangible results, with a record of delivering successful designs on schedule.
Demonstrated ability to organize, manage, and complete multiple assignments with challenging timelines independently and effectively.
Demonstrated analytical and problem-solving skills with high attention to detail.
Proactive approach to problem-solving. Build relationships with stakeholders to support successful design, build and testing.
Strong verbal and written communication, good attitude, and work ethic. Ability to communicate technical concepts and results clearly.
Experience with Git and Azure DevOps, a plus.",3.0,"Simple Solutions
3.0","San Jose, CA","Morgantown, WV",1 to 50 employees,2006,Company - Private,IT Services,Information Technology,Less than $1 million (USD),-1
"Senior SDE, Catalog Big Data and Machine Learning",-1,"Amazon's Catalog DataWorks team is looking for highly motivated engineers. We are embarking on multiple new initiatives to re-organize Amazon's catalog of billions of products, in new and interesting views, that drive several features Amazon's customers love. Today, these views drive hundreds of popular features like product recommendations, clustering of similar products, and shopping with Alexa. We will build a new near real-time Catalog Data Lake on AWS, to enable engineers and scientists across Amazon to solve customer problems faster. Come join us on this exciting journey!

As an engineer on this team, you will own the Catalog Data Lake end-to-end. You will work closely with business partners to synthesize technical requirements. You will design and implement significant parts of the platform. You will learn and use industry standards like Spark and Parquet as well as modern AWS offerings like EMR, Glue, Athena, and Redshift. We are fortunate to be at the cusp of innovation in both the e-commerce business as well as cloud technology. As a key stakeholder, you will constantly learn new patterns, solve key customer problems and strive to make AWS better along the way.Basic Qualifications
Bachelor's degree or higher in computer science or math is required.
Strong computer science fundamentals - algorithms, data structures and design patterns.
At least 8 years of software development experience.
At least 3 years of experience building and operating Big Data systems.
Experience mentoring, guiding and influencing peers.
Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.",-1,Amazon Corporate LLC,"Seattle, WA",-1,-1,-1,-1,-1,-1,-1,-1
Senior Data Engineer,-1,"We invite you to explore a future with us at PRA Group, a diverse and growing company that has a tangible impact on the global economy.

Position Summary:

As a Senior Data Engineer, you will be part of a team of data engineers who research and development design, test, and deployment of automated process, reports and data processing systems. Data engineer team use their analytics skills to develop solutions for storing and retrieving information related to the processing, publication, and distribution of scientific data products You will help the team philosophy on software engineering and serves as a mentor for understanding the inner workings and the debugging of complex queries and workflows on parallel data processing systems.
The candidate will have a strong technical ability, excellent project management skills, great communication skills, and a motivation to achieve results in a fast-paced environment.

Responsibilities
Create and maintain the high-quality data set to serve as the source of truth for various fundamental data captured, and hence enabling data scientist to be more confident on their analysis, machine learning training and reporting.
Create and maintain blue print for data to integrate, centralize and maintain the data sources.
Implement data preparation solutions.
Implement, verify, design, and maintain software systems.
Ensure data integrity by leveraging proven methodologies, including data reconciliation, data integration and data audits.

Requirements
MS in Computer Science, Engineering, Mathematics, relevant certificates or work experience
6+ years of experience working with relational databases, data warehousing and advanced working SQL knowledge.
6+ years of successful history in manipulating, processing, and analysis of large datasets (million+ records) and comfortable analyzing datasets of 10+ million records
6+ years of experience with the following tools/concepts:
ETL process development tools, preferably SQL Server Integration Services (SSIS)
Object-oriented development
Software development lifecycle
4+ years of experience working with Data Visualization and Descriptive Statistics, preferably SQL Server Reporting Services (SSRS) and/or Microsoft Power BI
4+ years of experience executing full software development life cycle.
Strong skills on identifying and resolving performance and data quality issues
Solid software engineering skills across multiple languages
Strong analytical and problem-solving skills
Passion for teaching and mentoring
Strong verbal and written communication skills

Desired Qualifications:
Experience working with finance industry.
Experience with one or more of the following:
Python
Scala
Java
Informatica
Manipulating/handling data in JSON or XML formats
PL/SQL
All qualified applicants will receive consideration for employment regardless of age, race, color, sex, gender, religion, national origin, physical or mental disability, citizenship, or any other classes recognized by state or local law or any other characteristic protected under applicable federal, state or local law. We are a drug free workplace.",2.9,"PRA Group
2.9","Richmond, VA","Norfolk, VA",1001 to 5000 employees,1996,Company - Public,Financial Transaction Processing,Finance,Unknown / Non-Applicable,-1
R&D Computer Scientist/Engineer - Space & Ground Systems (Experienced),"$67K-$121K
(Glassdoor est.)",":

Passionate about your work and dream of utilizing state-of-the-art facilities to explore solutions? Join a robust, Agile team that solves significant issues and challenges for our nation's security\!

We are seeking a Computer Scientist to join our dynamic team. We specialize in research, development, and delivery of robust ground systems for remote sensing assets of national security importance. Our emphasis is on creating maintainable, high-quality software through proven Agile techniques. We believe in the value of teamwork and maintaining a cohesive, performance driven team capable of implementing rapid solutions to novel problems.

On any given day, the selected candidate can expect to:
Work on an Agile team to develop software systems which solve challenging remote sensing problems
Apply your experience and knowledge to improve the software, the development process, and the team
Partner collaboratively with domain specialists, phenomenologist, architects, developers, technical leads, and customers
Research and develop new techniques and technologies with an aim to enhance the quality of our software, how we produce the software, and how we use the data collected
Required:
Undergraduate and advanced degree (Masters or PhD) in Computer Science or a related STEM field; a bachelor's degree (Computer Science) plus four years' experience may be considered in lieu of an advanced degree
Two or more years related experience, in addition to the education requirement above (or PhD in related field)
Experience in software design, engineering and development skills, including familiarity with modern software development practices and tools
Experience with object-oriented software development (e.g., C\+\+, Java and Python)
Experience with Unix/Linux systems
Can obtain a DOE Q clearance
Desired:
Knowledge and experience with implementation of the full software development process using Agile or Iterative methodologies
Experience with large-scale (1M\+ lines of code) systems
Experience using a subset of the following: git, CMake, system engineering, hardware and software architecture, distributed system design, data exploitation/mining/fusion algorithms, digital signal processing, image processing, optical systems, command and control systems, numerical analysis, modeling and simulation, relational/object/geographic database technologies, user interfaces, scientific data visualization, web services technologies, and multi-core/GPU/parallel computing
Active DOE clearance
Department Description:

We develop operational monitoring software in supports of the US and International nuclear monitoring and non-proliferation mission. From basic research and development to fully deployed operational data processing and analysis systems, the department specializes in software feature development, geophysics, seismology/infrasound, machine learning, data analytics, algorithm development and data analysis. This department is currently responsible for the National Data Center Modernization and the design and engineering of systems supporting Proliferation Assessment.

About Sandia:

Sandia National Laboratories is the nations premier science and engineering lab for national security and technology innovation, with teams of specialists focused on cutting-edge work in a broad array of areas. Some of the main reasons we love our jobs:
Challenging work withamazingimpact that contributes to security, peace, and freedom worldwide
Extraordinary co-workers
Some of the best tools, equipment, and research facilities in the world
Career advancement and enrichment opportunities
Flexible schedules, generous vacations,strongmedical and other benefits, competitive 401k, learning opportunities, relocation assistance and amenities aimed at creating a solid work/life balance\
World-changing technologies. Life-changing careers._ Learn more about Sandia at: http://www.sandia.gov

*These benefits vary by job classification.

Security Clearance:

Sandia is required by DOE to conduct a pre-employment drug test and background review that includes checks of personal references, credit, law enforcement records, and employment/education verifications. Applicants for employment need to be able to obtain and maintain a DOE Q-level security clearance, which requires U.S. citizenship. If you hold more than one citizenship (i.e., of the U.S. and another country), your ability to obtain a security clearance may be impacted.

Applicants offered employment with Sandia are subject to a federal background investigation to meet the requirements for access to classified information or matter if the duties of the position require a DOE security clearance. Substance abuse or illegal drug use, falsification of information, criminal activity, serious misconduct or other indicators of untrustworthiness can cause a clearance to be denied or terminated by DOE, resulting in the inability to perform the duties assigned and subsequent termination of employment.

EEO Statement:

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, or veteran status and any other protected class under state or federal law.",3.8,"Sandia National Laboratories
3.8","Albuquerque, NM","Albuquerque, NM",10000+ employees,1949,Government,Federal Agencies,Government,$2 to $5 billion (USD),"Los Alamos National Laboratory, Lawrence Livermore National Laboratory"
Senior Software Engineer - Infrastructure,-1,"Freenome is looking for an experienced Senior Software Engineer - Infrstructure to help build a cloud-native machine learning platform for the world's largest multi-analyte cancer genomics dataset.As an engineering-forward biotech company, we apply modern engineering practices to build reliable, maintainable, scalable, and secure production systems for our clinical lab and Computational and Molecular Research Scientists.Our infrastructure team is a small group where you will help set the culture and build the systems that allow us to move fast without breaking things. This is an opportunity to do meaningful engineering work that will directly save lives.We value:* Rapid iteration and tight feedback loops* Continual improvement rather than disruption* Technical simplicity and elegance* A focus on the larger goals* Mutual respect and blameless postmortems* A culture of diversity and inclusionResponsibilities include:* Improving the reliability and scalability of our platform for genomic research in concert with the Software Engineers and Computational Scientists who depend on it daily* Planning for significant growth and scaling challenges as we transition from research to product development* Lending your expertise to design and code reviews* Anticipating technical scaling limits before we reach them* Continually improving our security posture* Reinforcing good development practices across the entire organizationWhat We're Looking For:* 5+ years of experience with production infrastructure, automation, and monitoring* B.S. or M.S. in computer science or a related technical field, or comparable experience* Experience in analyzing and troubleshooting distributed systems* Software design and development expertise, especially in Python* Practical knowledge of Linux internals* A systematic problem-solving approach, coupled with effective communication skills and a sense of ownership and driveNice to Haves:* Machine learning and data science tools, such as TensorFlow, PyTorch, Jupyter, or Kubeflow* Systems programming languages such as Go, Rust, or modern C++* Kubernetes, including tools such as Helm or Flux* Docker and Linux containers* Production deployment automation tools, such as Terraform or Ansible* Large-scale and/or high-performance storage systems, such as PostgreSQL, MySQL, Redis, HBase, Spanner, or Cassandra* Microservices, service meshes, or distributed tracing* Security, encryption, and certificate management* Networking, firewalls, load balancers, and HTTP internals* Monitoring, alerting, logging, and tracing tools, such as Prometheus, fluentd, or Jaeger* Data pipelines, such as Kafka, Spark, Airflow, Argo, Beam, or Flink* Google Cloud Platform experience* Experience with software in a regulated environment* Genomics or bioinformatics backgroundAbout FreenomeFreenome is on a mission to empower everyone with the tools they need to detect, treat, and ultimately prevent diseases.By applying advanced machine learning techniques to recent breakthroughs in genomic science, Freenome is developing simple blood tests to detect early-stage cancer and make treatments more effective. The company has raised $238 million from investors such as RA Capital, Polaris Partners, Perceptive Advisors, Andreessen Horowitz, funds and accounts advised by T. Rowe Price Associates, Inc., GV (formerly Google Ventures), Roche Venture Fund, Kaiser Permanente Ventures, American Cancer Society's BrightEdge Ventures, Data Collective Venture Capital, Novartis, and Verily Life Sciences (formerly Google Life Sciences).Our ScienceFreenome is building technology to gain an understanding of the body through several analytes derived from blood. These signals include cell-free DNA, methylation of cell-free DNA, cell-free RNA, circulating proteins, and immune profiling derived from thousands of prospective samples. By developing novel statistical learning methods and applying them to integrate various -omics datasets, Freenome is a leader in modeling specific biological mechanisms to capture disease dependent signatures such as gene expression, immune response, tumor burden, the tissue of origin, and 3D chromatin structure.By building comprehensive discovery datasets and modeling critical biological systems, Freenome is learning what biological changes are present within the blood between a variety of different disease states including cancer, autoimmune disorders, infections, drug response, and aging. With the combination of Freenome's datasets, cross-functional technical expertise, and mission to uncover the biological truth, we seek to positively change the lives of millions through the early detection and early treatment of disease.Our CultureFreenomers are technical and creative, visionary and grounded, empathetic and passionate. We build teams around divergent expertise, which allows us to solve problems and uncover opportunities in unique ways. Freenomers are some of the most talented experts in their fields, coming together to advance healthcare one breakthrough at a time.We value empathy, integrity, and trust in one another. That means embracing other's perspectives, those of our coworkers and those of the patients and communities we serve. It means knowing when to push, and when to listen. At Freenome, we give each other the benefit of the doubt in the belief that we're all working as a team toward the same goals, and empower others to grow in a collaborative environment.What does a successful person look like at Freenome?Those who thrive at Freenome prioritize, manage, and execute their own goals in alignment with those of the company. They embrace our values of empathy, integrity, and trust, and hold themselves and their team accountable. They crave collaboration with brilliant minds from unfamiliar fields of study and believe that hiring and mentorship are fundamental to our success. Above all, they welcome and provide constructive feedback and criticism, trusting in the good intentions of others, and secure in the knowledge that embracing mistakes is the best way to learn and move on. For those who crave challenges, understudied problems, and the chance to see their work impact the lives of millions of people affected by cancer every year, there's no better place to be.Freenome is proud to be an equal opportunity employer, we value diversity in every way. Freenome does not discriminate on the basis of race, religion, color, sex, gender identity, sexual orientation, age, non-disqualifying physical or mental disability, national origin, veteran status or any other basis covered by appropriate law.",5.0,"Freenome
5.0","South San Francisco, CA","South San Francisco, CA",51 to 200 employees,2014,Company - Private,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,Unknown / Non-Applicable,-1
Senior Data Scientist,"$113K-$180K
(Glassdoor est.)","Requisition ID: 255369
Work Area: Software-Research
Expected Travel: 0 - 50%
Career Status: Professional
Employment Type: Regular Full Time
Career Level: T3
Posting Date : 6/10/2020

COMPANY DESCRIPTION

SAP started in 1972 as a team of five colleagues with a desire to do something new. Together, they changed enterprise software and reinvented how business was done. Today, as a market leader in enterprise application software, we remain true to our roots. That’s why we engineer solutions to fuel innovation, foster equality and spread opportunity for our employees and customers across borders and cultures.
SAP values the entrepreneurial spirit, fostering creativity and building lasting relationships with our employees. We know that a diverse and inclusive workforce keeps us competitive and provides opportunities for all. We believe that together we can transform industries, grow economics, lift up societies and sustain our environment. Because it’s the best-run businesses that make the world run better and improve people’s lives.

Purpose and Objective: SAP America, Inc. seeks a Senior Data Scientist at our office location in Palo Alto, CA to execute mathematical modeling of our customers’ business problems, develop algorithms, and applications to solve these problems, and help our customers directly to understand and implement the results of the analysis.

Expectations and Tasks: Work directly with industry experts and technology experts to translate our customers’ business needs into mathematical models and present and deliver a solution to the client. Support and provide expert advises to SAP’s sales team (Go-To-Market) to generate new customer business in the area of data science. Responsible to lead small project teams in the execution of our customer projects. Work and communicate as a part of a high-performance team in an international environment. 50% travel required.

Education and Qualifications/Skills and Competencies: Bachelor's degree in Computer Science, Engineering, Mathematics, or related field of study and 6 years of experience required. The company will also accept a Master's degree and 4 years of experience.

Work Experience: Experience must involve 4 years in the following: Foundation topics in Linear Algebra, Probability & Statistics, Multivariate Calculus; programming with SQL, Python, R; working with big data preferably in a productive project. Experience must also involve: supervised and unsupervised Machine Learning algorithms and deep learning frameworks; Data Visualization; data wrangling, developing pipelines for Machine Learning and data preparation activities for developing a Machine Learning application; and Distributed Application development. 50% travel required.

Travel: 50% travel required.

Internal use only: reference code lhrs4262

EX:OUT

SAP'S DIVERSITY COMMITMENT

To harness the power of innovation, SAP invests in the development of its diverse employees. We aspire to leverage the qualities and appreciate the unique competencies that each person brings to the company.

SAP is committed to the principles of Equal Employment Opportunity and to providing reasonable accommodations to applicants with physical and/or mental disabilities. If you are interested in applying for employment with SAP and are in need of accommodation or special assistance to navigate our website or to complete your application, please send an e-mail with your request to Recruiting Operations Team (Americas: Careers.NorthAmerica@sap.com or Careers.LatinAmerica@sap.com, APJ: Careers.APJ@sap.com, EMEA: Careers@sap.com). Requests for reasonable accommodation will be considered on a case-by-case basis.

EOE AA M/F/Vet/Disability:

Qualified applicants will receive consideration for employment without regard to their age, race, religion, national origin, gender, sexual orientation, gender identity, protected veteran status or disability.

Additional Locations :",4.6,"SAP
4.6","Palo Alto, CA","Walldorf, Germany",10000+ employees,1972,Company - Public,Computer Hardware & Software,Information Technology,$10+ billion (USD),"Salesforce, Oracle, Microsoft"
Senior Data Engineer,"$104K-$120K
(Glassdoor est.)","Position Overview: From software hacking to hardware hacking, we help secure everything from cryptocurrency exchanges and space telescopes to autonomous vehicles and the electric grid. Today, Praetorian is making significant investments in terms of financial and engineering resources to develop a radically new customer experience we call “Security-as-a-Service” to provide customers with a unified, efficient, and data-driven security platform. We are looking to add the right individual to our growing team supporting the next wave of cybersecurity products and solutions.

As part of that investment, Praetorian is seeking a seasoned Data Engineer with a successful track record in data engineering in a hyper growth company setting. You will have the opportunity to work with some of the best security engineers in the world who hail from organizations such as Amazon, CIA, Facebook, Google, Microsoft, NSA, Redhat, Sun Microsystems, and US Air Force. As an Inc. Best Places to Work, Inc. 500 | 5000, Cybersecurity 500, and Austin Fast 50 Award recipient, we are seeking an individual that understands the professional and personal growth attached to this opportunity and who has the corresponding internal drive to maximize it.

To learn more about Praetorian, visit: https://www.praetorian.com/careers

Career opportunity:
Join an industry with massive socio, economic, and political importance in the 21st century
Work alongside some of the best and the brightest minds in the security industry
Leave an indelible mark on a company where individual input has real impact
Be recognized, internally and publicly, for your contributions in a high profile position
Align your career trajectory with a hyper growth company that is on the move
Core responsibilities:
Create pipelines to ingest and maintain complex data sets into Praetorian's data stores for use in machine learning models
Create tools to scour the internet to find important security information and ingest it into Praetorian's infrastructure
Work with data scientists to create and maintain data ontologies for security
Create the roadmap of how to continually evolve the data engineering infrastructure and techniques to improve Praetorian's ability to find security information
Mentor junior data engineers and teach them how to use data engineering techniques to solve real world problems
Communicate complex concepts to team members

Accountable for:
Creation of data engineering pipelines to find and ingest security vulnerabilities
Creation of data engineering tools to help label and validate data

Required qualifications:
At least 8 years experience designing and building data processing/ETL pipelines
At least 8 years experience in Python and Spark or similar technologies
At least 8 years experience with SQL and relational databases
At least 8 years experience parsing flat files
8+ years development experience
Prior track record in a hyper-growth, high-tech company
Bachelor's degree or equivalent practical experience

Desired qualifications:
Experience working with Google Tensorflow
Experience with modern technology stacks
Experience with micro-services architectures
Experience with cloud platforms and SaaS solutions
Experience with agile/scrum development practices
Experience with test driven development, continuous integration, continuous deployment
Experience with Git, JIRA, Confluence
Experience with Google Compute, Firebase, and GKE
Experience with Docker

Desired behaviors:
Relentless restlessness to turn theory into practice and develop production worthy code that solves real-world customer problems
Determination to always learn and get better and never rest on ones laurels
Personable individual who enjoys working in a team-oriented environment
Comfort dealing with ambiguity in an environment where we build the plane as we fly it
Ability to work within constraints and to challenge the status quo
Ability to self-direct work and truly own the position in a hyper-growth environment

Compensation package:
Competitive compensation
Ownership opportunity through employee stock option plan
Health, dental, and vision insurance
4% company 401K matching vested immediately

In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification document form upon hire.

We are committed to an inclusive and diverse Praetorian. We are an equal opportunity employer. We do not discriminate based on race, ethnicity, color, ancestry, national origin, religion, sex, sexual orientation, gender identity, disability, veteran status, genetic information, marital status, or any other legally protected status.

We ask that you please include a few paragraphs about yourself and what you are passionate about in your application.",4.7,"Praetorian
4.7","Austin, TX","Austin, TX",51 to 200 employees,2010,Company - Private,Enterprise Software & Network Solutions,Information Technology,$10 to $25 million (USD),-1
Software Architect/Engineer,"$139K-$155K
(Glassdoor est.)","Requisition ID: 47886

All Locations: El Segundo, CA (California)

A trusted partner. A national resource. A leader in national security space. We are THE Aerospace Corporation. A team that takes pride in our readiness to solve some of the most complex technical challenges in existence. With challenges spanning government to commercial, you’ll have the unique opportunity to work on projects that are literally evolving our nation's space and launch capabilities. We all share a common passion and aspiration – to serve a mission much bigger than ourselves. When you join our team, you’ll be part of a rare collection of thought leaders and game-changing innovators. Are you ready to launch your career?
Responsibilities
Do you enjoy solving challenging software problems? Want to contribute to the success of the nation's vital space systems? Aerospace is looking for software engineers interested in investigating and applying emerging software technologies to space-related systems. Aerospace's Applied Software Technologies Department (ASTD) team is growing as a leader in applying new software approaches and is looking for your contributions.

Key Functions
Providing software systems engineering skills to space, ground, and launch systems in the national security, civil, and commercial domains
Applying skills and adaptability in various areas that may include resolution of software systems issues. Support may include software development; lifecycle guidance; software consulting; software architectures; enterprise systems; and other related areas.
Expertise in artificial intelligence and data science is desirable
Providing technology recommendations, risk assessments, trade studies, and analyses
Providing expertise at technical interchange meetings, reviews, briefings to Aerospace, customer, and contractor personnel.
Learning new skills and mentoring others
Qualifications
Required
B. S. in computer science, computer engineering, electrical engineering, or equivalent required
Eight or more years experience ideally in complex systems
Ability to obtain and maintain a secret security clearance which is issued by the US government. US citizenship is required in order to obtain a security clearance.
Strong software technical background
Ability to work both independently and as part of a team
Ability to lead tasks
Willing to learn new approaches and mentor others
Ability to work on multiple tasks concurrently
Excellent communication and strong interpersonal skills
Willing to travel occasionally
Preferred
An M.S. or advanced degree in computer science, computer engineering, electrical engineering, or equivalent.
Strong experience in machine learning, deep learning, artificial intelligence, and/or cognitive/intelligent system techniques for use in data analysis and predictive response.
Transcript Requirement
Transcripts are required for this position.

Additional Requisition Details

Clearance Requirement: None

Access: None

Polygraph: None

Relocation Available: Yes

Employment Type: Regular

Work Schedule: Full Time

Company Statement

The Aerospace Corporation has provided independent technical and scientific research, development, and advisory services to national security space programs since 1960. We operate a federally funded research and development center (FFRDC) for the United States Air Force and the National Reconnaissance Office, and support all national security space programs. We also apply more than 50 years of experience with space systems to provide critical solutions to technologically complex systems in such areas as communications, shipping, law enforcement, and cyber, among others.

From our inception, our highly skilled technical staff has focused on ensuring the success of every mission and developing the most effective and economic space-related hardware and software in the world. Our greatest asset is the technical expertise of our people. Our state-of-the-art laboratory facilities are staffed by some of the leading scientists in the world.

All Aerospace employees working in organizations with technical responsibilities are required to apply for and maintain at least a Secret clearance. U.S. citizenship is required for those positions.

Equal Opportunity Commitment

The Aerospace Corporation is an Equal Opportunity/Affirmative Action employer. We believe that a diverse workforce creates an environment in which unique ideas are developed and differing perspectives are valued, producing superior customer solutions. All qualified applicants will receive consideration for employment and will not be discriminated against on the basis of race, age, sex (including pregnancy, childbirth, and related medical conditions), sexual orientation, gender, gender identity or expression, color, religion, genetic information, marital status, ancestry, national origin, protected veteran status, physical disability, medical condition, mental disability, or disability status and any other characteristic protected by state or federal law. If you’re an individual with a disability or a disabled veteran who needs assistance using our online job search and application tools or need reasonable accommodation to complete the job application process, please contact us by phone at 310.336.5432 or by email at ieo.mailbox@aero.org. You can also review The Equal Employment Opportunity is the Law poster and the supplement, as well as the Pay Transparency Policy Statement.",3.9,"The Aerospace Corporation
3.9","El Segundo, CA","El Segundo, CA",1001 to 5000 employees,1960,Nonprofit Organization,Aerospace & Defense,Aerospace & Defense,$1 to $2 billion (USD),-1
Sea Bird Scientific Senior Software Engineer,-1,"Help Delight the Scientists who will use our Next Generation of Software:
We are building a next-generation software suite to interact with
oceanographic research instruments. The software suite that Sea-Bird
Scientific ships with their instruments is used by oceanographers and
scientists to configure the instruments, retrieve measurement data, and
provide data processing, validation, and graphing capabilities.
Come help create a new next-generation of software that works across
platforms, makes use of the Cloud, and provides a better user experience
for the researchers using these instruments.

You_Might_Be_The_Ideal_Candidate_If_You
Are looking for a technical leadership role on a growing team, with room
to grow.
Like using new and advanced technology to make things easy for end-users
across multiple platforms (Windows, Mac, IOS, Android)
Like making complex functionality and scientific data easy for people to
work with and understand
Like to work with electronics and measurement instruments, measuring
things about the real world
Care about the oceans, and enabling scientists to study them with high
precision
Want to work with and help develop less experienced software and
electronics engineers while building software
Want to be in on the ground floor of a new software product, helping
define the architecture and select the technology used, working as part
of an experienced and stable company

As a senior member of the development team, you will:

Provide_Technical_Leadership_On_The_Team
Lead software design, considering architectural issues and tradeoffs
Develop and maintain programs in C#, JavaScript, C/C++, Python, Java and/
or other languages as required
Provide technical leadership on the development team, helping make the
whole team better, more efficient, and keeping the quality bar high
Design, implement, test and deploy both client and service software
Design and implement data communication software that uses RS-232 serial,
Ethernet, TCP-IP, and USB hardware and protocols
Test software with Sea-Bird Scientific s instruments and on various
operating systems and platforms
Design code for testability and code-sharing to support multiple
applications
Develop automated tests for unit and regression testing (functional,
integration, UI)
Help improve team processes and code quality, including Agile/Scrum,
Continuous Integration, automated testing, deployment, distributed source
code management, design and code reviews, etc.
Gain experience with a broad range of software technologies and make
technology choices objectively. Recommend how to bring new technology
into our products.
Build relationships with peers across the business and uses these
relationships to drive innovation

Delight Our Customers; the Scientists who use our Instruments:
User-centered design process to deliver products that delight our
customers.
User Experience (UX) / User Interface design and implementation (desktop,
or web UI)
Ability to work with customers and user representatives to understand
their needs and translate them into successful solutions
Cultivate innovations to provide rich functionality with ease of use
Develop and measure user feedback and feature usage metrics using
telemetry
Excellent Communication and Presentation Skills
Use low-investment prototyping to get UX feedback
Use Machine Learning/Artificial Intelligence to make our applications
smarter, able to help with things like data quality checks and instrument
health.

Requirements_For_This_Role
BS with 5+ years experience or MS with 3+ years experience in
Computer Science, Computer Engineering, Electronics Engineering or a
related STEM field. MS a plus.
Exceptional problem solving, critical thinking, and analysis skills,
applying computer science fundamentals like data structures and
algorithms
Experience with two or more programming languages such as: C# .NET,
JavaScript, C/C++, Python or Java.
Experience developing application UI for web and/or desktop applications,
e.g. using HTML, CSS, JavaScript, jQuery, Java or .NET. Experience with
JS frameworks like Angular or React a plus.
Demonstrated understanding of User Experience, User Interface and
Interaction Design with an emphasis on maximizing usability
Knowledge of using RESTful web services, JSON, and working with a server
API. Experience developing REST API and web services a plus.
Relentless focus on optimizing time to market while increasing usability
and quality
Experience in designing and developing complex framework and platform
solutions with practical use of design patterns
Experience maintaining high-quality software and User Experience by using
metrics and an analytics driven quality monitoring effort. Using software
telemetry to gather data a plus.
Excellent and persuasive verbal and written communication skills
Effective project and time management skills, especially using Agile
development
Solid data analysis and reporting skills
Experience writing complex multi-threaded applications
Experience configuring and using automated build and test pipeline for
CI/CD, e.g. Jenkins
Familiarity with developing software for desktop computing, embedded
devices, or Cloud services at Enterprise or web scale
Experience mentoring and growing other team members
Experience participating in the interviewing and hiring process for
developers
Familiarity with measurement instrument control and calibration concepts
is a plus.
Knowledge and experience with Machine Learning/AI concepts and
implementation is a plus.

Who is Sea-Bird Scientific?

Sea-Bird Scientific is the market leader in precision measurement instruments
for oceanographic measurement and research. Sea-Bird Scientific, located in
Bellevue WA, is a company that designs, manufacture and market oceanographic
instrumentation and systems that enable the world s leading scientists to
push the boundaries of ocean knowledge. Sea-Bird Scientific works with a global
network of international representatives and partners to serve customers in
more than 30 countries around the world. Our dedicated team is comprised of
individuals with diverse backgrounds and interests with a common goal of
serving the world s oceanographic community with leading edge technology an
solutions. We offer an entrepreneurial environment that is team-centered,
customer-driven, quality-focused, and growth-oriented. Working at Sea-Bird
Scientific gives you access to a robust career development process and
challenging 'stretch' opportunities, including a career growth path to other
operating companies owned by the Danaher Corporation.

Danaher Corporation and all Danaher Companies are equal opportunity employers
that evaluate qualified applicants without regard to race, color, national
origin, religion, sex, age, marital status, disability, veteran status, sexual
orientation, gender identity, or other characteristics protected by law. The
EEO is the Law poster is available here.
Show moreShow less",3.0,"Hach
3.0","Seattle, WA","Loveland, CO",1001 to 5000 employees,1947,Subsidiary or Business Segment,Miscellaneous Manufacturing,Manufacturing,$1 to $2 billion (USD),"Xylem, Thermo Fisher Scientific, In-Situ"
Software Engineer Senior,"$80K-$161K
(Glassdoor est.)","C++ Senior Software Engineer- Remote due to COVID, but will be required to sit in Lincolnshire once restrictions are lifted. Start time would be 9AM Central
There is a possibility to move from Temp to FT Hire
Visa sponsorship is not available, now or in the near future, for this position
CTO AI services is a central group innovating new AI centric products, supporting Business Units on program acceleration and building an ecosystem that will allow Client to scale its AI components across the business and partners.
As C++ Developer / C++ Software Engineer at our company you will be responsible for participating in the full development lifecycle of our back-end systems, helping design innovative new products, planning and writing code and creating Unit tests.
Our team consists of top Engineers, Scientists and thought leaders internationally - so as a C++ Software Engineer you will have the chance to learn and work in an environment where you will get exposure to cutting edge artificial intelligence techniques.
You will also get the opportunity to shape architecture and be influential in applying best practice; using Continuous Integration and TDD. You will also be developing scalable products for cloud platforms, such as Google Cloud and on device AIoT.
You must be passionate, pro-active, ambitious and open to learn latest technologies and trends.
Ensuring good coding practice throughout the team: code review, documenting code and choices, share knowledge with other team members and be able to reuse code without reinvent the wheel.
Responding to time critical issues, understand how to balance delivering projects on time, find good/better solutions when building software with the ability to be technology agnostic and testing out different solutions to find the best fit for every challenge.
Required Skills:
A Computer Science degree or related technical field or equivalent practical experience
Strong C++ programming ability - ability to write high quality and maintainable code
A good understanding of algorithms, software architecture and design
An ability to collaborate within an Agile team and communicate effectively
Good problem solving and analysis skills
Must be a team player: communicative person who works well as individual (doesnt need hand holding) as well as part of a team. Keen to learn happy to ask questions, eager to push the boundaries bring their own ideas, delivery focused who also follow requirements.
Keen to take ownership, attention to detail and make a difference
Ability to respond under a dynamic work environment with quickly changing priorities
Solid experience of coding in C++11 or newer, multi-threading, parallel-processing, code-optimisation, and low-level debugging.
At least 5 years experience in commercial environment and full development life cycle and testing. Working knowledge of TDD is essential.
Excellent Object-oriented design principles and data structures
Good experience using GIT or other version control systems.
Familiar with Agile development methodology.
A plus in a candidate would have the below knowledge/qualifications
Experience with parallel-processing on GPUs using CUDA.
Experience with any machine-learning frameworks (OpenVino, TensorFlow, Caffe, Torch).
Experience of development within Google Cloud.
Experience of scripting using Bash or Python.
Experince of MLFlow.",3.9,"ApTask
3.9","Lincolnshire, IL","Iselin, NJ",201 to 500 employees,2010,Company - Private,IT Services,Information Technology,$50 to $100 million (USD),"Collabera, Mitchell Martin, The Judge Group"
Software Development Engineer II,-1,"Have you ever ordered a product on Amazon and when that box with the smile arrived, wondered how it got to you so fast? Wondered where it came from and how much it cost Amazon? If so, the Amazon Global Supply Chain Optimization organization is for you.

Watch this video to learn more about our organization, SCOT: http://bit.ly/amazon-scot

We are Optimal Sourcing team (OSS) within SCOT and are hiring! We work with several vendor inputs/constraints and other SCOT systems to execute a sourcing strategy, ultimately translating an optimal plan into real world execution by systematically connecting with suppliers. We own cost negotiations with vendors, import ordering, inbound optimization, supplier performance and procurement automation. We aim to maximize supply availability that directly drive top line by improving instock levels and total sourcing cost reduction improving bottom line of Amazon Retail.

What will you do?
You will be partnering with research scientists, product managers and software engineers to solve complex problems and building innovative solutions to drive $100B inventory buying decisions. You will design/build scalable, distributed computing solutions.Candidate needs to have a high sense of ownership, ability to develop end to end solutions and improve customer experience. This role would expose you to solving problems of scale in the areas of data mining, machine learning algorithms and distributed systems of cloud-scale. You will be responsible for driving the team's technical direction, strategizing and shaping our long-term vision and architecture.

Basic Qualifications
Bachelor's Degree in Computer Science with advanced degrees preferred.
* Experience building complex software systems that have been successfully delivered to customers
* 2+ years of relevant work experience in software development, including design, implementation, debugging, and support
* Deep technical expertise and hands-on architectural understanding of cloud-scale distributed and service-oriented architectures.
* Has delivered large-scale commercial enterprise software systems or large scale online services
* Solid programming skills in and a deep understanding of object oriented design.
* Excellent verbal and written communication
Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.",-1,Amazon Corporate LLC,"Seattle, WA",-1,-1,-1,-1,-1,-1,-1,-1
Senior Big Data Engineer,-1,"Analytics
Senior Big Data Engineer - QuantumBlack

Boston

Apply Now

Qualifications

Degree educated in Computer Science, Engineering, Mathematics, or equivalent experience
Previous commercial experience in a data-driven role
Ability to write clean, maintainable, and robust code in Python, Scala, Java or similar languages
Knowledge of software engineering concepts and best practices
Familiarity with the latest OSS, cloud, container, query and database technologies as well as query languages
Confirmed experience building data pipelines in production and ability to work across structured, semi-structured and unstructured data
Experience preparing data for analytics and following a data science workflow
Commercial client-facing or senior stakeholders management experience

Who You'll Work With


You will be part of a global Data Engineering community and you will work in cross-functional and Agile project teams alongside Project Managers, Data Scientists, Machine Learning Engineers, other Data Engineers, and industry experts.

You will work hands in hands with our clients, from data owners and users to C-level executives.

Who you are

You are a highly collaborative individual and enjoy solving problems that focus on adding business value. You have a sense of ownership and enjoy hands-on technical work. Our values resonate with yours.

What You'll Do


As a Senior Data Engineer in Boston, you will...
Partner with our clients, from data owners and users to C-level executives, to understand their needs and build impactful analytics solutions
Design and build data pipelines to support data science projects following software engineering best practices
Use state of the art technologies to acquire, ingest and transform big datasets
Map data fields to hypothesis, curate, wrangle and prepare data to be used in advanced analytics models
Create and manage data environments in the cloud or on premise
Ensure information security standards are maintained at all time
Contribute to cross-functional problem-solving sessions with your team and deliver presentations to colleagues and clients
Be flexible to travel to our clients' offices to deliver presentations, gather information or share knowledge
Have the opportunity to contribute to R&D and internal asset development projects
Our tech stack

While we advocate for using the right tech for the right task, we often leverage the following technologies: Python, PySpark, SQL, Airflow, Databricks, our own OSS called Kedro, container technologies such as Docker and Kubernetes, cloud solutions such as AWS, GCP or Azure, and more!

What you'll benefit from
Real-World Impact– No project is ever the same. We work with top-tier clients across multiple sectors, providing unique learning and development opportunities internationally.
Fusing Tech & Leadership– We work with the latest technologies and methodologies and offer first class learning programmes at all levels.
Multidisciplinary Teamwork- Our teams include data scientists, engineers, project managers, UX and visual designers who work collaboratively to enhance performance.
Innovative Work Culture– Creativity, insight and passion come from being balanced. We cultivate a modern work environment through an emphasis on wellness, insightful talks and training sessions.
Striving for Diversity– With colleagues from over 40 nationalities, we recognise the benefits of working with people from all walks of life.
Visit our Careers site to watch our video and read about our interview processes and benefits.

Industries
High Tech

Functions
Technology

Apply Now
FOR U.S. APPLICANTS: McKinsey & Company is an Equal Opportunity/Affirmative Action employer.
All qualified applicants will receive consideration for employment without regard to sex, gender
identity, sexual orientation, race, color, religion, national origin, disability, protected Veteran
status, age, or any other characteristic protected by applicable law.

FOR NON-U.S. APPLICANTS: McKinsey & Company is an Equal Opportunity employer. For additional details
regarding our global EEO policy and diversity initiatives, please visit our
McKinsey Careers and
Diversity & Inclusion sites.",3.8,"QuantumBlack
3.8","Boston, MA","London, United Kingdom",501 to 1000 employees,2009,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,"Palantir Technologies, Google, Microsoft"
"Aviation Software Engineer - Huntsville, AL - ASL",-1,"ID: 495365
Type: Researchers
Location: Huntsville, AL
Categories: Aircraft, Algorithm Development, Autonomous Systems, Avionics, High Performance Computing, Networking, Software Development/Design
Job Description


The Aviation Systems Division of the Applied Systems Laboratory in Huntsville, AL is looking for several entry- to mid-level software developers.

We are looking for a software engineer interested in supporting the development of simulations for rotorcraft systems. You will analyze, design, and develop software used to simulate aircraft, sensors, and the 3-D world. As part of a team, you will participate in the development of simulations to support hardware-in-the-loop testing of avionics components. As part of the effort, you will also be responsible for specifying, implementing (C++, Python), and testing your SW components. Effort will be in support of system design and analysis for the Army Aviation platforms, handling aviation-based interfaces.

Travel Requirements

Education & Length of Experience


Research Engineer/Scientist I
A Bachelor's degree in Computer Engineering, Software Engineering, or Computer Science.
Research Engineer/Scientist II
A Master’s degree in Computer Engineering, Software Engineering, or Computer Science and three (3) years of relevant full-time experience after completion of that degree,
A Master’s degree in Computer Engineering, Software Engineering, or Computer Science and five (5) years of relevant full-time experience after completion of a Bachelor’s degree, or
A Doctoral degree in Computer Engineering, Software Engineering, or Computer Science.
Required Minimum Qualifications
Excellent skills and practice in programming with one or more software languages; C, C++, Python
Experience with software interfaces like Ethernet, I2C, SATA, SPI, UART, USB
Debugging skills and practice in the use of debugging tools
Experience in software integration and test, including unit test development
Very good communication skills in written and spoken English
Preferred Qualifications
Active DoD Secret Clearance
Master’s degree in Computer Engineering, Software Engineering, or Computer Science
Experience with avionics interfaces e.g., ARINC-429, MIL-STD-1553
Experience with graphics libraries (OpenGL)
Experience with Data Distribution Service (DDS) interfaces
Experience with machine learning
Experience with 3D world simulation tools or flight simulators
Working knowledge of Agile SW development methodologies
Experience with test equipment and tools (oscilloscopes, wireshark, logic/bus analyzers)
Interest in publishing papers in professional conferences and journals
U.S. Citizenship Requirements


Due to our research contracts with the US federal government, candidates for this position are required to be US Citizens.

Clearance Type Required


Ability to obtain Secret Clearance upon hire

Diversity & Inclusion


Diversity & Inclusion (D&I) at Georgia Tech Research Institute aims to enhance the Institute’s mission of solving the world’s most complex technical problems by creating a workforce with a shared appreciation for diversity, raising awareness around inclusiveness, and fostering a sense of belonging and appreciation for all members of our community.

Equal Employment Opportunity


Georgia Tech Research Institute is an Equal Opportunity Employer of individuals with disabilities and protected veterans and actively seeks diversity among its employees. Equal Employment Opportunity is the Law.

Posted: 02/19/2020
Closes: 08/14/2020",3.6,"Georgia Tech Research Institute
3.6","Huntsville, AL","Atlanta, GA",1001 to 5000 employees,1943,Subsidiary or Business Segment,Research & Development,Business Services,$100 to $500 million (USD),"MIT Lincoln Laboratory, Johns Hopkins University Applied Physics Laboratory"
Senior Software Engineer- Cybersecurity,"$83K-$160K
(Glassdoor est.)","Description

Overview
If you have a deep passion for building tools, love handling massive data sets, and get excited from solving hard security problems, Akamai is the place for you. We are seeking a highly motivated Software Engineer who will work with team of Data Scientist, developing the next generation of Data Science utilities and algorithms to identify automated bots and online fraud.

Responsibilities include but are not limited to:
Build capabilities that will be used by the Data Science team to automate diagnosis and response to Bot attacks
Develop working prototypes of algorithms (statistical and machine learning based) and evaluate and compare metrics based on the real-world data sets

* Building data analysis and visualizations to help customers and internal support teams to understand the health of their products

* Develop software for highly scalable automated alerting systems to improve the security of our products and platforms

* Collaborate with multi-disciplinary teams across Operations, Security Operation Center, Services to design and execute best solutions

About the Team
The Web Security Engineering team has responsibility for the technologies that power Security Products. These include Kona Site Defender, Bot Manager, Web Application Firewall and Siteshield. These provide protection from both DDoS and application specific web attacks with high availability.
Akamai's global footprint of over 220,000 servers provides an overlay network with scale and capacity to not just deliver the largest web events but also secure the largest Internet brands from attack. The team builds and extends Akamai's highly fault-tolerant wide area distributed content delivery and application acceleration systems to improve performance, security, reliability and availability of high value web sites. Akamai powers over 85% of the top online retailers, with over $2 billion in annual revenue.

Qualifications

Required Education and Experience:

* 5 years of relevant experience and a Bachelors degree Computer Science or Applied Machine Learning or its equivalent or

* 3 years of relevant experience Masters degree in Computer Science or Applied Machine Learning or its equivalent

Required Skills:

* 3 years experience working with programming languages

* 2 years experience using SQL

* 1 or more years of experience working with APIs

Desired Skills:
Ability to work productively with team members, identify and resolve tough issues in a collaborative manner

* Familiarity with HTTP, HTML, TLS/SSL and JavaScript

* Understanding of Data Structures, Algorithms and Design Patterns

Akamai Technologies is an Affirmative Action, Equal Opportunity Employer that values the strength that diversity brings to the workplace. All qualified applicants will receive consideration for employment and will not be discriminated against on the basis of gender, race/ethnicity, protected veteran status, disability, or other protected group status.",4.0,"Akamai
4.0","Cambridge, MA","Cambridge, MA",5001 to 10000 employees,1998,Company - Public,IT Services,Information Technology,$2 to $5 billion (USD),"Mirror Image Internet, Limelight Networks"
Principal Data & Server Engineer,-1,"Summary

We are looking for an experienced Data Engineer to join our team. You will use various methods and data engineering technologies to transform various raw data into useful data systems on cloud server platform. To succeed in this data engineering position, you should have strong analytical skills and the ability to aggregate various data from numbers of different sources. This job also requires familiarity with program languages and data query languages.

Core Responsibilities

-Development of Logics and Algorithms for Personalized Video Content Recommendation

-Design the architecture of data processing system and build the actual data pipeline components in cloud server platform which processes various different type of datasets that Xumo is working with these days, e.g. OTT video streaming data, content metadata, time and location, etc. This role further includes the tasks of developing in-house algorithms and data aggregation logics to realize advanced recommendation and personalization experience from the endpoints on cloud server to client applications which has more than 15MM unique active users.

-This position also includes the role of designing and developing data pipeline which continuously run to combine raw information from different source to analyze the performance of the contents and programs provided in production to measure multiple critical key metrics both from engineering and business metrics perspective, e.g. user visit, navigation, engagement, return frequency and user satisfaction, CAC, ARPU, LTV, etc. by the data gathered back from the client application through the internal/external data tracking platforms.

-Development of Server System for Promotions, Notifications and Various Testing with Data.

Another important role of this position is designing and developing server system and data processing systems to deliver push notifications and promotion campaigns to the devices both for the new user acquisition and for the user retention. This includes the role of evaluating business needs and objectives, collaborating with data scientist, building algorithms and prototypes by interpreting trends and patterns in OTT video streaming area, creating the target user segments for Smart TV / Mobile devices and Desktop Applications, running A-B tests to compare the performances, developing analytical tools and programs conducting complex data analysis and report on results to provide reporting to internal / external stake holders.

-This position includes some Data Science Research roles which takes care of identifying business trends and changes through advanced data analytics by using a variety of techniques to interpret results from multiple data sources by taking statistical analysis, data aggregation, and data mining. This role will be needing certain experience in Big Data Analytics with some practical experience of Machine Learning, AI, Deep Learning, Predictive Analytics, Data modeling and evaluation skills. You will be working closely with marketers, decision-makers, and other stakeholders in their projects and products to channelize/communicate all possible outcomes.

Data Skillset

-Expertise in computer fundamentals

-Great numerical and analytical skills

-Experience of developing solutions that improve business performance

-Knowledge/experience on/with statistical programming languages, including R, Python, SAS, Google Big Query, etc.

-Experience of designing and analyzing algorithms. (Brute-force or exhaustive search, Divide & Conquer, Greedy, etc.)

-Data modeling and evaluation skills. Entity relationship diagram, data dictionary, data map

-Understanding of data security and privacy protection

Software Programming Skillset

-Multilingual coding knowledge/experience: Java, JavaScript, C, C++, etc.

-Knowledge and hands-on experience of database platform technologies, MySQL, Mongo, GBQ, Redos, etc.

-Experience of developing server endpoints for importing/exporting data.

-Software build and deployment in Google Cloud and Amazon AWS (VM, Microservice deployment, Kubernetes, Cloud SQL, RabbitMQ)

Education and Years of Experience

-Bachelor’s Degree in computer science, IT, engineering, or similar field; Master’s degree is a plus

-Professional Data engineering certification is a plus

-Good communication skills to promote cross-team collaboration

-A natural inclination toward solving complex problems

-Generally requires 11+ years related experience

Employees at all levels are expected to:

-Understand our Operating Principles; make them the guidelines for how you do your job

-Own the customer experience - think and act in ways that put our customers first, give them seamless digital options at every touchpoint, and make them promoters of our products and services

-Know your stuff - be enthusiastic learners, users and advocates of our game-changing technology, products and services, especially our digital tools and experiences

-Win as a team - make big things happen by working together and being open to new ideas

-Be an active part of the Net Promoter System - a way of working that brings more employee and customer feedback into the company - by joining huddles, making call backs and helping us elevate opportunities to do better for our customers

-Drive results and growth

-Respect and promote inclusion and diversity

-Do what's right for each other, our customers, investors and our communities",3.1,"Contingent Network Services
3.1",United States,"West Chester, OH",201 to 500 employees,1984,Company - Private,Enterprise Software & Network Solutions,Information Technology,$25 to $50 million (USD),-1
Python Software Engineer - CI Poly - REMOTE (VA) with Security Clearance,-1,"Our client is the Public Sector Engineering team of a massively-funded Silicon Valley Geospatial & Signals Intelligence firm backed by nearly 20 VCs. They utilize Artificial Intelligence (computer vision, deep learning, convolutional neural networks) to process the rapidly expanding imagery and other data sets from satellites, drones, mobile devices, and IoT devices, world-wide. This is true Petabyte-scale cloud computing, translating enormous visual information into actionable intelligence that the world's leading decision-makers (both in government and in private industry) use to answer critical questions. Their accolades are impressive, being named to several ""most innovative companies"" and ""best machine learning companies"" lists, and they are viewed as a likely future unicorn (the venture capital industry's term for a privately-held company with a value over $1 billion). Their credo is using the power of AI ethically, to create progress in the world. Their core products are used in both commercial and Intelligence Community settings, with this team focused on developing new features for federal customers and deploying the products in classified environments. There are three types of people needed in their Engineering Group - Computer Vision Scientists, Software Engineers, and DevOps Engineers. Computer Visions Scientists design, train, and deploy computer vision models and work with machine learning, image processing, deep learning, object detection, and automated analysis of imagery data. Software Engineers utilize Python to build enterprise-scale server-side software utilizing containerization (Docker, Kubernetes, etc.) and cloud-based systems (C2S and other classified cloud environments). DevOps Engineers deploy software to C2S and other classified cloud environments, script in Python and Bash, work with all sorts of DevOps tools, and navigate the authority-to-operate (ATO) process. All staff are considered part of the corporate Product Engineering team, so if you don't have a specific public sector effort to work on, you just keep helping evolve the product. Work locations are REMOTE, work-from-home, with some visits to customer SCIFs throughout the DC metro area. SCIF visits are only when needed. The working style is fast-paced, with bright co-workers who have broad knowledge and who love to discuss and debate approaches, investigate new science and engineering topics on their own, and then teach each other. People are rather self-managing, so independent learners who appreciate flexibility and don't fear change fit in well. People are congenial and get along very well. Before the current crisis, people used to meet together for lunch regularly, and now that that is impractical, they have started forming technical book clubs, playing virtual board games, and having frequent one-on-one calls between each person and their manager. Slack and other collaboration tools are highly leveraged on a daily basis. Compensation includes a strong base salary, a 10% annual performance bonus incentive, and very generous stock options that could be extremely valuable over time. The company pays 100% of medical / dental / vision for employees and almost 100% for dependents, and there are many other benefits as well. All roles require US citizenship and a current TS/SCI security clearance. A TS/SCI + CI Poly is preferred but not required. Clearance crossover is NOT required for you to start working, however. cjobs-cat:""IT - Software"" 12015",-1,Stanley Reid & Company,"Arlington, VA","Saint Petersburg, FL",1 to 50 employees,-1,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Python Software Engineer - TS/SCI - REMOTE (VA) with Security Clearance,-1,"Our client is the Public Sector Engineering team of a massively-funded Silicon Valley Geospatial & Signals Intelligence firm backed by nearly 20 VCs. They utilize Artificial Intelligence (computer vision, deep learning, convolutional neural networks) to process the rapidly expanding imagery and other data sets from satellites, drones, mobile devices, and IoT devices, world-wide. This is true Petabyte-scale cloud computing, translating enormous visual information into actionable intelligence that the world's leading decision-makers (both in government and in private industry) use to answer critical questions. Their accolades are impressive, being named to several ""most innovative companies"" and ""best machine learning companies"" lists, and they are viewed as a likely future unicorn (the venture capital industry's term for a privately-held company with a value over $1 billion). Their credo is using the power of AI ethically, to create progress in the world. Their core products are used in both commercial and Intelligence Community settings, with this team focused on developing new features for federal customers and deploying the products in classified environments. There are three types of people needed in their Engineering Group - Computer Vision Scientists, Software Engineers, and DevOps Engineers. Computer Visions Scientists design, train, and deploy computer vision models and work with machine learning, image processing, deep learning, object detection, and automated analysis of imagery data. Software Engineers utilize Python to build enterprise-scale server-side software utilizing containerization (Docker, Kubernetes, etc.) and cloud-based systems (C2S and other classified cloud environments). DevOps Engineers deploy software to C2S and other classified cloud environments, script in Python and Bash, work with all sorts of DevOps tools, and navigate the authority-to-operate (ATO) process. All staff are considered part of the corporate Product Engineering team, so if you don't have a specific public sector effort to work on, you just keep helping evolve the product. Work locations are REMOTE, work-from-home, with some visits to customer SCIFs throughout the DC metro area. SCIF visits are only when needed. The working style is fast-paced, with bright co-workers who have broad knowledge and who love to discuss and debate approaches, investigate new science and engineering topics on their own, and then teach each other. People are rather self-managing, so independent learners who appreciate flexibility and don't fear change fit in well. People are congenial and get along very well. Before the current crisis, people used to meet together for lunch regularly, and now that that is impractical, they have started forming technical book clubs, playing virtual board games, and having frequent one-on-one calls between each person and their manager. Slack and other collaboration tools are highly leveraged on a daily basis. Compensation includes a strong base salary, a 10% annual performance bonus incentive, and very generous stock options that could be extremely valuable over time. The company pays 100% of medical / dental / vision for employees and almost 100% for dependents, and there are many other benefits as well. All roles require US citizenship and a current TS/SCI security clearance. A TS/SCI + CI Poly is preferred but not required. Clearance crossover is NOT required for you to start working, however. cjobs-cat:""IT - Software"" 12016",-1,Stanley Reid & Company,"Arlington, VA","Saint Petersburg, FL",1 to 50 employees,-1,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Senior Front-end Software Engineer,-1,"Who You Are

You are an outstanding Senior Front-end Software Engineer who excels at building modern browser-based JavaScript applications that make Ajax calls to RESTful Microservices. You have worked with React and Redux; you want to go deep with these technologies to build the next generation of web applications. You are also familiar with the D3.js library and enjoy building compelling data visualizations.

You hold yourself and your teammates to a high standard when it comes to writing clean, performant, and maintainable code that powers well-designed web applications. You are very productive and deliver extremely high quality front-end code where the separation of concerns is clear and follows architectural best practices. You apply software patterns well and take testing your code seriously. You write unit tests while writing production code rather than as an afterthought. Your code meets the rigorous standards needed for Continuous Integration and Continuous Deployment workflows.

You care deeply about your work and its impact on your team's productivity. You work well in cross-functional settings that include User Experience Designers, Product Owners, Data Scientists, and Service Layer Engineers. You are constantly proactive in finding new ways to improve the design, performance, and testing of the software that you and your team build. You value the security of a company with a proven business model and enjoy the opportunities a startup offers.

You have a great work ethic and are able to take on major projects from start to finish, either solo or collaborating with other engineers. You are a top performer who is effective in mentoring other front-end engineers. You inspire the best in your teammates. On a personal note, you are fun to work with; you maintain a positive attitude throughout the Agile Sprint cycle.

Who We Are


Quantifind is a uniquely positioned data science and human insights company. We use Machine Learning to empower our customers to make better decisions by combining their intuition with insights extracted from vast quantities of unstructured data. We offer marketing decision-makers tools to help them better understand their customers' interests and priorities. We are currently building out a new vertical aimed at financial crimes risk management including anti-money laundering (AML) and fraud detection. The clients in this vertical are data-rich and in search of data-driven advantages in their quest to root out criminal behavior. Our advantage is existing science, engineering, and SaaS product capabilities that align very well with the technology needs.

To help you succeed, we provide a supportive environment that fosters collaboration between teams and team members, where learning and professional growth are considered a key part of your success, and of ours. We offer a flexible work environment with a family friendly work-life balance, catered lunches three times a week, and fun team activities to keep you healthy, happy, and stress-free.

What a Great Candidate Looks Like:


BS or MS in Computer Science
Professional software engineer for at least 5 years with a focus on front-end engineering
Professional experience for at least 2 years using React
Professional experience at a software startup preferred
Professional experience with JavaScript, HTML5, and CSS3
Professional experience developing rich, powerful, and reusable components with frameworks such as React, Polymer, and LitElement
Professional experience using Redux to manage application state
Familiarity with the strengths and shortcomings of different client-side JavaScript frameworks
Experience with data visualization using D3.js, SVG, Canvas, etc.
Strong UX and design sensibilities and attention to detail
Professional experience with server-side JavaScript using Express.js or something similar
Professional experience working with MongoDB
Professional experience writing unit tests and automated integration tests
Solid understanding of concurrency and distributed systems
Effective representing the Front-end team when interacting with other technical specialties to elaborate and refine technical requirements
You enjoy leading by example and helping others understand complex ideas
The Opportunity We Offer


Quantifind is seeking a Senior Front-end Software Engineer for our Front-end team in Menlo Park, CA. You will create browser-based, responsive applications built with reusable components. The Front-end team works closely with our Data Scientists and Platform Engineers to build an interactive product that reveals Machine Learning insights so our clients can take action.

We are an equal opportunity employer. We pride ourselves on living our values. We are curious. We respect each other. We are proactively transparent. We relentlessly solve problems. We win together.

Will you join us? Apply now!",4.3,"Quantifind
4.3","Menlo Park, CA","Menlo Park, CA",51 to 200 employees,2009,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Grp 53 Assoc Mid-Level: Security Software Systems Engineer,"$101K-$126K
(Glassdoor est.)","We live in a time in which you have a choice – a choice where to work, where to apply your talents and ideas, where to grow and look for self-fulfillment.

We, the members of the Secure, Resilient Systems and Technology Group, have made our choice. We are here. We are software, hardware and electrical engineers, cryptographers, computer scientists, system analysts and security architects who share a common passion for helping solve some of the hardest technical problems relevant to National security. We pursue innovative, high-impact, practical research in small, focused teams. We succeed by participating in all R&D phases, including problem analysis and innovative solution design, system architecture, rapid prototyping and field-testing, and ultimately transfer of our technology to DoD and Intelligence Community users, sponsors, and Industry. Being part of MIT, we also collaborate closely with academia and publish our research in top-tier venues. We are having fun.

If you would like to work on things that truly matter, and learn a lot from doing that, apply here to learn more. MIT is a place that combines a culture of academic excellence, an abundance of resources and work-life balance. You may discover this is exactly the place you are looking for.

You will help us create advanced technologies for ensuring security and resiliency of next-generation mission-critical systems relevant to National Security.

Requirements:
Master’s degree in Computer Security, System Engineering, Computer Science, Software Engineering, Computer Engineering, Electrical Engineering, or related fields; in lieu of MS, a Bachelor’s with 3 or more years of relevant experience will be considered.
Deep knowledge and extensive experience in one or more of the following:
Analysis, modeling, design, development, testing, and verification of embedded systems (C, VHDL, etc.).
Analysis, architecture, design, implementation, and measurement of secure sub-systems and systems.
Academic or professional research experience and/or publications in the areas of computer security.
The passion to convert vision into reality, excellent work ethic, and effective communication skills are essential.
Desired Knowledge includes one or more of the following:
System engineering. Computer and software security. Familiarity with or interest in secure programming. Multi-core/multi-thread computing.
Operating system internals, OS-level middleware, distributed systems, and network protocols. Data-structures, state-machines, and algorithms.
Embedded and hardware systems security, Real-time systems security, Industrial Control Systems (ICS)/SCADA
Moving target defense techniques: Dynamic Runtime Environment, Networks, Platforms, Software, and Data
Embedded systems, processor, and microelectronics design lifecycle, fab, and verification (FPGA and/or ASIC)
Communication protocols at chip, board, and system levels. Co-design and integration of software and hardware, IP cores, sensors, system-on-chip design and verification.
For Benefits Information, click http://hrweb.mit.edu/benefits

MIT Lincoln Laboratory is an Equal Employment Opportunity (EEO) employer. All qualified applicants will receive consideration for employment and will not be discriminated against on the basis of race, color, religion, sex, sexual orientation, gender identity, national origin, age, veteran status, disability status, or genetic information;

U.S. citizenship is required.

Requisition ID: 27671",3.8,"MIT Lincoln Laboratory
3.8","Lexington, MA","Lexington, MA",1001 to 5000 employees,1951,Nonprofit Organization,Aerospace & Defense,Aerospace & Defense,Unknown / Non-Applicable,-1
"Computer Science Researcher in Data Science, Machine Learning, and High Performance Computing, Senior - ICL",-1,"ID: 495728
Type: Researchers
Location: Atlanta, GA
Categories: Algorithm Development, Artificial Intelligence, Data Analytics/Science, Health Informatics, High Performance Computing, Image Processing, Machine Learning
Job Description


Full-time, permanent position available in the Information and Communications Laboratory working on a wide variety of data science and computer science/engineering problems. Our team is looking for a data scientists and computer scientists with experience working on large datasets to extract meaningful insight. In particular, skillsets both in doing data science (statistical analysis and inference, machine learning, and graph analytics) as well as software engineering experience building tools and applications for data science (using Python, R, Julia, etc.) are required. Demonstrated experience working with multiple programming languages and development environments is preferred.

Preference will be given to candidates with strong fundamentals in computer science and/or computer engineering. Experience with managing business or scientific problems and working with customers is also needed. Prior work consulting for or working for Federal Government and/or Department of Defense agencies will be given preference.

Candidate needs to be able to communicate effectively their results both through documentation as well as through technical writing and reports. Candidate may also be asked to work on proposals for funding, thus proposal writing experience is preferred. Candidates should be adept in learning new programming languages and frameworks quickly, and should be able to demonstrate the ability to integrate large projects together that span multiple languages and problem domains.

The projects are based out of the Tech Square area in Atlanta on the Georgia Tech campus. Occasional travel may be required and is project dependent. The High Performance Computing and Data Analytics branch at GTRI works on problems ranging from low-level computer architecture design, to building scalable algorithms and data structures, to machine learning and statistical inference. Our team spans the full technology stack to bring cutting-edge research in data analytics to scale, and then apply those analytics to real-world problems to enable actionable insight. Our team works on a variety of projects ranging from data analytics in healthcare, predictive modeling, predictive maintenance, and large scale parallel and discrete scientific models and simulations. We are looking for candidates that are excited by working on a variety of problems always with an eye on sponsor value, performance, and scalability.

This position may additionally support the design, development, analysis, and implementation of parallel computing codes on medium- and large-scale clusters. Additional job functions may include creating parallel computing tools and frameworks to support mission applications, implementing security controls on HPC systems, and contributing to technical reports. Experience with image/signal processing or functional programming is beneficial.

Candidate must be a US citizen eligible for a security clearance. An active clearance is not required at time of application.

Travel Requirements

Education & Length of Experience


Senior Research Engineer/Scientist
A Master’s degree in Computer Science, Computer Engineering, Electrical Engineering, Applied Mathematics, Physics, Industrial Sciences and Engineering, Computational Sciences and Engineering or other majors with sufficient work in the field of data science or computer science and seven (7) years of relevant full-time experience after completion of that degree,
A Master’s degree in Computer Science, Computer Engineering, Electrical Engineering, Applied Mathematics, Physics, Industrial Sciences and Engineering, Computational Sciences and Engineering or other majors with sufficient work in the field of data science or computer science and nine (9) years of relevant full-time experience after completion of a Bachelor’s degree, or
A Doctoral degree in Computer Science, Computer Engineering, Electrical Engineering, Applied Mathematics, Physics, Industrial Sciences and Engineering, Computational Sciences and Engineering or other majors with sufficient work in the field of data science or computer science and four (4) years of relevant full-time experience after completion of a Bachelor's degree.
U.S. Citizenship Requirements


Due to our research contracts with the US federal government, candidates for this position are required to be US Citizens.

Clearance Type Required


Ability to obtain Secret Clearance upon hire

Diversity & Inclusion


Diversity & Inclusion (D&I) at Georgia Tech Research Institute aims to enhance the Institute’s mission of solving the world’s most complex technical problems by creating a workforce with a shared appreciation for diversity, raising awareness around inclusiveness, and fostering a sense of belonging and appreciation for all members of our community.

Equal Employment Opportunity


Georgia Tech Research Institute is an Equal Opportunity Employer of individuals with disabilities and protected veterans and actively seeks diversity among its employees. Equal Employment Opportunity is the Law.

Posted: 05/28/2020
Closes: 08/28/2020",3.6,"Georgia Tech Research Institute
3.6","Atlanta, GA","Atlanta, GA",1001 to 5000 employees,1943,Subsidiary or Business Segment,Research & Development,Business Services,$100 to $500 million (USD),"MIT Lincoln Laboratory, Johns Hopkins University Applied Physics Laboratory"
Senior Software Engineer,-1,"About OpenSesame

OpenSesame helps develop the world's most productive and admired workforces. With the most comprehensive catalog of elearning courses from the world's top publishers, we are here to help you every step of the way, from finding courses, mapping them to your core competencies, syncing them with your LMS to increasing utilization and improving your L&D programs. Not only will you have the flexibility of multiple purchasing options from OpenSesame, you'll find it simple to use and administer your e-learning courses. To learn more, visit www.opensesame.com/about.

About the Team

The Simon team is building a new, green-field product that targets the learning space with some extremely exciting technology. The team is defining the best frameworks, infrastructure, architecture and practices to build out a product that is going to be evolving enormously over the next few years. Help us create something uniquely valuable for anyone who wants to share their expertise with those who want to master additional skills and knowledge. Our product will allow learners to take these courses regardless of their background, culture, geographical location or preferred language. We have a strong culture of working in an agile, continuously improving, and automation-oriented environment. We recognize the need to always be evolving, to look objectively at where things are getting better or worse, and take action.

About the Job

As a Senior Software Engineer you will be one of the technical leaders of the OpenSesame engineering team. Our team has a strong culture of working in an agile, continuous improvement and automation environment. We recognize the need to always improve, to look objectively at where things are getting better or worse, and take action. You will be expected to be a great engineer, teaching, learning, mentoring, planning and most of all, developing systems that will move OpenSesame forward.

We're looking for a self-motivated, hands-on engineer, who will be responsible for working on our core platform. The desired candidate will be a well-rounded developer, who is not afraid to jump into any level of the stack and has proven experience in web development, a flexible attitude and aptitude to learn and share. This person enjoys working in a fast-paced agile environment, cares about their decisions, and is focused on quality driven development.

Job Description
Have a background in continuous build and deployment, in particular automation of environment creation and deployment in AWS and other cloud environments.
Strong in Go, automation scripting, TypeScript, Python or C#.
Be a fearless automator able to read and write multiple languages to facilitate whatever is needed.
Lead projects from technical discovery to delivery while writing testable and well-documented frontend and backend code,
Design, develop, and deliver software systems that provide or support new product features.
Work with Product Managers to measure, analyze, and improve product metrics.
Work with Data Scientists to implement experiments that leverage machine learning models.
Work with UX Developers to implement features that allow users to better manage their communication preferences.
Never be satisfied, always see room for improvement in process and technology.
Have strong software engineering background to keep automation well factored and under automated test whenever possible.
Have a thirst to explore and evaluate supporting different mechanisms for code execution and or deployment for instance Docker or Lambda and equivalents.
Possess excellent technical and personal communications skills including writing documentation and diagraming when appropriate, we are first and foremost a team.
A habit of forever learning, both from others and individually.
Have great mentoring skills and a track record or improving the team around them.
Requirements / Qualifications
5+ years of strong software development experience in an object-oriented language building highly-reliable, mission-critical software
Experience building large web applications in a distributed environment and can make pragmatic engineering decisions
Interest in working full-stack, from optimizing database transactions to building distributed systems and frontend web applications
And a track record of pursuing self-directed side projects, research, or open source projects
Experience with Git, continuous integration and deployment tools
Strong database fundamentals including SQL, performance and schema design.
Strong systems fundamentals including multi-threading, IO subsystem and scheduling.
Strong CS fundamentals including data structures, algorithms, and distributed systems.
Nice to Have
Security and safety. You care about correctness, automated testing and data security. You are careful and methodical and incorporate security into your thinking at every stage of development.
Growth mindset. You want to learn and know that you can. You like digging deeply into new technologies, new domains or new ideas. You're excited to take on something you've never done before.
Self prioritization. You constantly ask yourself what your top priorities are and if you're supporting the overall goals of the company. When things are not certain, you're not shy about asking for help.
Entrepreneurial spirit. You want to build something incredibly valuable and have real impact on the world. You're excited to get your hands dirty in pursuit of that goa
Experience implementing and supporting SAML and SSO integrations
API design experience
Technical and/or team leadership and mentoring experience
Experience developing tools leveraged by other developers
Experience developing reusable software components that other developers will leverage
Our tech stack is outlined below, however, we strongly believe in using the right technology for a given job and in constantly experimenting to see what new technology can do for us. That being said we have systems using or implemented in:
TypeScript
Go
Node
React
C#
Python
Nginx
Cloudformation
Chef
AWS
We help companies worldwide train their amazingly diverse workforces. We understand how different perspectives are vital to the success of a company. At OpenSesame, we are committed to inclusion across race, gender, religion, age, and identity. We work hard, challenge ourselves to learn quickly, embrace daily improvements, and support each other and our customers every step of the way. Driven by our people. Strengthened by our differences.",4.2,"OpenSesame
4.2",Remote,"Portland, OR",1 to 50 employees,2011,Company - Private,Education Training Services,Education,Unknown / Non-Applicable,-1
Senior Frontend Software Engineer,-1,"Job Description
Company Overview

Machine learning is changing the way the world does business. Recommendations are smarter than ever, and predictions are closer to reality. But is it good enough? Many predictions are still off-mark, and companies are missing opportunities to deliver stellar customer experiences and drive down costs with ad hoc data infrastructure and ML processes. At Kaskada, we are revolutionizing enterprise machine learning through the use of real-time data. Our team is delivering an end-to-end machine learning platform powering feature engineering and productionization.

Job Summary

Are you passionate about interactive data visualization and interested in building a product that makes data science intuitive and fun? Kaskada is hiring an experienced engineer to help build our Machine Learning Feature Studio.

Some of the things you will work on:
Building visualizations that enable data scientists to create better ML features.
Creating a product that empowers people to deploy models to production with the click of a button.
Mentoring and developing engineers on the team.
Helping us scale our culture and processes as we continue to grow.
About You
Experienced front-end developer with 5+ years building web applications
Enjoy working on software architecture in a fast-paced, iterative development environment.
Expert in modern front end web technologies like React/Redux
Passionate about building product experiences that delight customers
Background building highly interactive interfaces using lots of data
Strong understanding of UX principles
Have a strong desire to be part of a small, lean and growing team
Highly motivated with strong communication skills
Benefits

Kaskada is a Seattle-area startup building a machine learning platform for event-based data. We are a team of doers with leadership roots from Google and AWS. We are actively building a team of other top performers to join the fun. The company is funded by leading PNW and Bay-area VCs, including Voyager Capital, NextGen Venture Partners, Founders’ Co-op, and Bessemer Venture Partners.

Kaskada offers competitive salaries including equity. Employees are also eligible to receive benefits including health insurance, dental, and vision insurance; life insurance, 401(k) plan, and more.

Powered by JazzHR

bV9CrcluH7",5.0,"Kaskada
5.0","Seattle, WA","Seattle, WA",1 to 50 employees,2018,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Senior Big Data Engineer,"$164K-$192K
(Glassdoor est.)","Absolute Software is looking for a Senior Big Data Engineer who will be responsible for designing, developing and building a robust data pipeline infrastructure required for optimal extraction, transformation, loading data from different data sources for our security analytics platform.

Also, you will have the opportunity to learn and apply cutting-edge AI technologies to solve real-world security issues in live enterprise environments. You will take ownership of large software components, help in the design of the architecture, apply your knowledge to functional design, utilize your programming skills for efficient and robust implementation, and guarantee the quality assurance in the whole software development cycle.

Responsibilities
Design, construct, test and maintain robust, reliable, and scalable data pipeline infrastructure
Ensure all systems meet the project requirements as well as industry practices
Investigate and integrate up-and-coming big data technologies into existing requirements
Recommend different ways to constantly improve data reliability and quality
Install/update system and component fault-tolerant procedures
Employ an array of technological tools to integrate with 3rd-party data systems
Research new uses for existing data
Develop set processes for data mining, data modeling, and data production
Collaborate with members of your team (e.g., data architects, data scientists, security researchers) on the project’s goals
Qualifications
5+ years of experience in design and implementation of robust and reliable big data infrastructure at scale, especially in supporting inline data ingestion, correlation, and aggregation of data from different data sources
Experience with designing real time and batch log analytics and search solutions using ELK stack
Experience with design, implementation, deployment and management of large Elasticsearch clusters and ELK solutions
Experience with performance tuning and optimization of Elasticsearch clusters
Experience with integration of Elasticsearch with Hadoop, RDBMS, Streaming technologies such as Kafka, Redis as well as and Data Science/Machine Learning frameworks at scale
Current hands-on experience with at least two coding and scripting languages e.g. Python, Java, Scala, Shell Scripting
Why Work For Us:

Absolute is the new standard for endpoint visibility and control, delivering self-healing endpoint security, always-connected IT asset management, and continuous data visibility—both on and off the network. Unlike other endpoint security agent solutions that can be corrupted, compromised or deleted, Absolute can self-heal itself and other critical applications through our patented Persistence technology that is embedded in the firmware of over 1 billion endpoints. No other security company can make this claim.

Headquartered in Vancouver, Canada with international offices in Austin, Texas, Reading, UK and Ho Chi Minh City, Vietnam, we are a collaborative and innovative place to make your mark in the world of security. Our agile, high energy culture rewards top performance and the contributions of those passionate about our collective growth and success. We celebrate our wins in our large common areas where we hold engineering hackathons, end of quarter celebrations, and monthly socials. We believe in a good work / life balance which is reflected in our annual employee retreat where it’s all about friends and family. To learn more about Absolute, visit our website at www.absolute.com or visit our YouTube channel.

Absolute is an equal opportunity employer.",3.5,"Absolute
3.5","San Jose, CA","Vancouver, Canada",201 to 500 employees,1993,Company - Public,Computer Hardware & Software,Information Technology,$100 to $500 million (USD),-1
Senior Data Engineer,"$52K-$100K
(Glassdoor est.)","Tokio Marine HCC is a leading specialty insurance group with offices in the United States, the United Kingdom and Continental Europe, transacting business in approximately 180 countries and underwriting more than 100 classes of specialty insurance. Tokio Marine HCC products and capabilities set the standard for the industry, and many of the Company’s almost 3,000 employees are industry-leading experts.

Position Summary:

The Senior Data Engineer is an important member of our organization that is responsible for developing and supporting best-in-class Actuarial data capabilities and a high-quality analytics environment for Tokio Marine HCC. This includes the creation of analytical databases and tools, provisioning datasets to be used for advanced analytics, implementation of information security best practices & policies, and building out automated data visualization and reporting tools.

The Senior Data Engineer will have an eye for building and optimizing data systems and will work closely with various stakeholders such as actuaries, underwriters, IT, and data scientists to develop data pipelines and ensure consistency and compatibility of data development across multiple projects. The Senior Data Engineer will support our group companies in developing new insights that leverage data assets.

Performance Objectives:
Create actuarial data and analytics roadmap based on best of breed technology aligned to business needs and priorities - including but not limited to:
Data Visualization
Predictive Modeling
Public Cloud Computing & Storage
AI & Machine-Learning
Help design data flows, reporting, and visualization tools to support actuarial pricing, reserving, and modeling processes.
Collaborate with corporate IT and company management on the development of a corporate-wide data hub
Define requirements for sourcing, analysis, and standardization of data required for Actuarial analysis and work with individual business units to enhance underlying data systems and feeds
Collect big data to be used in pricing, underwriting, and reserving from external data sources (such as websites) to be shared and utilized on a group wide basis
Develop data assets that support organizational decision making and create pilot cases for actual usage of big data. Some examples include:
Text mining to utilize unstructured data in predictive models
Provide expert advice in cutting edge modeling tools and techniques
A common mapping/geocoding solution
Interface with Corporate IT management on end user hardware, software, and support requirements
Implementation of TMHCC information security best practices & policies, including data protection and data privacy standards
Ensure data quality and compliance with data governance standards
Qualifications:

Minimum 5-10 years’ real project experience as a data engineer or similar role, including background and experience in the insurance industry (property/casualty preferable)
Experience and understanding of modern data technologies and analytical tools (HIVE/ Impala/R/Python/Scala) as well as experience with cloud computing services (Azure and/or AWS), and business reporting tools such as Power BI and Microstrategy.
Experience working closely with actuaries and data scientists in designing datasets and analytical and visualization tools and processes
Strong interpersonal skills and ability to project manage and work with cross-functional teams
Flexible and responsive with ability to adapt to rapid change in direction or business priority
Ability to work independently with limited supervision as well as contribute to team efforts is required
Ability and desire to communicate technical matters in order to train others and lead adoption of new tools and technologies
Demonstrated experience in working on development processes and agile methodologies
Sound analytical skills, as well as strong problem-solving aptitude. Able to proactively respond to a changing diverse business environment
Skilled at optimizing of work processes. Knows the most effective and efficient processes to get things done, with a focus on continuous improvement
Excellent oral and written communication skills
Ability to innovate and apply new ideas
Some domestic and international travel is possible
Bachelor's Degree or higher (desired majors include, but are not limited to: Computer Science/Engineering, Management Information Systems, or Data Analytics)
The Tokio Marine HCC Group of Companies offer a competitive salary and employee benefit package. We are a successful, dynamic organization experiencing rapid growth and are seeking an energetic and confident individual to join our team of professionals. The Tokio Marine HCC Group of Companies are equal-opportunity employers. Please visit www.tmhcc.com for more information about our companies.

#LI
#GD
#CB",3.4,"Tokio Marine HCC
3.4","Houston, TX","Houston, TX",1001 to 5000 employees,1974,Company - Private,Insurance Carriers,Insurance,Unknown / Non-Applicable,"Zurich Insurance, AXA XL, Allianz"
Senior Software Engineer,-1,"Come work at Smarter Sorting!

About You
We are in the midst of transforming our platform to reliably serve our customer's data needs. We are looking for a Senior Software Engineer experienced in building Python and Go web services to help us develop scalable solutions.

Our ideal teammate is a digital carpenter who is excited at the opportunity to craft a platform that serves the increasing demands of our customers. Ultimately, our engineer will take ownership of all data science related areas of our platform and infrastructure.

You will be joining a team of experienced software architects and developers who are creating a data platform to disrupt the compliance space and further our sustainable mission.

What You'll Be Doing
Help transform our R&D grade platform to a stable and performant production system
Create services to serve the data needs of both internal and external customers
Ultimately owning the portions of the platform interfacing with our data scientists
What We're Looking For
BA/BS in CS, MIS, Math, Statistics, Engineering or related degree
Expert in Python and Go and software engineering fundamentals
Experienced building web applications with Python frameworks
Experienced with REST and queue based services
Experienced working with data scientists and machine learning frameworks
Familiar with Postgres, Mongo, ElasticSearch
Familiar with Kubernetes and containerized deployment
Communicative and able to work independently
Approaches ambiguity with a decisive and investigative mind
Takes ownership and responsibility of critical systems
Enjoys building code that gets deployed and used
Your first month
Demonstrate understanding of our system architecture
Work on tickets for building out our production data platform
Complete organizational onboarding
Your first 3 months
Work on new platform features as the transition completes
Collaborate with data science team on migration to new infrastructure
Your first 6 months
Ownership of infrastructure used by the data science team
Ownership of the production platform interface with the data science team
Your Benefits & Perks
Competitive Compensation Packages
401k program
Medical, dental & vision insurance
Short-term disability insurance
Generous Parental Leave
Unlimited Paid Time Off
Continuing Education Sponsorship
Bi-Annual All-Hands, Volunteering & Special Events (with baby goats in attendance)
Unlimited snacks & drinks

About Us
Smarter Sorting is a purpose-driven company committed to advancing sustainability at every phase of the consumer product lifecycle. Our cutting-edge machine learning technology enables cost-effective, legally compliant decisions for all unsold products, and our process advances our partners’ zero-waste goals.

As a collective group of machine learning experts, successful serial entrepreneurs, data scientists, sustainability experts, and national account program managers, our passion for data-driven sustainability drives us toward a singular goal: to reduce waste through the salvation of unwanted items. Our goal is to minimize valuable product disposal and maximize sustainable alternatives such as donation, reuse, and recycling.

A healthy culture is key to our company’s success and more importantly our employees’ happiness. At Smarter Sorting: We do what it takes. We are driven to become experts. We are not jerks. We are real. We have grit. Our core values drive our culture and in turn, we achieve our vision.

Better decisions. Better data. Greener planet. All made possible by the best people. Come join our team!",5.0,"Smarter Sorting
5.0","Austin, TX","Austin, TX",1 to 50 employees,2016,Company - Private,Enterprise Software & Network Solutions,Information Technology,$1 to $5 million (USD),-1
"Immediate hiring Sr. AWS developer, Sr. Bizops, Sr. Cloud engineer",-1,"Multiple positions with our client Only W2. Immediate hiring Sr. AWS developer, Sr. Bizops, Sr. Cloud engineer 1.Job Description AWS Developer Herndon, VA Lead position The client is seeking a Developer IV to design, develop, and implement applications on AWS using general languages and technologies (e.g. Java,Python) to support business requirements. Developer IV performs high complexity (i.e. system level applications) analysis, design, development and unit testing of software applications from user requirements and design documents. The candidate also resolves defects encountered during various testing cycles. Required Skills bull AWS Services bull PythonJava bull SQL Job Requirements bull Minimum of 5 years of experience with developing solutions on the AWS platform using services such as RDS, S3, IAM, Lambda, API Gateway bull Hands-on experience migrating customers to the cloud and designing DevOps operational processes, deployment checklists, etc. bull Experience with ScrumAgile methodology bull Experience working in cloud migration services bull Have a keen interest in using any and all appropriate tools, especially Cloud-based, to solve the problem at hand bull Expert level demonstrated experience in developing code, implementation and adopting to cloud strategy bull Experience working in Cloud environments, AWS, Big data environments bull Minimum of 5 yearsrsquo experience writing code in high-level language like Java, scripting language like Python . 3-4 yrs. of experience building integrations between applications using REST APIs bull Configure and implement AWS tools such as CloudWatch, CloudTrail and direct system logs for monitoring. bull At least one language common to cloud platforms such as Java or Python 2. Sr. Bizops Longterm O'Fallen, MOJob Description The BizOps team is looking for a Site Reliability Engineer who can help us solve problems, build our CICD pipeline and lead Mastercard in DevOps automation and best practices. Are you a born problem solver who loves to figure out how something works? Are you a CICD geek who loves all things automation? Do you have a low tolerance for manual work and look to automate everything you can? Business Operations is leading the DevOps transformation at Mastercard through our tooling and by being an advocate for change standards throughout the development, quality, release, and product organizations. We need team members with an appetite for change and pushing the boundaries of what can be done with automation. Experience in working across development, operations, and product teams to prioritize needs and to build relationships is a must. Mission The role of business operations is to be the production readiness steward for the platform. This is accomplished by closely partnering with developers to design, build, implement, and support technology services. A business operations engineer will ensure operational criteria like system availability, capacity, performance, monitoring, self-healing, and deployment automation are implemented throughout the delivery process. Business Operations plays a key role in leading the DevOps transformation at Mastercard through our tooling and by being an advocate for change and standards throughout the development, quality, release, and product organizations. We accomplish this transformation through supporting daily operations with a hyper focus on triage and then root cause by understanding the business impact of our products. The goal of every biz ops team is to shift left to be more proactive and upfront in the development process, and to proactively manage production and change activities to maximize customer experience, and increase the overall value of supported applications. Biz Ops teams also focus on risk management by tying all our activities together with an overarching responsibility for compliance and risk mitigation across all our environments. A biz ops focus is also on streamlining and standardizing traditional application specific support activities and centralizing points of interaction for both internal and external partners by communicating effectively with all key stakeholders 3. Sr. Cloud Engineer VirginiaJob Description As a Data Engineer, you'll be part of a team thats building new analytical and machine learning tools and frameworks to exploit advantages in the latest developments in cloud computing - EMR, Airflow, SageMaker, etc. You will participate in detailed technical design, development and implementation of applications used by our data scientists and business analysts to build and launch models, analyze data, and make decisions. Qualifications 5+ years of experience in Python, Scala, or R for large scale data analysis 5+ years' experience with Relational Database Systems and SQL (PostgreSQL or Redshift) 5+ years of UNIXLinux experience 2+ years of data modeling experience 2+ years of experience with Cloud computing (AWS) 2+ years of experience with Spark Kindly share profiles to kevinvkoresolutions.com",-1,VKore Solutions LLC,"Herndon, VA","Austin, TX",Unknown,-1,Company - Public,-1,-1,Unknown / Non-Applicable,-1
Senior Full Stack Engineer,-1,"At Perceptive Automata, we use our understanding of human behavior, computer vision, and machine learning to make autonomous vehicles safer for people on and near the road.

We are looking for an experienced software engineer to help develop, extend, and maintain our data collection, aggregation, and annotation platform. We're a rapidly growing startup with a steadily growing volume of data coming through the pipeline used to train and validate our machine learning models. In this role, you will play a critical role in helping to scale the platform to support that growth.

Strongly Preferred Skills & Background:
B.S. in computer science or equivalent practical experience
4+ years experience with full-stack web development
Strong Python programming skills
Well-versed in full stack development architecture and design best practices, including REST API, micro services, Flask
Experience with javascript and modern front end frameworks, preferably React
Experience with PostgreSQL or other relational databases using both raw SQL queries and ORM
Solid software design skills and experience writing well-tested and scalable code
Strong communication skills (both written and verbal)
Eagerness to learn and master new skills
Also Helpful:


Experience with AWS, including EC2, S3, and RDS
Experience with automated testing tools such as Selenium
Benefits:


Year-End week-long shutdown, 3 weeks paid vacation & 11 holidays
100% Premium paid health insurance
Monthly transit or parking benefit provided by Perceptive Automata
Flexible spending & dependent care accounts
Health care reimbursement account (50% or more of your deductible covered by Perceptive Automata)
Eye & dental insurance
Flexible maternal & paternal leave
Equity-based compensation
Efficient 401K plan
Perks:


Modern urban office space with natural light and greenery
Lunch provided daily by local restaurants
Unlimited healthy snacks & beverages
Journal clubs, guest speakers & learning opportunities
In-office gaming, board games & books
Office lending library
Company outings
Diverse events organized by team members on an ad-hoc basis
Company Overview:


Perceptive Automata is a machine learning and computer vision company started by Harvard and MIT scientists that is developing a novel approach to help make autonomous vehicles safer for others on (or near) the road. We are supported by top Silicon Valley investors and global car makers and are growing rapidly in response to increasing demand for this technology.",5.0,"Perceptive Automata
5.0","Boston, MA","Somerville, MA",1 to 50 employees,2016,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Senior Full-Stack Software Engineer,"$115K-$198K
(Glassdoor est.)","CircleUp harnesses the power of machine learning and predictive analytics to discover and evaluate some of the fastest-growing companies in the consumer & retail sector. Our mission is to help entrepreneurs to thrive by giving them the capital and resources they need, while empowering investors to transition away from a reliance on gut toward data-driven decisions.

Our data platform, Helio, is leveraged by investors to discover, evaluate, and understand the drivers behind successful CPG companies. We are seeking a software engineer with full stack web and data engineering experience to help develop the tools and applications needed to bring the data-driven revolution that has occurred in the public markets to the private markets. As a generalist engineer you will work across the stack and leverage the Helio data platform to complete projects such as scaling our application backend system, building the MVP user interface for investors to sort and filter companies, and building out new data pipelines. You will have the opportunity to work cross-functionally and hear feedback directly from investors as we iterate on the product through user testing.

CircleUp was recently honored as one of Fast Company's Top 10 Most Innovative Companies in Data Science and has been named a CB Insights FinTech 250, a Top 5 Most Disruptive Company in Finance by CNBC, and to the Forbes FinTech 50. Founded in 2012, CircleUp is headquartered in San Francisco and backed by Union Square Ventures, GV, Canaan Partners, QED Advisors, and others

Responsibilities:
End-to-end ownership of new tools and applications built on top of our data platform, ensuring scalability, responsiveness, and usability of the front-end and back-end components
Work closely with the Helio Platform team to build out scalable data services that efficiently and reliably deliver data to external applications
Contribute to the development of the data platform and bringing on new data sources when needed
Work in a fast-paced Build-Test-Iterate cycle in order to quickly meet both technical and customer needs
Design and implement tools to track and understand success metrics for new tools and applications
Requirements:
6+ years experience as a Software Engineer or similar role
B.S., M.S. or Ph.D. in computer science, engineering, or a related technical field
Significant experience with our stack (Python 3, Spark, Pandas, Javascript, Django/Flask, Docker, AWS ecosystem) or comparable stack
Strong communication skills collaborate cross-functionally with product managers, data and ML engineers, data scientists, business teams, and customers
Excellent software engineering skills and strong fundamentals in algorithms, data structures, system design, and big data concepts
If you got to this point, we hope you’re feeling excited about the job description you just read! Even if you feel that you don't meet all of the requirements and qualifications, we still encourage you to apply. We’re eager to speak with those who share our passion to help entrepreneurs thrive - not just those who match every bullet point in our job descriptions.

CircleUp is an equal opportunity employer. We do not discriminate based upon race, religious creed, color, national origin, ancestry, physical or mental disability, medical condition, genetic information, marital status (including registered domestic partnership status), sex and gender (including pregnancy, childbirth, lactation and related medical conditions), gender identity and gender expression (including transgender individuals who are transitioning, have transitioned, or are perceived to be transitioning to the gender with which they identify), age, sexual orientation, Civil Air Patrol status, military and veteran status and any other consideration protected by federal, state or local law. We encourage those who really want to make an impact to apply for our open positions.",4.5,"CircleUp
4.5","San Francisco, CA","San Francisco, CA",51 to 200 employees,2012,Company - Private,Venture Capital & Private Equity,Finance,Unknown / Non-Applicable,-1
"Senior Software Engineer, Performance and Optimization","$95K-$181K
(Glassdoor est.)","The Aerial 5G Team is bringing GPU-Accelerated 5G Virtual Radio Access Networks (vRAN) to meet growing consumer demand. We are working on the delivery of an application framework for building high-performance, software-defined, cloud-native 5G applications, and achieve optimized results with parallel processing on the GPU for baseband signals and data flow. We are seeking the following key talent to help us achieve our goals.

What you'll be doing:

As a member of Aerial 5G team, you will be responsible for defining and designing performance/verification frameworks for GPU based PHY/MAC layers for 5G NR/LTE vRAN. You will work with System, HW, Algorithm, CUDA and SW groups to nail down bottlenecks and work with them to come up with right optimization solutions. You will also define performance and test cases.

What we need to see:
BS/MS in a relevant field and 10+ years’ experience or PhD with 5+ years’ experience or equivalent.
Must have a good understanding of software development and testing concepts for wireless handsets for various air interface standards.
Understand Physical/MAC layers and Call Processing concepts.
Experience and knowledge of field test requirements for performance and/or Product Technical Acceptance with Wireless Carriers.
Knowledge of CPU and GPU computing architecture, as well as memory and I/O interfaces.
Familiarity with air interface performance analysis, characterization and optimization.
Must have experience in one or more programming / scripting languages: C/C++, Java, Perl, Python/, shell scripting.
Ways to stand out:
Desire to go deep into GPU, CUDA and algorithms details to address functional and performance issues.
Appetite to learn about the application of machine and deep learning algorithms for vRAN signal processing.
Our technology has no boundaries! NVIDIA is building the world’s most groundbreaking and state of the art compute platforms for the world to use. It’s because of our work that scientists, researchers and engineers can advance their ideas. At its core, our visual computing technology not only enables an amazing computing experience, it is energy efficient!

We pioneered a supercharged form of computing loved by the most demanding computer users in the world - scientists, designers, artists, and gamers. It’s not just technology though! It is our people, some of the brightest in the world, and our company culture make NVIDIA one of the most fun, innovative and dynamic places to work in the world! At the center of NVIDIA's culture are our core values like innovation, excellence and determination and team, that guide us to be the best we can be. NVIDIA offers highly competitive salaries and a comprehensive benefits package. We have some of the most forward-thinking and talented people in the world working for us and, due to unprecedented growth, our world-class engineering teams are growing fast. If you're a creative and autonomous engineer with real passion for technology, we want to hear from you.

NVIDIA is committed to fostering a diverse work environment and proud to be an equal opportunity employer. As we highly value diversity in our current and future employees, we do not discriminate (including in our hiring and promotion practices) on the basis of race, religion, color, national origin, gender, gender expression , sexual orientation, age, marital status, veteran status, disability status or any other characteristic protected by law.",4.6,"NVIDIA
4.6","Durham, NC","Santa Clara, CA",10000+ employees,1993,Company - Public,Computer Hardware & Software,Information Technology,$5 to $10 billion (USD),-1
Senior Image Processing Engineer,-1,"Senior Image Processing Engineer

United States Citizenship Required

At Expedition Technology, we push the boundaries of what is possible every day. Our engineers excel in tackling traditional signal processing problems and creating novel solutions using machine learning/deep learning algorithms. We are one of a very few companies that has been successful in employing deep learning to traditional signal processing. Our collaborative culture is conducive to researching and developing the cutting-edge solutions our DOD and IC customers seek.

We are currently seeking like-minded engineers and developers to join our growing team.

As an engineer and technologist in image processing, machine learning, and/or computer vision with our team, you will be working with our clients to design, create, evaluate, and maintain solutions using your experience and expertise in image processing, machine learning, computer vision and data science.

In your role you will work with various teams to research, develop, and deploy machine/deep learning solutions for national security missions spanning satellite, space, radio frequency and imaging systems. Your work will be instrumental in transforming the way intelligence communities handle and analyze information and translate it into actionable intelligence.

You will join Expedition Technology at a very exciting time as we continue to grow our software and signal processing capabilities. Today our team consists of developers, scientists, engineers, researchers, and analysts that have served federal, state, and local government clients on high-consequence problems in analytics, AI/machine learning and signal processing.

We are engaged in programs across the Department of Defense and the Intelligence Community and have been instrumental in making our customers programs successful in ways they never imagined.

Required Qualifications
US Citizenship must be able to obtain and maintain a US Government issued security clearance of Top Secret or higher. Only US citizens are eligible.
BA/BS in a technology, engineering, computer science or related discipline
At least 5 years of hands-on experience in one or more of the fields of image processing, machine learning, computer vision, and data science
Hands-on experience of a broad ranges of technology systems and ability to work with:
A range of image processing and computer vision frameworks and libraries
Any of the following AI/machine learning frameworks, statistical packages, and libraries: Tensorflow, Caffe, Amazon Machine Learning, Apache Singa, Torch, Scikit-learn, Microsoft CNTK, Apache Mahout, SQL, d3.js, map-reduce, R, Weka, Orange, as well as open source and other emerging technologies/frameworks
A range of programming languages and scripting methods including: Python, C, C++, Java, .NET, Bash, AWK (need not know all)
Preference for using Linux (Ubuntu) over Windows
Experience conducting (and/or leading) research and development of SIGINT, RF and advanced Image Processing systems
Experience with developing alternate concepts of operation to improve image quality, including automated image quality assessment, image enhancement, device calibration
Ability to develop software algorithms to assess and improve image quality
A strong desire to work in an agile and cross functional team environment, understand team goals and generate appropriate, innovative analytical insights to drive process and experience improvement
You are someone who thrives on challenging the status quo, is hungry to explore, evaluate, and understand new technologies, and wishes to share insights and mentor your peers
The ability to qualify for a US Government-issued Top-Secret Clearance
US Citizenship is REQUIRED in order to obtain the proper level of clearance
Desired Qualifications
Advanced degree with a MS/PhD specializing in data science, computer vision, machine learning, and artificial intelligence
Exemplary written and verbal communication skills (e.g., technical writing)
Experience working with DOD and IC clients, operational components, and stakeholders
People who enjoy solving problems, and who are comfortable with ambiguity
The ability to self-manage, with strong self-organization skills, and eagerness to contribute
Consuming desire to be an excellent engineer, eager to explore new technologies, and develop new skills
Active TS/SCI strongly desired
Expedition Technology (EXP) is an employee-owned defense and aerospace technology small business that has become a market leader in developing software applications running advanced machine learning algorithms for the DOD and Intelligence Communities. We offer a collaborative team-based culture, a people-first mentality and a focus on cutting edge solutions.

We offer self-directed, company-paid, medical, dental and vision benefits. Additionally, our team enjoys a 401k with up to 12% company match, equity shares, paid holidays, paid time off, tuition reimbursement programs and a student loan repayment option. Most importantly, we offer an environment where we are encouraged to push boundaries, take risks and enjoy the rewards.

EXP is proud that our dynamic and collaborative culture along with our generous benefits package allowed us to earn a spot on the 2019 and the 2020 Washington Business Journal's Best Places to Work List.

If you are interested in seeing for yourself why our employees' voices made us a Best Place to Work, we'd love to talk with you.

EXP is proud to be an Equal Opportunity Employer that believes a diverse range of talent creates an environment that fuels creativity and innovation. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, age, disability, national origin, genetic information or protected veteran status.

Powered by JazzHR",5.0,"Expedition Technology, Inc.
5.0","Herndon, VA","Dulles, VA",1 to 50 employees,2013,Company - Private,Aerospace & Defense,Aerospace & Defense,$10 to $25 million (USD),-1
Senior Software Development Engineer,-1,"THE Amazon Business Product Discovery TEAM
Amazon Business Search is a new group of seasoned engineers, product managers, designers and scientists DETERMINED to redefine how business customers discover products for work. Our vision is to make Amazon Business the default product discovery destination for businesses. We will provide business customers with the relevant products to their job function and create shopping experiences that will be unparalleled. Amazon Business is a marketplace on Amazon.com that combines the selection, convenience and value customers have come to know and love from Amazon, with new features and unique benefits that address the needs of businesses.
THE CHALLENGES WE WILL TACKLE
As with every project within Amazon, we work backwards from our customer's needs and the challenges they have. Our team tackles some of the toughest problems in retail search for businesses:
Streamline the discovery and purchase experience for products across Amazon.com and remove all stress in the process. It will be easy to discover and purchase ""the relevant one"".
Inspire our customers with beautiful experiences and relevant products.
Personalize customer experience to help them find useful products that match their preferences, interests and job functions.
Provide expert advice and information that help guide our customers in their decision-making process.
Allow customers to create their personal work preferences and use that to influence the website's shopping experience.
Improve the customer's search experience on the website by providing intelligent filter using user profile, their industry and job function.
THE TECHNOLOGY
In order to achieve our vision, we think big and tackle technology problems that are cutting edge. Where technology does not exist, we will build it. Where it exists, we will need to modify it to make it work at Amazon scale. As the problem is so wide and the team new, we need members who are passionate and willing to learn:
Search&Discovery. We build core product search and discovery technology to produce the most relevant and accurate results for our customers pertaining to their business.
Amazon scale systems. All of our technology needs to work at Amazon scale, serving business customers with millisecond level latencies.
Big data & analytics. Amazon is data driven and a strong data backbone is necessary in our systems. We build upon core AWS services such as EC2, S3, DynamoDB, etc. If you are interested in learning or gaining expertise, join us.
Personalization and machine learning. All technologies will be used in experiences adapted to what customer need, want or prefer. We work with advanced machine learning technologies to tackle these problems.
User interface & web development. We will create beautiful and dynamic frontend experiences that requires deep knowledge of relevant technologies such as AngularJS, JQuery, etc.
OUR CULTURE AND YOU
We are a tightly knit group that share our experiences and help each other succeed. We love hard problems and like to move fast in a growing and changing environment. We use data to guide our decisions and we always push the technology and process boundaries of what is feasible on behalf of our customers. The most successful members of our team are obsessed with helping our customers in creative ways and bring clarity to ambiguity through data driven experimentation. If that sounds like an environment you like, join us.

Your role will include:
Writing solid code, making smart design decisions and building scalable software services.
Work across Amazon to creatively leverage existing services and APIs for our product
Work with category leaders and product managers to build features used by millions of people every day, and be proud of it.
Solve complex problems that have a large and direct impact to customers and high visibility
Basic Qualifications
B.S/M.S. in Computer Science or a related field
7+ years professional experience in software development. 3+ years of full stack development.
Proficiency in object oriented languages like Java/C#
Computer Science fundamentals in data structures, object-oriented design, algorithm design and problem solving.
Work well in a fast-moving team environment and effectively drive cross-team solutions having complex dependencies and requirements
Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.",-1,Amazon Corporate LLC,"Seattle, WA",-1,-1,-1,-1,-1,-1,-1,-1
"Staff Software Engineer, Threat Protection","$113K-$219K
(Glassdoor est.)","About Netskope

Today, there's more data and users outside the enterprise than inside, causing the network perimeter as we know it to dissolve. We realized a new perimeter was needed, one that is built in the cloud and follows and protects data wherever it goes, so we started Netskope to redefine Cloud, Network and Data Security.

Since 2012, we have built the market-leading cloud security company and an award-winning culture powered by hundreds of employees spread across offices in Santa Clara, San Francisco, Seattle, Bangalore, London, Melbourne, and Tokyo. Our core values are openness, honesty, and transparency, and we purposely developed our open desk layouts and large meeting spaces to support and promote partnerships, collaboration, and teamwork. From catered lunches and office celebrations to employee recognition events and social professional groups such as the Awesome Women of Netskope (AWON), we strive to keep work fun, supportive and interactive. Visit us at netskope.com/company/careers and follow us on Twitter @Netskope and Facebook.

We are looking for a senior level engineer to join a small team to build a brand new analytics product. By applying various machine learning technologies, it detects threats by analyzing User and Entity behavior. This is SaaS, multi-tenant, microservice based application that performs advanced security analytics in real time in a massive scalable manner.

This is a great opportunity for engineers who love to build something new, learn something new, dig deep and write solid code. You will have the opportunity to work with a team of talented engineers, researchers and data scientists to solve the most challenging cloud security problems.

Responsibilities:
Design and build cloud based products with massive scalability and reliability requirements
Work with the PM and different stakeholders to help transform the vision to reality
Write modular and clean code
Test driven development
End-to-end ownership of software development lifecycle, from requirements validation, design, coding, unit testing all the way to maintenance.
Qualifications:
Strong understanding of Object Oriented design principles
Expertise in Java or Scala a big plus
Expert understanding of distributed systems, data structures and algorithms
A skilled problem solver well-versed in considering and making technical tradeoffs
5+ years of experience in the field of software development
A strong communicator and collaborator
Knowledge of security domain is a bonus
Education:
BS or MS in Computer Science or equivalent technical degree
#LI-SC1",4.1,"Netskope
4.1","San Francisco, CA","Santa Clara, CA",501 to 1000 employees,2012,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,"Skyhigh Networks, Zscaler, NortonLifeLock"
CMR Software Engineer II,-1,"Software Engineer II Riverdale, MD

The Raytheon Intelligence & Space (RI&S) business is seeking a talented entry level Software Engineer based out of Riverdale, MD. The selected candidate will join Raytheons EED-2 (EOSDIS Evolution and Development) team which supports NASA in its mission to provide scientists, and other users, access to data from NASAs Earth science missions. As a member of the EED-2 team, software engineers will build innovative tools allowing scientists and students alike to discover, transform, update and improve the quality of earth science data in the pursuit of solving a wide range of environmental and socio-economic issues. Specifically, this opening is for a software engineer on EED-2s Common Metadata Repository (CMR) team. The CMR is an AWS hosted scalable repository for ~500M earth science metadata records from around the world. It receives approximately 3M queries per week and is envied for its speed and reliability. The CMR team is an established and high performing agile team working in the Scaled Agile Framework methodology.

Primary Responsibilities:


Participate in all aspects of the software development lifecycle from user story generation, through design, development, automated testing and operational support
Develop new feature ideas to meet the ever evolving needs of our end-users
Continually help the team grow by sharing new ideas and industry best practices
Suggest improvements to processes and tools to help the team be more efficient
Other duties as assigned
Requirements:
This position requires the eligibility to pass a National Agency Clearance with Inquires (NACI) screening. Except in rare circumstances, U.S. citizenship is required to be screened.
Experience or exposure with a functional programming language, such as Clojure
Experience or exposure with Amazon Web Services (AWS)
Experience or exposure with the Atlassian tool suite (JIRA, Confluence, Bamboo)
Able to work independently or as a member of small team using Agile/Scrum methodologies
Firm commitment to automated testing and continuous integration
Proponent of continuous improvement and willingness to bring new ideas to the team
Desired Requirements:
Previous intern or full time Software Engineering experience
Experience with machine learning, algorithm optimization, & Elasticsearch
Experience developing in Clojure
Experience with Geographic information systems (GIS)
Experience developing on MacOS X and deploying to Red Hat Enterprise Linux
Experience with the Scaled Agile Framework (SAFe)
Experience presenting at technical conferences
A GPA of 3.0+ is strongly desired
Required Education:
A Masters Degree in Engineering, Computer Science, Physics, Math or a closely related STEM field obtained in the last 18 months or by Summer 2020.
A Bachelors Degree meeting the above degree requirements with 2+ years of experience can also be considered for the G07 level.
**Please include your GPA on your resume and attach a copy of your transcript**

This position requires either a U.S. Person or a Non-U.S. Person who is eligible to obtain any required Export Authorization.

163313

Raytheon is an Equal Opportunity/Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to race, age, color, religion, creed, sex, sexual orientation, gender identity, national origin, disability, or protected Veteran status.",3.5,"Raytheon Intelligence & Space
3.5","East Riverdale, MD","Arlington, VA",10000+ employees,2020,Subsidiary or Business Segment,Aerospace & Defense,Aerospace & Defense,$10+ billion (USD),-1
"Senior Software Engineer, Data","$91K-$178K
(Glassdoor est.)","Develop a state-of-the-art product. Make sense of the future. Use data to grow your business.

If you are a coding fanatic and passionate about programming, we want you to help us make a huge impact. Our clients love our product and are thirsty for more!

At CB Insights we build products that help clients make sense of the future and drive their businesses forward using data. Our system retrieves large amounts of structured and unstructured data and uses scientific methods to extract knowledge and insights from that data. We present those analytics through a sophisticated, dynamic user interface which enables our clients to find answers to their most important questions.

Your main tasks:

Senior Data Engineer will be the main engineering resource within our data science team. Reporting to the R&D Team Lead, you will work alongside data scientists on cutting-edge problems. The goal is to build efficient and reusable data and machine learning pipelines to enable rapid R&D work, make it easy to productionize the research, quickly adopt new data sources, and maintain the best software engineering practices. The data engineer will collaborate with software engineers from other teams and influence the company's engineering strategy.

You will join a small and very motivated team doing interesting and unique work in NLP and knowledge discovery. You'll get access to rich and interesting data and a chance to build cutting-edge data processing pipelines. Here is your chance to be all you can be. This position is critical to scaling the data science team. You'll be responsible for enabling data science in a truly data-centric company.

What you bring to the table:
4+ years professional experience in Python. Familiarity with Go is a plus
Relational database proficiency (e.g. Redshift, MySQL, Aurora)
Experience using Spark, Sqoop, AWS services (Spectrum, Glue) and other related tools in the big data ecosystem
Knowledgeable of data modeling, data storage techniques, data warehousing and general data architecture
Experience with engineering data pipelines to capture, store and process unstructured data
Proficiency developing in a Mac/Linux environment
The Perks:
Amazing culture: Happy, Helpful, Humble, Hungry. Learn more here
A newsletter that 600k people follow: Sign up here.
Be Healthy: Health with HSA and FSA options, dental, and vision insurance along with unlimited/take what you need sick day policy
Plan for the future: 401k with up to 4% match
Continued Learning: $1,000 yearly continuing education stipend
Rest and Relax: Competitive vacation and holiday plans
Refuel: Daily lunch stipend, unlimited snacks/coffee
We are dedicated to adding new perspectives to the team and encourage everyone to apply if your experience is close to what we are looking for.

Equal Opportunity Employer: CB Insights is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status.

If you know someone who'd be perfect for the role,
submit here and you'll be eligible for $5,000!

#LI-FR1",4.1,"CB Insights
4.1","New York, NY","New York, NY",201 to 500 employees,2009,Company - Private,Enterprise Software & Network Solutions,Information Technology,$25 to $50 million (USD),-1
Senior Machine Learning Engineer,-1,"About ConcertAI

ConcertAI is the leading provider of precision oncology solutions for biopharma and healthcare, leveraging the largest collection of research-grade Real-world Data and the only broadly deployed oncology-specific AI solutions. Our mission is to improve translational sciences; accelerate therapeutic clinical development; and provide new capabilities for post-approval studies to accelerate needed new medical innovations to patients and to improve patient outcomes.
ConcertAI has emerged as one of the highest growth technology companies in Real-world Data and AI, backed by industry leading private equity companies: SymphonyAI, Declaration Partners, Maverick Ventures, and Alliance|Bernstein.

ConcertAI is looking for a talented Senior Machine Learning Engineer to build advanced AI and Machine solutions as part of our eurekaHealth solution team engaging in projects and programs of high priority. You should have a good mix of programming/CS skills and data science experience. You will be responsible for designing, implementing and maintaining software that powers the company’s data operations, production analytics (AI/ML/DS) and products. You will collaborate with data scientists on prototypes and work on productization, focusing on scalability and robustness (tests, documentation, etc).This role reports to the Vice President of Data Science.
Responsibilities
Lead, design, develop, and implement AI production software to address client’s needs.
Collaborate on software projects with data scientists, and provide technical guidance.
Develop ML/AI algorithms using high level libraries and high performing implementation.
Stay current on the most recent AI/ML algorithms, design principles, and programming paradigms.
Write documentation and test suites, and help maintain several codebases.
Requirements
PhD in computer science, math, physics, or engineering and 3+ years of relevant work experience.
Experience with Python or another high level programming language (e.g. Java, C++).
Production software development experience.
Expertience with advanced data science and machine learning concepts and libraries.
Experience with data munging with Spark/Scala/Sq.
Experiece with cloud technologies (AWS, Docker, Git).
Experience with healthcare data (Electronic Health Records, claims data) is preferred.
Strong communication, project management and technical leadership skills with an enthusiasm for working in an interdisciplinary environment.
Learn More About ConcertAI

ConcertAI is transforming how healthcare is delivered and dedicated to improving patient outcomes in oncology by offering innovative solutions on how data and intelligence is used to solve healthcare problems. We are creating something special in our culture, by building a collaborative, engaged, patient focused, team approach to our mission. Our high-performance teams are looking to add great talent to the mix and we are hiring for the right mix of new skills and diverse mindset. Learn more about ConcertAI at www.concertai.com or on LinkedIn .",3.4,"Concerto HealthAI
3.4","Boston, MA","Boston, MA",501 to 1000 employees,2018,Company - Private,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,Unknown / Non-Applicable,-1
"Senior Software Engineer, Reasoning",-1,"OpenAI’s mission is to discover and enact the path to safe, beneficial AGI. On this path, the Reasoning team aims to develop machine learning systems that achieve high performance on tasks that require reasoning for humans, such as answering questions about the world, understanding logic puzzles and games, solving math problems, and proving theorems. To do this, we believe that we will need to develop systems for acquiring data of unprecedented scale and quality.

We are looking for an experienced full-stack software engineer to develop systems that enable us to procure and process data for a wide variety of research projects. This includes maintaining and scaling a web application for collecting data from human annotators, harvesting datasets from the web, and building new tools that use machine learning to clean and prepare data. This is a core role integrated within a team of research scientists and engineers working on pushing the limits of reasoning capabilities.
You will:
Work at all levels of the web application stack, using HTML and CSS, VueJS or React, NodeJS, Python (Django), as well as Heroku, AWS, or another cloud platform
Own the process of finding large-scale datasets and acquiring them via crawling and scraping
Develop and implement new deep learning-based methods for getting feedback from humans and for cleaning and curating datasets, in order to make them accessible for research within OpenAI
Partner with researchers across OpenAI to understand their research and data needs
Design reusable, scalable data infrastructure that can be applied across multiple teams
You’ll be a good fit for this role if you are:
Excited to work closely with a fast-paced results-oriented research team with dynamic requirements
An expert in Javascript, Python, and Linux, and comfortable with large Python and Javascript codebases
Experienced in maintaining and scaling performant web applications
Experienced in developing web crawlers and scrapers, and processing web-sourced data
Comfortable with the fundamentals of machine learning and excited to develop expertise in deep learning
Excited to use machine learning to develop tools for filtering, balancing, and deduplicating data
Engaged with OpenAI’s mission of building safe and beneficial artificial general intelligence
About OpenAI
We’re building safe Artificial General Intelligence (AGI), and ensuring it leads to a good outcome for humans. We believe that unreasonably great results are best delivered by a highly creative group working in concert. We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

This position is subject to a background check for any convictions directly related to its duties and responsibilities. Only job-related convictions will be considered and will not automatically disqualify the candidate. Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.

Benefits
Health, dental, and vision insurance for you and your family
Unlimited time off (we encourage 4+ weeks per year)
Parental leave
Flexible work hours
Lunch and dinner each day
401(k) plan",5.0,"OpenAI
5.0","San Francisco, CA",-1,51 to 200 employees,-1,Nonprofit Organization,-1,-1,Unknown / Non-Applicable,-1
Sr Data Engineer,-1,"Recognized as a top 10 finalist in Google's Machine Learning Competition and by industry as Decoded Fashions top start up, Trendalytics is working on the industry's most pertinent and cutting edge problems in predictive analytics.

We are seeking a Sr Data Engineer who is eager to solve complex and intellectually stimulating problems related to designing and developing robust, scalable solutions for collecting, analyzing large social media, search and e-commerce data sets, creating and maintaining data pipelines, data structures and reports to be used by multiple Fortune 500 companies and disruptive online retailers.
Responsibilities
Partner end-to-end with Product Managers and Data Scientists to understand customer requirements and design prototypes and bring ideas to production
Design, implement and manage data pipelines at enterprise scale with unit testing, data migration and production data maintenance.
Use your expert coding skills across a number of languages like SQL, Python and Java to support analysts and data scientists
Design and develop new framework and automation tools to enable teams to consume and understand data faster. Enhance, refine and implement existing applications and systems.
Formulate and refine analytics algorithms leveraging data from search, social and e-commerce in time series, text and image-based formats.
Responsible for development, testing, documentation and analysis of modules or features of distributed software systems and products.
Develop accurate time, cost and resource estimates for developing and maintaining systems.
Qualifications
B.S. or MS degree in Computer Science or Computer Engineering, or related.
5+ years of SQL (PostgreSQL, Oracle, AWS Redshift, Hive, etc) experience required, No-SQL experience is a plus.
5+ years professional coding experience in Python, C/C++, Java or Go.
5+ years professional experience with data warehousing, data architecture, ETL data pipeline and/or data engineering environments at enterprise scale.
Professional experience architecting and developing large scale cloud based distributed systems. Experience in concurrency, multithreading and synchronization.
Communication skills including the ability to identify and communicate data driven insights
Trendalytics is an equal opportunity and affirmative action employer. Individuals seeking employment at Trendalytics are considered without regards to race, sex, color, creed, religion, national origin, age, disability, genetics, marital status, pregnancy, unemployment status, sexual orientation, citizenship status or veteran status.",3.2,"Trendalytics
3.2","New York, NY","New York, NY",1 to 50 employees,2013,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Senior Cyber RD Engineer/Scientist,-1,"Senior Cyber R & D Engineer/Scientist
Tracking Code
HR9074
Job Description

Radiance Technologies is an employee-owned company with benefits that are unmatched by most companies in the Dayton OH area. Employee ownership, generous 401K, full health/dental/life/vision insurance benefits, educational reimbursement, competitive salaries, interesting assignments and a pleasant work environment combine to make Radiance Technologies a great place to work and succeed. In fact, Radiance was named by the Dayton Business Journal as one of the Best Places to Work in Dayton in 2017, 2018, 2019 and 2020!
Radiance Technologies, supporting multiple technology development efforts, performs advanced research and development using machine learning, program analysis, optimization, artificial intelligence (AI), and formal methods for the cybersecurity and resiliency of cyber-physical systems. Addressing the most urgent national security challenges, Radiance Technologies is developing fundamentally new capabilities in cyber-physical systems modeling, vulnerability analysis, and attack detection and remediation.
We are seeking engineers and scientists who are passionate about technology and security, from the bare metal to the cloud, and everywhere in between. We are growing rapidly and hiring at all levels and across disciplines for new and exciting projects. Radiance Technologies is committed to creating a collaborative learning environment that supports deep technical understanding and recognizes the contributions and achievements of all team members. We strive for excellence in technical work that addresses the most important problems in national security.
We believe that each employee has a unique set of skills, experiences, and perspectives that are essential to providing our customers with innovative solutions. The skills listed below are intended to give you a sense for the position. If you see an overlap with your skills, go ahead and apply! All applicants must be US citizens who are willing and able to obtain and maintain a security clearance.
Role
Work in small research teams to develop innovative software prototypes
Apply a diverse set of advanced technologies, e.g., program analysis (static, dynamic, symbolic), formal methods, artificial intelligence, and machine learning, to solve the most difficult cybersecurity challenges
Span the stack or find a niche: from developing tools for the automatic instrumentation and modification of program binaries, to automation and planning technologies to coordinate large-scale cyber operations, Radiance Technologies' cyber programs cover a broad territory
Required Skills
Strong analytical skills with demonstrated ability to understand and handle concepts at a fundamental level
Strong programming background
Strong technical writing and oral communication skills
Motivated collaborator and effective communicator to both technical and non-technical audiences
Ability to work independently or in a team environment
US citizenship with the ability to obtain and maintain security clearance
Required Experience
A BS in Computer Science, Computer Engineering, Electrical Engineering, Physics, Mathematics, Cybersecurity or related field
Minimum of five (5) years of relevant experience, or minimum of three (3) years of relevant experience and a higher technical degree (MS or PhD)
Demonstrated ability to design, develop, analyze, modify and evaluate complicated and difficult technical problems
Demonstrated ability to direct technical efforts within projects or major phases of significant projects
Desired Qualifications

The skills/qualifications listed below are intended to give you a sense for the position. If you see an overlap with your skills, please go ahead and apply.
Proficiency in programming languages (e.g., C/C++, C#, Java, Python, Assembly, MATLAB)
Experience with the functional programming paradigm in one or more languages, such as Rust, Scala, ML, Racket, Common Lisp, Haskell
Understanding of operating system internals, such as memory/process/thread management
AI, machine learning or autonomy in the context of network operations and security
Experience with software and hardware emulation tools such as QEMU
Experience with cyber vulnerability discovery
Virtualization software, virtual hardware device development, VHDL/Verilog simulation
Knowledge of operating system internals including memory/process/thread management
Linux and/or Windows development with kernel development and/or driver development
Experience performing static/dynamic/symbolic program analysis
Experience with graph theory as applied to taint tracking and data flows
Compiler intermediate representations (e.g. LLVM) and virtualization
Reverse engineering of software using tools such as IDA, Binary Ninja, or Ghidra
Mathematical analysis and optimization
Signal processing expertise
Performing research and development in an Agile environment using tools such as JIRA, Confluence, and Bitbucket
Currently pursing or possesses a master's or PhD in relevant areas
TS/SCI Clearance
Job Location
Dayton, Ohio, United States
Position Type
Full-Time/Regular
US Citizenship Required
Yes
Ability to obtain a Security Clearance
Yes
Polygraph Required
Not Required",3.6,"Radiance Technologies
3.6","Dayton, OH","Huntsville, AL",501 to 1000 employees,1998,Company - Private,Aerospace & Defense,Aerospace & Defense,$100 to $500 million (USD),-1
Sr. Software Engineer - AI/Machine Learning,"$133K-$160K
(Glassdoor est.)","C3.ai is a leading enterprise AI software provider for accelerating digital transformation. The comprehensive and proven C3 AI Suite uses a model-driven abstraction layer to enable organizations to develop, deploy, and operate enterprise scale AI applications 40x to 100x faster than alternative approaches. www.c3.ai

We are looking for a seasoned software engineer to build the next generation AI platform scaling to petabyte level data volumes.

As a member of C3.ai's platform engineering team, you will be responsible for the entire software engineering lifecyle, i.e design, document, build, test, maintain. As one of the core teams, this role is integral to the success of the company. A successful candidate will thrive in a fast-paced, highly collaborative environment and demonstrate an ability to execute precisely and quickly. The ideal candidate will have in-depth experience with Data Science workflows and built scalable machine learning systems.

- Build systems and tools that enable data scientists to create machine learning applications using the C3.ai Platform.
Enable scalable, end-to-end machine learning pipelines in a distributed system.
Work with other platform engineering teams to enable streaming, batch, or ad-hoc data analysis.
Collaborate with and support data scientists to understand the utility of the C3.ai Platform and define new requirements.
Define and lead the development of longer-term C3.ai Platform capabilities.
Mentor junior members of the team.

Requirements:

- Advanced degree in computer science, math, or similar field.
Excellent programming and algorithmic skills and a taste for DRY code.
In-depth understanding of supervised and unsupervised machine learning algorithms.
Proven track record of applying learning algorithms in a production system.
Strong programming skills in Java, Python and JavaScript.
Demonstrated end-to-end ownership of projects.
Stellar listening and explanation skills.
Thorough knowledge of data structures, algorithms, profiling/optimization, and Object-Oriented and Functional Programming.
A minimum of 3 years of work experience in a fast-paced software company.

C3.ai provides a competitive compensation package and excellent benefits including:
Competitive salary, generous stock options, 401K, medical, dental, and vision benefits. At the office, we offer a fully stocked kitchen with catered breakfast and lunch, table tennis and pool table, free membership at our on-site gym, Friday evening social hours with food, drink and music and a fun team of great people.
C3.ai is proud to be an Equal Opportunity and Affirmative Action Employer. We do not discriminate on the basis of any legally protected characteristics, including disabled and veteran status.",4.7,"C3.ai
4.7","Redwood City, CA","Redwood City, CA",201 to 500 employees,2009,Company - Private,Enterprise Software & Network Solutions,Information Technology,$100 to $500 million (USD),"GE Digital, Palantir Technologies, Uptake"
"Senior Data Engineer (Salt Lake City, UT)","$63K-$118K
(Glassdoor est.)","Earnest empowers people with the financial capital they need to live better lives.

We're an accomplished team of technology, finance, and design geeks who believe consumer lending can be radically improved and are doing something about it. We are disrupting the trillion dollar student loan industry by redefining what it means to be creditworthy. We created a company that combines data science, streamlined design, and technology to:
Build products that simplify the lending process
Personalize loans to suit the needs of our customers
Engage with our customers through more human experiences
Our culture is one that values transparency and blameless problem solving. Earnest has a strong track record of employee growth and career progression. Earnies are empathetic, product-focused, proactive, and curious.

As a Senior Data Engineer, you will report to the Head of Data and work with members of the Data team to maintain and improve data pipelines, deploy predictive models as a service, and build our nextgen data infrastructure. Expect an environment where you will always learn and be encouraged to work with tools, languages, frameworks that are outside the area of your expertise.

We believe data engineers should spend time writing tooling and creating abstractions to empower and support the work of analysts and data scientists in the team. It enables team members to write and maintain their own ETL.

Tools, Frameworks, and Languages you will work with:
Languages: Python, Scala, and occasionally R and Node.js
Storage: Postgres, Redshift, S3
Compute: Spark, Athena, EC2
Workflow Management: Airflow
Infrastructure: Terraform, Kubernetes
What you'll do:
Work with Data Scientists to deploy trained machine learning models as a Python microservice.
Create abstractions and tools for running ETL and non-ETL jobs.
Manage overall data pipeline orchestration including Airflow.
Create databases and access controls in data warehouses.
Ideal background and expertise:
5+ years of experience building and managing data pipelines, data warehouses, and backend services
3+ years of experience with Python or Scala
Experience with server-side concepts (e.g. microservices, database, caching, performance, monitoring and scalability)
Experience with OLTP databases such as Postgres, MySQL
Experience making data available in data lakes such as S3
Experience with orchestration tools such as Airflow (preferred), Luigi, Ooozie
Familiarity with Business Intelligence tools such as Tableau, Looker, Superset is a plus
Domain experience developing software for Fintech, Banking, or related Consumer Financial Services companies is a plus
Nice to Have:
Familiarity with Business Intelligence tools such as Tableau, Looker, Superset
Domain experience developing software for Fintech, Banking, or related Consumer Financial Services companies
Earnest Perks & Benefits:
Great culture and an awesome team
Health, Dental, & Vision benefits plus savings plans
Employee Stock Purchase Plan
401(k) plan to help you save for retirement plus a company match
Tuition reimbursement program
$1000 flight on each Earnie-versary to anywhere in the world and 25 days of annual PTO
Earnest provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability or genetics. Qualified applicants with criminal histories will be considered for the position in a manner consistent with the Fair Chance Ordinance",3.9,"Earnest
3.9","Salt Lake City, UT","San Francisco, CA",51 to 200 employees,2013,Subsidiary or Business Segment,Lending,Finance,Unknown / Non-Applicable,"SoFi, CommonBond, Organic"
"Software Engineer, Research Informatics","$61K-$127K
(Glassdoor est.)","Company:

Generate Biomedicines, Inc. is a Flagship backed, privately-held biotechnology company on a mission to reimagine the drug discovery process to one of dynamic, data-driven generation. We pursue this audacious vision because we believe in the unique and revolutionary power of generative biology to radically transform the lives of billions, with an outsized opportunity for patients in need. Generate will be successful by constantly turning innovative ideas into methods, technologies, and products that solve some of the most difficult challenges with developing medicines. We are seeking collaborative, relentless problem solvers that share our passion for impact to join us!

Generate was founded by Flagship Pioneering. Flagship Pioneering conceives, creates, resources, and develops first-in-category life sciences companies to transform human health and sustainability. Since its launch in 2000, the firm has applied a unique hypothesis-driven innovation process to originate and foster more than 100 scientific ventures, resulting in over $30 billion in aggregate value. The current Flagship ecosystem comprises 37 transformative companies, including: Moderna Therapeutics (NASDAQ: MRNA), Rubius Therapeutics (NASDAQ: RUBY), Indigo Agriculture, and Sana Biotechnology.

Position:

We are seeking a creative, motivated Software Engineer to help build our data platform. Generate Biomedicines is an innovative platform company leveraging Machine Learning to design novel protein therapeutics. This role will be an integral part of building a powerful, integrated data platform that streamlines data flow between wet and dry lab functions. The successful candidate will work closely with scientists from across the organization to understand both platform and project requirements, and translate those into high-quality software that rapidly advances our scientific programs.

Responsibilities:
Work with colleagues from Platform Biology, Protein Sciences, Oncology & Immunology, and Data Science / Machine Learning teams to elicit requirements and identify opportunities for data platform improvements
Design, implement, deploy and maintain high-quality, production, user-facing web applications using Aurelia
Integrate third party applications into the data platform using APIs/SDKs
Integrate automation robots with the data platform for high-throughput processes
Write and maintain both internal and user documentation
Write unit and integration tests
Help maintain and enhance cloud (AWS) infrastructure
Qualifications:
Self-motivated and curious with strong desire to both learn from and teach others
Outstanding communications and interpersonal skills
BS, MS, or equivalent in Computer Science, Data Science, or related field plus 3 yrs (BS) or 1 yr (MS) experience working in the pharmaceutical or biotech domain
Demonstrated proficiency in Javascript/Typescript web development, and experience using a modern MV(C/VM) framework (proficiency in Aurelia a plus)
Demonstrated Proficiency in SQL
Demonstrated understanding of data management best practices and biological data
Proficiency in Python and/or Java a plus
Experience with AWS a plus
Recruitment & Staffing Agencies: Flagship Pioneering and its affiliated Flagship Lab companies (collectively, ""FSP"") do not accept unsolicited resumes from any source other than candidates. The submission of unsolicited resumes by recruitment or staffing agencies to FSP or its employees is strictly prohibited unless contacted directly by Flagship Pioneering's internal Talent Acquisition team. Any resume submitted by an agency in the absence of a signed agreement will automatically become the property of FSP, and FSP will not owe any referral or other fees with respect thereto.",3.4,"Flagship Pioneering, Inc.
3.4","Cambridge, MA","Cambridge, MA",51 to 200 employees,2000,Company - Private,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,$1 to $5 million (USD),Third Rock Ventures
"Senior Data Engineer (San Francisco, CA)","$98K-$175K
(Glassdoor est.)","Earnest empowers people with the financial capital they need to live better lives.

We're an accomplished team of technology, finance, and design geeks who believe consumer lending can be radically improved and are doing something about it. We are disrupting the trillion dollar student loan industry by redefining what it means to be creditworthy. We created a company that combines data science, streamlined design, and technology to:
Build products that simplify the lending process
Personalize loans to suit the needs of our customers
Engage with our customers through more human experiences
Our culture is one that values transparency and blameless problem solving. Earnest has a strong track record of employee growth and career progression. Earnies are empathetic, product-focused, proactive, and curious.

As a Senior Data Engineer, you will report to the Head of Data and work with members of the Data team to maintain and improve data pipelines, deploy predictive models as a service, and build our nextgen data infrastructure. Expect an environment where you will always learn and be encouraged to work with tools, languages, frameworks that are outside the area of your expertise.

We believe data engineers should spend time writing tooling and creating abstractions to empower and support the work of analysts and data scientists in the team. It enables team members to write and maintain their own ETL.

Tools, Frameworks, and Languages you will work with:
Languages: Python, Scala, and occasionally R and Node.js
Storage: Postgres, Redshift, S3
Compute: Spark, Athena, EC2
Workflow Management: Airflow
Infrastructure: Terraform, Kubernetes
What you'll do:
Work with Data Scientists to deploy trained machine learning models as a Python microservice.
Create abstractions and tools for running ETL and non-ETL jobs.
Manage overall data pipeline orchestration including Airflow.
Create databases and access controls in data warehouses.
Ideal background and expertise:
5+ years of experience building and managing data pipelines, data warehouses, and backend services
3+ years of experience with Python or Scala
Experience with server-side concepts (e.g. microservices, database, caching, performance, monitoring and scalability)
Experience with OLTP databases such as Postgres, MySQL
Experience making data available in data lakes such as S3
Experience with orchestration tools such as Airflow (preferred), Luigi, Ooozie
Familiarity with Business Intelligence tools such as Tableau, Looker, Superset is a plus
Domain experience developing software for Fintech, Banking, or related Consumer Financial Services companies is a plus
Nice to Have:
Familiarity with Business Intelligence tools such as Tableau, Looker, Superset
Domain experience developing software for Fintech, Banking, or related Consumer Financial Services companies
Earnest Perks & Benefits:
Great culture and an awesome team
Health, Dental, & Vision benefits plus savings plans
Employee Stock Purchase Plan
401(k) plan to help you save for retirement plus a company match
Tuition reimbursement program
$1000 flight on each Earnie-versary to anywhere in the world and 25 days of annual PTO
Earnest provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability or genetics. Qualified applicants with criminal histories will be considered for the position in a manner consistent with the Fair Chance Ordinance

#LI-KO1",3.9,"Earnest
3.9","San Francisco, CA","San Francisco, CA",51 to 200 employees,2013,Subsidiary or Business Segment,Lending,Finance,Unknown / Non-Applicable,"SoFi, CommonBond, Organic"
Software Development Engineer Amazon AI Labs,"$119K-$149K
(Glassdoor est.)","Come and be part of the Amazon AI Labs team and work on cutting edge machine learning algorithms for the Amazon SageMaker platform!

With Machine Learning, businesses now ask our machines to do more than repetitive, strictly-defined tasks. We are taking it one step further and have begun to ask them to not only learn on their own but to also interpret data and report to the customer before they even knew they needed it. It's a step in history for you to be a part of. You will be building a platform that incorporates best practices and runs advanced algorithms at production scale and reliability.

We are a team of data scientists and engineers who experiment, research, and turn machine/deep learning and AI research into great products for our customers.

You will work in a fast-paced environment and do everything from determining priorities, designing features, re-architecting as necessary, automating testing, and mentoring others. The best candidates show true end-to-end ownership. In this role, you will be responsible for building algorithms, tooling, frameworks, and operational processes using technologies like MxNet, Python, C++, CUDA, Docker, etc.

Amazon is an Equal Opportunity-Affirmative Action Employer Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation

Basic Qualifications

· Bachelors or Ph.D degree in Computer Science or equivalent work experience.
· 5+ years professional experience in software development of multi-threaded, scalable and highly-available distributed systems.
· Computer Science fundamentals in object-oriented design, data structures, high-performance computing.
· Computer Science fundamentals in algorithm design, complexity analysis, problem solving and diagnosis.
· Proficiency in, at least, one modern programming language such as Java, Python, C/C++, C#, Perl.

Preferred Qualifications

· Experience taking projects from scoping requirements through V1 launch and V2 iterations.
· Knowledge of professional software engineering practices and best practices for the full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations.
· Experience with highly distributed, multi-tenet systems with clear state-full/state-less boundaries.
· Experience with machine learning, deep learning, data mining, and/or statistical analysis tools.
· Proficiency designing SDKs, frameworks, and working with data science frameworks such as Numpy, MxNet, Tensorflow, etc.
· Passion and experience for mechanical sympathy and performance engineering - in particular using GPGPUs.",3.9,"Amazon
3.9","East Palo Alto, CA","Seattle, WA",10000+ employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),"Google, Microsoft, Walmart"
Senior Software Engineer (Back-end),"$121K-$185K
(Glassdoor est.)","Position Title: Senior Software Engineer (Back-end)

Position Description / Responsibilities:

Tapjoy is seeking a Senior Engineer in our Data Science group who will work closely with Data Scientists, Data Platform, and Ad Server Engineering teams to help productionalize, scale, and support Tapjoy's Optimization platform. We are looking for someone who has had experience working with vast amounts of data, scaling systems, and, supporting low-latency applications.
Essential duties and responsibilities may include, but are not limited to:
Design and build scalable, personalized ad-serving algorithm REST service API with Data Scientists Design and create a robust service that serves a high volume of requests
Implement generalized a/b test frameworks to support multivariate testing covering component change/user segmentation and bucketing / metadata driven auto experiment set up, etc.
Competencies:
You possess strong computer science fundamentals, including knowledge of data structures, algorithms, and object-oriented design
You have strong SQL understanding and some data analysis experience.
You have experience with or interest in Java, and interfacing with REST APIs Is self-directed and self-driven Is results-oriented with a high emphasis on ""on-time"" delivery of projects and features
Values collaboration with various teams and stakeholders highly
Communicates often and well about potential roadblocks and tradeoffs between performance and complexity
Requirements:
B.S. or M.S. in Computer Science
3+ years of Software Engineering experience (preferably with Java)
Strong knowledge of data structures, SQL, software design patterns and algorithms (i.e., indexing, hash tables, joins, aggregation)
Knowledge of low-latency, high-throughput services
Strongly prefer someone who has had experience with big data platforms and challenges that come with large scale platforms.
Prefer someone who understands general machine learning and data mining concepts
Experience with advertising industry is a big plus
Tapjoy is a leading mobile advertising and app monetization company. Our platform empowers advertisers to connect with over 975 million monthly active users through value exchange advertising that drives awareness, engagement and the metrics that matter most to their overall growth. Meanwhile, companies such as Scopely, Crowdstar, Topps and many of the Top 200 grossing app publishers trust our platform to monetize their content, grow their audiences and reward their users. Founded in 2007 and headquartered in San Francisco, Tapjoy is a global organization with more than a dozen offices worldwide.

Tapjoy is an equal opportunity employer. We believe that diversity and inclusion lead to stronger, more innovative teams and better business results; we want to draw from the broadest talent pool possible and encourage qualified applicants. Tapjoy does not discriminate on the basis of sex, race, ethnicity, color, age, sexual orientation, gender (including identity and expression), disability (mental or physical), religion, national origin, citizenship, marital status, military or veteran status, or any other protected classification protected by applicable law; we will provide reasonable accommodations for qualified individuals with disabilities, and pursuant to applicable fair chance ordinances, we will consider for employment qualified applicants with arrest and conviction records.

For more information, please visit www.tapjoy.com.

]]>",3.6,"Tapjoy
3.6","San Francisco, CA","San Francisco, CA",201 to 500 employees,2007,Company - Private,Internet,Information Technology,$10 to $25 million (USD),"FLURRY, Chartboost"
Senior Backend Java - ML Engineer,"$131K-$225K
(Glassdoor est.)","Who we are


Fueled by a fundamental belief that having access to financial services creates opportunity, PayPal (NASDAQ: PYPL) is committed to democratizing financial services and empowering people and businesses to join and thrive in the global economy. Our open digital payments platform gives PayPal’s 305 million active account holders the confidence to connect and transact in new and powerful ways, whether they are online, on a mobile device, in an app, or in person. Through a combination of technological innovation and strategic partnerships, PayPal creates better ways to manage and move money, and offers choice and flexibility when sending payments, paying or getting paid. Available in more than 200 markets around the world, the PayPal platform, including Braintree, Venmo and Xoom, enables consumers and merchants to receive money in more than 100 currencies, withdraw funds in 56 currencies and hold balances in their PayPal accounts in 25 currencies.

When applying for a job you are required to create an account, if you have already created account - click Sign In.

Creating an account will allow you to follow the progress of your applications.

Note:

Provide full legal first Name/Family Name
DO: Capitalize first letter of First and Last Name. Example: John Smith
DON'T: Capitalize entire First and/or Last Name. Example: JOHN SMITH
NOTE: Use correct grammar for Names with multiple cases. Example: McDonald or O'Connell
Provide full address details

Resume is required

Multiple attachments can be uploaded including Resume and Cover Letter for each application

Job Description Summary:

PayPal’s Risk organization is in charge of implementing unique, best-of-breed fraud-detection algorithms with cutting-edge technologies including Machine Learning etc. We are looking for a motivated team player, to join a highly skilled team of experienced professionals, which believe in best-of-breed software craftsmanship, clean and elegant coding, using the right tool for the job, and always exploring and learning new technologies and approaches.

Job Description:
Be responsible for practicing technical design, developing new functionality and maintaining existing components
Implement Machine Learning Platform and related tools
Deep dive into PayPal’s world class risk systems and algorithms and work side by side with data scientists and analysts on data centric analytic solutions
Contribute to PayPal’s efforts to fight Fraud, using advanced algorithms and technology, while deploying the code you develop into PayPal’s live systems, and having a true global effect
Build end to end system for model training, testing and deployment
Requirements:
At least 5 years solid server-side development with Java
Experience on Big Data platform
Experience on front end technologies
Solid knowledge of data structure and algorithms
Knowledge about Machine Learning and AI
A passion for developing robust, scalable software systems
Strong OOP skills, ability to analyze requirements and prepare design
Hands on experience with common open-source and Java EE technologies
Spring
SQL, JDBC/ORM, JMS
App servers / Servlet containers
Maven/Git/Continuous integration
B.S. in computer sciences or equivalent
Advantage:
Experience working in agile methodology
Experience working both in startups and in large companies
Good communication skill to global business and technical partners
Highly motivated, goal driven, Can-do approach
Innovative, entrepreneurial, team player, ability to multi-task
Subsidiary:

PayPal

Travel Percent:

0

Primary Location:

San Jose, California, United States of America

Additional Locations:

We're a purpose-driven company whose beliefs are the foundation for how we conduct business every day. We hold ourselves to our One Team Behaviors which demand that we hold the highest ethical standards, to empower an open and diverse workplace, and strive to treat everyone who is touched by our business with dignity and respect. Our employees challenge the status quo, ask questions, and find solutions. We want to break down barriers to financial empowerment. Join us as we change the way the world defines financial freedom.

PayPal provides equal employment opportunity (EEO) to all persons regardless of age, color, national origin, citizenship status, physical or mental disability, race, religion, creed, gender, sex, pregnancy, sexual orientation, gender identity and/or expression, genetic information, marital status, status with regard to public assistance, veteran status, or any other characteristic protected by federal, state or local law. In addition, PayPal will provide reasonable accommodations for qualified individuals with disabilities. If you are unable to submit an application because of incompatible assistive technology or a disability, please contact us at paypalglobaltalentacquisition@paypal.com.",3.9,"PayPal
3.9","San Jose, CA","San Jose, CA",10000+ employees,1998,Company - Public,Internet,Information Technology,$10+ billion (USD),"Square, Amazon, Apple"
Engineer / Scientist 3,-1,"Engineer / Scientist 3

Level
Experienced
Job Location
Charleston, SC (VNE) - Charleston, SC
Position Type
Full Time
Education Level
Bachelor's Degree
Salary Range
Undisclosed
Travel Percentage
Negligible
Job Shift
Undisclosed
Job Category
Undisclosed
Vickers and Nolan Enterprises (VNE) is an engineering company that provides Government projects and programs with experienced and dedicated system architects, engineers, subject matter experts (in tactical intelligence), and program managers. VNE also develops training courses and tools to prepare warfighters to effectively employ tactical intelligence systems and provide management guidance to the Government organizations that develop these systems.

VNE has earned a reputation for exceptional performance, innovation, agility, and responsiveness in the Intelligence Community (IC). We attack our mission with a comprehensive understanding of the data available and required; skilled research, design, development, integration, and testing of systems and software solutions; expertise in cybersecurity/information assurance and technology; programmatic, acquisition, and logistics support know-how; and our own unique training curricula that enables students to excel at intelligence operations across all levels of the community.

VNE is devoted to improving tactical operations at home and abroad by enabling the seamless transition of data across the intelligence community and developing/integrating solutions to unify operations and intelligence.

VNE is a Service Disabled Veteran Owned Small Business (SDVOSB) founded in 2004 in Stafford, VA.
VNE, LLC is looking for 12 Secret Cleared Engineer / Scientist 3

Minimum Qualifications:
BS degree in Engineering or Physical Science. Software Engineer only: Working towards the following certifications within one and a half year after assuming duties: Professional Software Engineering Master (PSEM)/Certified Software Development Professional (CSDP) or with COR approval complete a vendor/platform specific certification (e.g., Microsoft Certified Solutions Developer (MCSD), Microsoft Certified Applications Developer (MCAD), Microsoft Certified Database Administrator (MCDBA), Sun Certified Professional (SCP), Red Hat Certification Program (RHCP), CISCO Certified Network Professional (CCNP), CISCO Certified Design Professional (CCDP), Oracle Certified Professional (OCP), etc.)
NOTE – All undergraduate degrees: Bachelor of Science (BS), Bachelor of Arts (BA), or Associate of Science (AS) in Applied Science, Computing, Engineering, and Technology shall be from an Accreditation Board for Engineering and Technology (ABET) accredited program (see www.abet.org)
NOTE – Technology degrees do not qualify as Engineering or Physical Science Degrees.
NOTE – Engineering Positions require diploma/written engineering degrees versus grandfathered degrees based on experience. If a state Professional Engineer (PE) License is required for the performance of the requirement, the government can specify any unique certifications under the “Specific Experience.”
NOTE – Unless otherwise specified, higher education above a labor category’s minimum can be credited as years of experience as long as the higher degree is within the same required field of study as the minimum degree required. The following Educational credit applies: a MS degree equals four (4) years of experience and a PhD degree equals five (5) years of experience.
LIFE CYCLE LOGISTICS LABOR CATEGORIES - DAWIA Certification for Contractors – Contractor personnel that do not have government DAWIA certification courses may demonstrate an equivalency in terms of academic degrees, courses completed, and experience as that of their counterparts in the DAWIA workforce. Equivalency shall be addressed for all Acquisition and Functional Training courses at the required Level 1, 2, or 3 as specified by the Defense Acquisition University website at the time the request for proposal is posted (http://icatalog.dau.mil/onlinecatalog/CareerLvl.aspx).
LABOR CATEGORIES PERFORMING CYBERSECURITY SUPPORT FOR DOD - Prior to performing cybersecurity related work, applicable contractor personnel shall meet specific certification and training requirements in accordance with DoD 8570.1-M, DoD 8570.1, and subsequent release of DoD 8140-M prior to performing cybersecurity related work. This includes personnel being certified/accredited at the appropriate levels based on task responsibilities. This will be verified by the Contracting Officer who will ensure that contractor personnel are entered in to the Defense Eligibility Enrollment System (DEERS) or other appropriate database. Contractor personnel not certified within 6 months of assignment of cybersecurity duties or who fail to maintain their certified status will not be permitted to carry out the responsibilities of the position, and shall be replaced with an individual who does meet the minimum certification requirements as mandated by DoD.
Six (6) years of experience in C4ISR, computer vision, machine learning, artificial intelligence, identity management, biometrics, or forensic science to include: Systems Analysis, Systems Architecture, Systems/Equipment Support, Test and Evaluation, and Logistics support of C4ISR requirements.
Three (3) years of technical experience in support of identity management, biometric enabled intelligence or forensic science.
Experience may be achieved simultaneously.
Secret Level Clearance Required
Job Description:
Employees will perform program management, engineering and related technical activities, such as cyber security, quality assurance, technical documentation development, configuration management and program management support services to the customer base within the Terrestrial Collections and Identity Operations (TCIO) Integrated Product Team (IPT). This task includes systems engineering for requirements, design, prototyping, and testing support.
For Test & Evaluation, see Statement of Work (SOW) section 3.2.4.
For Software Engineering, see SOW 3.2.3 and 3.2.5.
For Cybersecurity, see SOW 3.2.6.
For Lifecycle Logistics, see SOW 3.3. ( All qualified applicants will receive a copy of the SOW)
Essential Duties of the Job:
Ability to communicate task requirement information to client in a clear and concise manner.
Must be able to sit and stand for prolonged periods of time, as well as lead and participate in meetings and working groups.
Requires visual acuity to use a keyboard.
Must be able to attend work each day, during scheduled hours, unless on travel or approved time off.
Ability to work on computer for long periods, and communicate with individuals by telephone, email and face-to-face
Physical Demands and Work Environment:
While performing duties of job, employee is occasionally required to stand; walk; sit; use hand to finger, handle or feel objects, tools, or controls; reach with hands and arms; talk and hear.
Employee must occasionally lift and/or move up to 25 pounds.
Specific vision abilities required by the job include close vision, distance vision, color vision, peripheral vision, depth perception, and the ability to adjust focus.
May be exposed to chemicals related to office equipment.
The noise level in the work environment is usually moderate (i.e. general office environment).
Benefits:
401 (K) w/ up to 3.5% Company Match
Health, Dental & Vision Insurance
Basic & Supplemental Life Insurance
Short & Long Term Disability Insurance
Flexible Spending Account
10 Paid Holidays
Paid Time Off (PTO)
Gym Membership (varies by location)
Corporate-Sponsored Events",3.5,"GS5, LLC
3.5","Charleston, SC","Dumfries, VA",51 to 200 employees,-1,Company - Private,Advertising & Marketing,Business Services,$10 to $25 million (USD),-1
Software Engineer (C++/MATLAB),-1,"Company Overview

Calling the adventurers ready to join a company that's pushing the limits of nanotechnology to keep the digital revolution rolling. At KLA, we're making technology advancements that are bigger—and tinier—than the world has ever seen.

Who are we? We research, develop, and manufacture the world's most advanced inspection and measurement equipment for the semiconductor and nanoelectronics industries. We enable the digital age by pushing the boundaries of technology, creating tools capable of finding defects smaller than a wavelength of visible light. We create smarter processes so that technology leaders can manufacture high-performance chips—the kind in that phone in your pocket, the tablet on your desk and nearly every electronic device you own—faster and better. We're passionate about creating solutions that drive progress and help people do what wouldn't be possible without us. The future is calling. Will you answer?

Group/Division

KLA has always had a close relationship with physics and data. Our optical and electron beam inspection and measurement tools use cutting edge physics models, both for hardware design and as part of their algorithms. AI, including several traditional machine learning techniques and deep learning are routinely used to process this data to meet application requirements.

The AI & Modeling Center of Excellence, centered in KLA’s R&D facility in Ann Arbor, MI, was setup with the mission of advancing KLA’s traditional strengths in physics and data and providing implementation solutions for multiple KLA Inspection and Metrology products targeted at the semiconductor manufacturing industry.

As a part of this group, you will be part of a world class team of physicists, HPC system designers, machine learning and application engineers who build cutting edge solutions for modeling complex imaging techniques and semiconductor processes. You will also work with a data scientists and AI infrastructure engineers whose mission is to build and scale machine learning based solutions for our semiconductor customers.

We are looking for engineers in a few different fields. If you are passionate about Physics Modeling, High Performance Computing - HPC (including GPU), ML, Data, or Cloud technologies – this is the place for you!

Responsibilities

We are looking for a software engineer with experience in C/C++ and MATLAB in the field of algorithm development. The successful candidate will be a technical contributor on our computational patterning software development team working on challenging problems in the semiconductor process domain. Experience and proven ability to provide software solutions in a scientific environment is essential. Candidate must bring a high level of energy and a willingness to work within KLA’s standard software development practices, bring a good attitude and be willing to work with other software professionals in a fast paced and energetic team environment.

Job duties will include: developing and implementing highly efficient algorithms and data processing routines, developing software requirements from marketing requirements, developing detailed software designs, developing production code, developing unit tests and test cases, and maintaining released products.

Qualifications
Experience with Windows and Linux environments
MATLAB or scientific computing with Python a plus
Qt C++ experience strongly preferred
Experience with Git and Git workflow a plus
Parallel programing experience a plus
Cluster computing experience a plus
Good written communication skills
Object oriented analysis and design
Minimum Qualifications

Master's Level Degree OR Bachelor's Level Degree with at least 1 years of experience

Equal Employment Opportunity

KLA is an Equal Opportunity Employer. Applicants will be considered for employment without regard to age, race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability, or any other characteristics protected by applicable law.",3.8,"KLA-Tencor
3.8","Ann Arbor, MI","Milpitas, CA",5001 to 10000 employees,1976,Company - Public,Industrial Manufacturing,Manufacturing,$2 to $5 billion (USD),"Applied Materials, Nanometrics"
Senior Data Engineer,-1,"Job Description
Our leading marketing technology company provides the infrastructure for the industry's first and only ecosystem of advertising exchanges for native search and metasearch media. We connect buyers and sellers to create efficient marketplaces for performance media across leading brand, metasearch, and comparison sites. Our technology platforms power over 50 million high-value transactions annually, representing more than $400 million in annual media spent across the insurance, travel, personal finance, education, and home service verticals. Our team of talented and passionate professionals work together to identify new solutions that keep our company and our partners one step ahead in the industry. Headquartered in Redmond, Washington and Los Angeles, California, our offices extend from Seminole, Florida and Carson City, Nevada to our international location in London.

We are currently seeking a seasoned, analytical, and creative Senior Data Engineer/Scientist to join our dynamic team! We are looking for someone with previous experience building and deploying models that can make real-time low-latency predictions. The ideal candidate will possess stellar problem-solving skills and be highly organized and self-motivated. They will enjoy designing and implementing production-ready solutions that process and analyze many ad transactions everyday!

The Senior Data Engineer/Scientist will participate in the entire software development lifecycle. They will work with stakeholders to identify any issues and provide solutions, run statistical analysis on large data sets, and prepare and deploy predictive models at scale.

While the company is open to relocating a candidate, we are seeking someone with ties in Seattle or a real desire to move to Seattle. For the right candidate, the company is willing to pay reasonable relocation fees.

Only seeking candidates with professional experience. No recent graduates need apply.

Responsibilities:
Own the full development lifecycle (implement high-performance real-time predictive engines that enable ad serving decisioning from data management to model training and evaluation to deployment and monitoring).
Run statistical analysis on large data sets.
Prepare and deploy predictive models at scale.
Participate in the software development lifecycle.
Implement high-performance ad serving software.
Create code to analyze ad performance data for optimization.
Direct specific ad-hoc projects across our five product verticals.
Work within a Perl development environment on a Linux platform.
Collaborate with the team to maintain and support our company’s platform.
Requirements:
Bachelor’s degree in Computer Science or other technical discipline.
Previous experience implementing statistical models, machine learning, and analysis using R or Python.
Previous experience working with engineers and non-technical stakeholders.
Strong knowledge of relational data modeling and SQL.
Strong programming skills, including software engineering methodologies and best practices.
Experience using web APIs.
Experience with Hadoop v2, MapReduce, and HDFS.
Previous experience with Perl, a plus!
Previous experience working with engineers and non-technical stakeholders.
Excellent communication and analytical skills.
Able to work on multiple tasks simultaneously and meet deadlines.
Highly detail-oriented with strong problem-solving skills.
Compensation:
Competitive salary and bonus program participation.
401K company contribution program after 1 year.
High quality health and dental care plans with no employee contributions and zero deductibles (in network). Flexible spending account.
Unlimited PTO.
Professional training and education reimbursements.
Employee perks, including mobile phone program and gym membership.
Powered by JazzHR

og9EOewBd7",-1,EvolvInc,"Redmond, WA","Los Angeles, CA",1 to 50 employees,2005,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
"Software Development Engineer, Critical Applications and Back End Services","$89K-$137K
(Glassdoor est.)","Amazon Lab126 is an inventive research and development company that designs and engineers high-profile consumer electronics. Lab126 began in 2004 as a subsidiary of Amazon.com, Inc., originally creating the best-selling Kindle family of products. Since then, we have produced groundbreaking devices like Fire tablets, Fire TV, Echo Show, and Echo Look.

Our projects require coordination of experimentation, causal analysis, forecasting, and predictive machine learning tools. You will act as the business-facing subject matter expert for data architecture, feature instrumentation, and data privacy, with the responsibility of managing end-to-end execution and delivery.

In this role you will be responsible for designing and implementing complex ETL pipelines, develop new data engineering patterns that leverage new cloud architectures, and extend or migrate existing data pipelines to the architectures as needed. You will work with scientists and engineers on a variety of machine learning use cases (computer vision, natural language processing, etc.)

Additionally, the position requires technical knowledge of application software development, as well as demonstrated experience successfully planning, organizing, and conducting software development projects in a dynamic environment. The ideal candidate is motivated to work in a data driven environment, have a desire to drive process improvement, and capable of translating high-level, ambiguous business goals to working solutions.

Some of the responsibilities of this role include:
· Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc
· Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS big data technologies.
· Build analytics tools that utilize the data pipelines to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
· Work closely with machine learning and data scientists to scale model training and explore new data sources and model features, recognize and help adopt best practices in reporting and analysis: data integrity, test design, analysis, validation, and documentation.
· Explore and learn the latest AWS technologies to provide new capabilities and increase efficiency
· Work with complex structured and unstructured data (batch and streaming).
· Implementing best practices for software development and documentation, making sure designs meet requirements, and delivering high quality work on tight schedules.
· Help continually improve ongoing reporting and analysis processes, automating or simplifying self-service support for customers.

Basic Qualifications

· Bachelor's degree in computer science, engineering, mathematics, or a related technical discipline
· 4+ years of industry experience in software development, data engineering, business intelligence, data science, or related field with a track record of manipulating, processing, and extracting value from large datasets
· Demonstrated strength in data modeling, ETL development, and data warehousing
· Experience working with AWS big data technologies (EMR, Redshift, S3, Glue, Kinesis and Lambda for serverless ETL)
· Knowledge of data management fundamentals and data storage principles
· Knowledge of distributed systems as it pertains to data storage and computing
· Fundamental software development experience in a common programming language (Python, Java, C++, etc.)

Preferred Qualifications

· Experience with large complex data (e.g. Finance, Electronic Health Records, Biomedical, Taxes, etc.)
· Experience developing cloud software services and understanding of design for scalability, performance and reliability.
· Experience with technical communications with both technical and non-technical members.
· Experience supporting machine learning applications and data scientists.
· Ability to define system architecture and explore the feasibility of various designs.
· Demonstrated ability to mentor other software developers to maintain architectural vision and software quality.
· 5+ years of data engineering/architecture experience in a company with large, complex data sources.
· Experience building/operating highly available, distributed systems of data extraction, ingestion, and processing of large data sets.
· Proven success in communicating with users, other technical teams, and senior management to collect requirements, describe data modeling decisions and data engineering strategy.
· Experience providing technical leadership and mentoring other engineers for best practices on data engineering.
· Knowledge of software engineering best practices across the development life-cycle, including agile methodologies, coding standards, code reviews, source management, build processes, testing, and operations
Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us//",3.9,"Amazon
3.9","Sunnyvale, CA","Seattle, WA",10000+ employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),"Google, Microsoft, Walmart"
"Senior Software Engineer, Cheminformatics",-1,"We are seeking an experienced software engineer with a degree in Chemistry to join our Cheminformatics team. Your expertise will guide decisions on appropriate representations of chemicals and their properties, selection of existing tools to incorporate, and evaluation of public data sets. You will work side-by-side with computational chemists, data scientists and other scientists to build the foundation on which key scientific and business decisions are made. This role provides an opportunity to make a significant impact on Zymergen in a high-priority project.The ideal candidate thrives in a fast-paced, multi-disciplinary, collaborative environment; values clear communication; balances pragmatism and idealism; and is not afraid of ambiguity and incompletely specified requirements. As a team member, there will be opportunities to hone your knowledge in software engineering, Machine Learning, chemistry, and more in the company of experts and expand your skills into a variety of new technologies.The software engineering team is responsible for building the tools that our scientists use on a daily basis and the computational infrastructure powers the Zymergen platform. You will apply your Python expertise to large-scale resilient distributed systems, analysis pipelines, and high performance data processing. Our primary projects in this team involve:* Ongoing development of a large-scale chemicals/molecules database, ETL process, and API's to support a UI and other programmatic interactions. This has been developed primarily utilizing AWS tools and capabilities. Integration of that DB and many other chemistry related tools (Electronic Lab Notebook, computational material modeling tools, ML tools, etc), together and interfacing with the existing software infrastructure at Zymergen* Cheminformatics analysis on groups of chemicals/molecules that are accessible through our biology and genetic engineering processes and fully managed and searchable through the core database.* Being a trusted partner, bridging communication between chemists and other software engineers, with the ability to deeply understand the user needs and grasp the science they are attempting to accomplish on the tools and platforms that we are building.Qualifications/Experience* BS + 5yrs or MS + 3 yrs* 4+ years of experience in software engineering. Specifically building infrastructure for data processing and retrieval* Experience working in distributed systems and/or systems programming. Python experience a plus* Database development + ORM experience (MySQL, Postgres, Oracle + SQLAlchemy)* Penchant for big data and related technologies* Mastery of software engineering principles and experience with git, unit and integration testing, and CI/CD pipelines.* Excellent written and verbal communication skills.* Demonstrated ability to work with a team of highly-motivated engineers* Ability to collaborate with research scientists, understand their challenges, and design software solutions to address challenges.* Strong communication, explanatory, and exploratory skills, including technical writing and ad hoc analysis with tools like Jupyter.Preferred* Full stack development* RESTful API and microservice development* Knowledge of chemical toolkits and various structure formats (RDKit, OpenEye, InChI, SMILES, SD File)* Experience with AWS services, Docker/K8s, and infrastructure as code (e.g. Terraform)* BSc. or higher in chemistry or related subject matter, especially polymer chemistry* Experience with chemical prediction and simulation, such as MD, DFT, or ML methods and descriptors* Knowledge of electronic lab notebooks and experiment data capture* Advanced python skills and working knowledge of asynchronous programming, generators, and multithreading techniques* Experience with NoSQL technologies, e.g. graph databases is a plusResponsibilities:* Design, development and deployment of a chemical database for Zymergen.* Collaborating with chemists and other scientists to understand their problem domain and how software tools can help.* Studying existing Zymergen systems to understand the overall ecosystem and how new projects / services should integrate into it.* Defining and building data models to represent chemicals and their properties; designing data transformation processes to populate the database(s).* Creating APIs to make the chemicals data queryable. Queries in question may need to be significantly more complex than simple boolean keyword searches or sql-like statements; search-by-example, probabilistic queries, and other approaches may come into play.* Evaluating and integrating 3rd-party and open-source tools as needed.* Working with computational chemists to enhance the design of the database which enables the management, storage and analysis of large-scale computational chemistry data.* Working with a front-end engineer to make sure the overall tool makes sense, and possibly contributing some front-end code.Legal authorization to work in the U.S. is required. Zymergen may agree to sponsor an individual for an employment visa now or in the future if there is a shortage of individuals with particular skills for this job.In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification form upon hire.Founded in 2013 and based in the San Francisco Bay Area, Zymergen is a technology company unlocking the power of biology. We deliver better economics for products made from biology that are used across industries, bring new products to market faster, and develop novel products. Our proprietary platform uses robots and machine learning to engineer microbes faster, more predictably, and to a level of performance previously unattainable. These microbes, and the products they produce, have broad applications across industries such as chemicals and materials, agriculture, and healthcare. For more information visit www.zymergen.com.",2.6,"Zymergen
2.6","Emeryville, CA","Emeryville, CA",201 to 500 employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
DevOps Engineer,-1,"About BlackLocus

BlackLocus is an innovation lab operating within The Home Depot, the top home improvement retailer in the world. To stay ahead of the curve, The Home Depot is making a substantial investment in data science, innovation, technology, and design. BlackLocus is contributing to this initiative by providing analytical tools to optimize and automate pricing, assortment, and product info by applying machine learning and revenue management techniques.

BlackLocus is a small collaborative environment where everyone is excited to work together every day. We are located in downtown Austin in an open space designed for collaboration, comfort, and productivity. We have a culture of learning providing 10% research time. We value diverse perspectives and strive to be an inclusive, safe environment. And finally, we love to have fun and celebrate together! If this sounds like something you are looking for, we can't wait to hear from you.

Job Summary
We are looking for an experienced DevOps engineer to help our team establish a superior DevOps practice driving productivity, security, and quality for BlackLocus. We build web and distributed applications in AWS and Google Cloud Platform with the bulk of our existing systems in AWS. Our developers work in Go, Python, JavaScript, and Java. We want to go faster without compromising quality or security. Our perfect fit is a collaborative, knowledgeable, energetic, hands-on, and pragmatic engineer who loves to solve problems and build durable solutions.

Come join a wonderful group of people who happen to be strong software engineers, analysts, and data scientists. We have big DevOps dreams and a lot to do!

Job Duties
70% - Delivery & Execution:
Collaborates and pairs with other product team members (UX, engineering, and product management) to create secure, reliable, scalable software solutions
Documents, reviews, and ensures that all quality and change control standards are met
Writes custom code or scripts to automate infrastructure, monitoring services, and test cases
Writes custom code or scripts to do ""destructive testing"" to ensure adequate resiliency in production
Creates meaningful dashboards, logging, alerting, and responses to ensure that issues are captured and addressed proactively
Drives destructive testing, automation, or engineering empowerment
Identifies unsecured code areas and implements fixes as they are discovered with or without tooling
Contributes to foundational code elements that can be reused many times by a product
Contributes to meaningful architecture diagrams and other documentation needed for security reviews or other interested parties
Defines Service Level Objectives for products to constantly measure their reliability in production and help prioritize backlog work

20% - Support & Enablement:
Fields questions from other product teams or support teams
Monitors tools and participates in conversations to encourage collaboration across product teams
Provides application support for software running in production
Proactively monitors production Service Level Objectives for products
Proactively reviews the performance and capacity of all aspects of production: code, infrastructure, data, and message processing
Triages high priority issues and outages as they arise

10% - Learning:
Participates in and leads learning activities around modern software design and development core practices (communities of practice)
Proactively views articles, tutorials, and videos to learn about new technologies and best practices being used within other technology organizations
Attends conferences and learns how to apply new technologies where appropriate

Responsibilities

Partners with software engineers and data scientists to build secure, usable, efficient tools to enable their work
Measures our development and operational effectiveness
Defines problems and solutions facing our development efforts
Helps drive our integration and deployment maturity
Improves monitoring and alerting
Leads and guides the team in identifying and implementing new technologies which will advance our security awareness
Drives adherence with compliance controls
Provides tools employing strong application and data security practices
Manages key and password rotation
Supports secure, cost-effective use of cloud compute cycles for our support and data science teams
Helps control overall cloud costs

Qualifications and Skills

5 years experience as a Devops Engineer
Ability and enthusiasm to collaborate with a diverse range of people and perspectives
Strong Linux system administration background
Good verbal and written communication skills
Strong knowledge of AWS and/or GCP
Knowledge of current and emerging deployment and integration technologies and paradigms
Strong knowledge of application and web security best practices
Experience with GitHub, Jenkins, and multiple test automation tools
Experience with one or more of the following: Java, Go, or Python configuration
Experience implementing vulnerability scanning such as AWS Inspector or Qualys in cloud deployments
Experience automating patch management for base virtual machine and container images
Experience with configuration Management tools such as Ansible, Chef, Puppet, or similar
Experience managing production infrastructure with Terraform, CloudFormation, or similar
Experience enabling automated test environments
Experience with container management (Docker, Kubernetes, etc.)

Benefits

Excellent work-life balance
Comprehensive benefit package
Competitive base and bonus package
Generous PTO policy
401(k) eligible for matching company contribution after one year
Restricted stock grants and Employee Stock Purchase Program
Stocked kitchen with healthy snacks, tons of drinks, and an espresso maker
Lots of team events including weekly catered lunches, happy hours, and other fun outings
Located in the heart of downtown Austin with garage parking provided
The Home Depot is an Equal Opportunity Employer

LEGAL DISCLAIMER: BlackLocus and The Home Depot are Equal Opportunity/M/F/Vet/Disabled Employers. Available positions may vary by location. Bilingual candidates are encouraged to apply. ©2005-2019 Home Depot Product Authority, LLC. All rights reserved. Know your rights. Click here to view Federal labor law posters.",3.7,"BlackLocus
3.7","Austin, TX","Austin, TX",51 to 200 employees,2010,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Software Development Engineer (Level 5),"$92K-$143K
(Glassdoor est.)","Amazon is looking for experienced Software Development Engineer for a technology team within Alexa Search. Alexa Search is part of our ongoing Alexa AI efforts focused on reinventing information extraction and retrieval for a voice-forward, multi-modal future. We are looking for creative engineers to help design, develop, and automate systems that can collect and process data at web scale; create text and data derivatives; and develop novel algorithms that use these derivatives to improve access to and retrieval of these derivatives in the context of Alexa user experiences and other Amazon services.

Successful candidates will build and optimize large scale systems for harvesting, processing, and managing web-scale repositories and will be involved in all stages of text processing and knowledge distillation, from collection, to processing and cleaning, to extraction and verification. In the process, they will collaborate closely with teams of Applied Scientists with expertise in specialized areas such as Natural Language Processing, Text Mining, Search, and Machine Learning.


Basic Qualifications

· 2+ years of non-internship professional software development experience
· Programming experience with at least one modern language such as Java, C++, or C# including object-oriented design
· 1+ years of experience contributing to the architecture and design (architecture, design patterns, reliability and scaling) of new and current systems.

Preferred Qualifications


- Masters degree in Computer Science, Computer Engineering or related technical discipline.

- Knowledge of professional software engineering practices & best practices for the full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations

- Experience with machine learning toolkits

- Experience with NLP algorithms and libraries

- Experience working with common Big Data infrastructure systems, such as Hadoop, Spark, EMR - Excellence in technical communication with peers and non-technical cohorts.


Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us//.",3.9,"Amazon
3.9","Manhattan Beach, CA","Seattle, WA",10000+ employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),"Google, Microsoft, Walmart"
"Senior Software Engineer, Python Platform","$87K-$173K
(Glassdoor est.)","Why TrueAccord?

Debt collection is failing consumers. Every year, more than 70 million Americans have negative experiences with the collections process, and they deserve a much better treatment - more relevant, more digital, less abrasive. That’s why banks, lenders, and industry leaders are coming to TrueAccord for innovative solutions in recovering outstanding receivables.

TrueAccord is a category-defining company. We combine machine learning with a human-based approach to guide both lenders and borrowers through a challenging financial process. With a world-class leadership team, passionate and driven team members, and a diverse and growing client base, TrueAccord is well positioned for continued success.

Your Role:

TrueAccord is looking for a Senior Python Engineer to join our Engineering team.

You will join a multi-functional engineering team of dedicated to creating a data driven culture, improving the efficiency and dependability of the way we make decisions, and developing our automated debt collection strategy. In this role, you will work closely with Data Scientists to understand the data science development process and take architectural owner take ownership of HeartBeat - our python based decision engine.

We’re looking for strong computer science fundamentals and an enthusiasm for system architecture, data and supporting others. You should be passionate about leading conversations on system architecture, implementing clean code, and determined to have a huge impact at TrueAccord.
Key Responsibilities:
Own and maintain HeartBeat as a platform - TrueAccord’s patented decision engine at the “heart” of its debt collection process
Lead discussion and development of our reactive decision making architecture as we enter the hyper growth phase
Partner with data science and product to understand the experimentation lifecycle and help design the underlying infrastructure for experiment development
Assist our data scientists in developing production quality models and model pipelines
You Have:
5+ years work experience | BA in Computer Science, Engineering or related field | Equivalent training
Excellent Python skills with dedication to writing clean understandable, testable code with an eye towards maintainability
Ability to lead technical architecture discussions and help drive technical decisions, as well as implement day-to-day changes
Zeal for building high throughput, real-time analytics systems
Project management and communication skills with experience working alongside cross-departmental partners
Desire to work in San Francisco.
You might also have:
Proficiency with statistical or data management Python libraries (scikit-learn, statsmodels etc. - huge plus if experience with Pandas)
Familiarity with machine learning or predictive modeling and related development technologies (Tensorflow, Spark, Jupyter etc.)
Interest in helping onboard new team members, mentoring, and teaching others
Knowledge of functional Scala
FinTech background


What TrueAccord offers you + Culture & Benefits

TrueAccord is distributed company with a major presence in the San Francisco Bay area and Lenexa, KS. We offer a healthy work environment that continuously builds an inclusive and diverse culture where everyone is able to develop the best version of themselves. We are a dynamic group of people who are subject matter experts with a passion for change.

We offer:
*** Generous paid time off
*** Paid training
*** We promote work/life harmony
*** Paid holidays
*** Health, dental and vision benefits
*** 401K with matching

Our teams are crafting solutions to big problems every day. If you’re looking for an opportunity to do impactful work, join TrueAccord and make a difference.

Our Dedication to Diversity & Inclusion

TrueAccord is an equal opportunity employer. We promote, value, and thrive with a diverse & inclusive team. Different perspectives contribute to better solutions and this makes us stronger every day. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.",3.2,"TrueAccord
3.2","San Francisco, CA","San Francisco, CA",51 to 200 employees,2013,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
"Senior Data Engineer, Ingestion",-1,"Chime is the largest and fastest-growing player in the challenger-banking space, providing mobile and online banking technology in the U.S. on behalf of partner banks and facilitating over 10M accounts with no physical branches. We're a technology company relentlessly focused on helping our members achieve financial peace of mind. That's why we offer access to an award-winning bank account that doesn't charge a ton of traditional bank fees, can give members early access to their paychecks, and enables members to grow their savings automatically. And we're just getting started. We are proud of our mission, devoted to our members, and passionate about applying technology to the challenge of making financial health a reality for everyone.We have one of the most experienced management teams in Fintech and have raised over $800M in funding from DST, General Atlantic, Iconiq, Coatue, Dragoneer, Menlo, Access, Forerunner, and others. If you're looking to join a fast-growing company with a beloved, daily-use product and an authentic mission that puts people first, we want to meet you.About the RoleIn this role, you'll be responsible overseeing the design, development and operations of large-scale, real-time data systems. The ideal candidate will be excited by the prospect of owning, optimizing or even re-designing our company's data architecture and building out a team to support our next generation of products and data initiatives. The data engineering team will support our software developers, database architects, data analysts, data scientists, and machine learning engineers on back-end data initiatives.ResponsibilitiesWe're looking for a leader who is self-directed and comfortable supporting the data needs of multiple teams, systems and products. Your responsibilities will include:* Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS 'big data' technologies* Work with stakeholders including the Analytics, Risk, Machine Learning, and Technical Operations teams to assist with data-related technical issues and support their data infrastructure needs* Participate in key technical and design discussions with technical leads in the team as a hands-on manager* Act as a project manager for the projects that your team is responsible for* Provide technical leadership to your team by giving guidance on designs and coding when time allows* Help manage and consult in designing our data governance initiativesRequirements* 6+ years of experience in designing, implementing, optimizing and operationalizing real-time big data analytics systems including data-pipelines, data warehouses and enterprise wide data-flows* You've earned a bachelor's degree in Computer Science or other technical field* Understanding of the tradeoffs between different big data solutions* Strong analytic skills related to working with unstructured datasets* Experience with a variety of traditional, streaming, and big data tools such as:* Hadoop ecosystem: Hadoop, Hive, Spark* Kafka, Sqoop, Flume* Airflow or other workflow scheduler* Data Warehouses: Redshift, Snowflake (preferred)* SQL databases, including MySQL, Postgres* AWS cloud services: EC2, EMR, RDS* Stream-processing systems: Storm or Spark-Streaming or equivalent.* Advanced SQL, Python, Java and/or ScalaWhat we offer* Competitive salary based on experience, with medical and dental benefits.* Free snacks and drinks, plus weekly catered lunches.* Flexible vacation policy.* Monthly happy hours and company events.* A challenging and fulfilling opportunity to join one of the most experienced teams in FinTech and help create a completely new kind of banking service.We know great work isn't done alone. We're building a team of individuals to Chime in with their different strengths to benefit our employees and members. We strongly believe that different backgrounds and ideas are a competitive advantage; we hire candidates of any race, color, ancestry, religion, sex, national origin, sexual orientation, gender identity, age, marital or family status, disability, Veteran status, and any other status. Chime is proud to be an Equal Opportunity Employer and will consider qualified applicants with criminal histories in a manner consistent with the San Francisco Fair Chance Ordinance. If you have a disability or special need that requires accommodation, please let us know. To learn more about how Chime collects and uses your personal information during the application process, please see the Chime Applicant Privacy Notice.",-1,Chime Bank,"San Francisco, CA",-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer - WW OPS compensation,-1,"Are you excited about taking an emerging product and helping it scale?

We are looking for an experienced, self-driven, analytical, and strategic Data Engineer. In this role, you will be working in a large and complex data warehouse environment. You should be passionate about working with disparate datasets and be someone who loves to bring data together to answer business questions. You should have deep expertise in the creation and management of datasets and the proven ability to translate the data into meaningful insights through collaboration with analysts and Data Scientists. In this role, you will have ownership of end-to-end development of data engineering solutions to complex questions and you'll play an integral role in strategic decision-making.

The right candidate will possess excellent business and communication skills, be able to work with business owners to develop and define key business questions, be able to work with external data vendors to onboard new datasets and integrate with internal datasets, and be able to collaborate to analyze data that will answer those questions.

In this role, you will have the opportunity to display and develop your skills in the following areas:
Design, implement, and support an analytical data infrastructure providing ad hoc access to large datasets and computing power
Interface with other technology teams to extract, transform, and load data from a wide variety of data sources using SQL and AWS big data technologies
Work with external data vendors to onboard data into existing infrastructure
Collaborate with Data Scientists to implement advanced analytics algorithms that exploit our rich data sets for statistical analysis, prediction, clustering and machine learning
Help continually improve ongoing reporting and analysis processes, simplifying self-service support for customersBasic Qualifications
Bachelor's degree in computer science, engineering, mathematics, or a related technical discipline
4+ years of industry experience in software development, data engineering, business intelligence, data science, or related field with a track record of manipulating, processing, and extracting value from large datasets
Demonstrated strength in data modeling, ETL development, and data warehousing
Experience using big data technologies
Experience using business intelligence reporting tools
Knowledge of data management fundamentals and data storage principles
Knowledge of distributed systems as it pertains to data storage and computing
Experience coding and automating processes using Python or R.
Strong customer focus, ownership, urgency, and drive.
Excellent communication skills and the ability to work well in a team.
Effective analytical, troubleshooting, and problem-solving skills.
Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.",-1,Amazon Corporate LLC,"Seattle, WA",-1,-1,-1,-1,-1,-1,-1,-1
Sr Software Development Engineer-Fire OS,"$112K-$170K
(Glassdoor est.)","Amazon Lab126 is an inventive research and development company that designs and engineers high-profile consumer electronics. Lab126 began in 2004 as a subsidiary of Amazon.com, Inc., originally creating the best-selling Kindle family of products. Since then, we have produced groundbreaking devices like Fire tablets, Fire TV, Fire phone, and Amazon Echo. What will you help us create?

Work hard. Have fun. Make history.

The Role:

We are looking for a passionate Sr. Software Development Engineer to help develop critical services and machine learning applications that drives the device health improvements release over release. You must be responsive, flexible and able to succeed within an open collaborative peer environment. You will take the lead in designing, prototyping, and building solutions to hard problems in the Amazon ecosystem. You will assist more junior engineers with designs and code structure to improve the functionality, quality, and maintainability of the teams work. You will work closely with engineers, data scientists, product and project managers, and other service teams to drive development from the concept stage to launch.

We are looking for hard-working and talented Software Development Engineers who have experience building innovative, mission critical, highly optimized applications. You will have an enormous opportunity to make a large impact on the design and architecture of cutting-edge products used every day by people you know. In this role, you will:
· Design, implement and maintain a high-volume, highly available, distributed big data processing system in AWS.
· Work with Data Scientists to design and implement data analytics and machine learning solutions.
· Be a champion for engineering excellence, applying best practices to all stages of the software development process.


Basic Qualifications

· 7+ years of experience in software development of large-scale data infrastructure and distributed systems
· 7+ years of experience in data extraction, transformation, statistical analysis and data modeling
· 7+ years of experience developing enterprise software using Java or Python



Preferred Qualifications


· Masters degree in Computer Science, Computer Engineering, Machine Learning, or related field;
· Advanced knowledge in performance, scalability, numerical accuracy, enterprise system architecture
· Experience building solutions using AWS big data and machine learning services
· Experience in applying Data Mining and Machine Learning techniques to solve business problems
· Working knowledge of major database systems and a statistical modeling tools such as R, SAS, SciKit-learn, or TensorFlow
· Ability to communicate complex technical concepts and solutions to all levels of the organization
· Excellent communication and consensus building

Lab126 is part of the Amazon.com, Inc. group of companies and is an Equal Opportunity Employer Minority / Women / Disability / Veteran / Gender Identity / Sexual Orientation / Age.",3.9,"Amazon
3.9","Sunnyvale, CA","Seattle, WA",10000+ employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),"Google, Microsoft, Walmart"
"Software Engineer (Data Scientist, C,C++,Linux,Unix) - SISW - MG","$72K-$142K
(Glassdoor est.)","During the current global health crisis, the priority for Siemens Digital Industries Software is the health and well-being of our entire community including current and future employees, which may add time to our hiring processes. We appreciate your patience and invite you to visit our website to learn more about how Siemens is responding to the pandemic.
Company: SISW - MG
Job Title: Software Engineer (Data Scientist, C,C++,Linux) - 189288
Job Location: USA - CA - Fremont
Job Category: R&D SW Engineering

Job Description:

We are looking for a highly motivated engineer to work in the RET team in the Calibre business unit. In this role you will be responsible for analyzing modeling data (experimental and synthetic/simulated) and coming up with novel ways to organize it, while deriving meaningful operations and extracting maximum information from this data.

You will also be expected to develop supporting software that will be properly integrated in the modeling suite of tools that are used specifically in modeling of semiconductor manufacturing.

You will be teaming up with a group of senior software engineers contributing to final production-level quality of new components and algorithms and to support existing components.

This is a unique role that will challenge you and allow you to grow in interdisciplinary areas of software engineering and data analysis.

Knowledge and experience in the area of data science/data analysis is preferred.

Some familiarity with physical modeling of any discipline (e.g. from fields in electrical or mechanical engineering) will be very useful for the suitable candidate.

Job
Qualifications:

The successful candidate will possess the following
combination of education and experience:
BS or
MS in Data Sciences, Computer Science, Electrical Engineering, Physics or
Applied Mathematics.
Working
knowledge in development of C and C++ on UNIX and/or LINUX platforms.
Excellent
programming skills in at least one mainstream scripting language, preferably
Python.
Experience/knowledge
in data analysis.
Experience/knowledge
in machine learning technology.
Experience
with Python, Keras and Tensorflow.
Demonstrated
ability to learn and explore new technologies.
Excellent
analysis and problem-solving skills.
Must
have the ability to collaborate closely with other members of the team and
develop critical components consistently and in a timely manner.
Experience
with MATLAB/R or equivalent mathematical package is expected.
This position may require access to export-controlled technology. If an export license is required and Mentor Graphics elects to apply for such a license, then candidates must be approved and licensed by the applicable government authorities as a condition of employment.

#LI-MGRP
#LI-JE1

Organization: Digital Industries

Company: Mentor Graphics Corporation

Experience Level: Recent College Graduate

Job Type: Full-time

Equal Employment Opportunity Statement
Siemens is an Equal Opportunity and Affirmative Action Employer encouraging diversity in the workplace. All qualified applicants will receive consideration for employment without regard to their race, color, creed, religion, national origin, citizenship status, ancestry, sex, age, physical or mental disability unrelated to ability, marital status, family responsibilities, pregnancy, genetic information, sexual orientation, gender expression, gender identity, transgender, sex stereotyping, order of protection status, protected veteran or military status, or an unfavorable discharge from military service, and other categories protected by federal, state or local law.

EEO is the Law
Applicants and employees are protected under Federal law from discrimination. To learn more, Click here.

Pay Transparency Non-Discrimination Provision
Siemens follows Executive Order 11246, including the Pay Transparency Nondiscrimination Provision. To learn more, Click here.

California Privacy Notice
California residents have the right to receive additional notices about their personal information. To learn more, click here.",4.2,"Mentor Graphics
4.2","Fremont, CA","Wilsonville, OR",5001 to 10000 employees,1981,Company - Public,Computer Hardware & Software,Information Technology,$1 to $2 billion (USD),"Cadence Design Systems, Synopsys, Altium Limited"
Sr. Software Engineer,-1,"Where good people build rewarding careers.

Think that working in the insurance field cant be exciting, rewarding and challenging? Think again. Youll help us reinvent protection and retirement to improve customers lives. Well help you make an impact with our training and mentoring offerings. Here, youll have the opportunity to expand and apply your skills in ways you never thought possible. And youll have fun doing it. Join a company of individuals with hopes, plans and passions, all using and developing our talents for good, at work and in life.
Job Description
We are looking for an engaged and enthusiastic Software Engineer to join our growing Data Science and Engineering team and build out the next generation of our platform. Our team is innovating the tools, technologies, and techniques that enable Allstate to stay on the leading edge of analytics, bring the best data-driven solutions to the enterprise.

We can hire mid and senior level engineers depending on your experience. The ideal candidate is a hands-on Java developer with significant experience in backend applications. Were looking for someone with experience in developing scalable and highly available enterprise-level applications. The candidate must have strong, first-hand technical expertise in a variety of configuration management and web technologies and the proven ability to fashion robust scalable solutions that can manage large data sets. They must be at ease working in an agile environment with little supervision. This person should embody a passion for continuous improvement and test-driven development.

Here's more on what the role entails:
Passion to develop products that people love to use.
Analyze, design and develop enterprise level applications.
Participate in product development in an agile environment.
Collaborate cross-functionally with data scientists, business users, project managers and other engineers to achieve elegant solutions.
Work alongside other engineers on the team to elevate technology and consistently apply best practices.
Identify new technologies to continuously enhance the existing products.
Job Qualifications
Were looking for a Java Engineer with a minimum of 3+ years of experience in B2B. As noted above, we can hire mid and senior level Engineers depending on experience. Candidates need a BS degree in computer science or similar, and the following qualifications:
Solid hands-on experience in Java Development is a must.
Good understanding of building APIs and services using REST.
Experience with test-driven development and automated testing frameworks.
Experience with Scrum/Agile development methodologies.
Capable of delivering on multiple competing priorities with little supervision.
Excellent verbal and written communication skills.
Experience in using build automation technologies like Gradle, Maven, Jenkins.
Following qualifications are a plus
Experience working with Python, R,
Machine Learning knowledge and exposure.
Familiarity with Spring Framework.
Exposure to Cloud Technologies: Pivotal Cloud Foundry, AWS, Docker, and Kubernetes
Exposure to Big Data and Streaming technologies such as: Hadoop, Spark, and Kafka

The candidate(s) offered this position will be required to submit to a background investigation, which includes a drug screen.

Good Work. Good Life. Good Hands®.

As a Fortune 100 company and industry leader, we provide a competitive salary but thats just the beginning. Our Total Rewards package also offers benefits like tuition assistance, medical and dental insurance, as well as a robust pension and 401(k). Plus, youll have access to a wide variety of programs to help you balance your work and personal life -- including a generous paid time off policy.

Learn more about life at Allstate. Connect with us on Twitter, Facebook, Instagram and LinkedIn or watch a video.

Allstate generally does not sponsor individuals for employment-based visas for this position.

Effective July 1, 2014, under Indiana House Enrolled Act (HEA) 1242, it is against public policy of the State of Indiana and a discriminatory practice for an employer to discriminate against a prospective employee on the basis of status as a veteran by refusing to employ an applicant on the basis that they are a veteran of the armed forces of the United States, a member of the Indiana National Guard or a member of a reserve component.

For jobs in San Francisco, please click here for information regarding the San Francisco Fair Chance Ordinance.
For jobs in Los Angeles, please click here for information regarding the Los Angeles Fair Chance Initiative for Hiring Ordinance.

To view the EEO is the Law poster click here. This poster provides information concerning the laws and procedures for filing complaints of violations of the laws with the Office of Federal Contract Compliance Programs

To view the FMLA poster, click here. This poster summarizing the major provisions of the Family and Medical Leave Act (FMLA) and telling employees how to file a complaint.

It is the Companys policy to employ the best qualified individuals available for all jobs. Therefore, any discriminatory action taken on account of an employees ancestry, age, color, disability, genetic information, gender, gender identity, gender expression, sexual and reproductive health decision, marital status, medical condition, military or veteran status, national origin, race (include traits historically associated with race, including, but not limited to, hair texture and protective hairstyles), religion (including religious dress), sex, or sexual orientation that adversely affects an employee's terms or conditions of employment is prohibited. This policy applies to all aspects of the employment relationship, including, but not limited to, hiring, training, salary administration, promotion, job assignment, benefits, discipline, and separation of employment.",3.4,"Allstate
3.4","Charlotte, NC","Northbrook, IL",10000+ employees,1931,Company - Public,Insurance Agencies & Brokerages,Insurance,$10+ billion (USD),"Progressive Insurance, State Farm, Farmers Insurance Group"
Cloud Development Research Engineer,"$65K-$117K
(Glassdoor est.)","Title Cloud Development Research Engineer Duration 12 month(s) Location Boulder, CO If you are interested please apply and send me your resume Liz Fox elizabeth.foxnttdata.com About the team This team in Boulder offers a unique environment for extremely skilled and motivated thinkers. The culture is highly charged with people who are passionate about a cause, using technology to enhance students' educational experiences. In addition, Boulder, Colorado has been named as the happiest place in the U.S. which is no surprise given its year-round outdoor activities, a surfeit of sunny days, a laid-back lifestyle, natural beauty, ultra-fresh dining and natural food scenes, the influence of the University of Colorado Boulder, and enough craft beer to put a smile on anyone's face. About the Client Our client is committed to a world that's always learning and to our talented team who makes it all possible. From bringing lectures vividly to life to turning textbooks into laptop lessons, we are improving the way people learn, whether it's one child in our own backyard or an education community across the globe. We are bold thinkers and standout innovators who motivate each other to explore new frontiers in an environment that supports and inspires us. By pushing the boundaries of technology - and each other to surpass these limits - we create seeds of learning that become the catalyst for the world's innovations, personal and global, large and small. Job Description We are looking for a talented, collaborative research engineer with a strong background in software development to help us build AI-driven data pipelines, services and applications in the cloud. As an RD organization, our mission is to push the boundaries of what's possible in education and to positively impact millions of learners around the globe. Degrees and formal qualifications are important, but for this position relevant experience and a proven track record to deliver are paramount. You will be working within a highly agile team responsible for developing cutting-edge educational technology with an emphasis on scaling up data processing pipelines and deploying machine learning models as cloud services. The ideal candidate will have experience in both software engineering and cloud devops. Responsibilities Identify, design, and develop Cloud-based integration solutions in close cooperation with RD scientists. Perform extensive research and analysis to make optimal architecture and design decisions. Integrate with external customers and 3rd-party systems. Build and deploy infrastructure to support GCP AWS-based Cloud services and topologies. Participate in new product concepts and create proof-of-concept prototypes. Additional desired skills Knowledge of machine learning technologies, techniques and life cycle Demonstrated ability in using Python, R or another statistical modeling language in support of RD scientists Experience developing backend systems for machine learning solutions. Experience creating and deploying pipelines and automation on Kubernetes clusters. Experience working with asynchronous processing such as pub-sub, messaging queues. Expertise with GitLab, Docker, Python, AWS, Terraform. Hands-on knowledge of AWS services like Redshift, S3, Lambda, KMS, CloudFormation etc. Unix shellPython scripting abilities. Minimum Required Skills 2+ years professional software development experience Familiar with Python, unit testing methodologies and related APIs. Knowledgeable of software development best practices including coding standards, code reviews, source control, build processes and testing. Proven track record of building and deploying webservices Minimum Education RequirementBachelor's degree in computer science, software engineering or similar The Company is an equal opportunity employer and makes employment decisions on the basis of merit and business needs. The Company will consider all qualified applicants for employment without regard to race, color, religious creed, citizenship, national origin, ancestry, age, sex, sexual orientation, genetic information, physical or mental disability, veteran or marital status, or any other class protected by law. To comply with applicable laws ensuring equal employment opportunities to qualified individuals with a disability, the Company will make reasonable accommodations for the known physical or mental limitations of an otherwise qualified individual with a disability who is an applicant or an employee unless undue hardship to the Company would result.",3.4,"NTT Data Services
3.4","Boulder, CO","Tokyo, Japan",10000+ employees,1967,Company - Public,IT Services,Information Technology,$10+ billion (USD),"Capgemini, Accenture, Deloitte"
Senior React UI Engineer,"$88K-$199K
(Glassdoor est.)","About us;

LogRhythm, a Thoma Bravo company is a world leader in NextGen SIEM, empowering thousands of enterprises on six continents to successfully reduce cyber and operational risk by rapidly detecting, responding to and neutralizing damaging cyberthreats. LogRhythm's technology serves as the foundation for the world's most modern enterprise security operations centers (SOCs), helping customers measurably secure their cloud, physical, and virtual infrastructures for both IT and OT environments. Built for security professionals by security professionals, the LogRhythm NextGen SIEM Platform has won countless customer and industry accolades.

Who we are looking for;

We are looking to add a Senior React UI Engineer to our team for development on our next generation greenfield project. Our product is designed to significantly reduce the time required to detect and respond to threats, enabling organizations to neutralize these threats before they cause a damaging cyber incident or data breach

We have pioneered a holistic approach to security intelligence that sits at the intersection of advanced cyber-security and Big Data analytics. Our highly scalable, purpose-built platform collects, classifies and contextualizes petabytes of machine and forensic data from across the extended IT and operational environment. We use correlation-based as well as Machine Learning technology to continuously and in real-time analyze this contextualized data to detect cyber-threats, including those that Big Data analytics are best positioned to detect. We also provide robust forensic analytics and centralized search capabilities that enable security and operational personnel to rapidly investigate and respond to threats.

You'll have the opportunity to work with a talented team of professionals, including software developers, UX researchers, designers, QA engineers, and data scientists. As a Senior Software Engineer, take pride in delivering an award-winning user experience to our customers and believe that a challenging and fun work environment is essential to this goal.

Here's an overview of the responsibilities & challenges ahead;
Development of front-end client application code in React, utilizing micro front-end architecture
Foster a collaborative, team-oriented, agile environment.
Evaluate new tools and technologies, and influence adoption across the broader Engineering organization.
Improve Engineering delivery through all phases of the software development lifecycle (build, test, and release).
Ability to successfully mentor other team members in growing their skills/careers.
Understand the product, our customers, and their needs.
Have a passion for beautiful, usable interfaces.
Required Skills:
Five (5) or more years of professional experience writing large, scalable and performant business applications in JavaScript.
Demonstrable experience and fluency with React.
Work well in a close-knit, ego-free team environment.
Outstanding attention to detail and software quality.
Solid written and verbal communication skills.
B.S. degree in Computer Science, a related field, or equivalent experience.
Workplace equality & inclusion are not just words or topics for LogRhythm, they are part of our core values, beliefs, and integral to our company culture. We hire the best of the best and do not discriminate based on race, gender, age, religion, sexual orientation, identity, or other personal factors. LogRhythm was built on the principals of innovation, dedication, creativity, and commitment. It is through these key areas we were able to grow as an equal and inclusive workplace, one where our employees feel respected and safe in.",3.5,"LogRhythm
3.5","Boulder, CO","Boulder, CO",501 to 1000 employees,2003,Company - Private,Computer Hardware & Software,Information Technology,$100 to $500 million (USD),"IBM, McAfee, Splunk"
Data Engineer,-1,"As a Data Engineer, you'll join our growing team of data scientists and engineers, reporting into Operations organization but working across multiple teams throughout the company. In this role, you(TM)ll be responsible for handling the design and construction of scalable data management systems "" ensuring that all data systems meet our company requirements "" and will also research and recommend new uses for data acquisition. As a Data Engineer, you will implement the data models and data structures needed for each use case, in the most convenient format to be used by the Data Science and Business Intelligence teams. Through regular interactions with stakeholders and functional business unit leaders, you will build high-performance algorithms, predictive models, and prototypes that influence data storage, piping, and usage. Additionally, you will participate in data requirements, modeling and testing activities. Each day will be unique, requiring an ability to think strategically and on your feet, be creative, take initiative, and employ a diverse set of skills.

WHO YOU ARE

Knowledgeable, Analytical, and Solution-Oriented. Without a doubt, you(TM)ve got strong quantitative skills and are comfortable analyzing large data set, spotting trends and patterns, and synthesizing relevant observations. You use a hypothesis-driven approach to engage in analysis that will deliver on your client questions. You like thinking outside the box to come up with innovative points of view on new challenges, relying on your previous analytic work and experience to help guide you along the way.

Results-Oriented. You demonstrate an inherent sense of urgency to drive great results, while being precise in executing your work. You are facile with creating and communicating a clear project plan, tracking progress, and keeping your business partners in the loop along the way.

Intellectually Curious. You're inherently interested in the ""why"" so that you can identify opportunities that represent unconventional solutions to the problems you are trying to solve.

Strong Communicator. Your writing and speaking skills are concise, articulate, and effective, providing an ability to interact with all levels/various teams across the organization, be understood, and develop trust and rapport within the organization.

Technologically Savvy. Microsoft Excel is a basic tool to you that you know like the back of your hand. You also have a strong skill set in R, Python, ArcGIS, machine learning, neural networks and/or other advanced analytics tools and techniques.

A Trusted Team Player. You enjoy partnering with others and build constructive working relationships that foster the collaboration necessary to deliver great results. You are accountable to your teammates and follow through on commitments.

Organized and Confident. You are flexible, composed, and able to prioritize multiple tasks and deadlines simultaneously, while confidently interacting with a variety of individuals, across all levels of the organization. You handle pressure well and do so with confidence.

WHAT YOU(TM)LL DO

Create data models and data processes, providing the right format and structure for use case solutions.

Participate in early data modeling and testing for use case development, providing input on how to improve proposed solutions and implement necessary changes.

Help to build, document, and maintain best practices, including but not limited to codebase management, work and issue tracking, testing and quality control/assurance measures, data dictionaries, and a documentation hub for both production level code and ad hoc analyses.

Interact with stakeholders and functional subject matter experts to understand all data requirements in order to develop effective business insights and translate them into actionable data structures and data models.

Assemble large, complex data sets that meet both functional and non-functional business requirements.

Extract relevant data to solve analytical challenges the organization and/or functional business units may face.

Work closely with IT teams on internal data acquisition (e.g., CRM, ERP, etc.).

Partner with stakeholders to provide technical support related to data structures, data models, data management and data infrastructure needs.

Work with data and analytics experts to strive for greater functionality in our data systems. Recommend different ways to constantly improve data reliability and quality.

Research new uses for existing data.

Create data tools for Business Intelligence, Analytics and Data Scientist team members that assist them in building and optimizing our Company use of data.

Collaborate regularly with key stakeholders to support and enhance the day-to-day operations of our business.

Produce various reports for stakeholders, as requested, to highlight areas of opportunity; works with teams to develop and implement changes, as needed.

Develop and maintain formal documentation that describes data and data structures, including data modeling.

PREVIOUS EXPERIENCE & REQUIREMENTS

Bachelor's Degree required, preferably in computer science, software/computer engineering, applied mathematics, or physics statistics.

Minimum 2 years data modeling experience and working with data management systems; deep expertise in data modeling and structuring required.

2+ years experience in high volume data environments and core data engineering activities (i.e. familiarity with cloud database set up, automation scheduling using directed acyclic graph (such as Airflow) and database optimization, including but not limited to partitioning, group and sort keys, and indexes).

Familiarity with a broad base of analytical methods e.g. data modeling (variable transformation and summarization) and processing (i.e. Spark, SQL Server, Hadoop/Hive, neo4j, etc).

Strong attention to detail and ability to think critically/conceptually.

Team oriented and flexible with proven track record in collaborating with multiple stakeholders.

Effective written and verbal communication skills required. Demonstrated ability to quickly learn new technologies a must.

Ability to think creatively when problem solving for new solutions and to work on numerous projects concurrently while effectively prioritizing workload. Tolerance for ambiguity required.

Tools/software:

Familiarity with data loading and management tools (i.e. Azure Storage""BlockBlob and relational and NoSQL databases and tools such as SQL Server, MongoDB, Data Stax, etc) required.

Must have programming and/or scripting experience (Python, Java) as well as experience with version control systems (Git/GitHub), continuous integration (circleCI) and other programming frameworks/approaches.

Proficiency in MS and Google application suites.

Must be available for overnight travel (approximately 10%)

Authorization to work in the US (without need for Visa sponsorship from employer) is required.",5.0,"CultureFit Technology Staffing
5.0","Chicago, IL","Deerfield, IL",1 to 50 employees,1997,Company - Private,Advertising & Marketing,Business Services,$1 to $5 million (USD),-1
DevOps Engineer with Azure,-1,"Title: DevOps Aazure Engineer
Location: Bellevue, WA
Duration: 12 months with possible extension

Roles and Responsibilities:
Senior Software Engineer Full Stack | Telecommunication Enterprise Solutions Delivery Telecommunication Enterprise Solutions Delivery develops cutting edge innovative closed-loop analytics solutions, enabling insights-driven decision making across the enterprise.
We collaborate with multiple functional areas and impact every element of our business: corporate, security, networks, retail, IT and others.
We are looking for a result-oriented full stack engineer to be part of the team who excel in turning apparently complex problems into an intuitive user experience, implemented in the most simple way endto-end.
You will have the opportunity to work on internal solutions (full stack development), performance/ scalability issues and building technical infrastructure on-prem and Azure.
You will need to understand the business objectives, think like an end user and knows that 90% done is only half done.
You love beautiful, simple user interfaces, and you constantly wonder what you could have done to simplify your last project.
You are passionate about e2e architecture and database design, focusing on flexibility and scalability.
You prioritize API design, as this is a must to build scalable, future-proof products.
You will work closely with data scientists / Client engineers, cloud and full stack experts to build advanced analytics platform in a hybrid environment integrating on-prem assets, Azure infrastructure and services.
Essential Functions
You will be responsible for designing, developing, integrating, and maintaining web-based portals, tools, databases, code improvements and scripts as part of the Machine Learning as a Service team
Participate in technical design discussions, influencing the team in strategic decisions
Work with data scientists / Client engineers, software developers and interfacing internal customers to translate their requirements to features and develop those solutions Identify ways to automate analysis through smarter software systems.
Designs, codes, tests, debugs, and documents requirements - code - models, ETL processes, SQL queries, and stored procedures.
Responds to data inquiries from various groups within client's organization.
Responsible for other duties/projects as assigned by business management / leadership.
Qualifications
Minimum Required
7 plus years of experience in software development
5 years of experience in Java script, Python, Flask API, Web API's, Kafka, Spark, Cloud technologies (Microsoft Azure preferred), containers, Kubernetes, CI/CD
Experience with Azure cloud-based services and supporting infrastructure
Experience designing and developing solutions with SQL database backends (MS SQL, PostgreSQL, MySQL)
2 plus years of experience in leading technical teams through agile and human-centered design methodologies like Design Thinking
Comfortable working with the bottom of the stack (like integrating our internal services or experimental new APIs) just as much as the top (like creating functional, user centric, customer facing prototypes)
Ability to provide technical oversight and guidance for projects across a full technology stack
Experience with analytics tools and how to use data to drive your decision making
Expertise with scaling pilot solutions to a large-scale production environment
Expertise with visualization tools such as PowerBI, D3JS etc.
Excellent written and verbal communication skills.
Desired
Bachelor or master's degree in computer science or equivalent domain specific experience in lieu of a degree.
Experience with architecting, designing, developing software solution in Azure and on-prem environments.
Experience with Azure Dev ops / Git hub / Gitlab CI/CD, Graph DB
Certifications AI / Client and Azure Cloud platforms",3.5,"Ekodus Inc
3.5","Bellevue, WA","Piscataway, NJ",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Software Engineer,"$50K-$108K
(Glassdoor est.)","GENERAL SUMMARY/ OVERVIEW STATEMENT:

The Massachusetts General Hospital (MGH) Neurology Department, an affiliate of Harvard Medical School and a world leader in brain research, is seeking a software engineer to help launch a multi-center collaborative database for critical care data sharing through the Center for Neurotechnology and NeuroRecovery's ICU Precision Medicine Lab. This Collaborative Hospital Repository to Unlock Synergy (CHoRUS) in Data will foster collaborative infrastructure, tools for working with medical Big Data; support clinical process improvements that can benefit from Big Data analytics; and enable highly granular retrospective and prospective studies using MGH's data archives and via continual capture of new data. Funded projects supporting our lab include investigation of traumatic brain injury (NIH/NINDS), subarachnoid hemorrhage (NIH/NINDS), and COVID-19 (Department of Defense). Our team is building the data resources, models, algorithms, and pipelines needed to harness the power of medical Big Data in pursuit of these projects' objectives. We are looking for a software engineer who can thrive in pursuit of this mission alongside experts in critical care, statistics, time series analysis, machine learning, and computer science.

PRINCIPAL DUTIES AND RESPONSIBILITIES:

This position involves a wide range of responsibilities, including:
Developing and deploying software and apps that interact with clinical information systems and mobile devices, and with existing databases and software systems.
Developing software for real-time interaction with clinical devices, including EEG recording devices, bedside ICU monitors, and mobile heath monitoring devices.
Developing software that generates insightful summaries of large & complex datasets.
Organizing, manipulating and integrating new datasets across different formats and robust synchronization with existing datasets and databases.
Under general direction, developing innovative analytical methods to help collaborators interpret results and design follow-up research.
Providing support to neurology researchers to develop and implement data-analyses.
Contribute to manuscript preparation and project-team reports.
Actively participate in project team meetings and provide necessary technical tutorials to elevate the team's understanding of modern software stacks.
Design, write, test, tune, document, deploy, maintain and support new features, analysis methods and infrastructure.
Maintain computing infrastructure and software deployments.
Mentor teammates with less engineering experience and share knowledge of computer science best practices with the team.
Contribute to system architecture and design.
Refine software development processes and best practices.
SKILLS/ABILITIES/COMPETENCIES REQUIRED:
Demonstrated ability in developing software applications that either manage or analyze time series data and/or data from electronic health record using language such as one of the following Python, Matlab, R, C .
Expertise in relational and/or NO-SQL database management and ETL for batch processing.
Facility with ""tools of the trade"", e.g., Unix system administration, shell scripting, building and deployment tools, version control.
Proven ability to meet deadlines and work cooperatively in a small collaborative team.
Demonstrated capability as highly organized, a creative problem-solver.
Detail-oriented, self-motivated, and able to work independently as well as within cross-functional teams.
Ability to adapt to rapidly changing and high-demand environments.
Experience with AWS, GCP, or IBM Cloud Object Storage.
Experience with the Spark big data stack (Hadoop, Spark, etc.) a plus.
Comfort with probability, linear algebra, and data analysis, and experience processing or analyzing biological data.
Demonstrated proficiency with several of the following technologies: R, Python, Matlab, Javascript, Unix, C .
Excellent written and oral communication skills.
EDUCATION:

Minimal Bachelor's degree in Computer Science, or related field, Master's degree preferred.

EXPERIENCE:

3 years industry experience working in software development.

WORKING CONDITIONS:

The research coordinator will work within a team of physicians, clinical research coordinators, and physician-scientist neurologists. Work will be performed in various adult ICUs at MGH, in collaboration and with other academic hospitals on the MGH and MIT main campus.",3.6,"Partners Healthcare System
3.6","Boston, MA","Boston, MA",10000+ employees,1994,Nonprofit Organization,Health Care Services & Hospitals,Health Care,$10+ billion (USD),"Beth Israel Deaconess Medical Center, Tufts Medical Center, Boston Children's Hospital"
Principal Software Engineer,-1,"Principal Software Engineer

Job Locations US-VA-Arlington | US-MD-Fort Meade | US-TX-Austin | US-TX-San Antonio

Job ID 2019-1172 # of Openings 1 State Arlington, VA Category Research Engineers/Scientists

Overview


Two Six Labs is seeking an experienced and motivated Principal Software Engineer to work within a cross-functional development team focused on advancing the state-of-the-art Cyber mission command system enhanced by artificial intelligence and machine learning. The successful candidate must have hands on experience developing towards cloud-based platforms.

Responsibilities
Represent program equities within Government locations
Lead development of core database and distributed analytic technologies
Ensure data platform can support program data scale and latency requirements
Optimize code for performance, scalability and stability
Qualifications
A four-year degree in CS, EE, or Math (advanced degree preferred)
An Active DoD Clearance (Secret or above)
Minimum five years in a technical leadership role - principally focused on tasking and mentoring junior engineers
Strong programming ability in Java and Python
Familiarity with Atlassian Tool Suite - Confluence/JIRA
Ability to iterate and deliver quickly
Experience with Postgres, AWS, Docker
Possess a deep understanding of Linux scripting and configuration management tools
Great communication skills
Self-driven work ethic
All applicants selected will be subject to a background investigation and must meet eligibility requirements for access to classified information.

Apply for this job online Apply

Share

Email this job to a friend Refer

Sorry the Share function is not working properly at this moment. Please refresh the page and try again later.

Share on your newsfeed

Two Six Labs is an Equal Opportunity Employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veteran status, or any other characteristic corrected by law.

As a federal contractor, Two Six Labs has established affirmative action programs to ensure non-discrimination and affirmative action in Two Six Labs's policies and practices for qualified women, minorities, protected veterans, and individuals with disabilities. The narrative portion of Two Six Labs affirmative action plans for individuals with disabilities and veterans are available for inspection at our offices during normal business hours. Employees and applicants interested in inspecting these plans should contact Human Resources by phone 703-543-9662 or by email at hr@twosixlabs.com for assistance.

If you are interested in applying for employment with Two Six Labs and need special assistance or an accommodation to apply for a posted position, contact our Human Resources department by email at hr@twosixlabs.com or by calling 703-543-9662.",4.3,"Two Six Labs
4.3","Arlington, VA","Arlington, VA",51 to 200 employees,2009,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Senior Perception Research Scientist/Engineer,-1,"Hyundai-Aptiv Autonomous Driving Joint Venture

The Hyundai-Aptiv Autonomous Driving Joint Venture develops world class production-ready autonomous driving systems. The joint venture leverages Hyundai Motor Group’s design, engineering, and manufacturing expertise and Aptiv’s autonomous driving solutions to commercialize an SAE Level 4 platform for robotaxi providers, fleet operators, and automotive manufacturers.

Headquartered in Boston, the Hyundai-Aptiv Autonomous Driving Joint Venture has operations in the US and Asia. An official name for the new joint venture will be unveiled soon!

About this position

Our Principal Research Scientist will play a key role in making the vehicle of the future a reality by developing technologies that deliver a turnkey, fully autonomous driving system for our customers and enable Mobility on Demand (MoD). As we expand our global footprint, we are looking for exceptional perception engineering talent to research and apply innovative solutions to our products. Do you enjoy working with prototypes? Do you have a knack for developing algorithms to identify objects and occlusions? If the answers are yes, we’re looking for you.
What You'll Do:
Develop perception algorithms to detect and identify objects, etc. for autonomous driving systems.
Collect data and analyze results of benchmarks, road, and regression tests.
Partner with colleagues to design innovative algorithms in motion planning, and control.
Integrate perception software into prototype autonomous driving systems.

What You'll Bring:
Master’s or PhD degree in Robotics, ECE, Computer Science, or a related field.
Experience with Radar, LiDAR, computer vision, sensor fusion, probabilistic perception, point cloud processing, object tracking, data association, optimization, and/or machine learning is a plus.
5+ years of experience in C++, Python or other programming language.
Experience with MATLAB.
Experience with mathematical modeling.
Experience with simulation environments
Strong problem solving skills with ability to learn.
Strong communication and interpersonal skills.
Flexible and creative thinking.
Hyundai-Aptiv AD LLC is an EOE. We celebrate diversity and are committed to creating an inclusive environment for all employees. To comply with Federal Law, we participate in E-Verify. All newly-hired employees are queried through this electronic system established by the DHS and the SSA to verify their identity and employment eligibility.",-1,Hyundai-Aptiv AD LLC,"Boston, MA",-1,-1,-1,-1,-1,-1,-1,-1
Senior Software Engineer - Backend,-1,"Freenome is hiring a Senior Software Engineer - Backend to develop software to combat cancer and other age-related diseases. You will work as part of an interdisciplinary team of engineers and scientists building end-to-end solutions for our ML team and clinical and R&D labs.

At Freenome, we're building a multi-omics platform that ingests clinical-grade, high-dimensional, biological data for early cancer detection. We're a diverse group of Engineers building tools and services which enable our Molecular and ML Scientists to turn great research into even better products. We will create actionable insights for health systems and will guide change for the way doctors think about early detection of colon cancer.

As a member of a fast-growing team, you'll take the lead on major projects and collaborate actively with our world-class team of engineers, scientists, designers, and product managers. You'll build reliable, maintainable, scalable, and fault-tolerant backend services that enable the rapid growth of our business and our mission to save lives.

Depending on your skills and our needs you'll be working on projects including ML platform development, job scheduler development, EMR system integration, and data CRUD operations and ETL. Our systems are built using the latest web software development technologies and methodologies.

Responsibilities:
Design, develop, and deploy reliable, maintainable, scalable, and fault-tolerant backend services that power both our internal and external systems
Collaborate with team members for code and design review
Work with scientists, designers, product managers, and other engineers to solve complex problems in the face of lots of dynamism and uncertainty
Take a mindful, transparent, and humane approach to your work and your interactions with others
Guide and champion engineering hygiene and culture as a core part of the engineering backbone
What We're Looking For:
5+ years of experience as a part of a software development team successfully shipping a software product
BS, MS, or PhD in Computer Science, Engineering or related field, or equivalent training, fellowship, and/or work experience
Experience with Python or similar scripting language
Excellent written and verbal communication skills
Direct experience with web service development
The ability to thrive in an environment where collaboration, communication, and compromise are an expected part of your day-to-day work
A mindful, transparent, and humane approach to your work and your interactions with others
Nice to Haves:
Expertise with Python
Experience with SQLAlchemy, Flask, or Django frameworks
Experience in Kubernetes, Docker, PostgreSQL, Google Cloud Platform
Previous experience leading teams or managing projects
Understanding of, and practical experience with, statistical and machine learning methods
Domain-specific experience in computational biology, genomics or a related field
Direct experience with clinical interoperability standards such as FHIR, IHE ITI Profiles or HL7v2
About Freenome

Freenome is on a mission to empower everyone with the tools they need to detect, treat, and ultimately prevent diseases.

By applying advanced machine learning techniques to recent breakthroughs in genomic science, Freenome is developing simple blood tests to detect early-stage cancer and make treatments more effective. The company has raised $238 million from investors such as RA Capital, Polaris Partners, Perceptive Advisors, Andreessen Horowitz, funds and accounts advised by T. Rowe Price Associates, Inc., GV (formerly Google Ventures), Roche Venture Fund, Kaiser Permanente Ventures, American Cancer Society's BrightEdge Ventures, Data Collective Venture Capital, Novartis and Verily Life Sciences (formerly Google Life Sciences).

Our Science

Freenome is building technology to gain an understanding of the body through several analytes derived from blood. These signals include cell-free DNA, methylation of cell-free DNA, cell-free RNA, circulating proteins, and immune profiling derived from thousands of prospective samples. By developing novel statistical learning methods and applying them to integrate various -omics datasets, Freenome is a leader in modeling specific biological mechanisms to capture disease dependent signatures such as gene expression, immune response, tumor burden, the tissue of origin, and 3D chromatin structure.

By building comprehensive discovery datasets and modeling critical biological systems, Freenome is learning what biological changes are present within the blood between a variety of different disease states including cancer, autoimmune disorders, infections, drug response, and aging. With the combination of Freenome's datasets, cross-functional technical expertise, and mission to uncover the biological truth, we seek to positively change the lives of millions through the early detection and early treatment of disease.

Our Culture

Freenomers are technical and creative, visionary and grounded, empathetic and passionate. We build teams around divergent expertise, which allows us to solve problems and uncover opportunities in unique ways. Freenomers are some of the most talented experts in their fields, coming together to advance healthcare one breakthrough at a time.

We value empathy, integrity, and trust in one another. That means embracing other's perspectives, those of our coworkers and those of the patients and communities we serve. It means knowing when to push, and when to listen. At Freenome, we give each other the benefit of the doubt in the belief that we're all working as a team toward the same goals, and empower others to grow in a collaborative environment.

What does a successful person look like at Freenome?

Those who thrive at Freenome prioritize, manage, and execute their own goals in alignment with those of the company. They embrace our values of empathy, integrity, and trust, and hold themselves and their team accountable. They crave collaboration with brilliant minds from unfamiliar fields of study and believe that hiring and mentorship are fundamental to our success. Above all, they welcome and provide constructive feedback and criticism, trusting in the good intentions of others, and secure in the knowledge that embracing mistakes is the best way to learn and move on. For those who crave challenges, understudied problems, and the chance to see their work impact the lives of millions of people affected by cancer every year, there's no better place to be.

Freenome is proud to be an equal opportunity employer, we value diversity in every way. Freenome does not discriminate on the basis of race, religion, color, sex, gender identity, sexual orientation, age, non-disqualifying physical or mental disability, national origin, veteran status or any other basis covered by appropriate law.",5.0,"Freenome
5.0","South San Francisco, CA","South San Francisco, CA",51 to 200 employees,2014,Company - Private,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,Unknown / Non-Applicable,-1
Senior Software Engineer,"$51K-$108K
(Glassdoor est.)","Company Description

Atmospheric and Environmental Research (AER), a Verisk business, has been helping businesses and governments better anticipate and manage climate and weather-related risks for more than 40 years. Large government agencies like NOAA, NASA and the Departments of Defense and Energy rely on AER’s scientists to help solve weather and climate related problems of vital national importance in energy, environment and national security. Large insurance, energy and investment firms count on AER to help them decrease weather-related losses and increase profitability by integrating state-of-the-art climate science and weather information into their planning and decision processes.  To learn more about AER please visit us at: www.aer.com. We are proud to be a part of the Verisk family of companies!

At the heart of what we do is help clients manage risk. Verisk (Nasdaq: VRSK) provides data and insights to our customers in insurance, energy and the financial services markets so they can make faster and more informed decisions.

Our global team uses AI, machine learning, automation, and other emerging technologies to collect and analyze billions of records. We provide advanced decision-support to prevent credit, lending, and cyber risks. In addition, we monitor and advise companies on complex global matters such as climate change, catastrophes, and geopolitical issues.

But why we do our work is what sets us apart. It stems from a commitment to making the world better, safer and stronger.

It’s the reason Verisk is part of the UN Global Compact sustainability initiative. It’s why we made a commitment to balancing 100 percent of our carbon emissions. It’s the aim of our “returnship” program for experienced professionals rejoining the workforce after time away. And, it’s what drives our annual Innovation Day, where we identify our next first-to-market innovations to solve our customers’ problems.

At its core, Verisk uses data to minimize risk and maximize value. But far bigger, is why we do what we do.

At Verisk you can build an exciting career with meaningful work; create positive and lasting impact on business; and find the support, coaching, and training you need to advance your career. We have received the Great Place to Work® Certification for the fourth consecutive year. We’ve been recognized by Forbes as a World’s Best Employer and a Best Employer for Women, testaments to our culture of engagement and the value we place on an inclusive and diverse workforce.

Job Description

Atmospheric and Environmental Research (AER) is seeking a motivated individual to work as part of an energetic team developing complex software for multiple Dept. of Defense and commercial programs providing solutions to real-world problems related to space weather impacts on operations. The successful applicant will interact closely with scientists, product developers and engineers in an agile development process to rapidly design, develop, test, integrate and deploy software capabilities with a DevOps mindset.

The position requires both new software development and ability to adapt/extend existing codes. New development will be mainly in C++ and Python but existing code also includes C and FORTRAN. Candidates must have a BS degree plus 8 years experience, MS degree plus 6 years experience, or PhD plus 4 years experience in computer science, electrical engineering, mathematics or sciences involving programming. A successful applicant will have demonstrated the ability to develop quality software for science or engineering applications and to rapidly learn new problem domains and software technologies. Strong technical and communication skills, teamwork, and problem solving in a fast-paced R&D environment are required.

Qualifications

The following are required:
Candidates must have a BS degree plus 8 years experience, MS degree plus 6 years experience, or PhD plus 4 years experience in computer science, electrical engineering, mathematics or sciences involving programming.
Strong modern C++ and Python programming skills and object-oriented design.
Development experience in Linux environments, including shell programming.
Demonstrated experience in software development of scientific, geospatial or engineering applications.
Understanding of the software lifecycle and experience in the use of software process tools including source control (Git, Subversion)
Demonstrated ability and enthusiasm for rapidly learning and applying new software technologies to complex problems.
An understanding or background in signal processing, RF propagation, and/or wave propagation.
An ability to manage and lead projects
An interest in participating on proposals and publishing / presenting in professional venues
Ability to obtain security clearance and US citizenship required.
The following are desired:
High performance computing and code optimization, including experience in multithreading and multiprocessing applications, and distributed programming
Data analytics, numerical methods, or modern machine learning experience
Interest in remote sensing/satellites, physics, meteorology, or other geophysical sciences
Experience with continuous integration tools such as Jenkins
#LI-SH1

Additional Information

Verisk Analytics is an equal opportunity employer.

All members of the Verisk Analytics family of companies are equal opportunity employers. We consider all qualified applicants for employment without regard to race, religion, color, national origin, citizenship, sex, gender identity and/or expression, sexual orientation, veteran's status, age or disability.

http://www.verisk.com/careers.html

Unsolicited resumes sent to Verisk, including unsolicited resumes sent to a Verisk business mailing address, fax machine or email address, or directly to Verisk employees, will be considered Verisk property. Verisk will NOT pay a fee for any placement resulting from the receipt of an unsolicited resume.

Consumer Privacy Notice",3.5,"AER
3.5","Albuquerque, NM","Lexington, MA",51 to 200 employees,1977,Subsidiary or Business Segment,Research & Development,Business Services,$25 to $50 million (USD),-1
Senior Software Engineer - DevOps,-1,"Position Overview

Beyond Limits product organization is seeking a high-energy, creative and passionate Sr DevOps Engineer to join our team. This position is a hybrid of DevOps and CloudOps, and entails working with product engineering to build out efficient development and cloud infrastructure systems interfacing with cutting-edge A.I. (Artificial Intelligence) technologies. This role has exposure to many different technologies and business verticals creating huge room for learning and professional growth.

Job Duties/Responsibilities
Build the development pipeline for efficiently & regularly deploying code to production
Design, administer, deploy and manage systems and services on the AWS cloud
Develop highly repeatable processes and have a keen interest in automation
Collaborate in an agile manner with engineers, data scientists, and other cross-functional teams to improve maintainability and reliability of services. Enhance team’s technical capabilities as it pertains to the DevOps culture.
Build effective monitoring, alerts, logging and metrics for production services
Serve as a technical SME for cloud services, providers, and platforms
Ensure compliance with appropriate security standards
Minimum Qualifications
BS or MS in Computer Science or a related degree
8 or more years of experience in DevOps and/or Cloud engineering, or in software engineering with strong exposure to DevOps and CloudOps practices
Passionate about Continuous Build, Integration, Test, and Delivery systems
Strong knowledge of infrastructure and automation of CI/CD pipelines using tools such as Jenkins, Harness, Maven, Nexus/Artifactory or equivalent
Be well versed in administration tasks of managing Docker images, container orchestration on Docker and Kubernetes or equivalent
Deep knowledge of major cloud technologies & concepts such as virtualization, containers, networking, etc.
Strong programming and scripting fundamentals – Python, Terraform, Shell or equivalent
Demonstrated work with one or more Cloud providers (AWS, Azure, Google)
Preferred Requirements
Experience using configuration management tools such as Chef, Ansible, Puppet, etc.
Familiarity with Security Ops topics in the cloud such as intrusion, penetration, and vulnerability scanning
Understanding of Network & Switches, VPN, Direct Connect, Routing, Firewalls
Experience in cloud technology architecture & service management as it pertains to resiliency and disaster recovery is a plus
About Beyond Limits

Beyond Limits is a pioneering Artificial Intelligence engineering company creating advanced software solutions that go beyond conventional AI. Founded in 2014 with a legacy in space exploration, Beyond Limits is transforming proven technologies from Caltech and NASA’s Jet Propulsion Laboratory into advanced AI solutions, hardened to industrial strength, and put to work for forward-looking companies on earth. We leverage this unparalleled innovation portfolio, along with proprietary cognitive technologies, to help companies solve tough, complex, mission-critical problems and transform their business. We apply a unique hybrid approach to AI, combining numeric AI techniques like machine learning with higher order symbolic AI and expert human knowledge to deliver intuitive cognitive reasoning and information. Our cognitive computing technology mimics human thought processes and provides explainable reasoning to aid human-like decision-making.

Beyond Limits provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability or genetics. In addition to federal law requirements, Beyond Limits complies with applicable state and local laws governing nondiscrimination in employment in every location in which the company has facilities. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.

Beyond Limits expressly prohibits any form of workplace harassment based on race, color, religion, gender, sexual orientation, gender identity or expression, national origin, age, genetic information, disability, or veteran status. Improper interference with the ability of Beyond Limit’s employees to perform their job duties may result in discipline up to and including discharge.",4.2,"Beyond Limits
4.2","Glendale, CA","Glendale, CA",51 to 200 employees,2014,Company - Private,Research & Development,Business Services,Unknown / Non-Applicable,-1
DevOps Engineer - CI Poly - REMOTE (VA),-1,"Our client is the Public Sector Engineering team of a massively-funded Silicon Valley Geospatial & Signals Intelligence firm backed by nearly 20 VCs. They utilize Artificial Intelligence (computer vision, deep learning, convolutional neural networks) to process the rapidly expanding imagery and other data sets from satellites, drones, mobile devices, and IoT devices, world-wide. This is true Petabyte-scale cloud computing, translating enormous visual information into actionable intelligence that the world's leading decision-makers (both in government and in private industry) use to answer critical questions. Their accolades are impressive, being named to several ""most innovative companies"" and ""best machine learning companies"" lists, and they are viewed as a likely future unicorn (the venture capital industry's term for a privately-held company with a value over $1 billion). Their credo is using the power of AI ethically, to create progress in the world.

Their core products are used in both commercial and Intelligence Community settings, with this team focused on developing new features for federal customers and deploying the products in classified environments. There are three types of people needed in their Engineering Group - Computer Vision Scientists, Software Engineers, and DevOps Engineers. Computer Visions Scientists design, train, and deploy computer vision models and work with machine learning, image processing, deep learning, object detection, and automated analysis of imagery data. Software Engineers utilize Python to build enterprise-scale server-side software utilizing containerization (Docker, Kubernetes, etc.) and cloud-based systems (C2S and other classified cloud environments). DevOps Engineers deploy software to C2S and other classified cloud environments, script in Python and Bash, work with all sorts of DevOps tools, and navigate the authority-to-operate (ATO) process. All staff are considered part of the corporate Product Engineering team, so if you don't have a specific public sector effort to work on, you just keep helping evolve the product.

Work locations are REMOTE, work-from-home, with some visits to customer SCIFs throughout the DC metro area. SCIF visits are only when needed. The working style is fast-paced, with bright co-workers who have broad knowledge and who love to discuss and debate approaches, investigate new science and engineering topics on their own, and then teach each other. People are rather self-managing, so independent learners who appreciate flexibility and don't fear change fit in well. People are congenial and get along very well. Before the current crisis, people used to meet together for lunch regularly, and now that that is impractical, they have started forming technical book clubs, playing virtual board games, and having frequent one-on-one calls between each person and their manager. Slack and other collaboration tools are highly leveraged on a daily basis.

Compensation includes a strong base salary, a 10% annual performance bonus incentive, and very generous stock options that could be extremely valuable over time. The company pays 100% of medical / dental / vision for employees and almost 100% for dependents, and there are many other benefits as well.

All roles require US citizenship and a current TS/SCI security clearance. A TS/SCI + CI Poly is preferred but not required. Clearance crossover is NOT required for you to start working, however.

cjobs-cat:""IT - Software""

12017",-1,stanleyreid,"Arlington, VA",-1,-1,-1,-1,-1,-1,-1,-1
DevOps Engineer - TS/SCI - REMOTE (VA),-1,"Our client is the Public Sector Engineering team of a massively-funded Silicon Valley Geospatial & Signals Intelligence firm backed by nearly 20 VCs. They utilize Artificial Intelligence (computer vision, deep learning, convolutional neural networks) to process the rapidly expanding imagery and other data sets from satellites, drones, mobile devices, and IoT devices, world-wide. This is true Petabyte-scale cloud computing, translating enormous visual information into actionable intelligence that the world's leading decision-makers (both in government and in private industry) use to answer critical questions. Their accolades are impressive, being named to several ""most innovative companies"" and ""best machine learning companies"" lists, and they are viewed as a likely future unicorn (the venture capital industry's term for a privately-held company with a value over $1 billion). Their credo is using the power of AI ethically, to create progress in the world.

Their core products are used in both commercial and Intelligence Community settings, with this team focused on developing new features for federal customers and deploying the products in classified environments. There are three types of people needed in their Engineering Group - Computer Vision Scientists, Software Engineers, and DevOps Engineers. Computer Visions Scientists design, train, and deploy computer vision models and work with machine learning, image processing, deep learning, object detection, and automated analysis of imagery data. Software Engineers utilize Python to build enterprise-scale server-side software utilizing containerization (Docker, Kubernetes, etc.) and cloud-based systems (C2S and other classified cloud environments). DevOps Engineers deploy software to C2S and other classified cloud environments, script in Python and Bash, work with all sorts of DevOps tools, and navigate the authority-to-operate (ATO) process. All staff are considered part of the corporate Product Engineering team, so if you don't have a specific public sector effort to work on, you just keep helping evolve the product.

Work locations are REMOTE, work-from-home, with some visits to customer SCIFs throughout the DC metro area. SCIF visits are only when needed. The working style is fast-paced, with bright co-workers who have broad knowledge and who love to discuss and debate approaches, investigate new science and engineering topics on their own, and then teach each other. People are rather self-managing, so independent learners who appreciate flexibility and don't fear change fit in well. People are congenial and get along very well. Before the current crisis, people used to meet together for lunch regularly, and now that that is impractical, they have started forming technical book clubs, playing virtual board games, and having frequent one-on-one calls between each person and their manager. Slack and other collaboration tools are highly leveraged on a daily basis.

Compensation includes a strong base salary, a 10% annual performance bonus incentive, and very generous stock options that could be extremely valuable over time. The company pays 100% of medical / dental / vision for employees and almost 100% for dependents, and there are many other benefits as well.

All roles require US citizenship and a current TS/SCI security clearance. A TS/SCI + CI Poly is preferred but not required. Clearance crossover is NOT required for you to start working, however.

cjobs-cat:""IT - Software""

12018",-1,stanleyreid,"Arlington, VA",-1,-1,-1,-1,-1,-1,-1,-1
Senior Front-End Engineer,-1,"Join our team of leading engineers, researchers, and data scientists who are building the next generation AI-assisted customer analytics technology. Syntasa leverages proven streaming, machine learning, visualization, and big data technologies to process billions of records in real-time, resulting in actionable intelligence that improves acquisition, conversion, and retention. This provides a unique opportunity to be a part of a growing team in a fast-paced and evolving environment that delivers business impacts from data-driven recommendations.

As a Senior Front-End Engineer, you will develop new features and improvements across the Syntasa application. You will work closely with the UX design team to build and design browser-based experiences that are easy to understand and use. Every day you will be coding in TypeScript using Angular and writing tests in Jest. You will be performing code reviews for your peers and leading the development effort for the front end. As the team grows, you'll have an opportunity to take on a management role if you so desire. You'll also have the opportunity to work on the back-end in a Node.js environment.

IN THIS ROLE, YOU WILL:
Take features from design to implementation
Build reusable code and libraries
Review pull requests and mentor junior engineers
Collaborate with other team members and stakeholders
Work with data scientists and back-end engineers to build and design new features
Build efficient and reusable front-end systems and abstractions
Find and address performance issues
Participate in design and code reviews
Identify and communicate front-end best practices
REQUIRED QUALIFICATIONS:
5+ years of industry front-end experience
2+ years’ experience with modern front-end frameworks like Angular, React, Vue, etc
Proficiency in JavaScript/Typescript, and JavaScript design patterns
Advanced knowledge of HTML and CSS (SCSS) and the features in the latest versions
Awareness of cross-browser compatibility issues and client-side performance considerations
Demonstrated design and UX sensibilities
Version control experience of Git, Unit
Unit testing using Jest or similar
PREFERRED QUALIFICATIONS:
Demonstrated expertise in Angular, React or Vue
Bachelor’s in Computer Science or relevant experience
Working experience with various JavaScript environments, such as Node.js
Strong communication abilities with team members as well as clients (i.e. software features and issues)
Strong sense of ownership and drive
Syntasa provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability or genetics.",4.7,"Syntasa US
4.7","Herndon, VA","Herndon, VA",1 to 50 employees,2014,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Sr. BI Solutions Engineer,-1,"Overview

Austin Industries has an outstanding opportunity for a Sr. BI Solutions Engineer to join our team at our corporate headquarters in Dallas, TX. This professional will be focused on expanding Business Intelligence capabilities on the Power BI and Azure platform with responsibility for the overall architecture, design, and direction of solutions and infrastructure. This role will be responsible for working with the business to architect, develop, implement and maintain the overall roadmap of the evolving Business Intelligence platform.

Responsibilities
Designing integration architectures and data mappings, developing data models, and consulting with the infrastructure team on server and data storage services.
Formulating and recommending standards for achieving maximum performance, compliance and efficiency of the Business Intelligence ecosystem.
Maintaining in-depth current knowledge of standards, guidelines, and industry trends for Data Warehouse Architecture and Azure as it relates to reporting and operations. Attending and interacting with user groups and researching software solution in the market.
Acting as a change agent in the organization to foster use of self-service analytics, data governance while guiding changes and limited reliance on manual data processes.
Championing data quality, integrity and reliability throughout the organization by designing data flow models and promoting development best practices with best of breed automation tools.
Developing business cases and impacting evaluation and ROI for the organization.
Assisting stakeholders by providing appropriate BI advice, direction, and solutions, including data models, Power BI reports, Machine Learning (ML) or dashboards.
Performing requirements definition, development, testing, analysis and ad-hoc reporting as requested.
Demonstrating up-to-date knowledge in software engineering practices and providing solutions for the development, implementation and scaling, execution, validation, monitoring, and improvement of data science solutions.
Collaborating with external Data Engineers and Data Scientists to build data and model pipelines and assisting in running machine learning tests and experiments.
Demonstrating end-to-end understanding of applications (including, but not limited to, the machine learning algorithms) being created and maintaining scalable machine learning solutions in production.
Qualifications
Bachelor's Degree from a four year college or university or equivalent work experience.
Minimum of eight (8) years' Data Mapping and Extract/Transform/Load (ETL) design and development experience.
Experience with Office 365, Azure, Data Warehousing, Bot Development, Microsoft Power BI and experience with API Integration including 3rd party products
Working knowledge of data modeling tools, Python & R
Experience with Big Data Projects using multiple types of structured and unstructured data.
Skilled in leading data modeling and data architecture.
Fluent in relational database concepts and processing files.
Prior experience with data lakes, data storage, and data normalization
Strong grasp of advanced SQL writing and query tuning/optimization
Strong understanding of dimensional modeling
Experience in creating data visualization and meeting end user requirements
Experience in implementation of significant BI deployment and other data analytic tools.
Migrating existing reports and interfaces from other platforms to Power BI & Azure.
General ERP knowledge (Prefer CMiC, but not required)
Construction Industry Operational Knowledge
Comprehensive knowledge in software development lifecycles/methodologies, i.e. agile
Strong presentation and collaboration skills and can communicate all aspects of the job requirements, including the creation of formal documentation and obtaining sign off.
We offer excellent benefits including medical, dental, life and disability insurance and a matching 401K plan, and we are proud to be a 100% Employee Owned Company. To learn more about Austin's Employee Ownership history, please go to http://www.austin-ind.com/core-values.html.

An equal employment opportunity employer

Austin (""The Company"") is an equal employment opportunity employer. The Company's policy prohibits discrimination against any applicant or employee based on race, color, sex, religion, national origin, age (40 and over), disability, military status, genetic information or any other basis protected by applicable federal, state, or local laws. The Company also prohibits harassment of applicants or employees based on any of these protected categories. It is also the Company's policy to comply with all federal, state and local laws respecting consideration of unemployment status in making hiring decisions.

No Agency Inquiries Please

Austin Industries and all operating divisions (Austin Bridge & Road, Austin Commercial, and Austin Industrial) do not accept unsolicited resumes, candidates' names or summaries from staffing agencies, search firms, or third-party recruiters. Any unsolicited resumes submitted to Austin Industries, or any of its employee-owners, becomes the property of Austin Industries and Austin Industries will not pay a placement fee.

About Austin Industries

Austin Industries and its operating companies engage in almost every type of civil, commercial and industrial construction. Austin is owned entirely by its employees through its Employee Stock Ownership Plan (ESOP). Austin Industries has a rich history. We are one of the largest and most diversified construction firms in the nation. Austin stands on the core values of Uncompromising Integrity, Employee-ownership, Exemplary Service and Excellence in Safety. To learn more about our history, culture and operations, visit us at www.austin-ind.com.",3.2,"Austin Industries, Inc.
3.2","Dallas, TX","Dallas, TX",5001 to 10000 employees,1918,Company - Private,Construction,"Construction, Repair & Maintenance",$2 to $5 billion (USD),"Zachry Construction, The Beck Group, Turner Construction"
Federal - Big Data Engineer,-1,"Organization: Accenture Federal Services
Location: Arlington, VA - Washington, DC

Accenture Federal Services, a wholly owned subsidiary of Accenture LLP, is a U.S. company with offices in Arlington, Virginia. Accenture's federal business has served every cabinet-level department and 30 of the largest federal organizations. Accenture Federal Services transforms bold ideas into breakthrough outcomes for clients at defense, intelligence, public safety, civilian and military health organizations.
We believe that great outcomes are everything. Its what drives us to turn bold ideas into breakthrough solutions. By combining digital technologies with what works across the worlds leading businesses, we use agile approaches to help clients solve their toughest problems fastthe first time. So, you can deliver what matters most.
Count on us to help you embrace new ways of working, building for change and put customers at the core. A wholly owned subsidiary of Accenture, we bring over 30 years of experience serving the federal government, including every cabinet-level department. Our 7,200 dedicated colleagues and change makers work with our clients at the heart of the nations priorities in defense, intel, public safety, health and civilian to help you make a difference for the people you employ, serve and protect.

AFS is seeking a Big Data Engineer to support our Federal portfolio. This role involves supporting the full software development lifecycle, utilizing emerging technologies and big data design principles in developing data pipelines, interfaces, and architecture to support big data and analytics initiatives. The candidate will work with other engineers, data analysts, data scientists, and data visualizers to bring powerful analytical solutions and insights to our clients.
Basic Skills and Qualifications:
Experience with Data Engineering or Big Data Technologies, or Data Transformation, and modeling
Experience in architecting and building scalable data platforms
Experience with Cloud Technologies (Data Lake, Azure, Google, AWS etc.) or experience with open source technologies (Spark, Kafka, Presto, Hive, Cassandra etc.)
Experience with SQL and/or NOSQL databases
Must be a US Citizen; no dual citizens

Preferred Skills and Qualifications:
Production implementation experience for all qualifications listed
Production experience in building real-time analytics applications
Experience in both batch and stream processing technologies
Experience with 2 of 3 - Java, Scala, and Python programming languages
Machine learning experience with Spark or similar
Ability to manage numerous requests concurrently and be able to prioritize and deliver
Good communication skills
Dynamic team player
Bachelors Degree

An active security clearance or the ability to obtain one may be required for this role.
Candidates who are currently employed by a client of Accenture or an affiliated Accenture business may not be eligible for consideration.
Applicants for employment in the US must have work authorization that does not now or in the future require sponsorship of a visa for employment authorization in the United States and with Accenture (i.e., H1-B visa, F-1 visa (OPT), TN visa or any other non-immigrant status).
Accenture is a Federal Contractor and an EEO and Affirmative Action Employer of Females/Minorities/Veterans/Individuals with Disabilities.
Equal Employment Opportunity
All employment decisions shall be made without regard to age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status or any other basis as protected by federal, state, or local law.
Job candidates will not be obligated to disclose sealed or expunged records of conviction or arrest as part of the hiring process.
Accenture is committed to providing veteran employment opportunities to our service men and women.",3.9,"Accenture
3.9","Multiple Locations, USA","Dublin, Ireland",10000+ employees,1989,Company - Public,Consulting,Business Services,$10+ billion (USD),"Cognizant Technology Solutions, EY, McKinsey & Company"
"Software Engineer (Data Scientist, C,C++,Linux,Unix) - SISW - MG","$57K-$119K
(Glassdoor est.)","During the current global health crisis, the priority for Siemens Digital Industries Software is the health and well-being of our entire community including current and future employees, which may add time to our hiring processes. We appreciate your patience and invite you to visit our website to learn more about how Siemens is responding to the pandemic.
Company: SISW - MG
Job Title: Software Engineer (Data Scientist, C,C++,Linux) - 189288
Job Location: USA - CA - Fremont
Job Category: R&D SW Engineering

Job Description:

We are looking for a highly motivated engineer to work in the RET team in the Calibre business unit. In this role you will be responsible for analyzing modeling data (experimental and synthetic/simulated) and coming up with novel ways to organize it, while deriving meaningful operations and extracting maximum information from this data.

You will also be expected to develop supporting software that will be properly integrated in the modeling suite of tools that are used specifically in modeling of semiconductor manufacturing.

You will be teaming up with a group of senior software engineers contributing to final production-level quality of new components and algorithms and to support existing components.

This is a unique role that will challenge you and allow you to grow in interdisciplinary areas of software engineering and data analysis.

Knowledge and experience in the area of data science/data analysis is preferred.

Some familiarity with physical modeling of any discipline (e.g. from fields in electrical or mechanical engineering) will be very useful for the suitable candidate.

Job
Qualifications:

The successful candidate will possess the following
combination of education and experience:
BS or
MS in Data Sciences, Computer Science, Electrical Engineering, Physics or
Applied Mathematics.
Working
knowledge in development of C and C++ on UNIX and/or LINUX platforms.
Excellent
programming skills in at least one mainstream scripting language, preferably
Python.
Experience/knowledge
in data analysis.
Experience/knowledge
in machine learning technology.
Experience
with Python, Keras and Tensorflow.
Demonstrated
ability to learn and explore new technologies.
Excellent
analysis and problem-solving skills.
Must
have the ability to collaborate closely with other members of the team and
develop critical components consistently and in a timely manner.
Experience
with MATLAB/R or equivalent mathematical package is expected.
This position may require access to export-controlled technology. If an export license is required and Mentor Graphics elects to apply for such a license, then candidates must be approved and licensed by the applicable government authorities as a condition of employment.

#LI-MGRP
#LI-JE1

Organization: Digital Industries

Company: Mentor Graphics Corporation

Experience Level: Recent College Graduate

Job Type: Full-time

Equal Employment Opportunity Statement
Siemens is an Equal Opportunity and Affirmative Action Employer encouraging diversity in the workplace. All qualified applicants will receive consideration for employment without regard to their race, color, creed, religion, national origin, citizenship status, ancestry, sex, age, physical or mental disability unrelated to ability, marital status, family responsibilities, pregnancy, genetic information, sexual orientation, gender expression, gender identity, transgender, sex stereotyping, order of protection status, protected veteran or military status, or an unfavorable discharge from military service, and other categories protected by federal, state or local law.

EEO is the Law
Applicants and employees are protected under Federal law from discrimination. To learn more, Click here.

Pay Transparency Non-Discrimination Provision
Siemens follows Executive Order 11246, including the Pay Transparency Nondiscrimination Provision. To learn more, Click here.

California Privacy Notice
California residents have the right to receive additional notices about their personal information. To learn more, click here.",3.9,"Siemens Healthineers
3.9","Fremont, CA","Erlangen, Germany",10000+ employees,1847,Company - Public,Health Care Services & Hospitals,Health Care,$10+ billion (USD),"GE Healthcare, Roche"
"Advanced Algorithm Engineer, 3D Maps",-1,"Vision

Hivemapper is modern mapping infrastructure. Our machine vision powered mapping tools help forward thinking teams build smarter maps. Maps that see changes. Maps that understand. Some of the world’s most important organizations trust Hivemapper to build their maps that can see.

Who We Are

With just under 20 employees, we are proud to have multiple PhD’s, and alum from top schools like Stanford, UC Berkeley, Cal Poly, lending their expertise to our product and business. Hivemapper is a team of mathematicians, designers, programmers, and scientists from well-known companies like Palantir, Mapbox, and Yahoo, working together to create a modern mapping platform fed by a network of videos. Our work is fast-paced, collaborative, and cross-disciplinary as we focus on solving truly challenging problems. Our team and tech are growing rapidly, we encourage skill development and learning new things, and we love to promote leaders from within.

What We Need

As we improve our technologies in speed, accuracy, information content, flexibility, and many other ways, we only have room for smart, ambitious people with at least some entrepreneurial blood running through their veins.

As a developer of advanced algorithms you will collaborate with teammates across the company to design, develop, test, and deploy sophisticated solutions to a wide variety of challenging problems. The ideal candidate for this role not only has strong technical implementation skills, but a demonstrated fluency in flexible mathematical and algorithmic thinking. We are open to hiring varying levels of experience for this role.
What You'll Do
Research, develop and prototype advanced hardware and software technologies related to 3D reconstruction, photometric stereo, object detection, and point cloud registration.
Develop algorithms for refining and denoising 3D maps and removing dynamic objects
Develop evaluation tools for ensuring the quality of large scale 3D maps
Design and implement 3D scene segmentation algorithms to intelligently map environments using a mix of geometric and deep learning approaches.
What We're Looking For
2+ years of experience, and Masters and above degree in Applied Maths or related field
C++ proficiency
Robust experience in mathematics and algorithms
Proficiency with probabilistic inference and 3D geometry
Nice To Haves
Experience in machine learning, AI, 3D data, high performance computing or other relevant domains.
Strong systems design sense",5.0,"Hivemapper
5.0","San Francisco, CA","Burlingame, CA",1 to 50 employees,2012,Company - Private,Computer Hardware & Software,Information Technology,$5 to $10 million (USD),-1
Research Engineer-Full Stack,-1,"Where good people build rewarding careers.

Think that working in the insurance field cant be exciting, rewarding and challenging? Think again. Youll help us reinvent protection and retirement to improve customers lives. Well help you make an impact with our training and mentoring offerings. Here, youll have the opportunity to expand and apply your skills in ways you never thought possible. And youll have fun doing it. Join a company of individuals with hopes, plans and passions, all using and developing our talents for good, at work and in life.
Job Description
The ResearchEngineer will develop novel methods, web service concepts, tools, algorithms and techniques that can leverage both structured andsemi-structured data to solve tough problems like mobility analytics, data visualization, accident avoidance andrisk prediction for traditional insurance and safety products. He/she will also assist in efforts to evaluate, extract, scrub/prep, analyze and visualize a host of internal and external datasets using machine learning and statistical analysis and communicate to various stakeholders across and outside the company.
Key Responsibilities
Implementation of key product innovations into working prototypes, and concept demonstrators.
Develop full stack solutions from web/client through supporting cloud services.
Collaborate in a fast-changing environment and to communicate clearly and effectively with colleagues who range from academic researchers, senior data scientists, Developers, Dev Ops, Hardware engineers, and Product managers.
Present findings and demonstrations for enterprise specific topics to senior leadership.
Prepare and deliver presentations and/or training sessions to share insights from research, software, tools or procedures to internal and external audienceon a periodic basis.
Develop methods, tools, algorithms, processing approaches for business solutions and product development.
Job Qualifications
Masters in computer science, math, or a highly quantitative discipline.
Deep hands on development skills in client/web services and/or cloud computing to support high volume and low latency-sensitive, and secure data.
Mastery of one or more of the following languages: HTML, CSS, JavaScript, Python, Java, Node, or C#, and agile development methodology and tool suites.
Knowledge of advanced data processing/real time systems and cloud technologies using tools such as Spark, Flume, Kafka and Akka, and serverless processing architectures.
5 to 7 years of experience in research and product development.
Proficiency and/or a good understanding of structured and non-structured databases.
Proficiency with data visualization and graphics tools for the creation of professional presentations, reports, web content, or education materials.
Genuinely excited and enthusiastic about learning and pushing technical limits when finding new solutions.
Ability to create and maintain good working relationships and collaborations while being able to work independently and take initiative.
Experience/knowledge in model optimization, evaluation, comparison, validation and selection.
Preferred Skills:
Experience taking ideas from inception to pre-production products is highly desired.

The candidate(s) offered this position will be required to submit to a background investigation, which includes a drug screen.

Good Work. Good Life. Good Hands.

As a Fortune 100 company and industry leader, we provide a competitive salary but thats just the beginning. Our Total Rewards package also offers benefits like tuition assistance, medical and dental insurance, as well as a robust pension and 401(k). Plus, youll have access to a wide variety of programs to help you balance your work and personal life -- including a generous paid time off policy.

Learn more about life at Allstate. Connect with us on Twitter, Facebook, Instagram and LinkedIn or watch a video.

Allstate generally does not sponsor individuals for employment-based visas for this position.

Effective July 1, 2014, under Indiana House Enrolled Act (HEA) 1242, it is against public policy of the State of Indiana and a discriminatory practice for an employer to discriminate against a prospective employee on the basis of status as a veteran by refusing to employ an applicant on the basis that they are a veteran of the armed forces of the United States, a member of the Indiana National Guard or a member of a reserve component.

For jobs in San Francisco, please click""here""for information regarding the San Francisco Fair Chance Ordinance.

For jobs in Los Angeles, please click""here""for information regarding the Los Angeles Fair Chance Initiative for Hiring Ordinance.

It is the Companys policy to employ the best qualified individuals available for all jobs. Therefore, any discriminatory action taken on account of an employees ancestry, age, color, disability, genetic information, gender, gender identity, gender expression, sexual and reproductive health decision, marital status, medical condition, military or veteran status, national origin, race, religion (including religious dress), sex, or sexual orientation that adversely affects an employee's terms or conditions of employment is prohibited. This policy applies to all aspects of the employment relationship, including, but not limited to, hiring, training, salary administration, promotion, job assignment, benefits, discipline, and separation of employment",3.4,"Allstate
3.4",United States,"Northbrook, IL",10000+ employees,1931,Company - Public,Insurance Agencies & Brokerages,Insurance,$10+ billion (USD),"Progressive Insurance, State Farm, Farmers Insurance Group"
Sr. Machine Learning Engineer,-1,"Every day our employees make their mark by helping clients better
manage and service their financial assets around the world.
Whether providing financial services for institutions,
corporations or individual investors, clients count on us across
time zones and in 35 countries and more than 100 markets. It's
the collective ambition, innovative thinking and exceptionally
focused client service paired with a commitment to doing what is
right that continues to set us apart.

Client Technology Solutions provides our business partners with
client-focused, technology-based solutions. These enhance their
ability to be successful through world-class software solutions
and leading-edge infrastructure. Client Technology Solutions
provides employees with the tools and resources to enhance their
professional qualifications and careers.

Description
Our Innovation Center is currently seeking Senior Data Scientists
to join our rapidly growing team. We are a startup within an
enterprise, focused on applied research that can be quickly
brought to market as production services and new financial
services products. We are the worlds leading provider of
financial services technology, and current business operations
provide a wealth of fascinating business opportunities and
requirements, as well as terabytes of the worlds most
interesting data science challenges. Help us revolutionize global
financial services!

Responsibilities
You will lead the development and enhancement of the relevance
engine in our new enterprise search platform.

Experience and Skills:
Advanced degree in Computer Science or related field (Masters
required, Ph.D. preferred) with a solid understanding of
Information Retrieval, Learning to Rank, Text Mining and Machine
Learning.
Experience with search engine log analysis and applying Machine
Learning to improve search engine relevance.
Experience in Text Mining, Information Extraction and Document
Classification.
Software development experience with Java.
Experience programming for a search platform like Lucene.
Experience with a scripting language like Python, Perl.
Strong communication and presentation skills; experience in
communicating results of machine learning and statistical
analysis to a broad audience

Make your mark!",-1,Stride Search,"Palo Alto, CA","Westlake Village, CA",1 to 50 employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Software Engineer,-1,"ECS is seeking a Software Engineer (C++) to work in our Fairfax, VA office. We are a rapidly growing company that considers our employees to be our most important asset. People truly are number one at ECS. We are situated in Merrifield, VA -- well positioned for most commutes in the Northern Virginia area. Our newly renovated office spaces are first class and provide an inspirational environment. We offer opportunities for telework and have some of the most interesting advanced IT business in the DC area. ECS has extraordinary customers who are thought and action leaders in the AI/ML field. We offer highly competitive compensation and benefits to the right person for this key position.

Job Description:

ECS is seeking a Software Engineer to lead and participate in a team of scientists and engineers, and to support the execution of a variety of projects including Artificial Intelligence/Machine Learning and Big Data/Cloud Solutions. This position is not a project manager; however, it requires strong leadership and technical skills in areas such as software system architecting and enterprise application integration. The candidate works closely with the Project Manager and technical team to swiftly develop solutions in an agile environment and deploy capabilities to the operational end user. The candidate cultivates an environment that promotes customer service, excellence, innovation, collaboration and teamwork.

The Software Engineer has prior experience in designing/architecting enterprise scale systems incorporating a variety of components (COTS, Open Source) and supporting integration. This individual performs in a multidisciplinary team environment with tight deadlines. The successful candidate is highly motivated, eager to implement new technologies, and thrives leading a team of scientists and engineers.

Required Skills:

· US Citizen

· BA/BS degree in Computer Science/Engineering or Computer/Electrical/Mechanical Engineering

· Active Secret clearance

· 3-5 years of experience designing, deploying, and supporting enterprise level systems

· Experience working with C++, Python, orchestration frameworks (Kubernetes), cloud technologies (AWS, Azure, GCP)

· Experience utilizing containerization technologies (e.g. Docker)

· Demonstrated cross-functional team collaboration skills in a rapidly changing, high intensity, mission-oriented work environment

· Experience developing Architecture and Data Flow Diagrams using graphing programs (e.g. Visio)

· A skilled, intelligent, articulate individual who possesses excellent technical writing and presentation skills

· Familiarity with Linux operating systems

· Ability to work in a fast-paced environment

· Ability to travel (10%) to mostly CONUS locations

· Ability to quickly grasp and implement new technologies

· A self-motivated, self-starter that enthusiastically embraces pushing imaginative solutions to hard operational problems

Desired Skills:

· Master's degree in Computer Science or a related technical field

· Active Top-Secret clearance

· Experience utilizing big data and cloud tools and technologies

· Ability to deploy to OCONUS and hardship locations for short periods (2 weeks) a plus

· Deep learning algorithms, NLP, ML tools and packages

· Experience working with Department of Defense organizations or performers.

ECS is an equal opportunity employer and does not discriminate or allow discrimination on the basis of race, color, religion, gender, age, national origin, citizenship, disability, veteran status or any other classification protected by federal, state, or local law. ECS promotes affirmative action for minorities, women, disabled persons, and veterans.

ECS is a leading mid-sized provider of technology services to the United States Federal Government. We are focused on people, values and purpose. Every day, our 3000+ employees focus on providing their technical talent to support the Federal Agencies and Departments of the US Government to serve, protect and defend the American People.",3.5,"Electronic Consulting Services, Inc.
3.5","Fairfax, VA","Fairfax, VA",1001 to 5000 employees,2000,Company - Public,IT Services,Information Technology,$500 million to $1 billion (USD),"Booz Allen Hamilton, Leidos, Deloitte"
"Senior Application Engineer, Backend",-1,"Job Description
Come work alongside some of the most talented minds in the agtech industry. We are a team of innovators who want to make an immediate and significant impact. You will be given the opportunity to work with an amazing group of people who care about each other and their work.

What we are looking for:

At Arable we operate at the intersection of innovative connected hardware, data science, and recommendation systems; and at the center of all of these are the data systems that run our IoT, ML, and application systems. We're building a backend system for our specialized hardware which provides in-field monitoring for agricultural solutions. Our fleet is expanding and we're pushing new technologies like NB-IoT and edge-based machine learning. If you’re motivated by working on complex technical problems, and driven to create a better, more sustainable future, then this is the right place for you.

Come help build the future of agriculture!

What we do:

At Arable, our goal is to connect all the world’s farms and provide the highest-quality data to power predictive analytics that will help optimize the global food system. This is an ambitious goal, but the need has never been greater to rethink how we will feed an ever-growing population and reduce our impact on natural resources. We believe the heart of the solution is digitizing the analog world with high-fidelity data to help food producers optimize their operations. If successful, we hope the impact of our work will improve the lives of farmers everywhere and be a major contribution to securing the global food supply for decades to come.

A few examples of the work we’re doing today:
Helping farmers in India and China through improved insights into crop development
Giving produce growers in California the tools to optimize production with less waste
Helping irrigated farmers in Nebraska manage water more efficiently and sustainably to protect our water supply

What you will do:
Build features and implement robust scalable software in Python and Postgres
Work closely with the backend team to develop new features and APIs
Work closely with QA, Firmware, Data Scientists, and Product management
Be your own DevOps and deploy code to the cloud
What you bring:

Qualifications:

4+ years in cloud-based backend application development
Experience in web services development in Python (Pandas is a plus)
Experience with relational databases and SQL
Experience implementing web-based APIs
Team player with excellent verbal and written communication skills
BSCS, MSCS, or Ph.D. in CS or equivalent experience

Preferred Qualifications:

Experience with cloud infrastructure (AWS a plus)
Experience with Docker and/or Linux environments
Experience with CI/CD
Understanding of REST protocols
Experience with Business Intelligence/Analytics tools

What we offer:

At Arable you will be joining a company of dedicated team players who bring together diverse expertise and a passion for building a more sustainable future. We are a fast-moving startup committed to providing a rewarding employee experience through the work we do, the team, compensation, and benefits including:
Excellent medical, dental, vision, life, disability benefits, and a 401k program
Flexible PTO
A focus on community involvement and career development
Being an intricate part of creating an excellent IoT product in the Agtech space and having a positive impact on the world we live in.

At Arable, we don't just accept difference—we celebrate and support it. Not only because it's the right thing to do, but because we draw on the differences in who we are, what we've experienced, and how we think to make Arable thrive. Arable is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity, gender expression, protected veteran status, and any other characteristic protected under applicable State or Federal laws and regulations.",5.0,"Arable Labs, Inc.
5.0","San Francisco, CA","San Francisco, CA",1 to 50 employees,2014,Company - Private,Farm Support Services,Agriculture & Forestry,Less than $1 million (USD),-1
Enterprise Sales Engineer,"$78K-$134K
(Glassdoor est.)","About the Job:

As Enterprise Sales Engineer at Samasource, you enjoy working directly with customers to solve challenging AI problems. You are equally comfortable in both business and technical context, interacting with executives and talking shop with technical audiences. Straddling the product and sales organizations you will work directly with the sales team to understand the needs of our customers and navigate complex sales cycles. You will be a technical guide, providing compelling value-based demonstrations and supporting enterprise Proof of Concepts.

Key Responsibilities:
Demonstrate the value of Samasource technology throughout the sales cycle, from demo to proof of concept to design and implementation.
Become an expert in Samasource products from a business and technical standpoint.
Serve as a trusted advisor for your customers, designing computer vision, NLP, and training data strategies.
Keep Marketing and Product informed with feedback gathered from customer meetings.
Lead custom development required to support customer pilots and POCs; this can require lite coding/scripting.
Partner with Sales, Product, and Engineering teams to design customer solutions that artfully balance the symbiosis between technology and humanity.
Minimum Qualifications:
3+ years of industry experience with 1+ years of experience selling SaaS products and working with enterprise customers in one of the following roles: technical pre-sales, sales engineer, solutions engineer, or technical consultant.
University degree in computer science, engineering, mathematics, a related field, or equivalent experience.
Be a skilled presenter at any level and setting: engineers, data scientists, C-level executives, meetups and conferences.
Be a problem solver, thriving in a dynamic environment and have the flexibility and willingness to jump in and get things done.
Hands on experience with scripting languages and web technologies such as XML, JSON and RESTful APIs.
Preferred Qualifications:
Knowledge of Machine Learning, Computer Vision, or Natural Language Processing.
Interest in Software SDLC 2.0, where apps are driven as much by training data as source code -- our customers are software engineers and data scientists!
Development experience in web development languages (i.e. Python, NodeJS etc.).
About Samasource:

25% of the Fortune 50 trust Samasource to deliver secure, high-quality training data and validation for the technology teams driving humanity forward. From self-driving cars to smart hardware, Samasource fuels AI. Founded over a decade ago, were experts in image, video and sensor data annotation and validation for machine learning algorithms in industries including automotive, navigation, AR/VR, biotech, agriculture, manufacturing, and e-commerce. Our staff are driven by a mission to expand opportunity for low-income people through the digital economy, and our social business model has helped lift over 50,000 people out of poverty.
Featured in Forbes: How to Train Your AI Dragon (Safely, Easily, and Without Bias)
Samasource Press Page
Our Culture:

Samasource is quite unique. We are a technology company with a social mission. People that thrive in a high growth environment, love working on the bleeding edge of technology, and really care about having a positive impact on the world are a great fit for the Samasource culture. Our core values are grit, integrity, humanity, and GTD (Get Things Done).

Our Benefits:
Samasource offers competitive compensation commensurate with experience and a full benefits package, including: medical, dental, and vision insurance, FSAs, HSAs, short- and long-term disability insurance, life and AD&D insurance, employer-matching 401K, pre-tax commuter benefits, generous holiday and vacation policies, sabbaticals, paid disability and baby bonding leave, a monthly fitness stipend, and professional development opportunities.

At Samasource, we take pride in being a diverse and equal opportunity employer.

Powered by JazzHR",3.8,"Samasource
3.8","San Francisco, CA","San Francisco, CA",1001 to 5000 employees,2008,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Site Reliability Engineer,-1,"We are looking for an SRE to join an existing strong team and help us maintain and improve our internal Platform-as-a-Service.

About Us
Axon VIBE is a location-based contextual platform that detects and predicts human behaviour. It was founded in 2014 by location technology veterans (Google Maps, Endoxon, Multimap) and has assembled a 100-strong team of software engineers, machine learning experts, designers and product visionaries.

Axon VIBE provides the technology to help public transport operators get ready for and lead one of the fastest, deepest, most consequential disruptions of transportation in history. By late 2020s, its predicted that U.S. passenger miles travelled will be served by on-demand vehicles owned by fleets, not individuals, in a new business model Transport-as-a-Service (TaaS). TaaS will unify public, private & autonomous transportation into an efficient service, that users can pay for with a single account. TaaS is predicted to virtually eliminate road accidents and we may see a largely carbon-free road transportation system.

Why we are hiring
Axon Vibe are expanding into the US market, working with the MTA in New York and further partnerships in the United States are planned. We need to expand our operations team into the US to provide our partners and their customers with first class operational support.

Why this is interesting
You will have the opportunity to work with Software Engineers, Test Automation Engineers, Mobile Engineers & Data Scientists, ensuring that their work reaches Production in the most efficient manner while adhering to the high quality and reliability standards you will help define.

We are in the fortunate position to use some of the latest tools and services available, within this role you will have the chance to work with:

Infrastructure : AWS, EKS, OpenShift, Kubernetes, CentOS, Terraform, Kong, Ansible, Docker, JFrog, Maven, Kibana, statsd, LDAP, BareOS, Prometheus, Flyway, Docker Registry

Tooling: DataDog, OpsGenie, Jenkins, GrayLog, GitLab, Jira, Confluence

Platform : Java, Spring framework, PostgreSQL, MongoDB, RabbitMQ, Elasticsearch, Redis

Your Responsibilities

Production Reliability
As one of the first Site Reliability Engineers for Axon Vibe you will bridge the gap between software and systems engineering with a focus on performance monitoring and cloud scalability within an AWS environment, optimising and automating systems and ensuring the reliability of a complex platform for our current and future partners.

Production Pipelines
We must ensure our Development teams have robust pipelines and builds which allow them to build and test their code before releases make their way to production. You will work with our DevOps team to ensure we have the best possible pipelines in place, moving us gradually to a Continuous Deployment process.

Data Management/Protection
You will work closely with a Data Engineer or Data Scientist in the US to ensure data can be analyzed correctly, while adhering to our strict data privacy guidelines.

Incident Response and investigation
You will triage, troubleshoot & resolve front line production support alerts and tickets, working closely with both our Partners and Engineering teams. You will ensure incident response is within our partners SLAs and post-mortems are carried out to prevent repeating issues.

What we need from you

The ability to communicate and collaborate in a remote team across time-zones is a must

A passion for technology and experience with modern tools including a variety of modern programming languages and frameworks.

Have hands-on experience across various platforms and can navigate your way across a complex and rapidly changing technology landscape and stay on top of industry trends.

Hands-on experience with Linux, Kubernetes and Docker

A desire to automate; Jenkins is a plus

Experience building visibility into system health with logging, metrics, and alerting

The best parts of the job

We operate a high degree of trust with our staff, autonomy is important, and we give you responsibility to shape your own work.

We are agile, and strive to continuously improve, one small win at a time.

As the business grows, as will our operations and security team. You will have opportunities to progress within DevOps Engineering or move into other roles within the organization.

You get to travel, at least to our HQ in Luzern, Switzerland, but also to other partner locations.

The worst parts of the job…perhaps!

We are a growing fast-paced and somewhat remote business, so the pace can sometimes feel too fast.

With the majority of your colleagues being located in Switzerland and the UK, to maximize collaboration time you will have to align some of your working day with European time zones.

SRE roles do involve some call-out responsibility; however, the overall mission is to reduce this as much as possible via self-service support. A generous remuneration package is offered for on-call work.

Being the broken record. You will be the gatekeeper for production, so must ensure the correct engineering and release procedures/processes are followed.

Benefits

27 days holiday per year + public holidays

A mix of remote working and also a Manhattan office (when needed)

Apple MacBook Pro as your work device

All company meet-up at least once a year in Luzern, Switzerland

Chance to Travel to great locations (London UK, Norwich UK, Da Nang VN)

Generous remuneration package for being on-call

Job Types: Full-time, Permanent

Salary: $110,000.00 - $200,000.00 per year

Benefits:
Flexible Schedule
Paid Time Off
Schedule:

Monday to Friday
COVID-19 considerations:
All employees have the option of working from home during COVID-19, we have also suspended all company meet-ups and face to face meetings.

Experience:
DevOps / SRE: 4 years (Required)
Location:
New York, NY 10012 (Required)
Application Question:
Do you have experience using OpenShift?
Do you have 2 years+ experience with kubernetes?

Visa Sponsorship Potentially Available:
No: Not providing sponsorship for this job
Company's website:
https://axonvibe.com/
Benefit Conditions:
Only full-time employees eligible
Work Remotely:
Yes",3.5,"Axon Vibe
3.5","New York, NY","Lucerne, Switzerland",51 to 200 employees,2014,Company - Private,Computer Hardware & Software,Information Technology,$50 to $100 million (USD),-1
Software Engineer,-1,"Software Engineer

Washington, DC, USA

Req #1743

Tuesday, December 31, 2019
*Summary**
The GEC's Office of Science and Technology requires highly qualified Software Engineers with unique expertise in various computer science specialties including information retrieval, distributed contributing, large-scale system design, networking and data storage, cyber security, artificial intelligence, national language processing, and user interface/experience design.
*Essential Functions**
The Software Engineer is responsible for making it as easy and efficient as possible to conduct the Center's mission and work with social media, news, and advertising data, including:

+ Design, develop, test, deploy, maintain, and enhance software solutions that are robust and scalable to enable a large volume of transactions and events to be processed.

+ Conduct design and code reviews to ensure that solutions are production ready at the outset and maintainable over the long term.

+ Analyze and improve efficiency, scalability, and stability of various system resources.

+ Manage individual project priorities, deadlines and deliverables with technical expertise.

+ Partner with S&T Leadership Team in defining and planning projects.

+ Assist directly and indirectly in the continual hiring and development of technical talent.

+ Assist in the career development of technical colleagues, actively mentoring individuals and the community on advanced technical issues and helping managers guide the career growth of their team members.

+ Engage in special projects or novel efforts across the GEC mission, supporting the core tenets of agility and innovation, including the development of tools and operational prototypes, or modification of existing platforms, to meet the goals and requirements of the GEC S&T team and wider partnerships across other GEC teams, other U.S. Government organizations, or GEC external partners. This may include software development, social program development, data collection strategies and implementation, machine learning training and execution, develops actions on cloud infrastructures, basic system administration, or other technical actions.

+ Develop a 'skunk works'-like culture focused on rapid prototyping and impactful tool development.

+ Work closely with GEC Scientists and Analysts to provide holistic insights into GEC mission problems focused on national security challenges.

+ Support the other GEC teams through tight collaboration and, as needed and directed by the leadership of the GEC S&T division, embed onto other teams to provide close analytic, data science, and/or social science support.
*Education**
+ Bachelor's degree in software engineering, computer science, electrical / computer engineering, or related fields.
*Experience**
+ Within the last seven (7) years, a minimum of four (4) years' experience with at least two of the following: Java, C++, or Go.

+ Within the last seven (7) years, a minimum of three (3) years' experience with two or more of the following: Python, Ruby, Lua, Perl, or Bash.

+ Within the last five (5) years, a minimum of one (1) years' experience with one (1) or more of the following open-source development tools: git, GitHub, or Fisheye/Crucible.

+ Demonstrated experience with RDBMS (e.g. MySql, Postgres) and/or NoSQL databases (e.g. Accumulo/HBase, Cassandra, Elasticsearch/MongoDB, and/or Redis)

+ Desired experience with Apache Hadoop.

+ Desired experience with one (1) or more of the following container, resource management, and orchestration technologies: Docker, Mesos, and/or Kubernetes.

+ Desired experience with statistical machine learning or equivalent advanced analytic methodologies
*Security Clearance**
+ Full performance in this position requires a Top Secret clearance. Candidates must have a MRPT upon appointment with the ability to obtain Top Secret with SCI access

_NOTE: These statements are intended to describe the general nature and level of work involved for this job. It is not an exhaustive list of all responsibilities, duties, and skills required of this job._

_The ALL NATIVE GROUP companies offer a rewarding career experience. In addition to dynamic career opportunities, we provide competitive salaries, excellent benefits, retirement funding, as well as ongoing training and professional development._

_We are committed to providing the best possible climate for maximum development and goal achievement for all our employees. As subsidiaries of a Native-owned corporation with offices around the world, ALL NATIVE GROUP companies are proud to promote an inclusive and diverse workplace and respect the cultural traditions in the communities where we operate._

_The ALL NATIVE GROUP companies are an equal opportunity employer. All applicants are considered without regard to age, sex, race, national origin, religion, marital status or physical disability. However, preference may be extended to persons of Indian descent in accordance with applicable laws._

_EOE/M/F/Vet/Disabled/Sexual Orientation/Gender Identity/Drug Free Employer_

_SBA 8(a), SDB Certified, HubZone, Buy Indian Certified Native American Tribally-owned company_

\#LI-FF1
*Other details**
+ Pay Type Salary

+ Washington, DC, USA",3.8,"ALL NATIVE GROUP
3.8","Washington, DC","Winnebago, NE",501 to 1000 employees,-1,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Big Data Engineer,-1,"Description Robert Half Technology is looking for an experienced Big DataETL Developer in the Great Pennsylvania area. Responsibilities bull Design, develop, optimize, and maintain data architecture and pipelines that adhere to ETL principles and business goals bull Solve complex data problems to deliver insights that helps our business to achieve their goals bull Create data products for analytics and data scientist team members to improve their productivity bull Advise, consult, mentor and coach other data and analytic professionals on data standards and practices bull Foster a culture of sharing, re-use, design for scale stability, and operational efficiency of data and analytical solutions bull Lead the evaluation, implementation and deployment of emerging tools and process for analytic data engineering in order to improve our productivity as a team bull Develop and deliver communication and education plans on analytic data engineering capabilities, standards, and processes bull Partner with business analysts and solutions architects to develop technical architectures for strategic enterprise projects and initiatives. bull Learn about machine learning, data science, computer vision, artificial intelligence, statistics, andor applied mathematics Skills bull Bachelors degree required Computer Science, MIS, or Engineering preferred bull 5 years of experience working in data engineering or architecture role, 7+ preferred bull Expertise in SQL and data analysis and experience with at least one programming language (PythonPySpark or Scala preferred) bull Exposure to machine learning, data science, computer vision, artificial intelligence, statistics, andor applied mathematics Requirements ETL, Python, Hadoop, BigQuery, Tableau, Power BI, Apache Hive, Impala, Apache Spark Robert Half Technology matches IT professionals with some of the best companies on a temporary, project or full-time basis. From roles in software and applications to IT infrastructure and operations, we provide you unparalleled access to exciting career opportunities. Our personalized approach, innovative matching technology and global network with local market expertise help you find the technology jobs that match your skills and priorities - fast. By working with us, you have access to challenging opportunities, competitive compensation and benefits, and training to enhance your skill sets. From philanthropy to environmental stewardship to employee programs, Robert Half is proud to have an active role in the communities in which we live and work. Our company has appeared on FORTUNE's ""Most Admired Companies"" list every year since 1998. Download our mobile app to take your job search on the go! Contact your local Robert Half Technology office at 888.490.4429 or visit www.roberthalf.comjobstechnology to apply for this job now or find out more about other job opportunities. All applicants applying for U.S. job openings must be authorized to work in the United States. All applicants applying for Canadian job openings must be authorized to work in Canada. 2020 Robert Half Technology. An Equal Opportunity Employer MFDisabilityVeterans. By clicking 'Apply Now' you are agreeing to Robert Half Terms of Use httpswww.roberthalf.comterms-of-use .",3.5,"Robert Half
3.5","Allentown, PA","Menlo Park, CA",10000+ employees,1948,Company - Public,Staffing & Outsourcing,Business Services,$2 to $5 billion (USD),"Adecco, Manpower"
Engineer / Scientist 4,-1,"Engineer / Scientist 4

Level
Experienced
Job Location
Charleston, SC (VNE) - Charleston, SC
Position Type
Full Time
Education Level
Bachelor's Degree
Salary Range
Undisclosed
Travel Percentage
Negligible
Job Shift
Undisclosed
Job Category
Undisclosed
Vickers and Nolan Enterprises (VNE) is an engineering company that provides Government projects and programs with experienced and dedicated system architects, engineers, subject matter experts (in tactical intelligence), and program managers. VNE also develops training courses and tools to prepare warfighters to effectively employ tactical intelligence systems and provide management guidance to the Government organizations that develop these systems.

VNE has earned a reputation for exceptional performance, innovation, agility, and responsiveness in the Intelligence Community (IC). We attack our mission with a comprehensive understanding of the data available and required; skilled research, design, development, integration, and testing of systems and software solutions; expertise in cybersecurity/information assurance and technology; programmatic, acquisition, and logistics support know-how; and our own unique training curricula that enables students to excel at intelligence operations across all levels of the community.

VNE is devoted to improving tactical operations at home and abroad by enabling the seamless transition of data across the intelligence community and developing/integrating solutions to unify operations and intelligence.

VNE is a Service Disabled Veteran Owned Small Business (SDVOSB) founded in 2004 in Stafford, VA.
VNE, LLC is looking for two Secret Cleared Engineer / Scientist 4

Minimum Qualifications:
BS degree in Engineering or Physical Science. Software Engineer only: Working towards the following certifications within one and a half year after assuming duties: Professional Software Engineering Master (PSEM)/Certified Software Development Professional (CSDP) or with COR approval complete a vendor/platform specific certification (e.g., Microsoft Certified Solutions Developer (MCSD), Microsoft Certified Applications Developer (MCAD), Microsoft Certified Database Administrator (MCDBA), Sun Certified Professional (SCP), Red Hat Certification Program (RHCP), CISCO Certified Network Professional (CCNP), CISCO Certified Design Professional (CCDP), Oracle Certified Professional (OCP), etc.)
NOTE – All undergraduate degrees: Bachelor of Science (BS), Bachelor of Arts (BA), or Associate of Science (AS) in Applied Science, Computing, Engineering, and Technology shall be from an Accreditation Board for Engineering and Technology (ABET) accredited program (see www.abet.org)
NOTE – Technology degrees do not qualify as Engineering or Physical Science Degrees.
NOTE – Engineering Positions require diploma/written engineering degrees versus grandfathered degrees based on experience. If a state Professional Engineer (PE) License is required for the performance of the requirement, the government can specify any unique certifications under the “Specific Experience.”
NOTE – Unless otherwise specified, higher education above a labor category’s minimum can be credited as years of experience as long as the higher degree is within the same required field of study as the minimum degree required. The following Educational credit applies: a MS degree equals four (4) years of experience and a PhD degree equals five (5) years of experience.
LIFE CYCLE LOGISTICS LABOR CATEGORIES - DAWIA Certification for Contractors – Contractor personnel that do not have government DAWIA certification courses may demonstrate an equivalency in terms of academic degrees, courses completed, and experience as that of their counterparts in the DAWIA workforce. Equivalency shall be addressed for all Acquisition and Functional Training courses at the required Level 1, 2, or 3 as specified by the Defense Acquisition University website at the time the request for proposal is posted (http://icatalog.dau.mil/onlinecatalog/CareerLvl.aspx).
LABOR CATEGORIES PERFORMING CYBERSECURITY SUPPORT FOR DOD - Prior to performing cybersecurity related work, applicable contractor personnel shall meet specific certification and training requirements in accordance with DoD 8570.1-M, DoDD 8570.1, and subsequent release of DoD 8140-M prior to performing cybersecurity related work. This includes personnel being certified/accredited at the appropriate levels based on task responsibilities. This will be verified by the Contracting Officer who will ensure that contractor personnel are entered in to the Defense Eligibility Enrollment System (DEERS) or other appropriate database. Contractor personnel not certified within 6 months of assignment of cybersecurity duties or who fail to maintain their certified status will not be permitted to carry out the responsibilities of the position, and shall be replaced with an individual who does meet the minimum certification requirements as mandated by DoD.
Ten (10) years of experience in C4ISR, computer vision, machine learning, artificial intelligence, identity management, biometrics, or forensic science to include: Technology Analysis and Assessment, Design Definition, Development of Systems Specification, Systems Analysis, Systems Architecture, Systems/Equipment Integration, Test & Evaluation Criteria, and Logistics support of C4ISR requirements.
Five (5) years of technical experience in support of identity management, biometric enabled intelligence or forensic science.
Experience may be achieved simultaneously.
IAT Level 3.
Secret Level Clearance Required
Job Description:
Employees will perform program management, engineering and related technical activities, such as cyber security, quality assurance, technical documentation development, configuration management and program management support services to the customer base within the Terrestrial Collections and Identity Operations (TCIO) Integrated Product Team (IPT). This task includes systems engineering for requirements, design, prototyping, and testing support.
For Test & Evaluation, see Statement of Work (SOW) section 3.2.4.
For Software Engineering, see SOW 3.2.3 and 3.2.5.
For Cybersecurity, see SOW 3.2.6.
For Lifecycle Logistics, see SOW 3.3. (All qualified applicants will receive a copy of the SOW)
Essential Duties of the Job:
Ability to communicate task requirement information to client in a clear and concise manner.
Must be able to sit and stand for prolonged periods of time, as well as lead and participate in meetings and working groups.
Requires visual acuity to use a keyboard.
Must be able to attend work each day, during scheduled hours, unless on travel or approved time off.
Ability to work on computer for long periods, and communicate with individuals by telephone, email and face-to-face
Physical Demands and Work Environment:
While performing duties of job, employee is occasionally required to stand; walk; sit; use hand to finger, handle or feel objects, tools, or controls; reach with hands and arms; talk and hear.
Employee must occasionally lift and/or move up to 25 pounds.
Specific vision abilities required by the job include close vision, distance vision, color vision, peripheral vision, depth perception, and the ability to adjust focus.
May be exposed to chemicals related to office equipment.
The noise level in the work environment is usually moderate (i.e. general office environment).
Benefits:
401 (K) w/ up to 3.5% Company Match
Health, Dental & Vision Insurance
Basic & Supplemental Life Insurance
Short & Long Term Disability Insurance
Flexible Spending Account
10 Paid Holidays
Paid Time Off (PTO)
Gym Membership (varies by location)
Corporate-Sponsored Events",3.5,"GS5, LLC
3.5","Charleston, SC","Dumfries, VA",51 to 200 employees,-1,Company - Private,Advertising & Marketing,Business Services,$10 to $25 million (USD),-1
"Senior Software Engineer, Backend","$126K-$193K
(Glassdoor est.)","Mercari is the selling app. We make it super easy to sell (or buy) almost anything. We all have things we don't use, never used or simply outgrew. But that stuff still has value. Mercari gives you the power to simply sell it, ship it, and earn some cash for it. Fashion to toys. Sporting goods to electronics. All the brands you know and love. Our mission is simple: to make selling easier than buying. And with 45M+ downloads in the U.S. and 225k new listings every day, we're just getting started.

We are aggressively growing our Backend team to develop large-scale systems with the latest technology.

What you'll be doing:
Coding in Go and PHP
Design, develop, test, deploy, maintain, and improve the backend system for our product
Design distributed systems with microservices architecture running on Kubernetes
Work with Product Managers and Designers for the design and specification of our product
Collaborate with iOS, Android, Web, Machine Learning, and Data engineers to develop new features on our product
Collaborate with QA Engineers to test and deliver the feature with high-quality and high-speed
Solve complex performance problems and architectural challenges
Write and maintain technical documentation
Manage own project requirements, deadlines, and qualities
Mentor software engineers in the same team or project
Requirements:
6+ years of experience in software engineering
Full-time working experience as software engineer with consumer applications
Excellent knowledge of data structures and algorithms
Experience with developing complex software systems scaling to millions of users with production quality deployment, monitoring, and reliability
Experience designing, developing, and managing microservices
Knowledge of software testing and the ability to write testable code and proper tests
An insatiable desire and ability to learn with a positive attitude
Ability to collaborate with team members including Product Managers, Data Scientists, Designer, Engineers, and QA Engineers to solve complex business problems
Ability to mentor engineers in an open, respectful, flexible, and empathetic manner
Nice-to-haves:
Deep knowledge of Go or PHP
Proficient computer science background such as a bachelor's, master's, or Ph.D. degree
Strong knowledge of container and orchestration technologies like Docker and Kubernetes
Experience working on cloud infrastructures like GCP or AWS
Technologies We Use:
Databases: Cloud Spanner & MySQL
Programming Language: Go & PHP
Containers & Orchestration: Docker, Kubernetes
Web Services & Hosting: Google Cloud Platform (GCP) & Amazon Web Services (AWS)
Perks:
Competitive medical, dental, and vision insurance options
401k match
Life & disability insurance
Employee Assistance Program
New parent paid leave
Rocket Lawyer legal services
Fond perks and rewards
Commuter reimbursement
Time when you need it - flexible vacation days
Catered lunches everyday
Team outings and events",2.7,"Mercari
2.7","Palo Alto, CA","Tokyo, Japan",1001 to 5000 employees,2013,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Senior Software Engineer - Data Platform,-1,"About Wellio


We're a growing software FoodTech company with a mission to help you nurture your family with home-cooked meals. Our AI-based Food Intelligence Platform powers Meal Hero, our native and web app that helps people discover, plan, shop, prepare, and enjoy meals at home with ease. This proprietary technology is based on millions of recipes and thousands of ingredients, and it's always improving.

To achieve our goal we have assembled a team of smart, empirically motivated, disagreeable givers who care about making a difference in the world. We believe that using technology, collaboration, innovation and diversity we can transform the way people eat, cook, and share meals. Wellio was acquired during the summer of 2018 by the Kraft Heinz Company.

Learn more at about.mealhero.com

Try Meal Hero on the web or download the app from the Apple App Store or Google Play Store

As a member of our data pipeline and operations team, you'll work with other engineers, data scientists, and product managers to enable the highest quality data products in our Food Intelligence Platform.

What you will do
Collaborate with a team of data scientists, data engineers, and product managers to develop food-related data products
Design, build, maintain, and improve a performant and highly scalable data platform to support both internal and external use cases. We give broad leeway to implement your best architectural decisions. Use cases for this core data include:
two-way flow of data to user-facing apps via microservices
structuring both core data and data exhaust for training machine learning models
Work with our data scientists to design and build a models platform that leverages and supports online learning and machine teaching to develop industry-leading models in the food and health space
Work with data scientists and engineers to build a CI/CD system for our ever-improving models that allows their performance to be monitored and improved in an automated manner
Basic qualifications
You are proficient in writing production-quality code (preferably in Python) and in software design best practices (minimum 3 years experience)
You are familiar with the software development lifecycle and interested in helping to maintain high quality software through CI/CD, TDD, and code reviews
Experience designing, building, and maintaining RESTful APIs
You previously worked with GCP, AWS, or another PaaS
Experience with relational and non-relational databases
Experience in system design and architecture
Preferred qualifications
Experience building both streaming and scheduled data pipelines (experience with Airflow/Cloud Composer is a plus)
Experience with containers and orchestration (e.g. Docker, Kubernetes)
Experience with industry-standard storage systems (e.g. Elasticsearch, Redis)
About you
You enjoy collaborating as part of a small, agile, and dynamic team where everyone is valued
You believe ""done is better than perfect"" and enjoy helping to ship features and quantify the right areas for iterative improvement
You enjoy both learning and teaching, and enjoy working with others from whom you can learn and who can learn from you
You have a passion for food and nutrition, and are excited to use your skills to help our customers nourish themselves
You believe that work should be fun and enjoy working with others
You like to try new things and believe in failing fast
If you got this far, perhaps you're the person we're looking for. We look forward to your application.",-1,Wellio,"San Francisco, CA","San Francisco, CA",1 to 50 employees,2017,Company - Public,Internet,Information Technology,Unknown / Non-Applicable,-1
Senior Data Engineer,-1,"As a Certified B Corporation, AeroFarms is a mission-driven company with global headquarters in Newark, NJ, championing indoor vertical farming and fundamentally transforming agriculture. Recognized by Fast Company as one of the Worlds Most Innovative Companies and by Inc.com as one of the Top 25 Disruptive Companies in the World, AeroFarms is scaling to meet the demand for our fresh, locally grown produce that is setting new culinary standards, and we need someone special who can bring their experience in recruiting to help us grow further. Must be aligned with our mission and passionate about making a difference.

We have:
An incredible change-the-world company with the eyes of the world focused on our success.
A team of motivated, intellectually-curious individuals to support you.
Backed by some seriously impressive firms including Goldman Sachs, Prudential, leading VCs, and strategic partners with a view on global expansion.
Job Description

We are looking for a highly-motivated Senior Data Engineer who will be responsible for accessing, moving, processing, modeling and managing large data sets in a fault-tolerant, scalable and performant manner. The ideal candidate will have a team first mentality and be a creative problem solver. This is a fantastic opportunity to engage in a positive, cutting-edge, and creative work environment that offers excellent benefits and rewards.

Responsibilities:
Develop a data quality framework to ensure delivery of high-quality data and analyses to stakeholders.
Develop and improve the current data architecture, data quality, monitoring and data availability.
Develop and manage stable, scalable data pipelines that cleanse, structure and integrate disparate big data sets into a readable and accessible format for end user analysis and targeting the use of stream and batch processing architectures.
Collaborate with Data Scientists to implement advanced analytics algorithms that exploit our rich data sets for statistical analysis, prediction, clustering, Machine Learning (ML), and modeling.
Develop and support continuous integrations build and deployment processes which use Jenkins, Docker, Git, etc.
Define and implement monitoring and alerting policies for data solutions.
Apply business understanding and a technology know-how to cutting edge Data Science problems.
Play a leading role in architecture design and implementation of next generation BI solutions.
Effectively communicate with various teams and stakeholders, escalate technical and managerial issues at the right time and resolve conflicts.
Peer review work. Actively mentor more junior members of the team, improving their skills, their knowledge of our systems and their ability to get things done.
You have:
Bachelors Degree in Computer Science, Engineering, Mathematics, Physics, or IT related field required.
Masters Degree in Computer Science or IT related field preferred.
5+ years of experience with detailed knowledge of data lake, data warehouse technical architectures, infrastructure components, ETL/ELT and reporting/analytic tools.
5+ years of hands-on experience in using advanced SQL queries (analytical functions), experience in writing and optimizing highly efficient SQL queries.
2+ years of programming experience using Javascript.
Experience with time series database technologies like TimescaleDB preferred.
Experience with analytical tools like Tableau preferred.
Experience working with AWS technologies including, EMR, S3, or RDS.
Experience with other data lake/data warehouse technologies including, Snowflake or similar solutions built around Hive/Spark etc.
Proven track record of delivering big data solutions batch and real-time.
Ability to design, develop and automate scalable ETL and reporting solutions that transform data into accurate and actionable business information.
Comfortable working with business customers to gather requirements and gain a deep understanding of varied datasets.
Experienced in testing and monitoring data for anomalies and rectifying them.
Knowledge of software coding practices across the development lifecycle, including Agile methodologies, coding standards, code reviews, source management, build processes, testing, and operations.
Familiar with build and deployment tools (e.g, Jenkins).
Some experience in Machine Learning (ML), AI and deployment of models would be preferred.
Familiar with other technologies like Kafka, microservices, React, and GraphQL preferred.
Powered by JazzHR",3.4,"AeroFarms
3.4","Newark, NJ","Newark, NJ",51 to 200 employees,-1,Company - Private,Food Production,Agriculture & Forestry,Unknown / Non-Applicable,-1
Principal Data Engineer,"$133K-$247K
(Glassdoor est.)","What if you could use your technology skills to develop a product that impacts the way communities' hospitals, homes, sports stadiums, and schools across the world are built? Construction impacts the lives of nearly everyone in the world, and yet it's also one of the world's least digitized industries, not to mention one of the most dangerous. That's why we're looking for a talented Principal Data Engineer to join Procore's journey to revolutionize a historically underserved industry.

As a Principal Data Engineer on our Data Engineering team, you'll drive solutions to wide-ranging data engineering and infrastructure challenges for product and internal operations. You'll partner with a group of highly skilled developers, engineers, architects, and data scientists to drive strategy, provide technical leadership, and collaborate on defining best practices around data engineering.

This position will report into the Director, Data Engineering, and has the opportunity to be based in our Carpinteria, CA, or Austin, TX offices. We're looking for someone to join us immediately.

What you'll do:
Provide technical leadership for efforts around tooling and infrastructure that enable teams to efficiently complete and maintain data science projects
Partner with teams on modeling and analysis problems—from transforming problem statements into analysis problems, to working through data modeling and engineering, to analysis and communication of results
Lead code reviews, design, and best practices
Coach and mentor senior engineers
Participate in the evolution of Data Engineering at Procore
Create and share best practices for the development and deployment of machine learning based solutions
Work alongside our Product, QA, UX, and Prototype Engineering teams, you'll leverage your experience and expertise in this space to influence our product roadmap, developing innovative solutions that add additional capabilities to our product suite
What we're looking for:
BS degree in Computer Science, a similar technical field of study, or equivalent practical experience is required; MS or Ph.D. degree in Computer Science or a related field is preferred
7+ years of experience in a Data Engineer role
Experience with AWS (EC2, EMR, RDS, Redshift), JAVA, PostgreSQL, Spark, Snowflake, and Data pipeline/streaming tools (Kafka) is preferred
Experience building and optimizing data pipelines, architectures, and data sets
Successful history of manipulating, processing, and extracting value from large disconnected datasets
Deep knowledge of stream processing and highly scalable 'big data' data stores
Demonstrated experience designing or implementing an enterprise-wide data strategy
Experience supporting and working with cross-functional teams in a dynamic environment
Strong oral and written communication skills
About Us
Procore Technologies is building the software that builds the world. We provide cloud-based construction management software that helps clients more efficiently build skyscrapers, hospitals, housing complexes, and more. Our headquarters is located on the bluffs above the Pacific Ocean in Carpinteria, CA, with growing offices worldwide. Check us out on Glassdoor to see what others are saying about working at Procore!

We are an equal opportunity employer and welcome builders of all backgrounds. We thrive in a diverse, dynamic, and inclusive environment. We do not tolerate discrimination against employees on the basis of age, color, disability, gender, gender identity or expression, marital status, national origin, political affiliation, race, religion, sexual orientation, veteran status, or any other classification protected by law.

Perks & Benefits
You are a person with dreams, goals, and ambitions—both personally and professionally. That's why we believe in providing benefits that not only match our Procore values (Openness, Optimism, and Ownership) but enhance the lives of our team members. Here are just a few of our benefit offerings: competitive health care plans, flexible paid time off (Procore Values Time), employee enrichment and development programs, and volunteer days.",4.2,"Procore Technologies
4.2","Carpinteria, CA","Carpinteria, CA",1001 to 5000 employees,2002,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Senior Data Engineer,-1,"About us:

CLARA analytics (""CLARA"") drives change in the commercial insurance markets with easy to use artificial intelligence (AI) based products that dramatically reduce claim costs by anticipating the needs of claimants and helping align the best resources to meet those needs. Leading examples of our products include CLARA Providers, an award-winning service with a provider scoring engine that helps rapidly connect injured workers with top performing doctors and getting them on a path to speedy recovery; and CLARA claims, an early warning system that helps frontline claims teams efficiently manage claims, reduce escalations and understand the drivers of complexity. CLARA’s customers include a broad spectrum from the top 25 insurance carriers to small, self-insured organizations.
This is a chance to get in early with a rapidly growing Silicon Valley company in the InsureTech space built using AI tools and to participate in developing the next generation of truly game-changing products. Job title and compensation will be adjusted as appropriate to meet the experience level of the right candidate.

About the role:

We are looking for a Senior Data Engineer to help build our data infrastructure using Apache opensource products in the Hadoop ecosystem. The candidate should be very comfortable working in a cloud environment like AWS or GCP and able to process both structured and unstructured data at scale. This role requires active development in one or more of the CLARA products, to enrich standardized data and facilitate our Data Science team with feature engineering and ML workflows. The ideal person needs to be comfortable juggling multiple priorities and working with application engineers, data scientists, product managers and product delivery team.



Responsibilities:

· Contribute to development projects for key CLARA products using customer data on insurance Claims, Bills, Medical Providers, Attorneys, etc.
· Actively use technologies like Apache Spark, Apache Hive and other tools in the Hadoop ecosystem to process and enrich data, catalog it and ingest into a data lake
· Use both SQL and NoSQL databases to store and index data. Create APIs for accessing this data for both internal teams and external customers
· Contribute to developing frameworks that allow ingesting data at massive scale
· Build ETL pipelines using Apache Airflow and integrate with multiple components and data sources and sinks
· Work with Data Science team to facilitate feature engineering, feeding into the AI modules that generate scores and predictions using enriched data
· Develop expertise in at least one CLARA product area and become the go-to person for it
· Effectively collaborate within and across other teams including Application engineering, Data Science, Product Management and Product Delivery teams
· Deliver high quality code in a timely manner that is well tested and meets CLARA’s performance guidelines

Requirements

· Bachelors or Master’s degree in Computer Science or related field with 3-6 years of relevant experience

Experience with the following software/tools is highly desired:
Apache Spark, Hive, Kafka, etc
SQL and NoSQL databases like MySQL, Postgres, DynamoDB, Elasticsearch
Workflow management tools like Airflow
AWS cloud services: RDS, AWS Lambda, AWS Glue, AWS Athena, EMR
Familiarity with Spark programming paradigms (batch and stream-processing)
RESTful API services
· Strong programming skills in at least one of the following languages: Java, Scala, C++. Familiarity with a scripting language like Python as well as Unix/Linux shells
· Excellent command of SQL and use of Analytic tools like Apache Presto or AWS Athena is a plus
· Basic knowledge of Machine Learning and AI
· Experience working with cross-functional teams in a fast-paced environment
· Ability to author Technical Feature Specifications and implement high quality code in collaboration with other members of the Data Engineering team
· Strong familiarity with services for one of the cloud vendors (AWS, GCP)

Benefits
● 401(K)
● Monthly wellness/gym reimbursement
● Public Transportation cost assistance
● Skill building reimbursement",3.3,"CLARA analytics, Inc.
3.3","Santa Clara, CA","Santa Clara, CA",1 to 50 employees,2016,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Senior Machine Learning Engineer,-1,"We are looking for a Data Scientist - Algorithms and Software Developer - to build new and amazing data products and algorithms. Bring data science into Human Resources: Extract knowledge about people, companies and positions, understand data and build learning engines to match the right person to the right position.

You Are:

Experienced in development and research of Machine Learning and/or NLP
(Natural Language Processing) algorithms in the industry (3+ Years)
Experienced in software development in the industry (3+ Years)
M.Sc. or above in Computer Science or other quantitative field (Mathematics, Statistics, Physics etc.)
Able to take product requirements and turn them into working software using advanced algorithms - from research to production
A motivated, self-thinker, explorer, passionate, always learning data enthusiast
Startup experience - an advantage

Your Skill Set:

Experience in Machine learning / Deep Learning / Prediction models and NLP techniques
Strong coding skills using big data tools and languages (Python / Java / Hadoop / Spark / Mongo DB etc.)
Agile person - getting things done – really wants to make products happen fast
Working with databases and large, complex data sets
Deep understanding of data

Your Responsibilities:

Creating algorithms and software to solve hard problems related people and jobs (HR-tech)
Extracting knowledge from texts and learning prediction models for matching the best candidates to positions
Analyzing complex data sets that few people in the world have access to
Working in a team to find unique solutions to unsolved universal problems using different data analysis techniques",3.3,"Cadre Inc
3.3","Santa Monica, CA","Santa Monica, CA",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
"Senior SW Engineer, Data Science ( Kubernetes/ Docker ) - Remote USA","$72K-$141K
(Glassdoor est.)","Job Description

If you dream of a job working in a field where all the hard problems are solved and you get to re-use previous research to get your job done, you need not apply. If, however, you are someone who wants to tackle problems that truly are on the cutting edge, then we encourage you to keep reading.

Data Science is an emerging field within cyber security. FireEye, given its deep expertise and comprehensive view on the advanced threat landscape, is uniquely positioned to enable data scientists to have major impact within our industry, company, and across our customer base. Detecting security breaches using machine learning and data analytics is an unsolved problem (this is not handwriting recognition folks) and has huge potential.

If you are someone who wants to be on the cutting edge of a high profile industry, who wants to make an impact by pushing both fields of data science and cyber security forward, you may be the perfect candidate to help us on our mission.

What you will do:
Develop, and manage data systems to ingest and process data at massive scale
Identify data sources both internally and externally that we can use to find evil.
Contribute towards the architecture and design of software solutions for long-term storage and retrieval.
Identify and implement data exploration technologies. Create dashboards and implement analytical tools for exploration
Work with data scientists to productize ML models and assist product teams with ML model releases into end products.
Collect requirements, design, and build backend components and tools to run ML models, assess ML model efficacy, manage large scale datasets, and generate features for ML models
Contribute to the evolution of coding and design practices within the organization.
Review code base commits and contribute to the growth of team members.
Qualifications

Requirements
Ability to work in an iterative, agile development environment.
Experience implementing ETL processes and building data pipelines
Experience developing reliable distributed systems.
Experience in Data modeling and schema design
Strong knowledge of a variety of operating systems, networking fundamentals, software design and programming best practices.
Experience with use of a wide array of algorithms and data structures.
Deep understanding and experience of going through the entire life cycle of building software platforms and products
Deep knowledge of various AWS services and associated tools
Strong experience developing in Python 3
Experience developing in at least 1 of the following: C, Go or Java
Experience with RDBMS, such as PostgreSQL or MySQL, as well as NoSQL
Experience with Kubernetes and Docker.
Experience deploying products in AWS
Additional Qualification:
Ability to pick up, work with and explore new analytical tools
Strong experience with DevOps practices and common tooling
Strong communication skills.
Ability to work with loosely defined requirements.
Additional Information

At FireEye we are committed to our #OneTeam approach combining diversity, collaboration, and excellence. All qualified applicants will receive consideration for employment without regard to race, sex, color, religion, sexual orientation, gender identity, national origin, protected veteran status, or on the basis of disability. Requests for accommodation due to disability can be sent directly to HR-Accommodations@FireEye.com.",3.3,"FireEye, Inc.
3.3","Denver, CO","Milpitas, CA",1001 to 5000 employees,2004,Company - Public,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,"Palo Alto Networks, Tanium"
Development/Operations Engineer,"$60K-$108K
(Glassdoor est.)","Responsibilities

The newly formed Cancer Data
Sciences group at the UCLA David Geffen School of Medicine and UCLA Jonsson
Cancer Center is seeking a Programmer/Analyst with extensive research and
development experience. The successful candidate will be working with a diverse
team of Data Scientists, developing new quantitative strategies to improve our
understanding and ability to treat cancer. Programmer/Analysts in our team are
passionate about applying their knowledge of software development and design to
improve scientific research. They develop scalable and distributed software
solutions that maximize utilization of both local high-performance computer
infrastructure and a growing set of cloud-based assets. Our datasets comprise
several petabytes, and are growing rapidly, creating fascinating problems in
storage, access, parallelization, distributability, optimization,
containerization and core algorithm design. This requires a strong background
in computer science, providing a platform for technical leadership, but linked
to strong personal communication and leadership skills, to help ensure insights
are broadly adopted. The successful candidate will be helping us perform
research that will transform the lives of cancer patients.

Your responsibilities will be
wide-ranging, and include an emphasis on using design, analysis and programming
skills to create systems that improve code quality and boost productivity of
the entire team. You will help drive professional level design and development
practices throughout the entire team, and serve as a local point of expertise
for workflow optimization and containerization. You will typically have one or
two major and several minor projects at any point in time, making appropriate
prioritization, time management and reporting across these. We are in a rapid
growth phase, and the successful candidate will be involved in hiring,
recruiting, onboarding and mentoring junior data scientists and software
engineers. You will have experience in either data-intensive research and
software engineering, or in a large-scale professional software engineering
environment.
Qualifications
Extensive applied software-engineering experience (5 years minimum, 10 years preferred)
Bachelor's degree in Software Engineering or Computer Science (highly desired)
Detailed working knowledge of C++, Perl or Python programming/scripting design
Working knowledge of software development tools and CASE tools
Strong verbal, interpersonal, and written communication skills
Experience with the full software development process including gathering requirements, turning them into a design, implementing the design, and validating the implementation against the original requirements.
Knowledge of LINUX/Unix operating system, and source-code versioning systems
Strong computer science knowledge, including software design patterns
Knowledge of SQL and data modeling
Working knowledge of containerization (e.g. Docker, Singularity)
Experience developing R-based code
Experience with machine-learning, bioinformatics and cancer or molecular biology
Knowledge of relational database software (e.g. Oracle, Postgres)
Familiarity with distributed programming
Understanding of core LAN networking protocols including ethernet, IP, TCP, UDP, ICMP

UCLA is an Equal Opportunity/Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or protected Veteran status.",4.0,"UCLA Health
4.0","Los Angeles, CA","Los Angeles, CA",5001 to 10000 employees,1919,Company - Public,Health Care Services & Hospitals,Health Care,Unknown / Non-Applicable,"Cedars-Sinai Medical Center, Loma Linda University Health, Harbor Hospital"
Big Data Engineer,-1,"We are looking for a Senior Engineer with cloud infrastructure experience to join our client s Big Data Platform Operations team. Our client provides cloud infrastructure to over 500 internal engineering and technical business users (Data Scientists and Analysts). This role will provide advanced operations support, contribute to automation and system improvements, and work directly with user teams to support platform adoption. ServerLogic has partnered with a local company to identify a Sr Data Engineer for a long-term project. Responsibilities Design and build product features in collaboration with business and IT Design reusable components, frameworks, libraries like User Defined Functions Build continuous integration and test-driven development environment Performancescalability tuning, algorithms and computational complexity Develop architecture and design patterns to process and store high volume data sets Participate in an Agile Scrum methodology to deliver high - quality software releases every 2 weeks through Sprints Troubleshoot production support issues post - deployment and come up with solutions as required Experience Good understanding and application of modern data processing technology, such as Snowflake, SQL, Spark, Hadoop ecosystem technologies, and others A Bachelor's degree in Business, Information Technology or related field 2+ years experience in a professional organization collaborating across multiple functions Familiarity with Agile project delivery methods Experience with AWS components and services (E.G. EMR, S3, and Lambda) Experience with Jenkins, BitbucketGitHub and scheduling tools like Airflow Strong programming, Python, shell scripting and SQL Good understanding of file formats including JSON, Parquet, Avro, and others Experience with data warehousesRDBMS like Oracle, Teradata, Snowflake Experience with data warehousing, dimensional modeling and ETL development Demonstrable ability to quickly learn new tools and technologies Machine learning frameworks statistical analysis with Python, R or similar Exceptional interpersonal and communication skills (written and verbal) Passion for data with demonstrated ability to use data to tell a story and influence decision making Educational qualifications MSBS in Computer Science or related field.",3.5,"Serverlogic
3.5","Beaverton, OR","Tigard, OR",1 to 50 employees,1992,Company - Private,IT Services,Information Technology,$10 to $25 million (USD),-1
Staff Platform Engineer (Knowledge Graph),-1,"Crunchbase is the go-to destination to find businesses to sell to, market to, research, work for, invest in, and buy from. We’re aggressively capitalizing on this to become the single place to find information on the world’s businesses.

We are hiring a Senior Platform Engineer skilled in Python to be one of the first engineers on our brand new Knowledge Graph Team. We are seeking a candidate with strong Backend Engineer fundamentals, extensive experience in metadata design, implementation, system architecture design and backend data service development.

Engineering at Crunchbase

The Crunchbase engineering team is a dynamic, fast paced team that is committed to quickly delivering features, evaluating their performance, and iterating towards the product vision shared by the company. We are organized in vertical teams that include cross-functional engineers as well as functional guilds aimed at working tightly with the product team to deliver high quality code while iterating quickly on features. We value open and honest communication, and strive to create an environment where opinions and views can be shared and considered in an effort to reach the best decision.

Knowledge Graph Team at Crunchbase

The Crunchbase Knowledge Graph team is working on automatically processing massive amounts of unstructured data, understanding the content of the information, categorizing the information, extracting useful information from text, and converting the data into a knowledge graph.
What you will do:
Help bring our data science models into live production, building features like company recommendations.
Help design, evaluate and improve machine learning model based features.
Work in a team with data scientists and data engineers to quickly deliver features from cradle to production.
Work closely with the Product team to define the scope of the features and iterate on features
Write high quality maintainable and tested code that runs as part of our production platform

Who you are:

You have a solid understanding of computer science and software engineering fundamentals.
You have strong Python foundations
You have experience with Kubernetes, Kafka, and an eventual consistent system
You have successfully built and shipped Python services in a microsystem architecture
You care about agile software, cross team collaboration and data driven development and evaluation.

What Crunchbase offers:

Competitive salary and equity
Generous Reimbursement policy for learning and development activities
Daily catered lunches and plenty of snacks
Fitness reimbursement (to work off the catered lunches)
Flexible Paid Time Off (PTO)
Volunteering Paid Time Off
Incredible medical, vision and dental benefits for employees and their families
Free One Medical Group membership for employees and their families
401(k) and Roth plans, and free annual financial adviser check-in
Monthly commuting stipend
Free Lyft rides anywhere in the Bay Area after late nights at the office
Prime location in the Financial District of SF, near BART and Muni stops
Carbon offsets for all employees
A team of creative, transparent entrepreneurs driven to accomplish our mission
Crunchbase does not discriminate on the basis of race, creed, color, ethnicity, national origin, religion, sex, sexual orientation, gender expression, age, height, weight, veteran status, military obligations, or marital status. Every day our team is honored to work with entrepreneurs and innovators from every corner of the globe, and we aim to build a team that reflects the diversity of our customers. Each individual at Crunchbase brings their own perspectives, work experiences, lifestyles, and cultures with them, and we believe that a more diverse team creates more innovative products, provides a better service to its customers, and helps us all grow and learn as individuals.",4.4,"CrunchBase
4.4","San Francisco, CA","San Francisco, CA",51 to 200 employees,2007,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Senior Data Scientist,-1,"Job Description
Title: Senior Data Scientist
Location: Washington, DC
Salary: $140,000 - 180,000
Contact: Paul Chatlos, pchatlos@smithhanley.com

Senior Data Scientist The Position

We are seeking a data scientist to participate as a key team member in envisioning, designing, coding, testing and improving the algorithms that are central to our mission as a company.

Some key challenges will include:

-Identifying external datasets and developing API or other methods for accessing them
-Fluidly self-educating on existing methods for modeling end-user behavior in a variety of contexts, or developing new methods for doing this when necessary
-Designing experiments to answer targeted questions
-Teaming with developers to embed algorithms in applications
-Understanding business economics, user motivation and other contextual information in order to guide analytical trade-offs, with a focus on ""minimum viable algorithm"" followed by intensive, iterative improvement

Senior Data Scientist The Successful Candidate

A successful candidate will be comfortable in a fluid, entrepreneurial environment, but one that is focused on developing reusable software applications, not bespoke analytical solutions.
He or she will likely have many of the following characteristics:
-8+ years professional experience using statistical software (R, S-Plus, SAS, or similar), relational and NoSQL databases and scripting languages (such as Python). Ideally, R and Python
-Familiar with general-purpose machine learning methods, such as neural networks, Bayesian networks, regression, decision trees and so on. Capable of self-teaching new algorithmic methods easily
-Passionate about using data to drive strategy and business recommendations.
-Well-rounded top performer who is able to ""crunch the numbers"" one minute, and critically think through strategic issues the next
-Self-starter with a high degree of rigor, organization, and discipline to get things done
-Able to communicate as effectively in delivering complex data-driven findings with businesspeople, as in discussing machine-learning specifications with engineer

Senior Data Scientist Academic Qualifications
-Very strong math, physics, CS or similar degree from a leading program
-Extremely high SAT or similar standardized test scores",4.5,"Smith Hanley Associates
4.5","Washington, DC","New York, 061",1 to 50 employees,1980,Company - Private,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,"Kforce, PageGroup, Robert Half"
Senior Machine Learning Engineer,"$130K-$211K
(Glassdoor est.)","Leading the future of luxury mobility

Lucid’s mission is to inspire the adoption of sustainable energy by creating the most captivating luxury electric vehicles, centered around the human experience. Working at Lucid Motors means having a shared vision to power the future in revolutionary ways. Be part of a once-in-a-lifetime opportunity to transform the automotive industry.

We are looking for a Senior Machine Learning Engineer who enjoys thinking big and looking to make their mark on an incredibly fast-growing company. If building large and building fast, working with a very talented team of engineers, and collaborating with the brightest mind in the Automotive industry is what you like, Lucid is the best to experience it.
The Role
Work on state-of-the-art large-scale machine learning projects
Perform advanced platform research and lead the architecture design for efficient ML model training and deployment in scale
Adapt machine learning and data mining algorithms to solve problems across several teams
Develop new machine learning models using structured and unstructured data.
Perform model training, hyper parameter tuning and model parallelization and distributed training to achieve top performance for accuracy and latency.
Perform research and utilize state-of-the-art and best practices for model compression, quantization and optimization for deployment
Perform and streamline continuous model performance monitoring and debugging in production
Research and develop ML computing paradigm such as in-memory on-device or in the cloud distributed learning and employ concepts such as online learning, etc.
Articulate business questions and use mathematical techniques to translate ideas to actionable projects to arrive at an answer.
Partner with internal stakeholders on projects to identify and articulate opportunities, see beyond the data to identify solutions that will raise the bar for decision making.
Use quantitative analysis and the presentation of data to see beyond the numbers and understand what can improve our processes.
Engage broadly with the organization to identify, prioritize, frame, and structure complex and ambiguous challenges, where advanced AI projects or tools can have the biggest impact.
Qualifications
Bachelor’s or advanced degree (Masters/PhD) in computer science or STEM field.
2+ years of deploying machine learning solutions in the cloud or edge devices.
Or 4+ years of experience working as Machine learning scientist or Data Scientist collaborating on implementing end-to-end ML pipelines
Programming experience with at least one modern language such as Java, Scala, C++, C# or Python including object-oriented design
Proficiency with machine/deep learning frameworks such as TensorFlow, Keras, Pytorch, Caffe, MXNet, etc
Experience in creating production level ML models for training, validation, and inference leveraging real-time systems
Experience working with cloud-based accelerated computing, GPU/TPU, CUDA, parallel computing
Experience with major cloud computing services for model training and hyper-parameter tuning
Experience deploying containers, scaling machine learning algorithms and monitoring programmatically, using open source ML platforms or managed services.
Software development skills; unit testing, integration testing, monitoring and debugging
Critical Thinking and good communication skills
Nice to Haves
Ph.D. or Masters in Computer Science, Statistics, Operations Research or related field.
Technical expertise and in-depth knowledge in one or more of the following areas:
-- 1-Anomaly detection and signal processing
-- 2-Advanced machine learning and unsupervised learning
-- 3-Deep learning, convolutional neural networks. RNN, LSTM or Machine Vision
-- 4-Bayesian inference
-- 5-Natural Language Processing (NLP), text mining, sentiment analysis, information retrieval, etc.
Experience with model compression, quantization and optimization is a huge plus
In-depth theoretical knowledge of Statistics, traditional ML, Deep Learning, CNNs and optimization algorithms.
Experience with RESTful API design and Web based application development (e.g. ASP .NET, Javascript or C#)
Experience with analytics and big data tools (Spark, SQL, Presto, Hive) to create horizontally scalable solutions.
Technical expertise and in-depth knowledge in one or more of the following areas:

1-Anomaly detection and signal processing
2-Advanced machine learning and unsupervised learning
3-Deep learning, convolutional neural networks. RNN, LSTM or Machine Vision
4-Bayesian inference
5-Natural Language Processing (NLP), text mining, sentiment analysis, information retrieval, etc.


Be part of something amazing

Come work alongside some of the most accomplished minds in the industry. Beyond providing competitive salaries, we’re providing a community for innovators who want to make an immediate and significant impact. If you are driven to create a better, more sustainable future, then this is the right place for you.

At Lucid, we don’t just welcome diversity - we celebrate it! Lucid Motors is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, national or ethnic origin, age, religion, disability, sexual orientation, gender, gender identity and expression, marital status, and any other characteristic protected under applicable State or Federal laws and regulations.

To all recruitment agencies: Lucid Motors does not accept agency resumes. Please do not forward resumes to our careers alias or other Lucid Motors employees. Lucid Motors is not responsible for any fees related to unsolicited resumes.",3.9,"Lucid Motors
3.9","Newark, CA","Newark, CA",1001 to 5000 employees,2007,Company - Private,Transportation Equipment Manufacturing,Manufacturing,Unknown / Non-Applicable,-1
Cloud Engineer,-1,"Job Description
Responsibilities:
Develop and implement technical efforts to design, build, and deploy AWS applications at the direction of lead architects, including large scale data processing, computationally intensive statistical modeling, and advanced analytics
Participate in all aspects of the software development life cycle for AWS solutions, including planning, requirements, development, testing, and quality assurance
Provide guidance, thought leadership and mentorship to development teams to build cloud competencies
Provide innovative thought leadership around Mathematica’s cloud solutions strategy and approach, including AWS best practices and market trends
Position Requirements:

6+ years of experience architecting, designing, developing and implementing cloud solutions on AWS platforms
Demonstrated experience with designing and implementing solutions using AWS platform and tools, such as: EC2, S3, Redshift, API Gateway, Lambda, DynamoDB, CloudFormation, RDS, VPC, IAM and security, QuickSight, CloudTrail, Config, CloudWatch, SNS, AMI generation
Understanding of and experience with the five pillars of a well-architected framework
Knowledge of SQL, R, and Python for data manipulation and statistical analysis is desirable
Familiarity with federal security regulations and standards (e.g. HIPAA, FISMA, FIPS, NIST, and FedRAMP)
Experience with security, especially knowledge of FedRAMP, HIPAA, PII/PHI, is desirable
Experience in several of the following areas: database architecture, ETL, Business Intelligence, Big Data, Machine Learning, Advanced Analytics
Proven ability to work collaboratively with multi-disciplinary teams of business analysts, developers, data scientists, and subject matter experts
Strong written, verbal and interpersonal communication skills
AWS Certifications (such as AWS solutions architect or other specialty certifications) are a plus
Bachelor's degree or equivalent combination of education and experience; degree in computer science, mathematics or related field preferred
Experience with other cloud platforms like Google Cloud Platform (GCP) is a plus",4.8,"RICEFW Technologies Inc
4.8","Princeton, NJ","East Lansing, MI",51 to 200 employees,2009,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Senior Software Engineer / Team Lead,"$112K-$220K
(Glassdoor est.)","Join our team dedicated to developing and executing innovative solutions in support of customer mission success.

Job Description:

Novetta has an exciting opportunity for a self-motivated and accomplished Computer Scientist to lead our entity analytics team. You will work on complex projects involving data analysis, software engineering, and deploying software in a cloud computing environment. The team combines data from disparate sources to visualize the complex relationships between entities. This effort involves large scale data integration and entity resolution leveraging a best in class Novetta product. We are looking for a flexible problem solver with significant technical experience to lead a team providing unique solutions for our customers and stakeholders.

Responsibilities include:
Lead a technical team of software engineers and computer scientists, working within a larger ecosystem delivering an Enterprise capability.
Navigate customer and prime environment, manage resources within and across team, and assist team with professional and technical growth.
Deploy applications on a large-scale data processing cluster using AWS technologies.
Design and implement entity correlation strategies that are tailored to mission needs and unique data qualities.
Develop algorithms and visualization tools to help stakeholders understand their data and prioritize new data sources.
Develop and integrate applications to automate ingestion, processing and monitoring of data
Develop and maintain tools to support operations and maintenance of production and development computing clusters.
Basic Qualifications:
Experience leading a team of software engineers.
A Bachelor's degree in computer science or related field and a minimum of 5 years of experience; or a Master's degree in computer science or related field and a minimum of 3 years of experience.
Experience in software development/engineering including requirements analysis, software development, installation, integration, evaluation, enhancement, maintenance, testing and problem diagnosis/resolution.
Software development experience on Linux-based systems in Python or shell scripting or JavaScript.
Experience developing against full-featured REST APIs and using a command line interface
Desired Skills:

Should meet a minimum of 3:
Software development experience with JavaScript, Python, or other modern programming languages.
Hands-on experience with Spark.
Experience working with Databricks
Interest in statistical analysis, machine learning, or data science.
Experience with entity resolution products or a background in data matching theory and technologies.
Experience developing applications in AWS.
Security Clearance:
The candidate must have a TS/SCI with Poly.
Novetta, from complexity to clarity.

Novetta delivers highly scalable advanced analytics and secure technology solutions to address challenges of national and global significance. Focused on mission success, Novetta pioneers disruptive technologies in machine learning, data analytics, full-spectrum cyber, cloud engineering, open source analytics, and multi-INT fusion for Defense, Intelligence Community, and Federal Law Enforcement customers. Novetta is headquartered in McLean, VA with over 1,000 employees across the U.S.

Our culture is shaped by a commitment to our core values:

Integrity • We hold ourselves accountable to the highest standards of integrity and ethics.

Customer Success • We strive daily to exceed expectations and achieve customer mission success.

Employee Focus • We invest in our employees' professional development and training, respecting individuality and fostering a culture of diversity and inclusion.

Innovation • We know that discovering new and innovative ways to solve problems is critical to our success and makes us a great company.

Excellence in Execution • We take pride in flawless execution as we build a company that is best in class.

Earn a REFERRAL BONUS for the qualified people you know.

For more details, or to submit a referral: bit.ly/NovettaReferrals

Novetta is an equal opportunity/affirmative action employer.

All qualified applicants will receive consideration for employment without regard to sex, gender identity, sexual orientation, race, color, religion, national origin, disability, protected veteran status, age, or any other characteristic protected by law.",4.5,"Novetta
4.5","Chantilly, VA","Mc Lean, VA",501 to 1000 employees,2012,Company - Private,Enterprise Software & Network Solutions,Information Technology,$100 to $500 million (USD),"Leidos, CACI International, Booz Allen Hamilton"
Data Fusion Engineer with Security Clearance,"$48K-$109K
(Glassdoor est.)","Description Job Description: Looking for work-life balance? Leidos offers generous leave and accommodating flex-time to help you juggle your personal and professional life. Are you a Software Engineer with experience finding and aligning signals across multiple modalities (image, video, audio, lidar, etc..)? Do you want to implement and customize algorithms to fusion multiple data modalities? If so we are looking for you, our next Data Fusion Engineer to work in Arlington, VA. We need you to be competent in Python and have the ability to read code in other programming languages like Java and C++ as well as have experience working with ML libraries like SciKit Learn, TensorFlow, Keras along with experience implementing solutions with those libraries on both CPU and GPU compute architectures. Like what you are reading so far? Keep going. We want you to be intellectually adaptive, inquisitive, good at expressing your needs, and able to self-manage when necessary. Work alongside software/system engineers and research/data scientists with expertise in multi-modal information retrieval, UI development, computer vision, metrics, information science, artificial intelligence, and autonomous systems. The Department of Defense and the Intelligence Community will be the main recipients your hard work. Fun stuff you will do on the job: - Use cases requiring identifying entity/objects, determining object association, object disambiguation, anomaly detection, state estimations, etc.
Develop and maintain data models (both physical and logical)
Get to be responsible for extraction, transform, and load (ETL) tasks related to the different modalities and algorithms being applied. This data ETL includes identifying the data's relevant metadata to ensure consistency, quality, accuracy, integrity, and information assurance and security.
Performing anomaly detection using various AI/ML techniques
Use algorithms to identify complex patterns across multiple modalities
Increasing the efficiency and quality data alignment and fusion
Enhance and maintain analysis tools, including automation of current processes using AI/ML algorithms
Conduct quantitative data analysis including developing retrieval, processing, fusion, analysis, and visualization of various datasets Skills required to be successful in this role: - Bachelor's Degree in Aerospace Engineering, Computer Science, Mathematics, Statistics, Physics, Electrical Engineering, Computer Engineering or related fields with 5 years of relevant experience
Must be able to obtain and maintain a TS/SCI security clearance
Experience with Deep Learning Frameworks such as Keras, Tensorflow, PyTorch, Mxnet, etc. - Ability to apply these frameworks to real problems in the 'time -series' domain
Experience with interpretability of deep learning models
Big Data Skills (Azure, Hadoop, Spark, recent deep learning platforms)
Practical experience with statistical analysis
Experience with text mining tools and techniques including in areas of summarization, search (e.g. ELK Stack), entity extraction, training set generation (e.g. Snorkel) and anomaly detection
Expert software development skills lifecycle including developing and maintaining good production quality code
Hands-on Software Development Skills (Python-Preferred)
Experience or educational courses/projects in Machine Learning, and/or Text Mining Algorithms You will wow us even more if you have these skills: - Visualizations/Web Development Skills (e.g. Tableau, D3, etc).
Hands-on experience with prototype development
Hands-on experience with automating data cleansing, formatting, staging, and transforming data human
Hands-on experience applying data analytics
Hands-on experience with intelligent systems and machine learning LInC External Referral Bonus: Ineligible Potential for Telework: No Clearance Level Required: Top Secret/SCI Travel: Yes, 10% of the time Scheduled Weekly Hours: 40 Shift: Day Requisition Category: Professional Job Family: Software Engineering Leidos Leidos is a Fortune 500® information technology, engineering, and science solutions and services leader working to solve the world's toughest challenges in the defense, intelligence, homeland security, civil, and health markets. The company's 33,000 employees support vital missions for government and commercial customers. Headquartered in Reston, Virginia, Leidos reported annual revenues of approximately $10.19 billion for the fiscal year ended December 28, 2018. For more information, visit www.Leidos.com . Pay and Benefits Pay and benefits are fundamental to any career decision. That's why we craft compensation packages that reflect the importance of the work we do for our customers. Employment benefits include competitive compensation, Health and Wellness programs, Income Protection, Paid Leave and Retirement. More details are available here . Securing Your Data Leidos will never ask you to provide payment-related information at any part of the employment application process. And Leidos will communicate with you only through emails that are sent from a Leidos.com email address. If you receive an email purporting to be from Leidos that asks for payment-related information or any other personal information, please report the email to [email protected] . Commitment to Diversity All qualified applicants will receive consideration for employment without regard to sex, race, ethnicity, age, national origin, citizenship, religion, physical or mental disability, medical condition, genetic information, pregnancy, family structure, marital status, ancestry, domestic partner status, sexual orientation, gender identity or expression, veteran or military status, or any other basis prohibited by law. Leidos will also consider for employment qualified applicants with criminal histories consistent with relevant laws.",3.5,"Leidos
3.5","Arlington, VA","Reston, VA",10000+ employees,1969,Company - Public,Aerospace & Defense,Aerospace & Defense,$10+ billion (USD),-1
Software Engineer,"$64K-$132K
(Glassdoor est.)","Every Analyst a Scientist - One of our primary goals is to empower intelligence analysts to be able to study their data like scientists. The tools we develop focus on streamlining intelligence analysis through integrated algorithms and software that provide insight into the geopolitical landscape for use in operational intelligence missions around the world.

The Role:
As a Software Engineer, you will be part of a team that transforms large and complex customer data into real-world, high-impact solutions. You will work with researchers and engineers to design and implement solutions to challenging national security problems. You will be responsible for building the software infrastructure to clean, ingest, and expose datasets and algorithms to both developers and end users. You will deploy algorithms, generate workflows, create engineer-facing tools, and design customer-facing prototype systems. You will occasionally travel to customer sites to engage with end users, demonstrate prototypes, and integrate analytics into customer systems.

If you would like to help intelligence and defense analysts keep pace with technology-driven innovation, then this role is for you!

Who you are:
A U.S. Citizen with the ability to obtain a Security Clearance
A degree in a scientific or engineering field, such as Computer Science, Mathematics, Physics, or Software Engineering
Proficiency with a scientific programming language such as Python, Java, or C++
Experience with database management and common query syntax
Motivated collaborator and excellent communicator of ideas to both technical and non-technical audiences
Knowledge of AWS, Spark, Dask, and/or similar technologies for working with data at scale
Even better:
Active Security Clearance
Track record of architecting, developing, deploying, or maintaining enterprise software
Experience with software development best practices and tools
Understanding of web development and visualization technologies, such as d3, Leaflet, Bootstrap, or others
Familiarity with machine learning or statistical modeling techniques",4.5,"Systems & Technology Research
4.5","Woburn, MA","Woburn, MA",201 to 500 employees,2010,Company - Private,Aerospace & Defense,Aerospace & Defense,$100 to $500 million (USD),-1
Sr. Data Scientist,-1,"Background Information:

Innovative Defense Technologies (IDT), provider of automated software testing, data analysis, and cybersecurity solutions for complex defense systems, is currently accepting applications for an anticipated Sr. Data Scientist role requiring 7+ years of experience for a position in support of its efforts implementing Artificial Intelligence solutions for a variety of customers.

Overview:

The Sr. Data Scientist position offers an engineer the opportunity to utilize his/her knowledge and talents as part of a collaborative team developing AI solutions for a growing company. A few of the responsibilities include supporting feasibility studies, applying modern data storage techniques, discovering explanatory features in high-dimensionality collections of data, and exploring data using scientifically valid techniques to exploit patterns found in the data with state-of-the-art AI/ML/DL solutions.

All applicants must be able to obtain/maintain an active U.S. Security Clearance.

Responsibilities Include:
Lead development of solutions to deliver AI/ML/DL models from problem formulation to a productized, deployable, maintainable capability
Contribute to AI/ML/DL technical roadmap development
Use Deep Learning frameworks such as Tensorflow and Keras to build and validate ML/DL models
Establish and leverage Big Data frameworks to store, extract and analyze relevant data
Ensure development of software solutions meets customer needs and program intent
Work closely with the Program Manager and Chief Engineer to design and implement software requirements and solutions
Determine operational feasibility by evaluating analysis, problem definition, requirements, solution development, and proposed solutions for large, complex systems
Be responsible for a team’s products meeting software design, quality, and performance requirements
Pursue new technology development via the DoD Small Business Innovative Research (SBIR) program
Work with minimal supervision in a collaborative work environment to implement best-in-class solutions
Minimum Required Qualifications:
Bachelor’s Degree in Computer Science, Computer Engineering, Electrical Engineering, Systems Engineering, Physics, or Math Required; PhD in relevant field highly preferred
7+ years of experience in predictive modeling, data science and analysis
Required Skills:
Previous experience in a ML or data scientist role and a track record of building ML or DL models
Extensive experience working with data mining algorithms including decision trees, probability networks, association rules, clustering, and neural networks
Experience using Python (or equivalent)
Experience using ML libraries, such as scikit-learn,
Experience using data visualization tools
Experience handling terabyte size dataset
Experience working with GPUs to develop models
Ability to travel 10% or less
Preferred Skills:
Experience with MapReduce programming (Hadoop)
Skills with programming languages, such as Java or C/C++
Demonstrated ability to develop experimental and analytic plans for data modeling processes, use of strong baselines, ability to accurately determine cause and effect relations
Consulting experience and track record of helping customers with their AI needs
Publications or presentations in recognized Machine Learning, Deep Learning and Data Mining journals/conferences
Combination of deep technical skills and business savvy enough to interface with all levels and disciplines within our customer’s organization
Experience diving into data to discover hidden patterns
Experience with application container platforms
Familiarity with continuous integration/delivery tools (e.g. Jenkins)
Familiarity with version control tools (e.g. Subversion, Git, etc.)
Familiarity with VMware or other virtualization software
Experience developing applications for DOD command and control systems
Competencies:
Solid analytical abilities, coupled with a strong sense of ownership, urgency, and drive
Attention to detail
Initiative, creativity, reliability, teamwork
Ability to deal well with ambiguity, prioritize needs, and deliver results in a dynamic environment
EEO Statement:

IDT is an Equal Opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, creed, sex, sexual orientation, gender identity, national origin, disability, protected Veteran status, or any other basis protected by federal, state, or local law.",-1,Innovative Defense Technologies (IDT),"Mount Laurel, NJ",-1,-1,-1,-1,-1,-1,-1,-1
Full Stack Software Engineer (Python/Vue),-1,"Position Summary Full Stack Software Engineer (Python VueJS) Company Overview Our client is an automated underwriting platform for real estate professionals that was built to disrupt the commercial real estate industry. The software allows investors, brokers, and lenders to analyze rent, operating expenses and returns for multifamily properties by applying machine learning to a database of live multifamily transaction data from every U.S. market. Our client has a creative and entrepreneurial culture ndash everyone on the team interacts directly with customers each day, and we all contribute to the product and planning. If you have an idea to improve something, there is no red tapehellip just build what needs to be built! Innovation and passion for transforming the old-fashioned real estate industry are our highest priorities. Job Description As a full-stack (Python, PostgreSQL and HTMLCSSJavaScript) developer, you'll work on the interface and backend infrastructure of products and features used by hundreds of underwriters and real estate analysts every day. The work is challenging, fast-paced, and always changing. You must have demonstrated analytical skills, an unwavering commitment to quality, a collaborative work ethic, and cutting-edge coding skills. You must display solid proficiency in the fundamentals of Python, PostgreSQL, JavaScript, HTMLCSS, and popular front-end frameworks like Vue.js. The role will include the delivery of reliable, scalable new features to users, developed in Python, interacting with a PostgreSQL database and using the Vue.js frontend framework. You will work with the development team to develop, test and deliver finished, high quality, compelling features and products. Our team includes designers, engineers and data scientists who are passionate about quality, usability, and simplicity. If you are ready to join a company that fosters learning, growth, experimentation and innovation, our client's team is for you. Requirements Qualifications 3-5 years of experience in full stack Python development 1-3 years of experience with PostgreSQL 1-3 years of experience with JavaScript frameworks such as React, Angular or Vue.js (Vue.js is preferred, this is what our client uses), and CSS pre-processing frameworks (Sass or Less) 1-2 years of experience integrating with VBA and Excel integration preferred Experience using GitHub and solid understanding of software version control Familiarity with JIRA or equivalent product management software Familiarity with agile development best practices Driven self-starter able to work on a small team and take initiative on new tasks Familiarity with real estate or finance is a plus Responsibilities Collaborate with interdisciplinary team of data scientists, software engineers and real estate professionals Strive for high quality and rapid output utilizing agile development best practices Support, maintain, and document software functionality Maintain industry standard coding, compliance, security practices Proactively learn product frameworks and code base Our client is a startup company, and as such the responsibilities outlined above may change and evolve over time. Flexibility, curiosity, an entrepreneurial mindset, and strong work ethic are essential for this role. It is encouraged that everyone on the team continually research new technologies and analytical opportunities to improve the platform.",5.0,"CultureFit
5.0","Chicago, IL","Deerfield, IL",1 to 50 employees,1997,Company - Private,Advertising & Marketing,Business Services,$1 to $5 million (USD),-1
AWS Data Engineer,-1,"About Infinitive:

At Infinitive, we do mission-critical work for great companies. We specialize in digital marketing and digital advertising solutions, customer data & analytics, digital & business transformation, and Technology solutions. Our Technology solutions focus on Managed Cloud Services, Cloud Enablement, Digital Operations, Application Development, DevOps, Product Development, Cloud Security, Data Science and Analytics, AI/ML, IoT, and everything in between.

Our experts are results-obsessed, focused and flexible, highly engaged and hugely experienced having sat in our clients seats. Those qualities are what make us different than old-school consulting shops. And surely, they are why clients and partners describe us as the gold standard in client experience.

Infinitive has been named a Best Small Firms to Work For by Consulting Magazine seven times, a Washington Post Top Workplace three times, a Washington Business Journal Best

About this Role:

Infinitive is growing its team in the Northern Virginia area and is currently seeking an Data Scientist to join our growing Technology practice. This person will utilize their experience in analytics, IoT, machine learning, and artificial intelligence advances to create value from structured and unstructured data. The ideal candidate has experience designing novel data analytic methods and workflows, including full data pipelines from raw data through analysis results. They must also have exposure to a variety of data mining/data analysis methods, data tools, building and implementing models, using/creating algorithms, and creating/running simulations.

We are looking for candidates who are accountable, passionate, assertive, proactive, open & honest, results oriented, and adaptable. Each project engagement represents a new challenge that will give you exposure to new clients, business issues, technologies, and people and will involve a range of responsibilities to include:
Developing in Java, Python, R, or other high-level languages.
Managing disparate data sources with varying data structures of content and preparing these for data science and machine learning applications.
Working with distributed scalable Big Data storage, processing, and computation, including AWS EMR, Spark, etc.
Implementation knowledge of, or desire to learn AWS / Azure data science capabilities.
Developing solutions and integrating and extending free and Open-source software (FOSS) or COTS products.
Conduct MapReduce programming with Apache Hadoop, the Hadoop Distributed File System (HDFS), and processing large data stores.
Knowledge of SQL and query languages.
Utilize real-time, large-scale data processing engine, including Apache Spark.
Lead and create Data Science and Analytics methodologies and frameworks for implementation.
Ability to build and develop Data Science demonstrations for clients
Qualifications:
4+ years of development experience (Java, Python, R, SQL)
3+ years of experience with distributed scalable Big Data storage, including AWS EMR, Spark, etc.
Desire to become AWS / Azure Certified architect / engineer.
Experience performing data Management, modeling, and warehousing.
Hands on experience with Amazon analytic tools (preferred)
Interest in being involved internally and growing a small business (entrepreneurial spirit)
Ability to travel (up to 20%) and to work independently
Experience using Agile software development methods in a DevOps environment.
Excellent leadership, peer management, and communication skills
Management consulting experience (preferred)
Bachelor's degree in related field (preferred)
Applicants for employment in the U.S. must possess work authorization which does not require sponsorship by the employer for a visa.

Infinitive is an Equal Opportunity Employer.

Powered by JazzHR",3.4,"Infinitive Inc
3.4","Arlington, VA","Cedar Rapids, IA",201 to 500 employees,1997,Company - Private,Enterprise Software & Network Solutions,Information Technology,$10 to $25 million (USD),-1
"Senior SW Engineer, Data Science ( Kubernetes/ Docker ) Remote USA","$72K-$141K
(Glassdoor est.)","If you dream of a job working in a field where all the hard problems are solved and you get to re-use previous research to get your job done, you need not apply. If, however, you are someone who wants to tackle problems that truly are on the cutting edge, then we encourage you to keep reading.

Data Science is an emerging field within cyber security. FireEye, given its deep expertise and comprehensive view on the advanced threat landscape, is uniquely positioned to enable data scientists to have major impact within our industry, company, and across our customer base. Detecting security breaches using machine learning and data analytics is an unsolved problem (this is not handwriting recognition folks) and has huge potential.

If you are someone who wants to be on the cutting edge of a high profile industry, who wants to make an impact by pushing both fields of data science and cyber security forward, you may be the perfect candidate to help us on our mission.

What you will do:
Develop, and manage data systems to ingest and process data at massive scale
Identify data sources both internally and externally that we can use to find evil.
Contribute towards the architecture and design of software solutions for long-term storage and retrieval.
Identify and implement data exploration technologies. Create dashboards and implement analytical tools for exploration
Work with data scientists to productize ML models and assist product teams with ML model releases into end products.
Collect requirements, design, and build backend components and tools to run ML models, assess ML model efficacy, manage large scale datasets, and generate features for ML models
Contribute to the evolution of coding and design practices within the organization.
Review code base commits and contribute to the growth of team members.
Requirements
Ability to work in an iterative, agile development environment.
Experience implementing ETL processes and building data pipelines
Experience developing reliable distributed systems.
Experience in Data modeling and schema design
Strong knowledge of a variety of operating systems, networking fundamentals, software design and programming best practices.
Experience with use of a wide array of algorithms and data structures.
Deep understanding and experience of going through the entire life cycle of building software platforms and products
Deep knowledge of various AWS services and associated tools
Strong experience developing in Python 3
Experience developing in at least 1 of the following: C, Go or Java
Experience with RDBMS, such as PostgreSQL or MySQL, as well as NoSQL
Experience with Kubernetes and Docker.
Experience deploying products in AWS
Additional Qualification: *
Ability to pick up, work with and explore new analytical tools
Strong experience with DevOps practices and common tooling
Strong communication skills.
Ability to work with loosely defined requirements.
At FireEye we are committed to our #OneTeam approach combining diversity, collaboration, and excellence. All qualified applicants will receive consideration for employment without regard to race, sex, color, religion, sexual orientation, gender identity, national origin, protected veteran status, or on the basis of disability. Requests for accommodation due to disability can be sent directly to .",3.3,"FireEye Inc
3.3","Denver, CO","Milpitas, CA",1001 to 5000 employees,2004,Company - Public,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,"Palo Alto Networks, Tanium"
"Senior SW Engineer, Data Science","$72K-$141K
(Glassdoor est.)","Job Description

If you dream of a job working in a field where all the hard problems are solved and you get to re-use previous research to get your job done, you need not apply. If, however, you are someone who wants to tackle problems that truly are on the cutting edge, then we encourage you to keep reading.

Data Science is an emerging field within cyber security. FireEye, given its deep expertise and comprehensive view on the advanced threat landscape, is uniquely positioned to enable data scientists to have major impact within our industry, company, and across our customer base. Detecting security breaches using machine learning and data analytics is an unsolved problem (this is not handwriting recognition folks) and has huge potential.

If you are someone who wants to be on the cutting edge of a high profile industry, who wants to make an impact by pushing both fields of data science and cyber security forward, you may be the perfect candidate to help us on our mission.

What you will do:
Develop, and manage data systems to ingest and process data at massive scale
Identify data sources both internally and externally that we can use to find evil.
Contribute towards the architecture and design of software solutions for long-term storage and retrieval.
Identify and implement data exploration technologies. Create dashboards and implement analytical tools for exploration
Work with data scientists to productize ML models and assist product teams with ML model releases into end products.
Collect requirements, design, and build backend components and tools to run ML models, assess ML model efficacy, manage large scale datasets, and generate features for ML models
Contribute to the evolution of coding and design practices within the organization.
Review code base commits and contribute to the growth of team members.",3.3,"FireEye Inc
3.3","Denver, CO","Milpitas, CA",1001 to 5000 employees,2004,Company - Public,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,"Palo Alto Networks, Tanium"
"Senior Machine Learning Engineer, Early Stage Pipeline, X",-1,"Senior Machine Learning Engineer, Early Stage Pipeline, X

Software Engineering

Mountain View, CA

We're an early stage team at X with a growing, interdisciplinary portfolio. To prove our path to the moon, we make early contact with the real world through both internal and external partnerships.

In this role, you will be responsible for taking early stage investigations from an idea stage to first prototypes to a full-blown projects. You'll be rapidly iterating through a set of prototypes to evaluate possible product directions. This is an extremely dynamic role and requires high cross-functional communication, organization, and planning. The ideal candidate is a self-starter and has a track record of effectively operating in a dynamic loosely structured environment (e.g. startup, new products within a larger company). The candidate will work on multiple projects/investigations.

Responsibilities:
Identify and implement a set of machine learning prototypes to aggressively de-risk projects building the whole solution: data acquisition, data processing pipelines, ML modeling.
Setup technical direction for investigations/projects working with the early stage leadership team.
Team lead investigations that grow to become projects.
Qualifications:
Hands-on experience with machine learning, one or more of; natural language processing (semantic understanding, sentiment analysis), computer vision, time series analysis.
Experience with building robust data pipelines.
Tech Lead experience.
Startup or early-stage product development experience.
Preferred Qualifications:
Experience with the Google Cloud Platform
About X, the Moonshot Factory

X creates radical new technologies to solve some of the world's biggest problems. We develop uncomfortably ambitious, potentially world-changing new ideas such as self-driving cars, balloon-powered Internet and smart contact lenses. We're a team of makers, entrepreneurs, engineers, designers and scientists with deep technical expertise who love the challenge of the seemingly impossible. We believe that a culture of psychological safety creates the foundation of trust and respect necessary to build moonshots. X was formerly known as Google[x] and is part of Alphabet .

At X, we don't just accept difference - we celebrate it, we support it, and we thrive on it for the benefit of our employees, our products and our community. We are proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements.

If you have a disability or special need that requires accommodation, please contact us at: (see application details) .",-1,"X, the moonshot factory","Mountain View, CA",-1,-1,-1,-1,-1,-1,-1,-1
"Senior/Staff Software Engineer, Data Infrastructure","$116K-$227K
(Glassdoor est.)","Senior/Staff Software Engineer, Data Infrastructure job posting

Every year, while Americans wait for their paychecks, more than $1 trillion of their hard-earned money is held up in the pay cycle. As a result, we accumulate over $50 billion in late and overdraft fees and turn to high-interest loans. Overdraft charges and bank fees often trap people in a cycle of debt that can lead to unhealthy decisions and falling victim to predatory businesses disguised as helpful services. We don't accept that.

Earnin is an app that creates products that help people gain control of their finances. Cash Out lets people get paid as soon as they leave work, with no fees, interest, or hidden costs. With Health Aid, Earnin negotiates on behalf of community members to lower their total unpaid medical bill and work out a budget-friendly payment plan. Cash Back Rewards is a way for members to earn up to 10% cash back on purchases from over a thousand local and national businesses without needing a credit card or having to reach spend thresholds to earn cash rewards — and they can withdraw the money at any time. We also offer free tools to help avoid overdrafts, to remind people when recurring bills are due, and we're working on more! There is never any required cost to use any of these products or services, users can choose to tip what they think is fair to support the service and pay it forward to keep the movement going.

Earnin is supported by funding partners including Andreessen Horowitz, Matrix Partners, Ribbit Capital, Felicis Venture, Thrive Capital, and others. Join us and help build a new financial system focused on fairness and people's needs.

You can help make a difference.

About the Team:

We are a data driven mobile financial tech company. The Data Infrastructure team builds the data services and data infrastructure that powers data science, analytics, and product development throughout Earnin. We are looking for a product-minded, self-driven Senior Software Engineer to own multiple large-scale projects that advance our mission of enabling people to gain access to their paycheck on demand.

What sets us apart:
High impact roles at a relatively small company that's aggressively growing our user base.
We are a collaborative team and genuinely enjoy working with each other.
We believe in empowering our people to be successful.
We're building a product that inspires fairness across the financial world and helps people not get taken advantage of.
As a Senior Engineer you will:
Break down complex problems into their bare essentials, translate this complexity into elegant design and create high quality, maintainable code.
Build massively scalable, production-grade data services.
Champion data quality and governance throughout the organization.
Build a world class data lake and data warehouse.
Design and develop new systems and tools to enable all of Earnin to consume and understand data faster.
Own the end to end design, build, and maintenance of platform services, data pipelines, and data products.
Implement comprehensive monitoring, logging, and alerting across our data infrastructure.
Work cross functionally with other teams (data science, design, product, marketing, and analytics) in high visibility roles as an engineering leader.
Build and deploy the data architecture that supports machine learning model development and actionable analytics.
Work with product engineering and data science teams to design scalable, performance model deployment architectures.
Communicate the tradeoffs of technical decisions to multiple stakeholders, including non-technical audiences.
Collaborate with and mentor other engineers and provide engineering direction to data scientists and analysts.
Actively engage and drive design reviews and code reviews.
Some skills we consider critical to being a Senior Engineer:
BS or MS degree in Computer Science, Engineering, or a related technical field.
8+ years of development experience in a fast-paced environment, especially startups.
5+ years of experience working with data systems.
Strong Python and SQL skills.
Strong programming and architecture skills.
Excellent written and verbal communication skills, including the ability to identify and communicate data driven insight.
Taking pride in your code quality and helping others elevate their own code quality.
Substantial experience with testing, data validation, and data quality assurance.
You can articulate the tradeoffs of different deployment architectures (e.g. streaming vs. batch vs. service-based).
Experience designing data platforms and services on cloud infrastructure, preferably AWS.
Hands-on experience designing and building large-scale solutions with the Hadoop stack and/or Spark.
Experience tuning and optimizing Spark-based applications.
Experience deploying and/or using query engines like AWS Athena, Presto, and Impala.
Experience with AWS analytical services like Redshift.
Hands-on experience working with a varied set of data storage technologies (e.g. Mysql, Postgres, DynamoDB, S3, etc.). You know where and when to use each.
Extensive experience with data modeling for multiple use cases and application styles, including NoSQL data modeling.
Experience working with data formats such as Avro and Parquet.
Experience working with alerting and monitoring tools like DataDog and PagerDuty.
Nice to haves:
You have experience building and deploying machine learning models.
You have experience using Terraform.
You have substantial experience working at a startup.
You have experience with data modeling in Redshift.
Experience with streaming infrastructure like Kafka.
Experience working with Kubernetes.
Experience building and deploying AWS Lambda applications.",3.1,"Earnin
3.1","Palo Alto, CA","Palo Alto, CA",201 to 500 employees,2012,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Engineer (open level),"$43K-$69K
(Glassdoor est.)","Title
Data Engineer (open level)

07/08/2020

What you'll do...
At H&R Block, your contributions will go far beyond any job description. When you join our team, you'll add to the momentum of a forward-thinking company - one that defined an industry and is now leading its transformation.

H&R Block is transforming tax preparation through data to ensure that every client we serve gets the best tax outcome possible.

We are building a new Data Engineering Team in the Data Science & Analytics organization. This new team will own the technology and data capabilities of the end-to-end data-and-analytics function. It will take responsibility for building and maintaining the analytical technologies that the data science teams use, managing data at an enterprise scale, leveraging relationships with IT teams throughout the enterprise, and leading information architecture.

We are looking for talented, curious, and creative data engineers of all levels to help launch this team. You will be a good match for our organization if you are:
Motivated by the idea of building something innovative, transformative, and impactful.
Committed to the idea that data can drive experiences and products that wow our business partners and clients
Obsessed with defying expectations and raising the bar
Driven by an innate sense of ownership for the products you create.
Day to day, you'll...
Design and deploy architecture, solutions, and software to capture, manage, store, and use structured and unstructured data from internal and external sources in both on-prem and cloud environments.
Deploy machine-learning models and other data-science products across the enterprise.
Navigate the balance between business needs, data governance best practices, and technical requirements.
Select or develop tools to cleanse, organize, and transform data and to maintain, defend, and update data structures and integrity on an automated basis.
Develop data products to facilitate self-service capabilities and assist the data teams to increase their efficiency and effectiveness.
Collaborate and communicate effectively within cross-functional teams that span internal Data Science & Analytics teams, IT, business groups, and executive stakeholders.
Be a positive force to cultivate a culture that is passionate about developing data tools as a business driver.
Job ID
368348BR

Address1
ONE H&R BLOCK WAY

City
KANSAS CITY

State
Missouri

Employee Type
Regular

What you'll bring to the team...
Education / work experience should include most of these, depending on level:
Bachelor’s degree in Computer Science or a related technical field (or equivalent work experience and technical skills)
Data warehousing and ETL solutions
APIs in a microservices architecture
Big-data technologies and the Hadoop stack (MapReduce, Hive, Pig, Hbase
NoSQL implementations (MongoDB)
Developing Java-based software solution
At least one scripting language (Python, Perl, JavaScript, Shell
Developing software solutions to solve complex business problems
Working with data scientists and other data users
Posting Title
Data Engineer (open level)

Sponsored Job
#hrbjob

Job Family
Corporate Analytics",3.6,"H&R Block
3.6","Kansas City, MO","Kansas City, MO",10000+ employees,1955,Company - Public,Other Retail Stores,Retail,$2 to $5 billion (USD),"Intuit, Jackson Hewitt, Liberty Tax Service"
Senior Modeling & Simulation Engineer,-1,"Applied Research Associates, Inc. is looking for a Senior Modeling and Simulation Engineer to join our multi-disciplinary team of engineers and scientists in the Capital Area Division, located in Alexandria, VA. The ideal candidate has a passion for predicting the behavior of physical systems in challenging environments and operational impact on mission success. Models will be developed, used, and improved to support a Department of Homeland Security customer to safeguard the nation’s borders and interior from chemical, biological, radiological, nuclear, and explosive materials, equipment, technologies, and their actors. Models may be based on the underlying physics or may be process or agent based to predict operational performance and impact. Modeling and analysis may require the use and development of 3D virtual worlds or geospatial data. Models will be verified and validated, and they will be used in support of test and evaluation activities of systems intended to detect and identify threats. The candidate may participate in test and evaluation activities to support the verification, validation, and overall improvement of models. Models may become part of larger, integrated modeling and simulation activities, and may require the use of high performance computing technologies and federated simulations.

This position is contingent upon award of a contract expected in Summer 2020 supporting the Department of Homeland Security.

Required Qualifications:
Ability to program in a high level programming language, such as Fortran, C++, or Java
Eagerness to learn new tools and techniques
Strong verbal and written communication skills
Must be a U.S. Citizen with the ability to obtain and maintain a security clearance
Bachelor’s degree with minimum of 10 years of experience or greater in a physical science (physics, chemistry, biology), engineering-related discipline (nuclear, chemical, civil, mechanical, electrical), or modeling& simulation disciple (computer modeling, computational science, operations research)
Ability to present to senior leadership on the status and issues associated with research or test efforts in preparation for acquisition decision meetings
Desired Experience and Qualifications:
Experience modeling CBRNE detectors or effects
Experience using multiple software tools such as MCNP, GadRas, SWORD, ExtendSim, Arena, SolidWorks, Fluent, ArcGIS, QGIS, VisIt, ParaView, or Cubit
Experience creating 3D models of systems, i.e., CAD
Experience using high performance computers (i.e., supercomputers)
Experience developing and using discrete event or agent based models and simulations to predict and assess system performance
Experience developing machine learning models
Background in a physical science or engineering discipline, such as Physics, Chemistry, Biology, Mechanical Engineering, Nuclear Engineering
Active DoD Secret or Top Secret clearance, DoE Q clearance, or DHS Suitability
COMPANY INFORMATION:

Applied Research Associates, Inc. is an employee-owned international research and engineering company recognized for providing technically superior solutions to complex and challenging problems in the physical sciences. The company, founded in Albuquerque, NM, in 1979, currently employs over 1200 professionals. ARA offices throughout the United States and Canada provide a broad range of technical expertise in defense technologies, civil technologies, computer software and simulation, systems analysis, environmental technologies, and testing and measurement. The corporation also provides sophisticated technical products for environmental site characterization, pavement analysis, and robotics.

At ARA, employees are our greatest assets. The corporation realizes that employee ownership spawns greater creativity and initiative along with higher performance and customer satisfaction levels. ARA gives its employees the tools, training, and opportunities to take more active roles as owners. The culture is challenging; innovation and experimentation are the norm. Employees are eligible for contributions which not only add to the company’s success, but also their own through the Employee Stock Ownership Plan (ESOP). The motto,“Engineering and Science for Fun and Profit” sums up the ARA experience. For additional information and an opportunity to join this unique workplace, please visit our website atwww.ara.com.",3.5,"Applied Research Associates
3.5","Alexandria, VA","Albuquerque, NM",1001 to 5000 employees,1979,Company - Private,Federal Agencies,Government,$100 to $500 million (USD),-1
Senior Data Engineer,-1,"This is a Data Engineer position for supporting a Navy program located in Quantico, Virginia.

We are seeking a Data Engineer to join our team of committed technical professionals to protect those who serve against criminal, terrorism and emerging threats. Are you passionate about analytics and innovation? Our employees enjoy a fast-paced, collaborative culture and the ability to directly impact our business. You will identify technical issues and opportunities for efficiency and provide technical insights through system design and configuration perspectives. This role is both challenging and rewarding.

You will support the mission through the implementation of a modern, integrated internal data infrastructure with a focus primarily on exploiting the established data foundation to make internal and customer-centric business processes as effective and efficient as possible, laying the foundation for cognitive capabilities that can sense and respond to both internal and external customer data needs. The candidate will also focus on expanding the organization’s data ecosystem to include context-rich data while maintaining the agility needed to spark innovation.

How you will make a difference:
Establish shared operational data and integrated enterprise data, all while managing and/or improving data quality and security through the creation of business-driven governance structures and culture change management.
Establish data policies, standards, and procedures that improve data quality, availability, accessibility, security, usability, and enforcement of enterprise information management (EIM) program requirements.
Establish enterprise standards – including a uniform and repeatable system development lifecycle methodology for Reference Data and Master Data (e.g., a common set of standards for data naming, abbreviations, and acronyms).
Develop a Master Data Management (MDM) Plan that focuses on the technology, tools, and processes ensuring master data is coordinated across the enterprise. MDM is a method used to define and manage the critical data of an organization to provide, with data integration, a single point of reference. The data that is mastered may include reference data – the set of permissible values, and the analytical data supporting decision making. MDM provides a unified master data service intended to provide accurate, consistent and complete master data across the enterprise and to business partners.
Recommend solutions based on performing industry-specific analysis, such as case studies describing data management best practices, identifying trends across the industry.
Make recommendations to improve the efficiency and effectiveness in how the agency acquires, stores, manages, shares and applies its data.
Engage business users and stakeholders for the increased release of actionable high-quality data on key operational and tactical activities at NCIS.
Develop technology solutions to provide the platform, training, and standardized tools enabling querying, data mining, statistical analysis, reporting, scenario modeling, data visualization, and dash-boarding, and processes for a centralized, or analytics as a service model, allowing for the sharing of data across the enterprise from a common hub, facilitates cross-organizational data initiatives due to its enterprise-wide view of data assets and needs.
Basic Qualifications
Required: A bachelor’s or master’s degree in computer science, data science, operations research, statistics, applied mathematics, or a related quantitative field [or equivalent work experience such as, economics, engineering and physics] is [preferred/required]. Alternate experience and education in equivalent areas such as economics, engineering or physics, is acceptable. Experience in more than one area is strongly preferred.
Required: Three to six (midlevel) of relevant project experience in successfully launching, planning, and executing data science projects. Preferably in the domains of risk modelling and quality assessment.
Preferred: Specialization in text analytics, image recognition, graph analysis or other specialized ML techniques such as deep learning, etc.
Preferred: the candidates are adept in agile methodologies and well-versed in applying DevOps/MLOps methods to the construction of ML and data science pipelines.
Coding knowledge and experience in several languages: for example, R, Python, Java, C++, Excel, MATLAB, etc.
Experience with popular database programming languages including SQL, PL/SQL, others for relational databases and upcoming non-relational databases such as NoSQL/Hadoop-oriented databases such as MongoDB, Cassandra, others.
Preferred: Specialized/operational data scientists may need further high-performance computing (HPC)/compute skills; larger data science teams, in particular, may require further degrees of specialization such as:
Experience with distributed data/computing tools such as MapReduce, Hadoop, Hive, Kafka, and MySQL
Experience of working across multiple deployment environments including cloud, on-premises and hybrid environments, multiple operating systems and through containerization techniques such as Docker, Kubernetes, AWS Elastic Container Service, and others.
Experience in one or more of the following commercial/open-source data discovery/analysis platforms: RStudio, Spark, KNIME, RapidMiner, Alteryx, Dataiku, H2O, SAS Enterprise Miner (SAS EM) and/or SAS Visual Data Mining and Machine Learning, Microsoft AzureML, IBM Watson Studio or SPSS Modeler, Amazon SageMaker, Google Cloud ML, SAP Predictive Analytics.
Preferred: Expertise in solving vision, text analytics, credit scoring, and failure prediction problems.
Knowledge and experience in statistical and data mining techniques such as generalized linear model (GLM)/regression, random forest, boosting, trees, text mining, hierarchical clustering, deep learning, convolutional neural network (CNN), recurrent neural network (RNN), T-distributed Stochastic Neighbor Embedding (t-SNE), graph analysis, etc.
Strong documentation skills. Required: Certifications as per Cybersecurity Workforce Management and Qualification Manual, SECNAV M-5239.2.
Required: Eligible AND adjudicated to the Top Secret (TS SCI) clearance level is required to start.
About Inventium.io:

Inventium.io LLC is a technical consulting and software development services company dedicated to protecting and advancing our national defense and scientific capabilities. Based out of the Washington DC area, we rely on innovation to continually advance our employees' skills and provide digital transformation solutions to our customers.

With proven records of successfully delivering quality services and solutions to multiple federal agencies, our technical competencies include Emerging Technology Solutions, DevSecOps, Cloud Migration, Machine Learning, System Modernization, and Technology Management.

Benefits and Perks
Employer paid Health Benefits (Medical, Dental and Vision)
Retirement Plan
Paid Time Off and Federal Holidays
Training and Development
Employee Referral Program
Awards and Recognition",5.0,"inventium.io LLC
5.0","Quantico, VA","Washington, DC",1 to 50 employees,2016,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Senior Software Engineer,-1,"At Pacific Biosciences, our R&D team is committed to developing innovative products that enable scientists to excel in a wide variety of life science research fields, including human biomedical, plant and animal sciences, and microbiology and infectious disease. Our unique Single Molecule, Real-Time (SMRT) sequencing platforms generate true high-quality long reads, giving researchers a more comprehensive view of genomes, transcriptomes, and epigenomes from any organism.

The Primary Analysis group, as part of the larger software engineering team at PacBio, develops algorithms and HPC solutions for decoding the raw data streams, generated through high-speed optical detection of the SMRT sequencing reactions, into DNA sequence reads. We operate at the intersection of cutting-edge nanotechnology and state-of-the-art bioinformatics tools, and our responsibilities span the full product development life cycle in an aggressive time-to-market environment. These include analysis and algorithm development in coordination with chemistry and systems R&D; the development of real-time analysis pipelines; and the development of validation and support infrastructure geared towards product system reliability and internal R&D support. We are seeking a talented algorithm engineer with a strong background in the physical or machine-learning/data sciences who also has a passion for designing and developing performance-critical data analysis solutions.

Responsibilities:

Design, develop, and test signal- and sequence-analysis algorithms that will drive fundamental improvements in basecalling accuracy and yield.
Work collaboratively in a team environment to solve challenging problems in software architecture and scalability of real-time analysis pipelines for our next-generation sequencing platforms.
All listed tasks and responsibilities are deemed as essential functions to this position; however, business conditions may require reasonable accommodations for additional tasks and responsibilities.

Key Skills and Background:

3+ years of experience shipping product software in a scientific or quantitative domain.
Demonstrated skills applying numerical methods, statistical signal processing, or machine-learning techniques to high-throughput, performance-critical analysis applications.
Linux-based systems programming experience with knowledge of OS, toolchain and hardware constraints.
Strong C++ programming experience in applications geared towards performance and scalability; previous experience in CUDA programming for GPU is a plus.
MS, PhD or equivalent experience in a quantitative field (physics, CS, etc.), preferably with an applied math or algorithmic focus.
Engineering instincts to efficiently investigate and solve the problem at hand, from prototype development (Python, R, MATLAB, etc.) to production designs.
Team player, with strong communication skills, and comfortable as a self-starter in an agile, fast-paced development environment.
All qualified applicants will receive consideration for employment without regard to race, sex, color, religion, national origin, protected veteran status, or on the basis of disability, gender identity, and sexual orientation.",3.7,"Pacific Biosciences
3.7","Menlo Park, CA","Menlo Park, CA",201 to 500 employees,2000,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,$50 to $100 million (USD),Illumina
Senior Data Engineer,-1,"ABOUT 605

At 605 we are engineers, analysts, data scientists, media experts, marketing strategists and political operatives. Our team of data scientists pioneered the field of TV data analytics. We offer unique, independent audience measurement and analytics to build better marketing and programming initiatives within the media and entertainment industries.

The Sr. Data Engineer at 605 must have a broad and deep data skillset as well as strong analytical capabilities . In addition to being a hands on individual contributor, the ideal candidate is a productive team player and a mentor to Junior. Data Engineers. Additionally, we are looking for strong technical experts.

Responsibilities include:
Actively participate in team technical discussions in all things data
Identify and address issues with data sets from multiple vendors
Identify and address code and data quality issues
Actively participate in code reviews and grooming sessions
Actively participate in technology architecture discussions for product development
Translate business requirements into strategy
Advocate for software best practices within your team as well as across engineering
Be ultra-responsive and capable of making instant decisions, always kicking the ball forward
Work on unique and interesting data challenges around architecting, building and managing pipelines that securely process hundreds of terabytes of data
Work closely with analysts and statisticians to ensure the validity of our processes
Our engineers are expected to wear a number of hats and have the opportunity to touch all parts of the stack. Our stack includes Apache Spark, Scala, Redshift and an ever-growing list of many other cool technologies.

Requirements
Skillful user of Apache Spark
Experience wrangling terabytes of big, complicated, imperfect data
Experience with AWS products (Redshift, EMR, S3, IAM, RDS, etc)
You have a deep understanding of scalable systems and you have large-scale engineering experience in an Agile development environment
Bachelor's degree in Computer Science or a related field (or 4 additional years of relevant work experience)
A strong understanding of data structures, algorithms, and effective software design
Significant development experience with a major modern language (e.g. Java, Scala, Python, Ruby, C/C++, etc.)
Significant experience working with structured and unstructured data at scale and comfort with a variety of different stores (key-value, document, columnar, etc.) as well as traditional RDBMSes and data warehouses
Experience with or interest in AWS Glue, Redshift Spectrum and any other tools that enable data querying at scale
Experience writing unit, functional and integration tests
Comfort with version control systems (e.g. Git, SVN)
Excellent verbal and written communication skills; must work well in an agile, collaborative team environment
Preferred Qualifications
Master's in Computer Science or a related field
Practical experience with supervised machine learning techniques
Strong background with test-driven development
Basic understanding of statistics and experience with statistical packages such as R, Matlab, SPSS, etc
Benefits

Important and Standard
Comprehensive health, dental and vision insurance for employees and their families
Life & Disability insurance
401k plan with match, eligible for match after one year
Pre-tax flexible compensation plan for medical, transit, parking or dependent care expenses
Up to 15 paid vacation days depending on grade level
7 paid sick days in a calendar year - if you’re sick, you stay home
Other cool benefits
4 work from home days/month
A kitchen stocked with sodas, snacks, yogurt and other goodies
A tight knit start up community who likes to eat! We celebrate everyone’s birthdays, have frequent team lunches, and do events in and out of the office
605 is an active participant in conferences
EEO STATEMENT

At 605, we’re just as passionate about diversity as we are about pioneering the field of TV data analytics. We are committed to cultivating an environment of mutual respect and equal opportunity. All hiring and advancement decisions are made on the basis of qualification, merit, and business need.",-1,605,"New York, NY",-1,-1,-1,-1,-1,-1,-1,-1
Sr Innovation Engineer,"$75K-$134K
(Glassdoor est.)","Company Information

Solid reputation, passionate people and endless opportunities. Thats Travelers. Our superior financial strength and consistent record of strong operating returns mean security for our customers and opportunities for our employees. You will find Travelers to be full of energy and a workplace in which you truly can make a difference.

Target Openings

1

Job Description Summary

Innovation is at the core of everything we do. We continue to ask ourselves, whats next? as we navigate the ever-changing insurance landscape. Continuing our customer journey toward the cutting-edge, we are looking for a forward-thinking individual that thrives in ambiguity, who believes that with every challenge comes a new opportunity for solutions.

As a member of the Innovation Technology team, you will partner with research scientists and product managers to discover, invent, and build solutions at scale. As a team, you will work on challenges in machine perception, data mining, machine learning, and natural language understanding.

We are looking for a hands-on individual with strong foundational knowledge highly scalable architectures and platforms. If you like using a variety of skills in technology and solving complex problems, work collaboratively in a small agile team environment, you might just be the person we need on our team!

Primary Job Duties & Responsibilities
Work closely with Cloud Engineering to build an innovation platform; a collection of reusable and extensible containers and tools specific to developing insurance products and platforms.
Recommend integration strategies, enterprise architectures, platforms and application infrastructure required to successfully implement a complete solution using best practices.
Produce quality output for highly visible IT products, services and future business development.
Assist in hands-on remediation of application stability and performance.
Adopt and communicate new concepts, ideas, techniques.
Manage multiple projects simultaneously.
Provide 'Shrink Wrap' solutions to solve business and technical needs. As part of our innovation process, be able to scale Minimum Viable Product to production systems.
Design and lead integration of analytic data products, including pilots and proof of concepts.
Frequently present and translate complex information in relevant business terms.
Constantly learn new skills within small teams.
No direct HR people management but will lead teams in project & program contexts.
Education, Work Experience, & Knowledge
Bachelors Degree in STEM (Science, Technology, Engineering, Mathematics) related field and 3+ years of experience or 10+ years of experience building highly scalable platforms and reusable components
Job Specific Technical Skills & Competencies
2+ years of experience working with Amazon Web Services (AWS) or equivalent cloud. Must be recent experience.
5+ years of designing and developing on-premise and cloud solutions.
3+ years of experience as a technical lead.
Experience in software engineering with relevant technologies (Java, JavaScript, Python etc.).
Experience with the application delivery process.
End-to-end experience with data, including querying, aggregation, analysis, and visualization.
Preferred Qualifications
AWS certified developer and/or architect
Proven ability to work creatively and analytically in a continuously evolving environment.
Exhibits high levels of learning agility in which they seek out and learn from unfamiliar experiences and then apply those lessons to succeed in the next new situation.
Ability to leverage business knowledge to determine approaches to execution.
Strong communication and presentation skills with the ability to present and translate complex information to leadership and non-technical teams in relevant business terms.
Uses effective listening skills and communication to build relationships across the organization.
Ability to Influence with experience working with matrixed staff to complete tasks in a timely manner.
Environmental / Work Schedules / Other
Travel Required
Equal Employment Opportunity Statement

Travelers is an equal opportunity employer.",4.1,"Travelers
4.1","Hartford, CT","Hartford, CT",10000+ employees,1853,Company - Public,Insurance Carriers,Insurance,$10+ billion (USD),-1
Senior AI Software Engineer,-1,"Company Overview

Calling the adventurers ready to join a company that's pushing the limits of nanotechnology to keep the digital revolution rolling. At KLA, we're making technology advancements that are bigger—and tinier—than the world has ever seen.

Who are we? We research, develop, and manufacture the world's most advanced inspection and measurement equipment for the semiconductor and nanoelectronics industries. We enable the digital age by pushing the boundaries of technology, creating tools capable of finding defects smaller than a wavelength of visible light. We create smarter processes so that technology leaders can manufacture high-performance chips—the kind in that phone in your pocket, the tablet on your desk and nearly every electronic device you own—faster and better. We're passionate about creating solutions that drive progress and help people do what wouldn't be possible without us. The future is calling. Will you answer?

Responsibilities

Group/Division
KLA has always had a close relationship with physics and data. Our optical and electron beam inspection and measurement tools use cutting edge physics models, both for hardware design and as part of their algorithms. AI, including several traditional machine learning techniques and deep learning are routinely used to process this data to meet application requirements.

The AI & Modeling Center of Excellence, centered in KLA’s R&D facility in Ann Arbor, MI, was setup with the mission of advancing KLA’s traditional strengths in physics and data and providing implementation solutions for multiple KLA Inspection and Metrology products targeted at the semiconductor manufacturing industry.

As a part of this group, you will be part of a world class team of physicists, HPC system designers, machine learning and application engineers who build cutting edge solutions for modeling complex imaging techniques and semiconductor processes. You will also work with a data scientists and AI infrastructure engineers whose mission is to build and scale machine learning based solutions for our semiconductor customers.

We are looking for engineers in a few different fields. If you are passionate about Physics Modeling, High Performance Computing - HPC (including GPU), ML, Data, or Cloud technologies – this is the place for you!

Responsibilities:
Software Engineers in the AI and Physics Modeling team may work on a variety of tasks including platform for large scale experimentation, scaleout of physics models, data management and inference solutions for KLA products.

Although familiarity with Machine Learning and Deep Learning solutions would be a big plus, this is primarily a Software Engineering position. Successful candidates are passionate about software, and will have exceptional skills and hands on experience with development in C/C++ and Python in a Unix environment. Deep conceptual understanding of multi threaded and multi process software systems is also necessary.

In addition to the above fundamental software skills, any of the following technical hands-on skills are highly desirable.

1) System Programming and Operating Systems.
2) Distributed systems for data management.
3) Distributed computing infrastructure.
4) Cloud technologies for storage, containerization and compute clusters.
5) Data Structures and algorithms
6) GPU architectures and data management.
7) Traditional machine learning using Random Forest, XG Boost, Logistic Regression.
8) Deep Learning for regression, classification. Generative models.
9) TensorFlow, NumPy, scikit-learn, and other ML and DL frameworks.
10) MPI and similar distributed computing framework.
11) GPU Architectures and CUDA (CuGraph, CuData, CuML etc).
12) GO Systems Programming, Java Programming.

Successful candidates for this position will also demonstrate the following non-technical skills.

1) Capability to formulate creative solutions through analyzing complex data
2) Good communication skills
3) Strong team player and motivated by team success
4) Strong problem solving skills

Minimum Qualifications

Doctorate (Academic) with at least 2 years of experience.
OR
Master's Level Degree with at least 4 years of experience.
OR
Bachelor's Level Degree with at least 5 years of experience.

Equal Employment Opportunity

KLA is an Equal Opportunity Employer. Applicants will be considered for employment without regard to age, race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability, or any other characteristics protected by applicable law.",3.8,"KLA-Tencor
3.8","Ann Arbor, MI","Milpitas, CA",5001 to 10000 employees,1976,Company - Public,Industrial Manufacturing,Manufacturing,$2 to $5 billion (USD),"Applied Materials, Nanometrics"
"Senior SDE, Catalog Big Data and Machine Learning",-1,"Amazon's Catalog DataWorks team is looking for highly motivated engineers. We are embarking on multiple new initiatives to re-organize Amazon's catalog of billions of products, in new and interesting views, that drive several features Amazon's customers love. Today, these views drive hundreds of popular features like product recommendations, clustering of similar products, and shopping with Alexa. We will build a new near real-time Catalog Data Lake on AWS, to enable engineers and scientists across Amazon to solve customer problems faster. Come join us on this exciting journey!

As an engineer on this team, you will own the Catalog Data Lake end-to-end. You will work closely with business partners to synthesize technical requirements. You will design and implement significant parts of the platform. You will learn and use industry standards like Spark and Parquet as well as modern AWS offerings like EMR, Glue, Athena, and Redshift. We are fortunate to be at the cusp of innovation in both the e-commerce business as well as cloud technology. As a key stakeholder, you will constantly learn new patterns, solve key customer problems and strive to make AWS better along the way.Basic Qualifications
Bachelor's degree or higher in computer science or math is required.
Strong computer science fundamentals - algorithms, data structures and design patterns.
At least 8 years of software development experience.
At least 3 years of experience building and operating Big Data systems.
Experience mentoring, guiding and influencing peers.
Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.",-1,Amazon Corporate LLC,"Seattle, WA",-1,-1,-1,-1,-1,-1,-1,-1
SENIOR SOFTWARE ENGINEER & SOFTWARE ARCHITECT,-1,"Job Description
Senior Software Engineer, Software Architect
JOB SUMMARY

The Senior Software Engineer, Software Architect will develop software for Company innovative semiconductor X-Ray inspection system. The Senior Software Engineer will collaborate with Applications, QA, and Algo teams for high performance solutions and optimization per customer issues. It will be important to be comfortable working in a small company environment and a typical startup with engineers and scientists.

ABOUT THE CLIENT

Based in San Jose, California, client was founded in 2013 expressly to bring high speed inspection and metrology technology to the semiconductor packaging industry. Client founders anticipated the need to deploy inline 100% transmissive inspection into the semiconductor packaging manufacturing process and developed the company’s technology with this end in mind. The results, Client’s HR-AXI technology suite brings together the company’s unique data acquisition architecture with proprietary machine learning analysis techniques to provide customers with process monitoring and defect detection capabilities not found on any other products in the market. This job description can be updated at any time.

RESPONSIBILITIES
Designs, develops, troubleshoots, and debugs software programs for enhancements and new products, focused on creating high quality and high-performance solutions while maintaining high-level coding standards.
Develops software and tools in support of design, infrastructure, and technology platforms. Develops software solutions by studying information needs, conferring with users, and studying systems flow, data usage, and work processes
Supports hardware compatibility and/or influences hardware design based on software needs; work as part of cross-functional team to solve and implement system level problems.
Monitor application stability, performance, and availability. Promptly resolve issues impacting operations.
Work with engineering, documentation, and applications departments to ensure successful development and delivery of overall product.
Provide appropriate project feedback to management in a timely and appropriate format.
QUALIFICATIONS AND REQUIRED SKILLS
Education requirement: Bachelor’s degree in Computer Science, Electrical Engineering, or similar technical field required. Master’s or PhD strongly preferred.
Experience requirement: Minimum of 8 years of related experience working in software development.
Strong expertise in C# .NET. WCF, WPF, Database development. In addition, Python experience a plus.
Experience with Image processing algorithms implementations is a plus
Experience with software development for Factory Automation for Semiconductor equipment, a plus.
Self-starter able to think and act independently to translate general objectives into tangible results, with a record of delivering successful designs on schedule.
Demonstrated ability to organize, manage, and complete multiple assignments with challenging timelines independently and effectively.
Demonstrated analytical and problem-solving skills with high attention to detail.
Proactive approach to problem-solving. Build relationships with stakeholders to support successful design, build and testing.
Strong verbal and written communication, good attitude, and work ethic. Ability to communicate technical concepts and results clearly.
Experience with Git and Azure DevOps, a plus.",3.0,"Simple Solutions
3.0","San Jose, CA","Morgantown, WV",1 to 50 employees,2006,Company - Private,IT Services,Information Technology,Less than $1 million (USD),-1
Cloud Engineer,-1,"Job Description
Responsibilities:
Develop and implement technical efforts to design, build, and deploy AWS applications at the direction of lead architects, including large scale data processing, computationally intensive statistical modeling, and advanced analytics
Participate in all aspects of the software development life cycle for AWS solutions, including planning, requirements, development, testing, and quality assurance
Provide guidance, thought leadership and mentorship to development teams to build cloud competencies
Provide innovative thought leadership around Mathematica’s cloud solutions strategy and approach, including AWS best practices and market trends
Position Requirements:

6+ years of experience architecting, designing, developing and implementing cloud solutions on AWS platforms
Demonstrated experience with designing and implementing solutions using AWS platform and tools, such as: EC2, S3, Redshift, API Gateway, Lambda, DynamoDB, CloudFormation, RDS, VPC, IAM and security, QuickSight, CloudTrail, Config, CloudWatch, SNS, AMI generation
Understanding of and experience with the five pillars of a well-architected framework
Knowledge of SQL, R, and Python for data manipulation and statistical analysis is desirable
Familiarity with federal security regulations and standards (e.g. HIPAA, FISMA, FIPS, NIST, and FedRAMP)
Experience with security, especially knowledge of FedRAMP, HIPAA, PII/PHI, is desirable
Experience in several of the following areas: database architecture, ETL, Business Intelligence, Big Data, Machine Learning, Advanced Analytics
Proven ability to work collaboratively with multi-disciplinary teams of business analysts, developers, data scientists, and subject matter experts
Strong written, verbal and interpersonal communication skills
AWS Certifications (such as AWS solutions architect or other specialty certifications) are a plus
Bachelor's degree or equivalent combination of education and experience; degree in computer science, mathematics or related field preferred
Experience with other cloud platforms like Google Cloud Platform (GCP) is a plus",4.8,"RICEFW Technologies Inc
4.8","Princeton, NJ","East Lansing, MI",51 to 200 employees,2009,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Senior Software Engineer / Team Lead,"$112K-$220K
(Glassdoor est.)","Join our team dedicated to developing and executing innovative solutions in support of customer mission success.

Job Description:

Novetta has an exciting opportunity for a self-motivated and accomplished Computer Scientist to lead our entity analytics team. You will work on complex projects involving data analysis, software engineering, and deploying software in a cloud computing environment. The team combines data from disparate sources to visualize the complex relationships between entities. This effort involves large scale data integration and entity resolution leveraging a best in class Novetta product. We are looking for a flexible problem solver with significant technical experience to lead a team providing unique solutions for our customers and stakeholders.

Responsibilities include:
Lead a technical team of software engineers and computer scientists, working within a larger ecosystem delivering an Enterprise capability.
Navigate customer and prime environment, manage resources within and across team, and assist team with professional and technical growth.
Deploy applications on a large-scale data processing cluster using AWS technologies.
Design and implement entity correlation strategies that are tailored to mission needs and unique data qualities.
Develop algorithms and visualization tools to help stakeholders understand their data and prioritize new data sources.
Develop and integrate applications to automate ingestion, processing and monitoring of data
Develop and maintain tools to support operations and maintenance of production and development computing clusters.
Basic Qualifications:
Experience leading a team of software engineers.
A Bachelor's degree in computer science or related field and a minimum of 5 years of experience; or a Master's degree in computer science or related field and a minimum of 3 years of experience.
Experience in software development/engineering including requirements analysis, software development, installation, integration, evaluation, enhancement, maintenance, testing and problem diagnosis/resolution.
Software development experience on Linux-based systems in Python or shell scripting or JavaScript.
Experience developing against full-featured REST APIs and using a command line interface
Desired Skills:

Should meet a minimum of 3:
Software development experience with JavaScript, Python, or other modern programming languages.
Hands-on experience with Spark.
Experience working with Databricks
Interest in statistical analysis, machine learning, or data science.
Experience with entity resolution products or a background in data matching theory and technologies.
Experience developing applications in AWS.
Security Clearance:
The candidate must have a TS/SCI with Poly.
Novetta, from complexity to clarity.

Novetta delivers highly scalable advanced analytics and secure technology solutions to address challenges of national and global significance. Focused on mission success, Novetta pioneers disruptive technologies in machine learning, data analytics, full-spectrum cyber, cloud engineering, open source analytics, and multi-INT fusion for Defense, Intelligence Community, and Federal Law Enforcement customers. Novetta is headquartered in McLean, VA with over 1,000 employees across the U.S.

Our culture is shaped by a commitment to our core values:

Integrity • We hold ourselves accountable to the highest standards of integrity and ethics.

Customer Success • We strive daily to exceed expectations and achieve customer mission success.

Employee Focus • We invest in our employees' professional development and training, respecting individuality and fostering a culture of diversity and inclusion.

Innovation • We know that discovering new and innovative ways to solve problems is critical to our success and makes us a great company.

Excellence in Execution • We take pride in flawless execution as we build a company that is best in class.

Earn a REFERRAL BONUS for the qualified people you know.

For more details, or to submit a referral: bit.ly/NovettaReferrals

Novetta is an equal opportunity/affirmative action employer.

All qualified applicants will receive consideration for employment without regard to sex, gender identity, sexual orientation, race, color, religion, national origin, disability, protected veteran status, age, or any other characteristic protected by law.",4.5,"Novetta
4.5","Chantilly, VA","Mc Lean, VA",501 to 1000 employees,2012,Company - Private,Enterprise Software & Network Solutions,Information Technology,$100 to $500 million (USD),"Leidos, CACI International, Booz Allen Hamilton"
Data Fusion Engineer with Security Clearance,"$48K-$109K
(Glassdoor est.)","Description Job Description: Looking for work-life balance? Leidos offers generous leave and accommodating flex-time to help you juggle your personal and professional life. Are you a Software Engineer with experience finding and aligning signals across multiple modalities (image, video, audio, lidar, etc..)? Do you want to implement and customize algorithms to fusion multiple data modalities? If so we are looking for you, our next Data Fusion Engineer to work in Arlington, VA. We need you to be competent in Python and have the ability to read code in other programming languages like Java and C++ as well as have experience working with ML libraries like SciKit Learn, TensorFlow, Keras along with experience implementing solutions with those libraries on both CPU and GPU compute architectures. Like what you are reading so far? Keep going. We want you to be intellectually adaptive, inquisitive, good at expressing your needs, and able to self-manage when necessary. Work alongside software/system engineers and research/data scientists with expertise in multi-modal information retrieval, UI development, computer vision, metrics, information science, artificial intelligence, and autonomous systems. The Department of Defense and the Intelligence Community will be the main recipients your hard work. Fun stuff you will do on the job: - Use cases requiring identifying entity/objects, determining object association, object disambiguation, anomaly detection, state estimations, etc.
Develop and maintain data models (both physical and logical)
Get to be responsible for extraction, transform, and load (ETL) tasks related to the different modalities and algorithms being applied. This data ETL includes identifying the data's relevant metadata to ensure consistency, quality, accuracy, integrity, and information assurance and security.
Performing anomaly detection using various AI/ML techniques
Use algorithms to identify complex patterns across multiple modalities
Increasing the efficiency and quality data alignment and fusion
Enhance and maintain analysis tools, including automation of current processes using AI/ML algorithms
Conduct quantitative data analysis including developing retrieval, processing, fusion, analysis, and visualization of various datasets Skills required to be successful in this role: - Bachelor's Degree in Aerospace Engineering, Computer Science, Mathematics, Statistics, Physics, Electrical Engineering, Computer Engineering or related fields with 5 years of relevant experience
Must be able to obtain and maintain a TS/SCI security clearance
Experience with Deep Learning Frameworks such as Keras, Tensorflow, PyTorch, Mxnet, etc. - Ability to apply these frameworks to real problems in the 'time -series' domain
Experience with interpretability of deep learning models
Big Data Skills (Azure, Hadoop, Spark, recent deep learning platforms)
Practical experience with statistical analysis
Experience with text mining tools and techniques including in areas of summarization, search (e.g. ELK Stack), entity extraction, training set generation (e.g. Snorkel) and anomaly detection
Expert software development skills lifecycle including developing and maintaining good production quality code
Hands-on Software Development Skills (Python-Preferred)
Experience or educational courses/projects in Machine Learning, and/or Text Mining Algorithms You will wow us even more if you have these skills: - Visualizations/Web Development Skills (e.g. Tableau, D3, etc).
Hands-on experience with prototype development
Hands-on experience with automating data cleansing, formatting, staging, and transforming data human
Hands-on experience applying data analytics
Hands-on experience with intelligent systems and machine learning LInC External Referral Bonus: Ineligible Potential for Telework: No Clearance Level Required: Top Secret/SCI Travel: Yes, 10% of the time Scheduled Weekly Hours: 40 Shift: Day Requisition Category: Professional Job Family: Software Engineering Leidos Leidos is a Fortune 500® information technology, engineering, and science solutions and services leader working to solve the world's toughest challenges in the defense, intelligence, homeland security, civil, and health markets. The company's 33,000 employees support vital missions for government and commercial customers. Headquartered in Reston, Virginia, Leidos reported annual revenues of approximately $10.19 billion for the fiscal year ended December 28, 2018. For more information, visit www.Leidos.com . Pay and Benefits Pay and benefits are fundamental to any career decision. That's why we craft compensation packages that reflect the importance of the work we do for our customers. Employment benefits include competitive compensation, Health and Wellness programs, Income Protection, Paid Leave and Retirement. More details are available here . Securing Your Data Leidos will never ask you to provide payment-related information at any part of the employment application process. And Leidos will communicate with you only through emails that are sent from a Leidos.com email address. If you receive an email purporting to be from Leidos that asks for payment-related information or any other personal information, please report the email to [email protected] . Commitment to Diversity All qualified applicants will receive consideration for employment without regard to sex, race, ethnicity, age, national origin, citizenship, religion, physical or mental disability, medical condition, genetic information, pregnancy, family structure, marital status, ancestry, domestic partner status, sexual orientation, gender identity or expression, veteran or military status, or any other basis prohibited by law. Leidos will also consider for employment qualified applicants with criminal histories consistent with relevant laws.",3.5,"Leidos
3.5","Arlington, VA","Reston, VA",10000+ employees,1969,Company - Public,Aerospace & Defense,Aerospace & Defense,$10+ billion (USD),-1
Software Engineer,"$64K-$132K
(Glassdoor est.)","Every Analyst a Scientist - One of our primary goals is to empower intelligence analysts to be able to study their data like scientists. The tools we develop focus on streamlining intelligence analysis through integrated algorithms and software that provide insight into the geopolitical landscape for use in operational intelligence missions around the world.

The Role:
As a Software Engineer, you will be part of a team that transforms large and complex customer data into real-world, high-impact solutions. You will work with researchers and engineers to design and implement solutions to challenging national security problems. You will be responsible for building the software infrastructure to clean, ingest, and expose datasets and algorithms to both developers and end users. You will deploy algorithms, generate workflows, create engineer-facing tools, and design customer-facing prototype systems. You will occasionally travel to customer sites to engage with end users, demonstrate prototypes, and integrate analytics into customer systems.

If you would like to help intelligence and defense analysts keep pace with technology-driven innovation, then this role is for you!

Who you are:
A U.S. Citizen with the ability to obtain a Security Clearance
A degree in a scientific or engineering field, such as Computer Science, Mathematics, Physics, or Software Engineering
Proficiency with a scientific programming language such as Python, Java, or C++
Experience with database management and common query syntax
Motivated collaborator and excellent communicator of ideas to both technical and non-technical audiences
Knowledge of AWS, Spark, Dask, and/or similar technologies for working with data at scale
Even better:
Active Security Clearance
Track record of architecting, developing, deploying, or maintaining enterprise software
Experience with software development best practices and tools
Understanding of web development and visualization technologies, such as d3, Leaflet, Bootstrap, or others
Familiarity with machine learning or statistical modeling techniques",4.5,"Systems & Technology Research
4.5","Woburn, MA","Woburn, MA",201 to 500 employees,2010,Company - Private,Aerospace & Defense,Aerospace & Defense,$100 to $500 million (USD),-1
Sr. Data Scientist,-1,"Background Information:

Innovative Defense Technologies (IDT), provider of automated software testing, data analysis, and cybersecurity solutions for complex defense systems, is currently accepting applications for an anticipated Sr. Data Scientist role requiring 7+ years of experience for a position in support of its efforts implementing Artificial Intelligence solutions for a variety of customers.

Overview:

The Sr. Data Scientist position offers an engineer the opportunity to utilize his/her knowledge and talents as part of a collaborative team developing AI solutions for a growing company. A few of the responsibilities include supporting feasibility studies, applying modern data storage techniques, discovering explanatory features in high-dimensionality collections of data, and exploring data using scientifically valid techniques to exploit patterns found in the data with state-of-the-art AI/ML/DL solutions.

All applicants must be able to obtain/maintain an active U.S. Security Clearance.

Responsibilities Include:
Lead development of solutions to deliver AI/ML/DL models from problem formulation to a productized, deployable, maintainable capability
Contribute to AI/ML/DL technical roadmap development
Use Deep Learning frameworks such as Tensorflow and Keras to build and validate ML/DL models
Establish and leverage Big Data frameworks to store, extract and analyze relevant data
Ensure development of software solutions meets customer needs and program intent
Work closely with the Program Manager and Chief Engineer to design and implement software requirements and solutions
Determine operational feasibility by evaluating analysis, problem definition, requirements, solution development, and proposed solutions for large, complex systems
Be responsible for a team’s products meeting software design, quality, and performance requirements
Pursue new technology development via the DoD Small Business Innovative Research (SBIR) program
Work with minimal supervision in a collaborative work environment to implement best-in-class solutions
Minimum Required Qualifications:
Bachelor’s Degree in Computer Science, Computer Engineering, Electrical Engineering, Systems Engineering, Physics, or Math Required; PhD in relevant field highly preferred
7+ years of experience in predictive modeling, data science and analysis
Required Skills:
Previous experience in a ML or data scientist role and a track record of building ML or DL models
Extensive experience working with data mining algorithms including decision trees, probability networks, association rules, clustering, and neural networks
Experience using Python (or equivalent)
Experience using ML libraries, such as scikit-learn,
Experience using data visualization tools
Experience handling terabyte size dataset
Experience working with GPUs to develop models
Ability to travel 10% or less
Preferred Skills:
Experience with MapReduce programming (Hadoop)
Skills with programming languages, such as Java or C/C++
Demonstrated ability to develop experimental and analytic plans for data modeling processes, use of strong baselines, ability to accurately determine cause and effect relations
Consulting experience and track record of helping customers with their AI needs
Publications or presentations in recognized Machine Learning, Deep Learning and Data Mining journals/conferences
Combination of deep technical skills and business savvy enough to interface with all levels and disciplines within our customer’s organization
Experience diving into data to discover hidden patterns
Experience with application container platforms
Familiarity with continuous integration/delivery tools (e.g. Jenkins)
Familiarity with version control tools (e.g. Subversion, Git, etc.)
Familiarity with VMware or other virtualization software
Experience developing applications for DOD command and control systems
Competencies:
Solid analytical abilities, coupled with a strong sense of ownership, urgency, and drive
Attention to detail
Initiative, creativity, reliability, teamwork
Ability to deal well with ambiguity, prioritize needs, and deliver results in a dynamic environment
EEO Statement:

IDT is an Equal Opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, creed, sex, sexual orientation, gender identity, national origin, disability, protected Veteran status, or any other basis protected by federal, state, or local law.",-1,Innovative Defense Technologies (IDT),"Mount Laurel, NJ",-1,-1,-1,-1,-1,-1,-1,-1
Full Stack Software Engineer (Python/Vue),-1,"Position Summary Full Stack Software Engineer (Python VueJS) Company Overview Our client is an automated underwriting platform for real estate professionals that was built to disrupt the commercial real estate industry. The software allows investors, brokers, and lenders to analyze rent, operating expenses and returns for multifamily properties by applying machine learning to a database of live multifamily transaction data from every U.S. market. Our client has a creative and entrepreneurial culture ndash everyone on the team interacts directly with customers each day, and we all contribute to the product and planning. If you have an idea to improve something, there is no red tapehellip just build what needs to be built! Innovation and passion for transforming the old-fashioned real estate industry are our highest priorities. Job Description As a full-stack (Python, PostgreSQL and HTMLCSSJavaScript) developer, you'll work on the interface and backend infrastructure of products and features used by hundreds of underwriters and real estate analysts every day. The work is challenging, fast-paced, and always changing. You must have demonstrated analytical skills, an unwavering commitment to quality, a collaborative work ethic, and cutting-edge coding skills. You must display solid proficiency in the fundamentals of Python, PostgreSQL, JavaScript, HTMLCSS, and popular front-end frameworks like Vue.js. The role will include the delivery of reliable, scalable new features to users, developed in Python, interacting with a PostgreSQL database and using the Vue.js frontend framework. You will work with the development team to develop, test and deliver finished, high quality, compelling features and products. Our team includes designers, engineers and data scientists who are passionate about quality, usability, and simplicity. If you are ready to join a company that fosters learning, growth, experimentation and innovation, our client's team is for you. Requirements Qualifications 3-5 years of experience in full stack Python development 1-3 years of experience with PostgreSQL 1-3 years of experience with JavaScript frameworks such as React, Angular or Vue.js (Vue.js is preferred, this is what our client uses), and CSS pre-processing frameworks (Sass or Less) 1-2 years of experience integrating with VBA and Excel integration preferred Experience using GitHub and solid understanding of software version control Familiarity with JIRA or equivalent product management software Familiarity with agile development best practices Driven self-starter able to work on a small team and take initiative on new tasks Familiarity with real estate or finance is a plus Responsibilities Collaborate with interdisciplinary team of data scientists, software engineers and real estate professionals Strive for high quality and rapid output utilizing agile development best practices Support, maintain, and document software functionality Maintain industry standard coding, compliance, security practices Proactively learn product frameworks and code base Our client is a startup company, and as such the responsibilities outlined above may change and evolve over time. Flexibility, curiosity, an entrepreneurial mindset, and strong work ethic are essential for this role. It is encouraged that everyone on the team continually research new technologies and analytical opportunities to improve the platform.",5.0,"CultureFit
5.0","Chicago, IL","Deerfield, IL",1 to 50 employees,1997,Company - Private,Advertising & Marketing,Business Services,$1 to $5 million (USD),-1
AWS Data Engineer,-1,"About Infinitive:

At Infinitive, we do mission-critical work for great companies. We specialize in digital marketing and digital advertising solutions, customer data & analytics, digital & business transformation, and Technology solutions. Our Technology solutions focus on Managed Cloud Services, Cloud Enablement, Digital Operations, Application Development, DevOps, Product Development, Cloud Security, Data Science and Analytics, AI/ML, IoT, and everything in between.

Our experts are results-obsessed, focused and flexible, highly engaged and hugely experienced having sat in our clients seats. Those qualities are what make us different than old-school consulting shops. And surely, they are why clients and partners describe us as the gold standard in client experience.

Infinitive has been named a Best Small Firms to Work For by Consulting Magazine seven times, a Washington Post Top Workplace three times, a Washington Business Journal Best

About this Role:

Infinitive is growing its team in the Northern Virginia area and is currently seeking an Data Scientist to join our growing Technology practice. This person will utilize their experience in analytics, IoT, machine learning, and artificial intelligence advances to create value from structured and unstructured data. The ideal candidate has experience designing novel data analytic methods and workflows, including full data pipelines from raw data through analysis results. They must also have exposure to a variety of data mining/data analysis methods, data tools, building and implementing models, using/creating algorithms, and creating/running simulations.

We are looking for candidates who are accountable, passionate, assertive, proactive, open & honest, results oriented, and adaptable. Each project engagement represents a new challenge that will give you exposure to new clients, business issues, technologies, and people and will involve a range of responsibilities to include:
Developing in Java, Python, R, or other high-level languages.
Managing disparate data sources with varying data structures of content and preparing these for data science and machine learning applications.
Working with distributed scalable Big Data storage, processing, and computation, including AWS EMR, Spark, etc.
Implementation knowledge of, or desire to learn AWS / Azure data science capabilities.
Developing solutions and integrating and extending free and Open-source software (FOSS) or COTS products.
Conduct MapReduce programming with Apache Hadoop, the Hadoop Distributed File System (HDFS), and processing large data stores.
Knowledge of SQL and query languages.
Utilize real-time, large-scale data processing engine, including Apache Spark.
Lead and create Data Science and Analytics methodologies and frameworks for implementation.
Ability to build and develop Data Science demonstrations for clients
Qualifications:
4+ years of development experience (Java, Python, R, SQL)
3+ years of experience with distributed scalable Big Data storage, including AWS EMR, Spark, etc.
Desire to become AWS / Azure Certified architect / engineer.
Experience performing data Management, modeling, and warehousing.
Hands on experience with Amazon analytic tools (preferred)
Interest in being involved internally and growing a small business (entrepreneurial spirit)
Ability to travel (up to 20%) and to work independently
Experience using Agile software development methods in a DevOps environment.
Excellent leadership, peer management, and communication skills
Management consulting experience (preferred)
Bachelor's degree in related field (preferred)
Applicants for employment in the U.S. must possess work authorization which does not require sponsorship by the employer for a visa.

Infinitive is an Equal Opportunity Employer.

Powered by JazzHR",3.4,"Infinitive Inc
3.4","Arlington, VA","Cedar Rapids, IA",201 to 500 employees,1997,Company - Private,Enterprise Software & Network Solutions,Information Technology,$10 to $25 million (USD),-1
"Senior SW Engineer, Data Science ( Kubernetes/ Docker ) Remote USA","$72K-$141K
(Glassdoor est.)","If you dream of a job working in a field where all the hard problems are solved and you get to re-use previous research to get your job done, you need not apply. If, however, you are someone who wants to tackle problems that truly are on the cutting edge, then we encourage you to keep reading.

Data Science is an emerging field within cyber security. FireEye, given its deep expertise and comprehensive view on the advanced threat landscape, is uniquely positioned to enable data scientists to have major impact within our industry, company, and across our customer base. Detecting security breaches using machine learning and data analytics is an unsolved problem (this is not handwriting recognition folks) and has huge potential.

If you are someone who wants to be on the cutting edge of a high profile industry, who wants to make an impact by pushing both fields of data science and cyber security forward, you may be the perfect candidate to help us on our mission.

What you will do:
Develop, and manage data systems to ingest and process data at massive scale
Identify data sources both internally and externally that we can use to find evil.
Contribute towards the architecture and design of software solutions for long-term storage and retrieval.
Identify and implement data exploration technologies. Create dashboards and implement analytical tools for exploration
Work with data scientists to productize ML models and assist product teams with ML model releases into end products.
Collect requirements, design, and build backend components and tools to run ML models, assess ML model efficacy, manage large scale datasets, and generate features for ML models
Contribute to the evolution of coding and design practices within the organization.
Review code base commits and contribute to the growth of team members.
Requirements
Ability to work in an iterative, agile development environment.
Experience implementing ETL processes and building data pipelines
Experience developing reliable distributed systems.
Experience in Data modeling and schema design
Strong knowledge of a variety of operating systems, networking fundamentals, software design and programming best practices.
Experience with use of a wide array of algorithms and data structures.
Deep understanding and experience of going through the entire life cycle of building software platforms and products
Deep knowledge of various AWS services and associated tools
Strong experience developing in Python 3
Experience developing in at least 1 of the following: C, Go or Java
Experience with RDBMS, such as PostgreSQL or MySQL, as well as NoSQL
Experience with Kubernetes and Docker.
Experience deploying products in AWS
Additional Qualification: *
Ability to pick up, work with and explore new analytical tools
Strong experience with DevOps practices and common tooling
Strong communication skills.
Ability to work with loosely defined requirements.
At FireEye we are committed to our #OneTeam approach combining diversity, collaboration, and excellence. All qualified applicants will receive consideration for employment without regard to race, sex, color, religion, sexual orientation, gender identity, national origin, protected veteran status, or on the basis of disability. Requests for accommodation due to disability can be sent directly to .",3.3,"FireEye Inc
3.3","Denver, CO","Milpitas, CA",1001 to 5000 employees,2004,Company - Public,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,"Palo Alto Networks, Tanium"
"Senior SW Engineer, Data Science","$72K-$141K
(Glassdoor est.)","Job Description

If you dream of a job working in a field where all the hard problems are solved and you get to re-use previous research to get your job done, you need not apply. If, however, you are someone who wants to tackle problems that truly are on the cutting edge, then we encourage you to keep reading.

Data Science is an emerging field within cyber security. FireEye, given its deep expertise and comprehensive view on the advanced threat landscape, is uniquely positioned to enable data scientists to have major impact within our industry, company, and across our customer base. Detecting security breaches using machine learning and data analytics is an unsolved problem (this is not handwriting recognition folks) and has huge potential.

If you are someone who wants to be on the cutting edge of a high profile industry, who wants to make an impact by pushing both fields of data science and cyber security forward, you may be the perfect candidate to help us on our mission.

What you will do:
Develop, and manage data systems to ingest and process data at massive scale
Identify data sources both internally and externally that we can use to find evil.
Contribute towards the architecture and design of software solutions for long-term storage and retrieval.
Identify and implement data exploration technologies. Create dashboards and implement analytical tools for exploration
Work with data scientists to productize ML models and assist product teams with ML model releases into end products.
Collect requirements, design, and build backend components and tools to run ML models, assess ML model efficacy, manage large scale datasets, and generate features for ML models
Contribute to the evolution of coding and design practices within the organization.
Review code base commits and contribute to the growth of team members.",3.3,"FireEye Inc
3.3","Denver, CO","Milpitas, CA",1001 to 5000 employees,2004,Company - Public,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,"Palo Alto Networks, Tanium"
"Senior Machine Learning Engineer, Early Stage Pipeline, X",-1,"Senior Machine Learning Engineer, Early Stage Pipeline, X

Software Engineering

Mountain View, CA

We're an early stage team at X with a growing, interdisciplinary portfolio. To prove our path to the moon, we make early contact with the real world through both internal and external partnerships.

In this role, you will be responsible for taking early stage investigations from an idea stage to first prototypes to a full-blown projects. You'll be rapidly iterating through a set of prototypes to evaluate possible product directions. This is an extremely dynamic role and requires high cross-functional communication, organization, and planning. The ideal candidate is a self-starter and has a track record of effectively operating in a dynamic loosely structured environment (e.g. startup, new products within a larger company). The candidate will work on multiple projects/investigations.

Responsibilities:
Identify and implement a set of machine learning prototypes to aggressively de-risk projects building the whole solution: data acquisition, data processing pipelines, ML modeling.
Setup technical direction for investigations/projects working with the early stage leadership team.
Team lead investigations that grow to become projects.
Qualifications:
Hands-on experience with machine learning, one or more of; natural language processing (semantic understanding, sentiment analysis), computer vision, time series analysis.
Experience with building robust data pipelines.
Tech Lead experience.
Startup or early-stage product development experience.
Preferred Qualifications:
Experience with the Google Cloud Platform
About X, the Moonshot Factory

X creates radical new technologies to solve some of the world's biggest problems. We develop uncomfortably ambitious, potentially world-changing new ideas such as self-driving cars, balloon-powered Internet and smart contact lenses. We're a team of makers, entrepreneurs, engineers, designers and scientists with deep technical expertise who love the challenge of the seemingly impossible. We believe that a culture of psychological safety creates the foundation of trust and respect necessary to build moonshots. X was formerly known as Google[x] and is part of Alphabet .

At X, we don't just accept difference - we celebrate it, we support it, and we thrive on it for the benefit of our employees, our products and our community. We are proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements.

If you have a disability or special need that requires accommodation, please contact us at: (see application details) .",-1,"X, the moonshot factory","Mountain View, CA",-1,-1,-1,-1,-1,-1,-1,-1
"Senior/Staff Software Engineer, Data Infrastructure","$116K-$227K
(Glassdoor est.)","Senior/Staff Software Engineer, Data Infrastructure job posting

Every year, while Americans wait for their paychecks, more than $1 trillion of their hard-earned money is held up in the pay cycle. As a result, we accumulate over $50 billion in late and overdraft fees and turn to high-interest loans. Overdraft charges and bank fees often trap people in a cycle of debt that can lead to unhealthy decisions and falling victim to predatory businesses disguised as helpful services. We don't accept that.

Earnin is an app that creates products that help people gain control of their finances. Cash Out lets people get paid as soon as they leave work, with no fees, interest, or hidden costs. With Health Aid, Earnin negotiates on behalf of community members to lower their total unpaid medical bill and work out a budget-friendly payment plan. Cash Back Rewards is a way for members to earn up to 10% cash back on purchases from over a thousand local and national businesses without needing a credit card or having to reach spend thresholds to earn cash rewards — and they can withdraw the money at any time. We also offer free tools to help avoid overdrafts, to remind people when recurring bills are due, and we're working on more! There is never any required cost to use any of these products or services, users can choose to tip what they think is fair to support the service and pay it forward to keep the movement going.

Earnin is supported by funding partners including Andreessen Horowitz, Matrix Partners, Ribbit Capital, Felicis Venture, Thrive Capital, and others. Join us and help build a new financial system focused on fairness and people's needs.

You can help make a difference.

About the Team:

We are a data driven mobile financial tech company. The Data Infrastructure team builds the data services and data infrastructure that powers data science, analytics, and product development throughout Earnin. We are looking for a product-minded, self-driven Senior Software Engineer to own multiple large-scale projects that advance our mission of enabling people to gain access to their paycheck on demand.

What sets us apart:
High impact roles at a relatively small company that's aggressively growing our user base.
We are a collaborative team and genuinely enjoy working with each other.
We believe in empowering our people to be successful.
We're building a product that inspires fairness across the financial world and helps people not get taken advantage of.
As a Senior Engineer you will:
Break down complex problems into their bare essentials, translate this complexity into elegant design and create high quality, maintainable code.
Build massively scalable, production-grade data services.
Champion data quality and governance throughout the organization.
Build a world class data lake and data warehouse.
Design and develop new systems and tools to enable all of Earnin to consume and understand data faster.
Own the end to end design, build, and maintenance of platform services, data pipelines, and data products.
Implement comprehensive monitoring, logging, and alerting across our data infrastructure.
Work cross functionally with other teams (data science, design, product, marketing, and analytics) in high visibility roles as an engineering leader.
Build and deploy the data architecture that supports machine learning model development and actionable analytics.
Work with product engineering and data science teams to design scalable, performance model deployment architectures.
Communicate the tradeoffs of technical decisions to multiple stakeholders, including non-technical audiences.
Collaborate with and mentor other engineers and provide engineering direction to data scientists and analysts.
Actively engage and drive design reviews and code reviews.
Some skills we consider critical to being a Senior Engineer:
BS or MS degree in Computer Science, Engineering, or a related technical field.
8+ years of development experience in a fast-paced environment, especially startups.
5+ years of experience working with data systems.
Strong Python and SQL skills.
Strong programming and architecture skills.
Excellent written and verbal communication skills, including the ability to identify and communicate data driven insight.
Taking pride in your code quality and helping others elevate their own code quality.
Substantial experience with testing, data validation, and data quality assurance.
You can articulate the tradeoffs of different deployment architectures (e.g. streaming vs. batch vs. service-based).
Experience designing data platforms and services on cloud infrastructure, preferably AWS.
Hands-on experience designing and building large-scale solutions with the Hadoop stack and/or Spark.
Experience tuning and optimizing Spark-based applications.
Experience deploying and/or using query engines like AWS Athena, Presto, and Impala.
Experience with AWS analytical services like Redshift.
Hands-on experience working with a varied set of data storage technologies (e.g. Mysql, Postgres, DynamoDB, S3, etc.). You know where and when to use each.
Extensive experience with data modeling for multiple use cases and application styles, including NoSQL data modeling.
Experience working with data formats such as Avro and Parquet.
Experience working with alerting and monitoring tools like DataDog and PagerDuty.
Nice to haves:
You have experience building and deploying machine learning models.
You have experience using Terraform.
You have substantial experience working at a startup.
You have experience with data modeling in Redshift.
Experience with streaming infrastructure like Kafka.
Experience working with Kubernetes.
Experience building and deploying AWS Lambda applications.",3.1,"Earnin
3.1","Palo Alto, CA","Palo Alto, CA",201 to 500 employees,2012,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Engineer (open level),"$43K-$69K
(Glassdoor est.)","Title
Data Engineer (open level)

07/08/2020

What you'll do...
At H&R Block, your contributions will go far beyond any job description. When you join our team, you'll add to the momentum of a forward-thinking company - one that defined an industry and is now leading its transformation.

H&R Block is transforming tax preparation through data to ensure that every client we serve gets the best tax outcome possible.

We are building a new Data Engineering Team in the Data Science & Analytics organization. This new team will own the technology and data capabilities of the end-to-end data-and-analytics function. It will take responsibility for building and maintaining the analytical technologies that the data science teams use, managing data at an enterprise scale, leveraging relationships with IT teams throughout the enterprise, and leading information architecture.

We are looking for talented, curious, and creative data engineers of all levels to help launch this team. You will be a good match for our organization if you are:
Motivated by the idea of building something innovative, transformative, and impactful.
Committed to the idea that data can drive experiences and products that wow our business partners and clients
Obsessed with defying expectations and raising the bar
Driven by an innate sense of ownership for the products you create.
Day to day, you'll...
Design and deploy architecture, solutions, and software to capture, manage, store, and use structured and unstructured data from internal and external sources in both on-prem and cloud environments.
Deploy machine-learning models and other data-science products across the enterprise.
Navigate the balance between business needs, data governance best practices, and technical requirements.
Select or develop tools to cleanse, organize, and transform data and to maintain, defend, and update data structures and integrity on an automated basis.
Develop data products to facilitate self-service capabilities and assist the data teams to increase their efficiency and effectiveness.
Collaborate and communicate effectively within cross-functional teams that span internal Data Science & Analytics teams, IT, business groups, and executive stakeholders.
Be a positive force to cultivate a culture that is passionate about developing data tools as a business driver.
Job ID
368348BR

Address1
ONE H&R BLOCK WAY

City
KANSAS CITY

State
Missouri

Employee Type
Regular

What you'll bring to the team...
Education / work experience should include most of these, depending on level:
Bachelor’s degree in Computer Science or a related technical field (or equivalent work experience and technical skills)
Data warehousing and ETL solutions
APIs in a microservices architecture
Big-data technologies and the Hadoop stack (MapReduce, Hive, Pig, Hbase
NoSQL implementations (MongoDB)
Developing Java-based software solution
At least one scripting language (Python, Perl, JavaScript, Shell
Developing software solutions to solve complex business problems
Working with data scientists and other data users
Posting Title
Data Engineer (open level)

Sponsored Job
#hrbjob

Job Family
Corporate Analytics",3.6,"H&R Block
3.6","Kansas City, MO","Kansas City, MO",10000+ employees,1955,Company - Public,Other Retail Stores,Retail,$2 to $5 billion (USD),"Intuit, Jackson Hewitt, Liberty Tax Service"
Senior Modeling & Simulation Engineer,-1,"Applied Research Associates, Inc. is looking for a Senior Modeling and Simulation Engineer to join our multi-disciplinary team of engineers and scientists in the Capital Area Division, located in Alexandria, VA. The ideal candidate has a passion for predicting the behavior of physical systems in challenging environments and operational impact on mission success. Models will be developed, used, and improved to support a Department of Homeland Security customer to safeguard the nation’s borders and interior from chemical, biological, radiological, nuclear, and explosive materials, equipment, technologies, and their actors. Models may be based on the underlying physics or may be process or agent based to predict operational performance and impact. Modeling and analysis may require the use and development of 3D virtual worlds or geospatial data. Models will be verified and validated, and they will be used in support of test and evaluation activities of systems intended to detect and identify threats. The candidate may participate in test and evaluation activities to support the verification, validation, and overall improvement of models. Models may become part of larger, integrated modeling and simulation activities, and may require the use of high performance computing technologies and federated simulations.

This position is contingent upon award of a contract expected in Summer 2020 supporting the Department of Homeland Security.

Required Qualifications:
Ability to program in a high level programming language, such as Fortran, C++, or Java
Eagerness to learn new tools and techniques
Strong verbal and written communication skills
Must be a U.S. Citizen with the ability to obtain and maintain a security clearance
Bachelor’s degree with minimum of 10 years of experience or greater in a physical science (physics, chemistry, biology), engineering-related discipline (nuclear, chemical, civil, mechanical, electrical), or modeling& simulation disciple (computer modeling, computational science, operations research)
Ability to present to senior leadership on the status and issues associated with research or test efforts in preparation for acquisition decision meetings
Desired Experience and Qualifications:
Experience modeling CBRNE detectors or effects
Experience using multiple software tools such as MCNP, GadRas, SWORD, ExtendSim, Arena, SolidWorks, Fluent, ArcGIS, QGIS, VisIt, ParaView, or Cubit
Experience creating 3D models of systems, i.e., CAD
Experience using high performance computers (i.e., supercomputers)
Experience developing and using discrete event or agent based models and simulations to predict and assess system performance
Experience developing machine learning models
Background in a physical science or engineering discipline, such as Physics, Chemistry, Biology, Mechanical Engineering, Nuclear Engineering
Active DoD Secret or Top Secret clearance, DoE Q clearance, or DHS Suitability
COMPANY INFORMATION:

Applied Research Associates, Inc. is an employee-owned international research and engineering company recognized for providing technically superior solutions to complex and challenging problems in the physical sciences. The company, founded in Albuquerque, NM, in 1979, currently employs over 1200 professionals. ARA offices throughout the United States and Canada provide a broad range of technical expertise in defense technologies, civil technologies, computer software and simulation, systems analysis, environmental technologies, and testing and measurement. The corporation also provides sophisticated technical products for environmental site characterization, pavement analysis, and robotics.

At ARA, employees are our greatest assets. The corporation realizes that employee ownership spawns greater creativity and initiative along with higher performance and customer satisfaction levels. ARA gives its employees the tools, training, and opportunities to take more active roles as owners. The culture is challenging; innovation and experimentation are the norm. Employees are eligible for contributions which not only add to the company’s success, but also their own through the Employee Stock Ownership Plan (ESOP). The motto,“Engineering and Science for Fun and Profit” sums up the ARA experience. For additional information and an opportunity to join this unique workplace, please visit our website atwww.ara.com.",3.5,"Applied Research Associates
3.5","Alexandria, VA","Albuquerque, NM",1001 to 5000 employees,1979,Company - Private,Federal Agencies,Government,$100 to $500 million (USD),-1
Senior Data Engineer,-1,"This is a Data Engineer position for supporting a Navy program located in Quantico, Virginia.

We are seeking a Data Engineer to join our team of committed technical professionals to protect those who serve against criminal, terrorism and emerging threats. Are you passionate about analytics and innovation? Our employees enjoy a fast-paced, collaborative culture and the ability to directly impact our business. You will identify technical issues and opportunities for efficiency and provide technical insights through system design and configuration perspectives. This role is both challenging and rewarding.

You will support the mission through the implementation of a modern, integrated internal data infrastructure with a focus primarily on exploiting the established data foundation to make internal and customer-centric business processes as effective and efficient as possible, laying the foundation for cognitive capabilities that can sense and respond to both internal and external customer data needs. The candidate will also focus on expanding the organization’s data ecosystem to include context-rich data while maintaining the agility needed to spark innovation.

How you will make a difference:
Establish shared operational data and integrated enterprise data, all while managing and/or improving data quality and security through the creation of business-driven governance structures and culture change management.
Establish data policies, standards, and procedures that improve data quality, availability, accessibility, security, usability, and enforcement of enterprise information management (EIM) program requirements.
Establish enterprise standards – including a uniform and repeatable system development lifecycle methodology for Reference Data and Master Data (e.g., a common set of standards for data naming, abbreviations, and acronyms).
Develop a Master Data Management (MDM) Plan that focuses on the technology, tools, and processes ensuring master data is coordinated across the enterprise. MDM is a method used to define and manage the critical data of an organization to provide, with data integration, a single point of reference. The data that is mastered may include reference data – the set of permissible values, and the analytical data supporting decision making. MDM provides a unified master data service intended to provide accurate, consistent and complete master data across the enterprise and to business partners.
Recommend solutions based on performing industry-specific analysis, such as case studies describing data management best practices, identifying trends across the industry.
Make recommendations to improve the efficiency and effectiveness in how the agency acquires, stores, manages, shares and applies its data.
Engage business users and stakeholders for the increased release of actionable high-quality data on key operational and tactical activities at NCIS.
Develop technology solutions to provide the platform, training, and standardized tools enabling querying, data mining, statistical analysis, reporting, scenario modeling, data visualization, and dash-boarding, and processes for a centralized, or analytics as a service model, allowing for the sharing of data across the enterprise from a common hub, facilitates cross-organizational data initiatives due to its enterprise-wide view of data assets and needs.
Basic Qualifications
Required: A bachelor’s or master’s degree in computer science, data science, operations research, statistics, applied mathematics, or a related quantitative field [or equivalent work experience such as, economics, engineering and physics] is [preferred/required]. Alternate experience and education in equivalent areas such as economics, engineering or physics, is acceptable. Experience in more than one area is strongly preferred.
Required: Three to six (midlevel) of relevant project experience in successfully launching, planning, and executing data science projects. Preferably in the domains of risk modelling and quality assessment.
Preferred: Specialization in text analytics, image recognition, graph analysis or other specialized ML techniques such as deep learning, etc.
Preferred: the candidates are adept in agile methodologies and well-versed in applying DevOps/MLOps methods to the construction of ML and data science pipelines.
Coding knowledge and experience in several languages: for example, R, Python, Java, C++, Excel, MATLAB, etc.
Experience with popular database programming languages including SQL, PL/SQL, others for relational databases and upcoming non-relational databases such as NoSQL/Hadoop-oriented databases such as MongoDB, Cassandra, others.
Preferred: Specialized/operational data scientists may need further high-performance computing (HPC)/compute skills; larger data science teams, in particular, may require further degrees of specialization such as:
Experience with distributed data/computing tools such as MapReduce, Hadoop, Hive, Kafka, and MySQL
Experience of working across multiple deployment environments including cloud, on-premises and hybrid environments, multiple operating systems and through containerization techniques such as Docker, Kubernetes, AWS Elastic Container Service, and others.
Experience in one or more of the following commercial/open-source data discovery/analysis platforms: RStudio, Spark, KNIME, RapidMiner, Alteryx, Dataiku, H2O, SAS Enterprise Miner (SAS EM) and/or SAS Visual Data Mining and Machine Learning, Microsoft AzureML, IBM Watson Studio or SPSS Modeler, Amazon SageMaker, Google Cloud ML, SAP Predictive Analytics.
Preferred: Expertise in solving vision, text analytics, credit scoring, and failure prediction problems.
Knowledge and experience in statistical and data mining techniques such as generalized linear model (GLM)/regression, random forest, boosting, trees, text mining, hierarchical clustering, deep learning, convolutional neural network (CNN), recurrent neural network (RNN), T-distributed Stochastic Neighbor Embedding (t-SNE), graph analysis, etc.
Strong documentation skills. Required: Certifications as per Cybersecurity Workforce Management and Qualification Manual, SECNAV M-5239.2.
Required: Eligible AND adjudicated to the Top Secret (TS SCI) clearance level is required to start.
About Inventium.io:

Inventium.io LLC is a technical consulting and software development services company dedicated to protecting and advancing our national defense and scientific capabilities. Based out of the Washington DC area, we rely on innovation to continually advance our employees' skills and provide digital transformation solutions to our customers.

With proven records of successfully delivering quality services and solutions to multiple federal agencies, our technical competencies include Emerging Technology Solutions, DevSecOps, Cloud Migration, Machine Learning, System Modernization, and Technology Management.

Benefits and Perks
Employer paid Health Benefits (Medical, Dental and Vision)
Retirement Plan
Paid Time Off and Federal Holidays
Training and Development
Employee Referral Program
Awards and Recognition",5.0,"inventium.io LLC
5.0","Quantico, VA","Washington, DC",1 to 50 employees,2016,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Senior Software Engineer,-1,"At Pacific Biosciences, our R&D team is committed to developing innovative products that enable scientists to excel in a wide variety of life science research fields, including human biomedical, plant and animal sciences, and microbiology and infectious disease. Our unique Single Molecule, Real-Time (SMRT) sequencing platforms generate true high-quality long reads, giving researchers a more comprehensive view of genomes, transcriptomes, and epigenomes from any organism.

The Primary Analysis group, as part of the larger software engineering team at PacBio, develops algorithms and HPC solutions for decoding the raw data streams, generated through high-speed optical detection of the SMRT sequencing reactions, into DNA sequence reads. We operate at the intersection of cutting-edge nanotechnology and state-of-the-art bioinformatics tools, and our responsibilities span the full product development life cycle in an aggressive time-to-market environment. These include analysis and algorithm development in coordination with chemistry and systems R&D; the development of real-time analysis pipelines; and the development of validation and support infrastructure geared towards product system reliability and internal R&D support. We are seeking a talented algorithm engineer with a strong background in the physical or machine-learning/data sciences who also has a passion for designing and developing performance-critical data analysis solutions.

Responsibilities:

Design, develop, and test signal- and sequence-analysis algorithms that will drive fundamental improvements in basecalling accuracy and yield.
Work collaboratively in a team environment to solve challenging problems in software architecture and scalability of real-time analysis pipelines for our next-generation sequencing platforms.
All listed tasks and responsibilities are deemed as essential functions to this position; however, business conditions may require reasonable accommodations for additional tasks and responsibilities.

Key Skills and Background:

3+ years of experience shipping product software in a scientific or quantitative domain.
Demonstrated skills applying numerical methods, statistical signal processing, or machine-learning techniques to high-throughput, performance-critical analysis applications.
Linux-based systems programming experience with knowledge of OS, toolchain and hardware constraints.
Strong C++ programming experience in applications geared towards performance and scalability; previous experience in CUDA programming for GPU is a plus.
MS, PhD or equivalent experience in a quantitative field (physics, CS, etc.), preferably with an applied math or algorithmic focus.
Engineering instincts to efficiently investigate and solve the problem at hand, from prototype development (Python, R, MATLAB, etc.) to production designs.
Team player, with strong communication skills, and comfortable as a self-starter in an agile, fast-paced development environment.
All qualified applicants will receive consideration for employment without regard to race, sex, color, religion, national origin, protected veteran status, or on the basis of disability, gender identity, and sexual orientation.",3.7,"Pacific Biosciences
3.7","Menlo Park, CA","Menlo Park, CA",201 to 500 employees,2000,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,$50 to $100 million (USD),Illumina
Senior Data Engineer,-1,"ABOUT 605

At 605 we are engineers, analysts, data scientists, media experts, marketing strategists and political operatives. Our team of data scientists pioneered the field of TV data analytics. We offer unique, independent audience measurement and analytics to build better marketing and programming initiatives within the media and entertainment industries.

The Sr. Data Engineer at 605 must have a broad and deep data skillset as well as strong analytical capabilities . In addition to being a hands on individual contributor, the ideal candidate is a productive team player and a mentor to Junior. Data Engineers. Additionally, we are looking for strong technical experts.

Responsibilities include:
Actively participate in team technical discussions in all things data
Identify and address issues with data sets from multiple vendors
Identify and address code and data quality issues
Actively participate in code reviews and grooming sessions
Actively participate in technology architecture discussions for product development
Translate business requirements into strategy
Advocate for software best practices within your team as well as across engineering
Be ultra-responsive and capable of making instant decisions, always kicking the ball forward
Work on unique and interesting data challenges around architecting, building and managing pipelines that securely process hundreds of terabytes of data
Work closely with analysts and statisticians to ensure the validity of our processes
Our engineers are expected to wear a number of hats and have the opportunity to touch all parts of the stack. Our stack includes Apache Spark, Scala, Redshift and an ever-growing list of many other cool technologies.

Requirements
Skillful user of Apache Spark
Experience wrangling terabytes of big, complicated, imperfect data
Experience with AWS products (Redshift, EMR, S3, IAM, RDS, etc)
You have a deep understanding of scalable systems and you have large-scale engineering experience in an Agile development environment
Bachelor's degree in Computer Science or a related field (or 4 additional years of relevant work experience)
A strong understanding of data structures, algorithms, and effective software design
Significant development experience with a major modern language (e.g. Java, Scala, Python, Ruby, C/C++, etc.)
Significant experience working with structured and unstructured data at scale and comfort with a variety of different stores (key-value, document, columnar, etc.) as well as traditional RDBMSes and data warehouses
Experience with or interest in AWS Glue, Redshift Spectrum and any other tools that enable data querying at scale
Experience writing unit, functional and integration tests
Comfort with version control systems (e.g. Git, SVN)
Excellent verbal and written communication skills; must work well in an agile, collaborative team environment
Preferred Qualifications
Master's in Computer Science or a related field
Practical experience with supervised machine learning techniques
Strong background with test-driven development
Basic understanding of statistics and experience with statistical packages such as R, Matlab, SPSS, etc
Benefits

Important and Standard
Comprehensive health, dental and vision insurance for employees and their families
Life & Disability insurance
401k plan with match, eligible for match after one year
Pre-tax flexible compensation plan for medical, transit, parking or dependent care expenses
Up to 15 paid vacation days depending on grade level
7 paid sick days in a calendar year - if you’re sick, you stay home
Other cool benefits
4 work from home days/month
A kitchen stocked with sodas, snacks, yogurt and other goodies
A tight knit start up community who likes to eat! We celebrate everyone’s birthdays, have frequent team lunches, and do events in and out of the office
605 is an active participant in conferences
EEO STATEMENT

At 605, we’re just as passionate about diversity as we are about pioneering the field of TV data analytics. We are committed to cultivating an environment of mutual respect and equal opportunity. All hiring and advancement decisions are made on the basis of qualification, merit, and business need.",-1,605,"New York, NY",-1,-1,-1,-1,-1,-1,-1,-1
Sr Innovation Engineer,"$75K-$134K
(Glassdoor est.)","Company Information

Solid reputation, passionate people and endless opportunities. Thats Travelers. Our superior financial strength and consistent record of strong operating returns mean security for our customers and opportunities for our employees. You will find Travelers to be full of energy and a workplace in which you truly can make a difference.

Target Openings

1

Job Description Summary

Innovation is at the core of everything we do. We continue to ask ourselves, whats next? as we navigate the ever-changing insurance landscape. Continuing our customer journey toward the cutting-edge, we are looking for a forward-thinking individual that thrives in ambiguity, who believes that with every challenge comes a new opportunity for solutions.

As a member of the Innovation Technology team, you will partner with research scientists and product managers to discover, invent, and build solutions at scale. As a team, you will work on challenges in machine perception, data mining, machine learning, and natural language understanding.

We are looking for a hands-on individual with strong foundational knowledge highly scalable architectures and platforms. If you like using a variety of skills in technology and solving complex problems, work collaboratively in a small agile team environment, you might just be the person we need on our team!

Primary Job Duties & Responsibilities
Work closely with Cloud Engineering to build an innovation platform; a collection of reusable and extensible containers and tools specific to developing insurance products and platforms.
Recommend integration strategies, enterprise architectures, platforms and application infrastructure required to successfully implement a complete solution using best practices.
Produce quality output for highly visible IT products, services and future business development.
Assist in hands-on remediation of application stability and performance.
Adopt and communicate new concepts, ideas, techniques.
Manage multiple projects simultaneously.
Provide 'Shrink Wrap' solutions to solve business and technical needs. As part of our innovation process, be able to scale Minimum Viable Product to production systems.
Design and lead integration of analytic data products, including pilots and proof of concepts.
Frequently present and translate complex information in relevant business terms.
Constantly learn new skills within small teams.
No direct HR people management but will lead teams in project & program contexts.
Education, Work Experience, & Knowledge
Bachelors Degree in STEM (Science, Technology, Engineering, Mathematics) related field and 3+ years of experience or 10+ years of experience building highly scalable platforms and reusable components
Job Specific Technical Skills & Competencies
2+ years of experience working with Amazon Web Services (AWS) or equivalent cloud. Must be recent experience.
5+ years of designing and developing on-premise and cloud solutions.
3+ years of experience as a technical lead.
Experience in software engineering with relevant technologies (Java, JavaScript, Python etc.).
Experience with the application delivery process.
End-to-end experience with data, including querying, aggregation, analysis, and visualization.
Preferred Qualifications
AWS certified developer and/or architect
Proven ability to work creatively and analytically in a continuously evolving environment.
Exhibits high levels of learning agility in which they seek out and learn from unfamiliar experiences and then apply those lessons to succeed in the next new situation.
Ability to leverage business knowledge to determine approaches to execution.
Strong communication and presentation skills with the ability to present and translate complex information to leadership and non-technical teams in relevant business terms.
Uses effective listening skills and communication to build relationships across the organization.
Ability to Influence with experience working with matrixed staff to complete tasks in a timely manner.
Environmental / Work Schedules / Other
Travel Required
Equal Employment Opportunity Statement

Travelers is an equal opportunity employer.",4.1,"Travelers
4.1","Hartford, CT","Hartford, CT",10000+ employees,1853,Company - Public,Insurance Carriers,Insurance,$10+ billion (USD),-1
Senior AI Software Engineer,-1,"Company Overview

Calling the adventurers ready to join a company that's pushing the limits of nanotechnology to keep the digital revolution rolling. At KLA, we're making technology advancements that are bigger—and tinier—than the world has ever seen.

Who are we? We research, develop, and manufacture the world's most advanced inspection and measurement equipment for the semiconductor and nanoelectronics industries. We enable the digital age by pushing the boundaries of technology, creating tools capable of finding defects smaller than a wavelength of visible light. We create smarter processes so that technology leaders can manufacture high-performance chips—the kind in that phone in your pocket, the tablet on your desk and nearly every electronic device you own—faster and better. We're passionate about creating solutions that drive progress and help people do what wouldn't be possible without us. The future is calling. Will you answer?

Responsibilities

Group/Division
KLA has always had a close relationship with physics and data. Our optical and electron beam inspection and measurement tools use cutting edge physics models, both for hardware design and as part of their algorithms. AI, including several traditional machine learning techniques and deep learning are routinely used to process this data to meet application requirements.

The AI & Modeling Center of Excellence, centered in KLA’s R&D facility in Ann Arbor, MI, was setup with the mission of advancing KLA’s traditional strengths in physics and data and providing implementation solutions for multiple KLA Inspection and Metrology products targeted at the semiconductor manufacturing industry.

As a part of this group, you will be part of a world class team of physicists, HPC system designers, machine learning and application engineers who build cutting edge solutions for modeling complex imaging techniques and semiconductor processes. You will also work with a data scientists and AI infrastructure engineers whose mission is to build and scale machine learning based solutions for our semiconductor customers.

We are looking for engineers in a few different fields. If you are passionate about Physics Modeling, High Performance Computing - HPC (including GPU), ML, Data, or Cloud technologies – this is the place for you!

Responsibilities:
Software Engineers in the AI and Physics Modeling team may work on a variety of tasks including platform for large scale experimentation, scaleout of physics models, data management and inference solutions for KLA products.

Although familiarity with Machine Learning and Deep Learning solutions would be a big plus, this is primarily a Software Engineering position. Successful candidates are passionate about software, and will have exceptional skills and hands on experience with development in C/C++ and Python in a Unix environment. Deep conceptual understanding of multi threaded and multi process software systems is also necessary.

In addition to the above fundamental software skills, any of the following technical hands-on skills are highly desirable.

1) System Programming and Operating Systems.
2) Distributed systems for data management.
3) Distributed computing infrastructure.
4) Cloud technologies for storage, containerization and compute clusters.
5) Data Structures and algorithms
6) GPU architectures and data management.
7) Traditional machine learning using Random Forest, XG Boost, Logistic Regression.
8) Deep Learning for regression, classification. Generative models.
9) TensorFlow, NumPy, scikit-learn, and other ML and DL frameworks.
10) MPI and similar distributed computing framework.
11) GPU Architectures and CUDA (CuGraph, CuData, CuML etc).
12) GO Systems Programming, Java Programming.

Successful candidates for this position will also demonstrate the following non-technical skills.

1) Capability to formulate creative solutions through analyzing complex data
2) Good communication skills
3) Strong team player and motivated by team success
4) Strong problem solving skills

Minimum Qualifications

Doctorate (Academic) with at least 2 years of experience.
OR
Master's Level Degree with at least 4 years of experience.
OR
Bachelor's Level Degree with at least 5 years of experience.

Equal Employment Opportunity

KLA is an Equal Opportunity Employer. Applicants will be considered for employment without regard to age, race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability, or any other characteristics protected by applicable law.",3.8,"KLA-Tencor
3.8","Ann Arbor, MI","Milpitas, CA",5001 to 10000 employees,1976,Company - Public,Industrial Manufacturing,Manufacturing,$2 to $5 billion (USD),"Applied Materials, Nanometrics"
"Senior SDE, Catalog Big Data and Machine Learning",-1,"Amazon's Catalog DataWorks team is looking for highly motivated engineers. We are embarking on multiple new initiatives to re-organize Amazon's catalog of billions of products, in new and interesting views, that drive several features Amazon's customers love. Today, these views drive hundreds of popular features like product recommendations, clustering of similar products, and shopping with Alexa. We will build a new near real-time Catalog Data Lake on AWS, to enable engineers and scientists across Amazon to solve customer problems faster. Come join us on this exciting journey!

As an engineer on this team, you will own the Catalog Data Lake end-to-end. You will work closely with business partners to synthesize technical requirements. You will design and implement significant parts of the platform. You will learn and use industry standards like Spark and Parquet as well as modern AWS offerings like EMR, Glue, Athena, and Redshift. We are fortunate to be at the cusp of innovation in both the e-commerce business as well as cloud technology. As a key stakeholder, you will constantly learn new patterns, solve key customer problems and strive to make AWS better along the way.Basic Qualifications
Bachelor's degree or higher in computer science or math is required.
Strong computer science fundamentals - algorithms, data structures and design patterns.
At least 8 years of software development experience.
At least 3 years of experience building and operating Big Data systems.
Experience mentoring, guiding and influencing peers.
Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.",-1,Amazon Corporate LLC,"Seattle, WA",-1,-1,-1,-1,-1,-1,-1,-1
SENIOR SOFTWARE ENGINEER & SOFTWARE ARCHITECT,-1,"Job Description
Senior Software Engineer, Software Architect
JOB SUMMARY

The Senior Software Engineer, Software Architect will develop software for Company innovative semiconductor X-Ray inspection system. The Senior Software Engineer will collaborate with Applications, QA, and Algo teams for high performance solutions and optimization per customer issues. It will be important to be comfortable working in a small company environment and a typical startup with engineers and scientists.

ABOUT THE CLIENT

Based in San Jose, California, client was founded in 2013 expressly to bring high speed inspection and metrology technology to the semiconductor packaging industry. Client founders anticipated the need to deploy inline 100% transmissive inspection into the semiconductor packaging manufacturing process and developed the company’s technology with this end in mind. The results, Client’s HR-AXI technology suite brings together the company’s unique data acquisition architecture with proprietary machine learning analysis techniques to provide customers with process monitoring and defect detection capabilities not found on any other products in the market. This job description can be updated at any time.

RESPONSIBILITIES
Designs, develops, troubleshoots, and debugs software programs for enhancements and new products, focused on creating high quality and high-performance solutions while maintaining high-level coding standards.
Develops software and tools in support of design, infrastructure, and technology platforms. Develops software solutions by studying information needs, conferring with users, and studying systems flow, data usage, and work processes
Supports hardware compatibility and/or influences hardware design based on software needs; work as part of cross-functional team to solve and implement system level problems.
Monitor application stability, performance, and availability. Promptly resolve issues impacting operations.
Work with engineering, documentation, and applications departments to ensure successful development and delivery of overall product.
Provide appropriate project feedback to management in a timely and appropriate format.
QUALIFICATIONS AND REQUIRED SKILLS
Education requirement: Bachelor’s degree in Computer Science, Electrical Engineering, or similar technical field required. Master’s or PhD strongly preferred.
Experience requirement: Minimum of 8 years of related experience working in software development.
Strong expertise in C# .NET. WCF, WPF, Database development. In addition, Python experience a plus.
Experience with Image processing algorithms implementations is a plus
Experience with software development for Factory Automation for Semiconductor equipment, a plus.
Self-starter able to think and act independently to translate general objectives into tangible results, with a record of delivering successful designs on schedule.
Demonstrated ability to organize, manage, and complete multiple assignments with challenging timelines independently and effectively.
Demonstrated analytical and problem-solving skills with high attention to detail.
Proactive approach to problem-solving. Build relationships with stakeholders to support successful design, build and testing.
Strong verbal and written communication, good attitude, and work ethic. Ability to communicate technical concepts and results clearly.
Experience with Git and Azure DevOps, a plus.",3.0,"Simple Solutions
3.0","San Jose, CA","Morgantown, WV",1 to 50 employees,2006,Company - Private,IT Services,Information Technology,Less than $1 million (USD),-1
Cloud Engineer,-1,"Job Description
Responsibilities:
Develop and implement technical efforts to design, build, and deploy AWS applications at the direction of lead architects, including large scale data processing, computationally intensive statistical modeling, and advanced analytics
Participate in all aspects of the software development life cycle for AWS solutions, including planning, requirements, development, testing, and quality assurance
Provide guidance, thought leadership and mentorship to development teams to build cloud competencies
Provide innovative thought leadership around Mathematica’s cloud solutions strategy and approach, including AWS best practices and market trends
Position Requirements:

6+ years of experience architecting, designing, developing and implementing cloud solutions on AWS platforms
Demonstrated experience with designing and implementing solutions using AWS platform and tools, such as: EC2, S3, Redshift, API Gateway, Lambda, DynamoDB, CloudFormation, RDS, VPC, IAM and security, QuickSight, CloudTrail, Config, CloudWatch, SNS, AMI generation
Understanding of and experience with the five pillars of a well-architected framework
Knowledge of SQL, R, and Python for data manipulation and statistical analysis is desirable
Familiarity with federal security regulations and standards (e.g. HIPAA, FISMA, FIPS, NIST, and FedRAMP)
Experience with security, especially knowledge of FedRAMP, HIPAA, PII/PHI, is desirable
Experience in several of the following areas: database architecture, ETL, Business Intelligence, Big Data, Machine Learning, Advanced Analytics
Proven ability to work collaboratively with multi-disciplinary teams of business analysts, developers, data scientists, and subject matter experts
Strong written, verbal and interpersonal communication skills
AWS Certifications (such as AWS solutions architect or other specialty certifications) are a plus
Bachelor's degree or equivalent combination of education and experience; degree in computer science, mathematics or related field preferred
Experience with other cloud platforms like Google Cloud Platform (GCP) is a plus",4.8,"RICEFW Technologies Inc
4.8","Princeton, NJ","East Lansing, MI",51 to 200 employees,2009,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Senior Software Engineer / Team Lead,"$112K-$220K
(Glassdoor est.)","Join our team dedicated to developing and executing innovative solutions in support of customer mission success.

Job Description:

Novetta has an exciting opportunity for a self-motivated and accomplished Computer Scientist to lead our entity analytics team. You will work on complex projects involving data analysis, software engineering, and deploying software in a cloud computing environment. The team combines data from disparate sources to visualize the complex relationships between entities. This effort involves large scale data integration and entity resolution leveraging a best in class Novetta product. We are looking for a flexible problem solver with significant technical experience to lead a team providing unique solutions for our customers and stakeholders.

Responsibilities include:
Lead a technical team of software engineers and computer scientists, working within a larger ecosystem delivering an Enterprise capability.
Navigate customer and prime environment, manage resources within and across team, and assist team with professional and technical growth.
Deploy applications on a large-scale data processing cluster using AWS technologies.
Design and implement entity correlation strategies that are tailored to mission needs and unique data qualities.
Develop algorithms and visualization tools to help stakeholders understand their data and prioritize new data sources.
Develop and integrate applications to automate ingestion, processing and monitoring of data
Develop and maintain tools to support operations and maintenance of production and development computing clusters.
Basic Qualifications:
Experience leading a team of software engineers.
A Bachelor's degree in computer science or related field and a minimum of 5 years of experience; or a Master's degree in computer science or related field and a minimum of 3 years of experience.
Experience in software development/engineering including requirements analysis, software development, installation, integration, evaluation, enhancement, maintenance, testing and problem diagnosis/resolution.
Software development experience on Linux-based systems in Python or shell scripting or JavaScript.
Experience developing against full-featured REST APIs and using a command line interface
Desired Skills:

Should meet a minimum of 3:
Software development experience with JavaScript, Python, or other modern programming languages.
Hands-on experience with Spark.
Experience working with Databricks
Interest in statistical analysis, machine learning, or data science.
Experience with entity resolution products or a background in data matching theory and technologies.
Experience developing applications in AWS.
Security Clearance:
The candidate must have a TS/SCI with Poly.
Novetta, from complexity to clarity.

Novetta delivers highly scalable advanced analytics and secure technology solutions to address challenges of national and global significance. Focused on mission success, Novetta pioneers disruptive technologies in machine learning, data analytics, full-spectrum cyber, cloud engineering, open source analytics, and multi-INT fusion for Defense, Intelligence Community, and Federal Law Enforcement customers. Novetta is headquartered in McLean, VA with over 1,000 employees across the U.S.

Our culture is shaped by a commitment to our core values:

Integrity • We hold ourselves accountable to the highest standards of integrity and ethics.

Customer Success • We strive daily to exceed expectations and achieve customer mission success.

Employee Focus • We invest in our employees' professional development and training, respecting individuality and fostering a culture of diversity and inclusion.

Innovation • We know that discovering new and innovative ways to solve problems is critical to our success and makes us a great company.

Excellence in Execution • We take pride in flawless execution as we build a company that is best in class.

Earn a REFERRAL BONUS for the qualified people you know.

For more details, or to submit a referral: bit.ly/NovettaReferrals

Novetta is an equal opportunity/affirmative action employer.

All qualified applicants will receive consideration for employment without regard to sex, gender identity, sexual orientation, race, color, religion, national origin, disability, protected veteran status, age, or any other characteristic protected by law.",4.5,"Novetta
4.5","Chantilly, VA","Mc Lean, VA",501 to 1000 employees,2012,Company - Private,Enterprise Software & Network Solutions,Information Technology,$100 to $500 million (USD),"Leidos, CACI International, Booz Allen Hamilton"
Data Fusion Engineer with Security Clearance,"$48K-$109K
(Glassdoor est.)","Description Job Description: Looking for work-life balance? Leidos offers generous leave and accommodating flex-time to help you juggle your personal and professional life. Are you a Software Engineer with experience finding and aligning signals across multiple modalities (image, video, audio, lidar, etc..)? Do you want to implement and customize algorithms to fusion multiple data modalities? If so we are looking for you, our next Data Fusion Engineer to work in Arlington, VA. We need you to be competent in Python and have the ability to read code in other programming languages like Java and C++ as well as have experience working with ML libraries like SciKit Learn, TensorFlow, Keras along with experience implementing solutions with those libraries on both CPU and GPU compute architectures. Like what you are reading so far? Keep going. We want you to be intellectually adaptive, inquisitive, good at expressing your needs, and able to self-manage when necessary. Work alongside software/system engineers and research/data scientists with expertise in multi-modal information retrieval, UI development, computer vision, metrics, information science, artificial intelligence, and autonomous systems. The Department of Defense and the Intelligence Community will be the main recipients your hard work. Fun stuff you will do on the job: - Use cases requiring identifying entity/objects, determining object association, object disambiguation, anomaly detection, state estimations, etc.
Develop and maintain data models (both physical and logical)
Get to be responsible for extraction, transform, and load (ETL) tasks related to the different modalities and algorithms being applied. This data ETL includes identifying the data's relevant metadata to ensure consistency, quality, accuracy, integrity, and information assurance and security.
Performing anomaly detection using various AI/ML techniques
Use algorithms to identify complex patterns across multiple modalities
Increasing the efficiency and quality data alignment and fusion
Enhance and maintain analysis tools, including automation of current processes using AI/ML algorithms
Conduct quantitative data analysis including developing retrieval, processing, fusion, analysis, and visualization of various datasets Skills required to be successful in this role: - Bachelor's Degree in Aerospace Engineering, Computer Science, Mathematics, Statistics, Physics, Electrical Engineering, Computer Engineering or related fields with 5 years of relevant experience
Must be able to obtain and maintain a TS/SCI security clearance
Experience with Deep Learning Frameworks such as Keras, Tensorflow, PyTorch, Mxnet, etc. - Ability to apply these frameworks to real problems in the 'time -series' domain
Experience with interpretability of deep learning models
Big Data Skills (Azure, Hadoop, Spark, recent deep learning platforms)
Practical experience with statistical analysis
Experience with text mining tools and techniques including in areas of summarization, search (e.g. ELK Stack), entity extraction, training set generation (e.g. Snorkel) and anomaly detection
Expert software development skills lifecycle including developing and maintaining good production quality code
Hands-on Software Development Skills (Python-Preferred)
Experience or educational courses/projects in Machine Learning, and/or Text Mining Algorithms You will wow us even more if you have these skills: - Visualizations/Web Development Skills (e.g. Tableau, D3, etc).
Hands-on experience with prototype development
Hands-on experience with automating data cleansing, formatting, staging, and transforming data human
Hands-on experience applying data analytics
Hands-on experience with intelligent systems and machine learning LInC External Referral Bonus: Ineligible Potential for Telework: No Clearance Level Required: Top Secret/SCI Travel: Yes, 10% of the time Scheduled Weekly Hours: 40 Shift: Day Requisition Category: Professional Job Family: Software Engineering Leidos Leidos is a Fortune 500® information technology, engineering, and science solutions and services leader working to solve the world's toughest challenges in the defense, intelligence, homeland security, civil, and health markets. The company's 33,000 employees support vital missions for government and commercial customers. Headquartered in Reston, Virginia, Leidos reported annual revenues of approximately $10.19 billion for the fiscal year ended December 28, 2018. For more information, visit www.Leidos.com . Pay and Benefits Pay and benefits are fundamental to any career decision. That's why we craft compensation packages that reflect the importance of the work we do for our customers. Employment benefits include competitive compensation, Health and Wellness programs, Income Protection, Paid Leave and Retirement. More details are available here . Securing Your Data Leidos will never ask you to provide payment-related information at any part of the employment application process. And Leidos will communicate with you only through emails that are sent from a Leidos.com email address. If you receive an email purporting to be from Leidos that asks for payment-related information or any other personal information, please report the email to [email protected] . Commitment to Diversity All qualified applicants will receive consideration for employment without regard to sex, race, ethnicity, age, national origin, citizenship, religion, physical or mental disability, medical condition, genetic information, pregnancy, family structure, marital status, ancestry, domestic partner status, sexual orientation, gender identity or expression, veteran or military status, or any other basis prohibited by law. Leidos will also consider for employment qualified applicants with criminal histories consistent with relevant laws.",3.5,"Leidos
3.5","Arlington, VA","Reston, VA",10000+ employees,1969,Company - Public,Aerospace & Defense,Aerospace & Defense,$10+ billion (USD),-1
Software Engineer,"$64K-$132K
(Glassdoor est.)","Every Analyst a Scientist - One of our primary goals is to empower intelligence analysts to be able to study their data like scientists. The tools we develop focus on streamlining intelligence analysis through integrated algorithms and software that provide insight into the geopolitical landscape for use in operational intelligence missions around the world.

The Role:
As a Software Engineer, you will be part of a team that transforms large and complex customer data into real-world, high-impact solutions. You will work with researchers and engineers to design and implement solutions to challenging national security problems. You will be responsible for building the software infrastructure to clean, ingest, and expose datasets and algorithms to both developers and end users. You will deploy algorithms, generate workflows, create engineer-facing tools, and design customer-facing prototype systems. You will occasionally travel to customer sites to engage with end users, demonstrate prototypes, and integrate analytics into customer systems.

If you would like to help intelligence and defense analysts keep pace with technology-driven innovation, then this role is for you!

Who you are:
A U.S. Citizen with the ability to obtain a Security Clearance
A degree in a scientific or engineering field, such as Computer Science, Mathematics, Physics, or Software Engineering
Proficiency with a scientific programming language such as Python, Java, or C++
Experience with database management and common query syntax
Motivated collaborator and excellent communicator of ideas to both technical and non-technical audiences
Knowledge of AWS, Spark, Dask, and/or similar technologies for working with data at scale
Even better:
Active Security Clearance
Track record of architecting, developing, deploying, or maintaining enterprise software
Experience with software development best practices and tools
Understanding of web development and visualization technologies, such as d3, Leaflet, Bootstrap, or others
Familiarity with machine learning or statistical modeling techniques",4.5,"Systems & Technology Research
4.5","Woburn, MA","Woburn, MA",201 to 500 employees,2010,Company - Private,Aerospace & Defense,Aerospace & Defense,$100 to $500 million (USD),-1
Sr. Data Scientist,-1,"Background Information:

Innovative Defense Technologies (IDT), provider of automated software testing, data analysis, and cybersecurity solutions for complex defense systems, is currently accepting applications for an anticipated Sr. Data Scientist role requiring 7+ years of experience for a position in support of its efforts implementing Artificial Intelligence solutions for a variety of customers.

Overview:

The Sr. Data Scientist position offers an engineer the opportunity to utilize his/her knowledge and talents as part of a collaborative team developing AI solutions for a growing company. A few of the responsibilities include supporting feasibility studies, applying modern data storage techniques, discovering explanatory features in high-dimensionality collections of data, and exploring data using scientifically valid techniques to exploit patterns found in the data with state-of-the-art AI/ML/DL solutions.

All applicants must be able to obtain/maintain an active U.S. Security Clearance.

Responsibilities Include:
Lead development of solutions to deliver AI/ML/DL models from problem formulation to a productized, deployable, maintainable capability
Contribute to AI/ML/DL technical roadmap development
Use Deep Learning frameworks such as Tensorflow and Keras to build and validate ML/DL models
Establish and leverage Big Data frameworks to store, extract and analyze relevant data
Ensure development of software solutions meets customer needs and program intent
Work closely with the Program Manager and Chief Engineer to design and implement software requirements and solutions
Determine operational feasibility by evaluating analysis, problem definition, requirements, solution development, and proposed solutions for large, complex systems
Be responsible for a team’s products meeting software design, quality, and performance requirements
Pursue new technology development via the DoD Small Business Innovative Research (SBIR) program
Work with minimal supervision in a collaborative work environment to implement best-in-class solutions
Minimum Required Qualifications:
Bachelor’s Degree in Computer Science, Computer Engineering, Electrical Engineering, Systems Engineering, Physics, or Math Required; PhD in relevant field highly preferred
7+ years of experience in predictive modeling, data science and analysis
Required Skills:
Previous experience in a ML or data scientist role and a track record of building ML or DL models
Extensive experience working with data mining algorithms including decision trees, probability networks, association rules, clustering, and neural networks
Experience using Python (or equivalent)
Experience using ML libraries, such as scikit-learn,
Experience using data visualization tools
Experience handling terabyte size dataset
Experience working with GPUs to develop models
Ability to travel 10% or less
Preferred Skills:
Experience with MapReduce programming (Hadoop)
Skills with programming languages, such as Java or C/C++
Demonstrated ability to develop experimental and analytic plans for data modeling processes, use of strong baselines, ability to accurately determine cause and effect relations
Consulting experience and track record of helping customers with their AI needs
Publications or presentations in recognized Machine Learning, Deep Learning and Data Mining journals/conferences
Combination of deep technical skills and business savvy enough to interface with all levels and disciplines within our customer’s organization
Experience diving into data to discover hidden patterns
Experience with application container platforms
Familiarity with continuous integration/delivery tools (e.g. Jenkins)
Familiarity with version control tools (e.g. Subversion, Git, etc.)
Familiarity with VMware or other virtualization software
Experience developing applications for DOD command and control systems
Competencies:
Solid analytical abilities, coupled with a strong sense of ownership, urgency, and drive
Attention to detail
Initiative, creativity, reliability, teamwork
Ability to deal well with ambiguity, prioritize needs, and deliver results in a dynamic environment
EEO Statement:

IDT is an Equal Opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, creed, sex, sexual orientation, gender identity, national origin, disability, protected Veteran status, or any other basis protected by federal, state, or local law.",-1,Innovative Defense Technologies (IDT),"Mount Laurel, NJ",-1,-1,-1,-1,-1,-1,-1,-1
Full Stack Software Engineer (Python/Vue),-1,"Position Summary Full Stack Software Engineer (Python VueJS) Company Overview Our client is an automated underwriting platform for real estate professionals that was built to disrupt the commercial real estate industry. The software allows investors, brokers, and lenders to analyze rent, operating expenses and returns for multifamily properties by applying machine learning to a database of live multifamily transaction data from every U.S. market. Our client has a creative and entrepreneurial culture ndash everyone on the team interacts directly with customers each day, and we all contribute to the product and planning. If you have an idea to improve something, there is no red tapehellip just build what needs to be built! Innovation and passion for transforming the old-fashioned real estate industry are our highest priorities. Job Description As a full-stack (Python, PostgreSQL and HTMLCSSJavaScript) developer, you'll work on the interface and backend infrastructure of products and features used by hundreds of underwriters and real estate analysts every day. The work is challenging, fast-paced, and always changing. You must have demonstrated analytical skills, an unwavering commitment to quality, a collaborative work ethic, and cutting-edge coding skills. You must display solid proficiency in the fundamentals of Python, PostgreSQL, JavaScript, HTMLCSS, and popular front-end frameworks like Vue.js. The role will include the delivery of reliable, scalable new features to users, developed in Python, interacting with a PostgreSQL database and using the Vue.js frontend framework. You will work with the development team to develop, test and deliver finished, high quality, compelling features and products. Our team includes designers, engineers and data scientists who are passionate about quality, usability, and simplicity. If you are ready to join a company that fosters learning, growth, experimentation and innovation, our client's team is for you. Requirements Qualifications 3-5 years of experience in full stack Python development 1-3 years of experience with PostgreSQL 1-3 years of experience with JavaScript frameworks such as React, Angular or Vue.js (Vue.js is preferred, this is what our client uses), and CSS pre-processing frameworks (Sass or Less) 1-2 years of experience integrating with VBA and Excel integration preferred Experience using GitHub and solid understanding of software version control Familiarity with JIRA or equivalent product management software Familiarity with agile development best practices Driven self-starter able to work on a small team and take initiative on new tasks Familiarity with real estate or finance is a plus Responsibilities Collaborate with interdisciplinary team of data scientists, software engineers and real estate professionals Strive for high quality and rapid output utilizing agile development best practices Support, maintain, and document software functionality Maintain industry standard coding, compliance, security practices Proactively learn product frameworks and code base Our client is a startup company, and as such the responsibilities outlined above may change and evolve over time. Flexibility, curiosity, an entrepreneurial mindset, and strong work ethic are essential for this role. It is encouraged that everyone on the team continually research new technologies and analytical opportunities to improve the platform.",5.0,"CultureFit
5.0","Chicago, IL","Deerfield, IL",1 to 50 employees,1997,Company - Private,Advertising & Marketing,Business Services,$1 to $5 million (USD),-1
AWS Data Engineer,-1,"About Infinitive:

At Infinitive, we do mission-critical work for great companies. We specialize in digital marketing and digital advertising solutions, customer data & analytics, digital & business transformation, and Technology solutions. Our Technology solutions focus on Managed Cloud Services, Cloud Enablement, Digital Operations, Application Development, DevOps, Product Development, Cloud Security, Data Science and Analytics, AI/ML, IoT, and everything in between.

Our experts are results-obsessed, focused and flexible, highly engaged and hugely experienced having sat in our clients seats. Those qualities are what make us different than old-school consulting shops. And surely, they are why clients and partners describe us as the gold standard in client experience.

Infinitive has been named a Best Small Firms to Work For by Consulting Magazine seven times, a Washington Post Top Workplace three times, a Washington Business Journal Best

About this Role:

Infinitive is growing its team in the Northern Virginia area and is currently seeking an Data Scientist to join our growing Technology practice. This person will utilize their experience in analytics, IoT, machine learning, and artificial intelligence advances to create value from structured and unstructured data. The ideal candidate has experience designing novel data analytic methods and workflows, including full data pipelines from raw data through analysis results. They must also have exposure to a variety of data mining/data analysis methods, data tools, building and implementing models, using/creating algorithms, and creating/running simulations.

We are looking for candidates who are accountable, passionate, assertive, proactive, open & honest, results oriented, and adaptable. Each project engagement represents a new challenge that will give you exposure to new clients, business issues, technologies, and people and will involve a range of responsibilities to include:
Developing in Java, Python, R, or other high-level languages.
Managing disparate data sources with varying data structures of content and preparing these for data science and machine learning applications.
Working with distributed scalable Big Data storage, processing, and computation, including AWS EMR, Spark, etc.
Implementation knowledge of, or desire to learn AWS / Azure data science capabilities.
Developing solutions and integrating and extending free and Open-source software (FOSS) or COTS products.
Conduct MapReduce programming with Apache Hadoop, the Hadoop Distributed File System (HDFS), and processing large data stores.
Knowledge of SQL and query languages.
Utilize real-time, large-scale data processing engine, including Apache Spark.
Lead and create Data Science and Analytics methodologies and frameworks for implementation.
Ability to build and develop Data Science demonstrations for clients
Qualifications:
4+ years of development experience (Java, Python, R, SQL)
3+ years of experience with distributed scalable Big Data storage, including AWS EMR, Spark, etc.
Desire to become AWS / Azure Certified architect / engineer.
Experience performing data Management, modeling, and warehousing.
Hands on experience with Amazon analytic tools (preferred)
Interest in being involved internally and growing a small business (entrepreneurial spirit)
Ability to travel (up to 20%) and to work independently
Experience using Agile software development methods in a DevOps environment.
Excellent leadership, peer management, and communication skills
Management consulting experience (preferred)
Bachelor's degree in related field (preferred)
Applicants for employment in the U.S. must possess work authorization which does not require sponsorship by the employer for a visa.

Infinitive is an Equal Opportunity Employer.

Powered by JazzHR",3.4,"Infinitive Inc
3.4","Arlington, VA","Cedar Rapids, IA",201 to 500 employees,1997,Company - Private,Enterprise Software & Network Solutions,Information Technology,$10 to $25 million (USD),-1
"Senior SW Engineer, Data Science ( Kubernetes/ Docker ) Remote USA","$72K-$141K
(Glassdoor est.)","If you dream of a job working in a field where all the hard problems are solved and you get to re-use previous research to get your job done, you need not apply. If, however, you are someone who wants to tackle problems that truly are on the cutting edge, then we encourage you to keep reading.

Data Science is an emerging field within cyber security. FireEye, given its deep expertise and comprehensive view on the advanced threat landscape, is uniquely positioned to enable data scientists to have major impact within our industry, company, and across our customer base. Detecting security breaches using machine learning and data analytics is an unsolved problem (this is not handwriting recognition folks) and has huge potential.

If you are someone who wants to be on the cutting edge of a high profile industry, who wants to make an impact by pushing both fields of data science and cyber security forward, you may be the perfect candidate to help us on our mission.

What you will do:
Develop, and manage data systems to ingest and process data at massive scale
Identify data sources both internally and externally that we can use to find evil.
Contribute towards the architecture and design of software solutions for long-term storage and retrieval.
Identify and implement data exploration technologies. Create dashboards and implement analytical tools for exploration
Work with data scientists to productize ML models and assist product teams with ML model releases into end products.
Collect requirements, design, and build backend components and tools to run ML models, assess ML model efficacy, manage large scale datasets, and generate features for ML models
Contribute to the evolution of coding and design practices within the organization.
Review code base commits and contribute to the growth of team members.
Requirements
Ability to work in an iterative, agile development environment.
Experience implementing ETL processes and building data pipelines
Experience developing reliable distributed systems.
Experience in Data modeling and schema design
Strong knowledge of a variety of operating systems, networking fundamentals, software design and programming best practices.
Experience with use of a wide array of algorithms and data structures.
Deep understanding and experience of going through the entire life cycle of building software platforms and products
Deep knowledge of various AWS services and associated tools
Strong experience developing in Python 3
Experience developing in at least 1 of the following: C, Go or Java
Experience with RDBMS, such as PostgreSQL or MySQL, as well as NoSQL
Experience with Kubernetes and Docker.
Experience deploying products in AWS
Additional Qualification: *
Ability to pick up, work with and explore new analytical tools
Strong experience with DevOps practices and common tooling
Strong communication skills.
Ability to work with loosely defined requirements.
At FireEye we are committed to our #OneTeam approach combining diversity, collaboration, and excellence. All qualified applicants will receive consideration for employment without regard to race, sex, color, religion, sexual orientation, gender identity, national origin, protected veteran status, or on the basis of disability. Requests for accommodation due to disability can be sent directly to .",3.3,"FireEye Inc
3.3","Denver, CO","Milpitas, CA",1001 to 5000 employees,2004,Company - Public,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,"Palo Alto Networks, Tanium"
"Senior SW Engineer, Data Science","$72K-$141K
(Glassdoor est.)","Job Description

If you dream of a job working in a field where all the hard problems are solved and you get to re-use previous research to get your job done, you need not apply. If, however, you are someone who wants to tackle problems that truly are on the cutting edge, then we encourage you to keep reading.

Data Science is an emerging field within cyber security. FireEye, given its deep expertise and comprehensive view on the advanced threat landscape, is uniquely positioned to enable data scientists to have major impact within our industry, company, and across our customer base. Detecting security breaches using machine learning and data analytics is an unsolved problem (this is not handwriting recognition folks) and has huge potential.

If you are someone who wants to be on the cutting edge of a high profile industry, who wants to make an impact by pushing both fields of data science and cyber security forward, you may be the perfect candidate to help us on our mission.

What you will do:
Develop, and manage data systems to ingest and process data at massive scale
Identify data sources both internally and externally that we can use to find evil.
Contribute towards the architecture and design of software solutions for long-term storage and retrieval.
Identify and implement data exploration technologies. Create dashboards and implement analytical tools for exploration
Work with data scientists to productize ML models and assist product teams with ML model releases into end products.
Collect requirements, design, and build backend components and tools to run ML models, assess ML model efficacy, manage large scale datasets, and generate features for ML models
Contribute to the evolution of coding and design practices within the organization.
Review code base commits and contribute to the growth of team members.",3.3,"FireEye Inc
3.3","Denver, CO","Milpitas, CA",1001 to 5000 employees,2004,Company - Public,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,"Palo Alto Networks, Tanium"
"Senior Machine Learning Engineer, Early Stage Pipeline, X",-1,"Senior Machine Learning Engineer, Early Stage Pipeline, X

Software Engineering

Mountain View, CA

We're an early stage team at X with a growing, interdisciplinary portfolio. To prove our path to the moon, we make early contact with the real world through both internal and external partnerships.

In this role, you will be responsible for taking early stage investigations from an idea stage to first prototypes to a full-blown projects. You'll be rapidly iterating through a set of prototypes to evaluate possible product directions. This is an extremely dynamic role and requires high cross-functional communication, organization, and planning. The ideal candidate is a self-starter and has a track record of effectively operating in a dynamic loosely structured environment (e.g. startup, new products within a larger company). The candidate will work on multiple projects/investigations.

Responsibilities:
Identify and implement a set of machine learning prototypes to aggressively de-risk projects building the whole solution: data acquisition, data processing pipelines, ML modeling.
Setup technical direction for investigations/projects working with the early stage leadership team.
Team lead investigations that grow to become projects.
Qualifications:
Hands-on experience with machine learning, one or more of; natural language processing (semantic understanding, sentiment analysis), computer vision, time series analysis.
Experience with building robust data pipelines.
Tech Lead experience.
Startup or early-stage product development experience.
Preferred Qualifications:
Experience with the Google Cloud Platform
About X, the Moonshot Factory

X creates radical new technologies to solve some of the world's biggest problems. We develop uncomfortably ambitious, potentially world-changing new ideas such as self-driving cars, balloon-powered Internet and smart contact lenses. We're a team of makers, entrepreneurs, engineers, designers and scientists with deep technical expertise who love the challenge of the seemingly impossible. We believe that a culture of psychological safety creates the foundation of trust and respect necessary to build moonshots. X was formerly known as Google[x] and is part of Alphabet .

At X, we don't just accept difference - we celebrate it, we support it, and we thrive on it for the benefit of our employees, our products and our community. We are proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements.

If you have a disability or special need that requires accommodation, please contact us at: (see application details) .",-1,"X, the moonshot factory","Mountain View, CA",-1,-1,-1,-1,-1,-1,-1,-1
"Senior/Staff Software Engineer, Data Infrastructure","$116K-$227K
(Glassdoor est.)","Senior/Staff Software Engineer, Data Infrastructure job posting

Every year, while Americans wait for their paychecks, more than $1 trillion of their hard-earned money is held up in the pay cycle. As a result, we accumulate over $50 billion in late and overdraft fees and turn to high-interest loans. Overdraft charges and bank fees often trap people in a cycle of debt that can lead to unhealthy decisions and falling victim to predatory businesses disguised as helpful services. We don't accept that.

Earnin is an app that creates products that help people gain control of their finances. Cash Out lets people get paid as soon as they leave work, with no fees, interest, or hidden costs. With Health Aid, Earnin negotiates on behalf of community members to lower their total unpaid medical bill and work out a budget-friendly payment plan. Cash Back Rewards is a way for members to earn up to 10% cash back on purchases from over a thousand local and national businesses without needing a credit card or having to reach spend thresholds to earn cash rewards — and they can withdraw the money at any time. We also offer free tools to help avoid overdrafts, to remind people when recurring bills are due, and we're working on more! There is never any required cost to use any of these products or services, users can choose to tip what they think is fair to support the service and pay it forward to keep the movement going.

Earnin is supported by funding partners including Andreessen Horowitz, Matrix Partners, Ribbit Capital, Felicis Venture, Thrive Capital, and others. Join us and help build a new financial system focused on fairness and people's needs.

You can help make a difference.

About the Team:

We are a data driven mobile financial tech company. The Data Infrastructure team builds the data services and data infrastructure that powers data science, analytics, and product development throughout Earnin. We are looking for a product-minded, self-driven Senior Software Engineer to own multiple large-scale projects that advance our mission of enabling people to gain access to their paycheck on demand.

What sets us apart:
High impact roles at a relatively small company that's aggressively growing our user base.
We are a collaborative team and genuinely enjoy working with each other.
We believe in empowering our people to be successful.
We're building a product that inspires fairness across the financial world and helps people not get taken advantage of.
As a Senior Engineer you will:
Break down complex problems into their bare essentials, translate this complexity into elegant design and create high quality, maintainable code.
Build massively scalable, production-grade data services.
Champion data quality and governance throughout the organization.
Build a world class data lake and data warehouse.
Design and develop new systems and tools to enable all of Earnin to consume and understand data faster.
Own the end to end design, build, and maintenance of platform services, data pipelines, and data products.
Implement comprehensive monitoring, logging, and alerting across our data infrastructure.
Work cross functionally with other teams (data science, design, product, marketing, and analytics) in high visibility roles as an engineering leader.
Build and deploy the data architecture that supports machine learning model development and actionable analytics.
Work with product engineering and data science teams to design scalable, performance model deployment architectures.
Communicate the tradeoffs of technical decisions to multiple stakeholders, including non-technical audiences.
Collaborate with and mentor other engineers and provide engineering direction to data scientists and analysts.
Actively engage and drive design reviews and code reviews.
Some skills we consider critical to being a Senior Engineer:
BS or MS degree in Computer Science, Engineering, or a related technical field.
8+ years of development experience in a fast-paced environment, especially startups.
5+ years of experience working with data systems.
Strong Python and SQL skills.
Strong programming and architecture skills.
Excellent written and verbal communication skills, including the ability to identify and communicate data driven insight.
Taking pride in your code quality and helping others elevate their own code quality.
Substantial experience with testing, data validation, and data quality assurance.
You can articulate the tradeoffs of different deployment architectures (e.g. streaming vs. batch vs. service-based).
Experience designing data platforms and services on cloud infrastructure, preferably AWS.
Hands-on experience designing and building large-scale solutions with the Hadoop stack and/or Spark.
Experience tuning and optimizing Spark-based applications.
Experience deploying and/or using query engines like AWS Athena, Presto, and Impala.
Experience with AWS analytical services like Redshift.
Hands-on experience working with a varied set of data storage technologies (e.g. Mysql, Postgres, DynamoDB, S3, etc.). You know where and when to use each.
Extensive experience with data modeling for multiple use cases and application styles, including NoSQL data modeling.
Experience working with data formats such as Avro and Parquet.
Experience working with alerting and monitoring tools like DataDog and PagerDuty.
Nice to haves:
You have experience building and deploying machine learning models.
You have experience using Terraform.
You have substantial experience working at a startup.
You have experience with data modeling in Redshift.
Experience with streaming infrastructure like Kafka.
Experience working with Kubernetes.
Experience building and deploying AWS Lambda applications.",3.1,"Earnin
3.1","Palo Alto, CA","Palo Alto, CA",201 to 500 employees,2012,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Engineer (open level),"$43K-$69K
(Glassdoor est.)","Title
Data Engineer (open level)

07/08/2020

What you'll do...
At H&R Block, your contributions will go far beyond any job description. When you join our team, you'll add to the momentum of a forward-thinking company - one that defined an industry and is now leading its transformation.

H&R Block is transforming tax preparation through data to ensure that every client we serve gets the best tax outcome possible.

We are building a new Data Engineering Team in the Data Science & Analytics organization. This new team will own the technology and data capabilities of the end-to-end data-and-analytics function. It will take responsibility for building and maintaining the analytical technologies that the data science teams use, managing data at an enterprise scale, leveraging relationships with IT teams throughout the enterprise, and leading information architecture.

We are looking for talented, curious, and creative data engineers of all levels to help launch this team. You will be a good match for our organization if you are:
Motivated by the idea of building something innovative, transformative, and impactful.
Committed to the idea that data can drive experiences and products that wow our business partners and clients
Obsessed with defying expectations and raising the bar
Driven by an innate sense of ownership for the products you create.
Day to day, you'll...
Design and deploy architecture, solutions, and software to capture, manage, store, and use structured and unstructured data from internal and external sources in both on-prem and cloud environments.
Deploy machine-learning models and other data-science products across the enterprise.
Navigate the balance between business needs, data governance best practices, and technical requirements.
Select or develop tools to cleanse, organize, and transform data and to maintain, defend, and update data structures and integrity on an automated basis.
Develop data products to facilitate self-service capabilities and assist the data teams to increase their efficiency and effectiveness.
Collaborate and communicate effectively within cross-functional teams that span internal Data Science & Analytics teams, IT, business groups, and executive stakeholders.
Be a positive force to cultivate a culture that is passionate about developing data tools as a business driver.
Job ID
368348BR

Address1
ONE H&R BLOCK WAY

City
KANSAS CITY

State
Missouri

Employee Type
Regular

What you'll bring to the team...
Education / work experience should include most of these, depending on level:
Bachelor’s degree in Computer Science or a related technical field (or equivalent work experience and technical skills)
Data warehousing and ETL solutions
APIs in a microservices architecture
Big-data technologies and the Hadoop stack (MapReduce, Hive, Pig, Hbase
NoSQL implementations (MongoDB)
Developing Java-based software solution
At least one scripting language (Python, Perl, JavaScript, Shell
Developing software solutions to solve complex business problems
Working with data scientists and other data users
Posting Title
Data Engineer (open level)

Sponsored Job
#hrbjob

Job Family
Corporate Analytics",3.6,"H&R Block
3.6","Kansas City, MO","Kansas City, MO",10000+ employees,1955,Company - Public,Other Retail Stores,Retail,$2 to $5 billion (USD),"Intuit, Jackson Hewitt, Liberty Tax Service"
Senior Modeling & Simulation Engineer,-1,"Applied Research Associates, Inc. is looking for a Senior Modeling and Simulation Engineer to join our multi-disciplinary team of engineers and scientists in the Capital Area Division, located in Alexandria, VA. The ideal candidate has a passion for predicting the behavior of physical systems in challenging environments and operational impact on mission success. Models will be developed, used, and improved to support a Department of Homeland Security customer to safeguard the nation’s borders and interior from chemical, biological, radiological, nuclear, and explosive materials, equipment, technologies, and their actors. Models may be based on the underlying physics or may be process or agent based to predict operational performance and impact. Modeling and analysis may require the use and development of 3D virtual worlds or geospatial data. Models will be verified and validated, and they will be used in support of test and evaluation activities of systems intended to detect and identify threats. The candidate may participate in test and evaluation activities to support the verification, validation, and overall improvement of models. Models may become part of larger, integrated modeling and simulation activities, and may require the use of high performance computing technologies and federated simulations.

This position is contingent upon award of a contract expected in Summer 2020 supporting the Department of Homeland Security.

Required Qualifications:
Ability to program in a high level programming language, such as Fortran, C++, or Java
Eagerness to learn new tools and techniques
Strong verbal and written communication skills
Must be a U.S. Citizen with the ability to obtain and maintain a security clearance
Bachelor’s degree with minimum of 10 years of experience or greater in a physical science (physics, chemistry, biology), engineering-related discipline (nuclear, chemical, civil, mechanical, electrical), or modeling& simulation disciple (computer modeling, computational science, operations research)
Ability to present to senior leadership on the status and issues associated with research or test efforts in preparation for acquisition decision meetings
Desired Experience and Qualifications:
Experience modeling CBRNE detectors or effects
Experience using multiple software tools such as MCNP, GadRas, SWORD, ExtendSim, Arena, SolidWorks, Fluent, ArcGIS, QGIS, VisIt, ParaView, or Cubit
Experience creating 3D models of systems, i.e., CAD
Experience using high performance computers (i.e., supercomputers)
Experience developing and using discrete event or agent based models and simulations to predict and assess system performance
Experience developing machine learning models
Background in a physical science or engineering discipline, such as Physics, Chemistry, Biology, Mechanical Engineering, Nuclear Engineering
Active DoD Secret or Top Secret clearance, DoE Q clearance, or DHS Suitability
COMPANY INFORMATION:

Applied Research Associates, Inc. is an employee-owned international research and engineering company recognized for providing technically superior solutions to complex and challenging problems in the physical sciences. The company, founded in Albuquerque, NM, in 1979, currently employs over 1200 professionals. ARA offices throughout the United States and Canada provide a broad range of technical expertise in defense technologies, civil technologies, computer software and simulation, systems analysis, environmental technologies, and testing and measurement. The corporation also provides sophisticated technical products for environmental site characterization, pavement analysis, and robotics.

At ARA, employees are our greatest assets. The corporation realizes that employee ownership spawns greater creativity and initiative along with higher performance and customer satisfaction levels. ARA gives its employees the tools, training, and opportunities to take more active roles as owners. The culture is challenging; innovation and experimentation are the norm. Employees are eligible for contributions which not only add to the company’s success, but also their own through the Employee Stock Ownership Plan (ESOP). The motto,“Engineering and Science for Fun and Profit” sums up the ARA experience. For additional information and an opportunity to join this unique workplace, please visit our website atwww.ara.com.",3.5,"Applied Research Associates
3.5","Alexandria, VA","Albuquerque, NM",1001 to 5000 employees,1979,Company - Private,Federal Agencies,Government,$100 to $500 million (USD),-1
Senior Data Engineer,-1,"This is a Data Engineer position for supporting a Navy program located in Quantico, Virginia.

We are seeking a Data Engineer to join our team of committed technical professionals to protect those who serve against criminal, terrorism and emerging threats. Are you passionate about analytics and innovation? Our employees enjoy a fast-paced, collaborative culture and the ability to directly impact our business. You will identify technical issues and opportunities for efficiency and provide technical insights through system design and configuration perspectives. This role is both challenging and rewarding.

You will support the mission through the implementation of a modern, integrated internal data infrastructure with a focus primarily on exploiting the established data foundation to make internal and customer-centric business processes as effective and efficient as possible, laying the foundation for cognitive capabilities that can sense and respond to both internal and external customer data needs. The candidate will also focus on expanding the organization’s data ecosystem to include context-rich data while maintaining the agility needed to spark innovation.

How you will make a difference:
Establish shared operational data and integrated enterprise data, all while managing and/or improving data quality and security through the creation of business-driven governance structures and culture change management.
Establish data policies, standards, and procedures that improve data quality, availability, accessibility, security, usability, and enforcement of enterprise information management (EIM) program requirements.
Establish enterprise standards – including a uniform and repeatable system development lifecycle methodology for Reference Data and Master Data (e.g., a common set of standards for data naming, abbreviations, and acronyms).
Develop a Master Data Management (MDM) Plan that focuses on the technology, tools, and processes ensuring master data is coordinated across the enterprise. MDM is a method used to define and manage the critical data of an organization to provide, with data integration, a single point of reference. The data that is mastered may include reference data – the set of permissible values, and the analytical data supporting decision making. MDM provides a unified master data service intended to provide accurate, consistent and complete master data across the enterprise and to business partners.
Recommend solutions based on performing industry-specific analysis, such as case studies describing data management best practices, identifying trends across the industry.
Make recommendations to improve the efficiency and effectiveness in how the agency acquires, stores, manages, shares and applies its data.
Engage business users and stakeholders for the increased release of actionable high-quality data on key operational and tactical activities at NCIS.
Develop technology solutions to provide the platform, training, and standardized tools enabling querying, data mining, statistical analysis, reporting, scenario modeling, data visualization, and dash-boarding, and processes for a centralized, or analytics as a service model, allowing for the sharing of data across the enterprise from a common hub, facilitates cross-organizational data initiatives due to its enterprise-wide view of data assets and needs.
Basic Qualifications
Required: A bachelor’s or master’s degree in computer science, data science, operations research, statistics, applied mathematics, or a related quantitative field [or equivalent work experience such as, economics, engineering and physics] is [preferred/required]. Alternate experience and education in equivalent areas such as economics, engineering or physics, is acceptable. Experience in more than one area is strongly preferred.
Required: Three to six (midlevel) of relevant project experience in successfully launching, planning, and executing data science projects. Preferably in the domains of risk modelling and quality assessment.
Preferred: Specialization in text analytics, image recognition, graph analysis or other specialized ML techniques such as deep learning, etc.
Preferred: the candidates are adept in agile methodologies and well-versed in applying DevOps/MLOps methods to the construction of ML and data science pipelines.
Coding knowledge and experience in several languages: for example, R, Python, Java, C++, Excel, MATLAB, etc.
Experience with popular database programming languages including SQL, PL/SQL, others for relational databases and upcoming non-relational databases such as NoSQL/Hadoop-oriented databases such as MongoDB, Cassandra, others.
Preferred: Specialized/operational data scientists may need further high-performance computing (HPC)/compute skills; larger data science teams, in particular, may require further degrees of specialization such as:
Experience with distributed data/computing tools such as MapReduce, Hadoop, Hive, Kafka, and MySQL
Experience of working across multiple deployment environments including cloud, on-premises and hybrid environments, multiple operating systems and through containerization techniques such as Docker, Kubernetes, AWS Elastic Container Service, and others.
Experience in one or more of the following commercial/open-source data discovery/analysis platforms: RStudio, Spark, KNIME, RapidMiner, Alteryx, Dataiku, H2O, SAS Enterprise Miner (SAS EM) and/or SAS Visual Data Mining and Machine Learning, Microsoft AzureML, IBM Watson Studio or SPSS Modeler, Amazon SageMaker, Google Cloud ML, SAP Predictive Analytics.
Preferred: Expertise in solving vision, text analytics, credit scoring, and failure prediction problems.
Knowledge and experience in statistical and data mining techniques such as generalized linear model (GLM)/regression, random forest, boosting, trees, text mining, hierarchical clustering, deep learning, convolutional neural network (CNN), recurrent neural network (RNN), T-distributed Stochastic Neighbor Embedding (t-SNE), graph analysis, etc.
Strong documentation skills. Required: Certifications as per Cybersecurity Workforce Management and Qualification Manual, SECNAV M-5239.2.
Required: Eligible AND adjudicated to the Top Secret (TS SCI) clearance level is required to start.
About Inventium.io:

Inventium.io LLC is a technical consulting and software development services company dedicated to protecting and advancing our national defense and scientific capabilities. Based out of the Washington DC area, we rely on innovation to continually advance our employees' skills and provide digital transformation solutions to our customers.

With proven records of successfully delivering quality services and solutions to multiple federal agencies, our technical competencies include Emerging Technology Solutions, DevSecOps, Cloud Migration, Machine Learning, System Modernization, and Technology Management.

Benefits and Perks
Employer paid Health Benefits (Medical, Dental and Vision)
Retirement Plan
Paid Time Off and Federal Holidays
Training and Development
Employee Referral Program
Awards and Recognition",5.0,"inventium.io LLC
5.0","Quantico, VA","Washington, DC",1 to 50 employees,2016,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Senior Software Engineer,-1,"At Pacific Biosciences, our R&D team is committed to developing innovative products that enable scientists to excel in a wide variety of life science research fields, including human biomedical, plant and animal sciences, and microbiology and infectious disease. Our unique Single Molecule, Real-Time (SMRT) sequencing platforms generate true high-quality long reads, giving researchers a more comprehensive view of genomes, transcriptomes, and epigenomes from any organism.

The Primary Analysis group, as part of the larger software engineering team at PacBio, develops algorithms and HPC solutions for decoding the raw data streams, generated through high-speed optical detection of the SMRT sequencing reactions, into DNA sequence reads. We operate at the intersection of cutting-edge nanotechnology and state-of-the-art bioinformatics tools, and our responsibilities span the full product development life cycle in an aggressive time-to-market environment. These include analysis and algorithm development in coordination with chemistry and systems R&D; the development of real-time analysis pipelines; and the development of validation and support infrastructure geared towards product system reliability and internal R&D support. We are seeking a talented algorithm engineer with a strong background in the physical or machine-learning/data sciences who also has a passion for designing and developing performance-critical data analysis solutions.

Responsibilities:

Design, develop, and test signal- and sequence-analysis algorithms that will drive fundamental improvements in basecalling accuracy and yield.
Work collaboratively in a team environment to solve challenging problems in software architecture and scalability of real-time analysis pipelines for our next-generation sequencing platforms.
All listed tasks and responsibilities are deemed as essential functions to this position; however, business conditions may require reasonable accommodations for additional tasks and responsibilities.

Key Skills and Background:

3+ years of experience shipping product software in a scientific or quantitative domain.
Demonstrated skills applying numerical methods, statistical signal processing, or machine-learning techniques to high-throughput, performance-critical analysis applications.
Linux-based systems programming experience with knowledge of OS, toolchain and hardware constraints.
Strong C++ programming experience in applications geared towards performance and scalability; previous experience in CUDA programming for GPU is a plus.
MS, PhD or equivalent experience in a quantitative field (physics, CS, etc.), preferably with an applied math or algorithmic focus.
Engineering instincts to efficiently investigate and solve the problem at hand, from prototype development (Python, R, MATLAB, etc.) to production designs.
Team player, with strong communication skills, and comfortable as a self-starter in an agile, fast-paced development environment.
All qualified applicants will receive consideration for employment without regard to race, sex, color, religion, national origin, protected veteran status, or on the basis of disability, gender identity, and sexual orientation.",3.7,"Pacific Biosciences
3.7","Menlo Park, CA","Menlo Park, CA",201 to 500 employees,2000,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,$50 to $100 million (USD),Illumina
Senior Data Engineer,-1,"ABOUT 605

At 605 we are engineers, analysts, data scientists, media experts, marketing strategists and political operatives. Our team of data scientists pioneered the field of TV data analytics. We offer unique, independent audience measurement and analytics to build better marketing and programming initiatives within the media and entertainment industries.

The Sr. Data Engineer at 605 must have a broad and deep data skillset as well as strong analytical capabilities . In addition to being a hands on individual contributor, the ideal candidate is a productive team player and a mentor to Junior. Data Engineers. Additionally, we are looking for strong technical experts.

Responsibilities include:
Actively participate in team technical discussions in all things data
Identify and address issues with data sets from multiple vendors
Identify and address code and data quality issues
Actively participate in code reviews and grooming sessions
Actively participate in technology architecture discussions for product development
Translate business requirements into strategy
Advocate for software best practices within your team as well as across engineering
Be ultra-responsive and capable of making instant decisions, always kicking the ball forward
Work on unique and interesting data challenges around architecting, building and managing pipelines that securely process hundreds of terabytes of data
Work closely with analysts and statisticians to ensure the validity of our processes
Our engineers are expected to wear a number of hats and have the opportunity to touch all parts of the stack. Our stack includes Apache Spark, Scala, Redshift and an ever-growing list of many other cool technologies.

Requirements
Skillful user of Apache Spark
Experience wrangling terabytes of big, complicated, imperfect data
Experience with AWS products (Redshift, EMR, S3, IAM, RDS, etc)
You have a deep understanding of scalable systems and you have large-scale engineering experience in an Agile development environment
Bachelor's degree in Computer Science or a related field (or 4 additional years of relevant work experience)
A strong understanding of data structures, algorithms, and effective software design
Significant development experience with a major modern language (e.g. Java, Scala, Python, Ruby, C/C++, etc.)
Significant experience working with structured and unstructured data at scale and comfort with a variety of different stores (key-value, document, columnar, etc.) as well as traditional RDBMSes and data warehouses
Experience with or interest in AWS Glue, Redshift Spectrum and any other tools that enable data querying at scale
Experience writing unit, functional and integration tests
Comfort with version control systems (e.g. Git, SVN)
Excellent verbal and written communication skills; must work well in an agile, collaborative team environment
Preferred Qualifications
Master's in Computer Science or a related field
Practical experience with supervised machine learning techniques
Strong background with test-driven development
Basic understanding of statistics and experience with statistical packages such as R, Matlab, SPSS, etc
Benefits

Important and Standard
Comprehensive health, dental and vision insurance for employees and their families
Life & Disability insurance
401k plan with match, eligible for match after one year
Pre-tax flexible compensation plan for medical, transit, parking or dependent care expenses
Up to 15 paid vacation days depending on grade level
7 paid sick days in a calendar year - if you’re sick, you stay home
Other cool benefits
4 work from home days/month
A kitchen stocked with sodas, snacks, yogurt and other goodies
A tight knit start up community who likes to eat! We celebrate everyone’s birthdays, have frequent team lunches, and do events in and out of the office
605 is an active participant in conferences
EEO STATEMENT

At 605, we’re just as passionate about diversity as we are about pioneering the field of TV data analytics. We are committed to cultivating an environment of mutual respect and equal opportunity. All hiring and advancement decisions are made on the basis of qualification, merit, and business need.",-1,605,"New York, NY",-1,-1,-1,-1,-1,-1,-1,-1
Sr Innovation Engineer,"$75K-$134K
(Glassdoor est.)","Company Information

Solid reputation, passionate people and endless opportunities. Thats Travelers. Our superior financial strength and consistent record of strong operating returns mean security for our customers and opportunities for our employees. You will find Travelers to be full of energy and a workplace in which you truly can make a difference.

Target Openings

1

Job Description Summary

Innovation is at the core of everything we do. We continue to ask ourselves, whats next? as we navigate the ever-changing insurance landscape. Continuing our customer journey toward the cutting-edge, we are looking for a forward-thinking individual that thrives in ambiguity, who believes that with every challenge comes a new opportunity for solutions.

As a member of the Innovation Technology team, you will partner with research scientists and product managers to discover, invent, and build solutions at scale. As a team, you will work on challenges in machine perception, data mining, machine learning, and natural language understanding.

We are looking for a hands-on individual with strong foundational knowledge highly scalable architectures and platforms. If you like using a variety of skills in technology and solving complex problems, work collaboratively in a small agile team environment, you might just be the person we need on our team!

Primary Job Duties & Responsibilities
Work closely with Cloud Engineering to build an innovation platform; a collection of reusable and extensible containers and tools specific to developing insurance products and platforms.
Recommend integration strategies, enterprise architectures, platforms and application infrastructure required to successfully implement a complete solution using best practices.
Produce quality output for highly visible IT products, services and future business development.
Assist in hands-on remediation of application stability and performance.
Adopt and communicate new concepts, ideas, techniques.
Manage multiple projects simultaneously.
Provide 'Shrink Wrap' solutions to solve business and technical needs. As part of our innovation process, be able to scale Minimum Viable Product to production systems.
Design and lead integration of analytic data products, including pilots and proof of concepts.
Frequently present and translate complex information in relevant business terms.
Constantly learn new skills within small teams.
No direct HR people management but will lead teams in project & program contexts.
Education, Work Experience, & Knowledge
Bachelors Degree in STEM (Science, Technology, Engineering, Mathematics) related field and 3+ years of experience or 10+ years of experience building highly scalable platforms and reusable components
Job Specific Technical Skills & Competencies
2+ years of experience working with Amazon Web Services (AWS) or equivalent cloud. Must be recent experience.
5+ years of designing and developing on-premise and cloud solutions.
3+ years of experience as a technical lead.
Experience in software engineering with relevant technologies (Java, JavaScript, Python etc.).
Experience with the application delivery process.
End-to-end experience with data, including querying, aggregation, analysis, and visualization.
Preferred Qualifications
AWS certified developer and/or architect
Proven ability to work creatively and analytically in a continuously evolving environment.
Exhibits high levels of learning agility in which they seek out and learn from unfamiliar experiences and then apply those lessons to succeed in the next new situation.
Ability to leverage business knowledge to determine approaches to execution.
Strong communication and presentation skills with the ability to present and translate complex information to leadership and non-technical teams in relevant business terms.
Uses effective listening skills and communication to build relationships across the organization.
Ability to Influence with experience working with matrixed staff to complete tasks in a timely manner.
Environmental / Work Schedules / Other
Travel Required
Equal Employment Opportunity Statement

Travelers is an equal opportunity employer.",4.1,"Travelers
4.1","Hartford, CT","Hartford, CT",10000+ employees,1853,Company - Public,Insurance Carriers,Insurance,$10+ billion (USD),-1
Senior AI Software Engineer,-1,"Company Overview

Calling the adventurers ready to join a company that's pushing the limits of nanotechnology to keep the digital revolution rolling. At KLA, we're making technology advancements that are bigger—and tinier—than the world has ever seen.

Who are we? We research, develop, and manufacture the world's most advanced inspection and measurement equipment for the semiconductor and nanoelectronics industries. We enable the digital age by pushing the boundaries of technology, creating tools capable of finding defects smaller than a wavelength of visible light. We create smarter processes so that technology leaders can manufacture high-performance chips—the kind in that phone in your pocket, the tablet on your desk and nearly every electronic device you own—faster and better. We're passionate about creating solutions that drive progress and help people do what wouldn't be possible without us. The future is calling. Will you answer?

Responsibilities

Group/Division
KLA has always had a close relationship with physics and data. Our optical and electron beam inspection and measurement tools use cutting edge physics models, both for hardware design and as part of their algorithms. AI, including several traditional machine learning techniques and deep learning are routinely used to process this data to meet application requirements.

The AI & Modeling Center of Excellence, centered in KLA’s R&D facility in Ann Arbor, MI, was setup with the mission of advancing KLA’s traditional strengths in physics and data and providing implementation solutions for multiple KLA Inspection and Metrology products targeted at the semiconductor manufacturing industry.

As a part of this group, you will be part of a world class team of physicists, HPC system designers, machine learning and application engineers who build cutting edge solutions for modeling complex imaging techniques and semiconductor processes. You will also work with a data scientists and AI infrastructure engineers whose mission is to build and scale machine learning based solutions for our semiconductor customers.

We are looking for engineers in a few different fields. If you are passionate about Physics Modeling, High Performance Computing - HPC (including GPU), ML, Data, or Cloud technologies – this is the place for you!

Responsibilities:
Software Engineers in the AI and Physics Modeling team may work on a variety of tasks including platform for large scale experimentation, scaleout of physics models, data management and inference solutions for KLA products.

Although familiarity with Machine Learning and Deep Learning solutions would be a big plus, this is primarily a Software Engineering position. Successful candidates are passionate about software, and will have exceptional skills and hands on experience with development in C/C++ and Python in a Unix environment. Deep conceptual understanding of multi threaded and multi process software systems is also necessary.

In addition to the above fundamental software skills, any of the following technical hands-on skills are highly desirable.

1) System Programming and Operating Systems.
2) Distributed systems for data management.
3) Distributed computing infrastructure.
4) Cloud technologies for storage, containerization and compute clusters.
5) Data Structures and algorithms
6) GPU architectures and data management.
7) Traditional machine learning using Random Forest, XG Boost, Logistic Regression.
8) Deep Learning for regression, classification. Generative models.
9) TensorFlow, NumPy, scikit-learn, and other ML and DL frameworks.
10) MPI and similar distributed computing framework.
11) GPU Architectures and CUDA (CuGraph, CuData, CuML etc).
12) GO Systems Programming, Java Programming.

Successful candidates for this position will also demonstrate the following non-technical skills.

1) Capability to formulate creative solutions through analyzing complex data
2) Good communication skills
3) Strong team player and motivated by team success
4) Strong problem solving skills

Minimum Qualifications

Doctorate (Academic) with at least 2 years of experience.
OR
Master's Level Degree with at least 4 years of experience.
OR
Bachelor's Level Degree with at least 5 years of experience.

Equal Employment Opportunity

KLA is an Equal Opportunity Employer. Applicants will be considered for employment without regard to age, race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability, or any other characteristics protected by applicable law.",3.8,"KLA-Tencor
3.8","Ann Arbor, MI","Milpitas, CA",5001 to 10000 employees,1976,Company - Public,Industrial Manufacturing,Manufacturing,$2 to $5 billion (USD),"Applied Materials, Nanometrics"
"Senior SDE, Catalog Big Data and Machine Learning",-1,"Amazon's Catalog DataWorks team is looking for highly motivated engineers. We are embarking on multiple new initiatives to re-organize Amazon's catalog of billions of products, in new and interesting views, that drive several features Amazon's customers love. Today, these views drive hundreds of popular features like product recommendations, clustering of similar products, and shopping with Alexa. We will build a new near real-time Catalog Data Lake on AWS, to enable engineers and scientists across Amazon to solve customer problems faster. Come join us on this exciting journey!

As an engineer on this team, you will own the Catalog Data Lake end-to-end. You will work closely with business partners to synthesize technical requirements. You will design and implement significant parts of the platform. You will learn and use industry standards like Spark and Parquet as well as modern AWS offerings like EMR, Glue, Athena, and Redshift. We are fortunate to be at the cusp of innovation in both the e-commerce business as well as cloud technology. As a key stakeholder, you will constantly learn new patterns, solve key customer problems and strive to make AWS better along the way.Basic Qualifications
Bachelor's degree or higher in computer science or math is required.
Strong computer science fundamentals - algorithms, data structures and design patterns.
At least 8 years of software development experience.
At least 3 years of experience building and operating Big Data systems.
Experience mentoring, guiding and influencing peers.
Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.",-1,Amazon Corporate LLC,"Seattle, WA",-1,-1,-1,-1,-1,-1,-1,-1
SENIOR SOFTWARE ENGINEER & SOFTWARE ARCHITECT,-1,"Job Description
Senior Software Engineer, Software Architect
JOB SUMMARY

The Senior Software Engineer, Software Architect will develop software for Company innovative semiconductor X-Ray inspection system. The Senior Software Engineer will collaborate with Applications, QA, and Algo teams for high performance solutions and optimization per customer issues. It will be important to be comfortable working in a small company environment and a typical startup with engineers and scientists.

ABOUT THE CLIENT

Based in San Jose, California, client was founded in 2013 expressly to bring high speed inspection and metrology technology to the semiconductor packaging industry. Client founders anticipated the need to deploy inline 100% transmissive inspection into the semiconductor packaging manufacturing process and developed the company’s technology with this end in mind. The results, Client’s HR-AXI technology suite brings together the company’s unique data acquisition architecture with proprietary machine learning analysis techniques to provide customers with process monitoring and defect detection capabilities not found on any other products in the market. This job description can be updated at any time.

RESPONSIBILITIES
Designs, develops, troubleshoots, and debugs software programs for enhancements and new products, focused on creating high quality and high-performance solutions while maintaining high-level coding standards.
Develops software and tools in support of design, infrastructure, and technology platforms. Develops software solutions by studying information needs, conferring with users, and studying systems flow, data usage, and work processes
Supports hardware compatibility and/or influences hardware design based on software needs; work as part of cross-functional team to solve and implement system level problems.
Monitor application stability, performance, and availability. Promptly resolve issues impacting operations.
Work with engineering, documentation, and applications departments to ensure successful development and delivery of overall product.
Provide appropriate project feedback to management in a timely and appropriate format.
QUALIFICATIONS AND REQUIRED SKILLS
Education requirement: Bachelor’s degree in Computer Science, Electrical Engineering, or similar technical field required. Master’s or PhD strongly preferred.
Experience requirement: Minimum of 8 years of related experience working in software development.
Strong expertise in C# .NET. WCF, WPF, Database development. In addition, Python experience a plus.
Experience with Image processing algorithms implementations is a plus
Experience with software development for Factory Automation for Semiconductor equipment, a plus.
Self-starter able to think and act independently to translate general objectives into tangible results, with a record of delivering successful designs on schedule.
Demonstrated ability to organize, manage, and complete multiple assignments with challenging timelines independently and effectively.
Demonstrated analytical and problem-solving skills with high attention to detail.
Proactive approach to problem-solving. Build relationships with stakeholders to support successful design, build and testing.
Strong verbal and written communication, good attitude, and work ethic. Ability to communicate technical concepts and results clearly.
Experience with Git and Azure DevOps, a plus.",3.0,"Simple Solutions
3.0","San Jose, CA","Morgantown, WV",1 to 50 employees,2006,Company - Private,IT Services,Information Technology,Less than $1 million (USD),-1
Cloud Engineer,-1,"Job Description
Responsibilities:
Develop and implement technical efforts to design, build, and deploy AWS applications at the direction of lead architects, including large scale data processing, computationally intensive statistical modeling, and advanced analytics
Participate in all aspects of the software development life cycle for AWS solutions, including planning, requirements, development, testing, and quality assurance
Provide guidance, thought leadership and mentorship to development teams to build cloud competencies
Provide innovative thought leadership around Mathematica’s cloud solutions strategy and approach, including AWS best practices and market trends
Position Requirements:

6+ years of experience architecting, designing, developing and implementing cloud solutions on AWS platforms
Demonstrated experience with designing and implementing solutions using AWS platform and tools, such as: EC2, S3, Redshift, API Gateway, Lambda, DynamoDB, CloudFormation, RDS, VPC, IAM and security, QuickSight, CloudTrail, Config, CloudWatch, SNS, AMI generation
Understanding of and experience with the five pillars of a well-architected framework
Knowledge of SQL, R, and Python for data manipulation and statistical analysis is desirable
Familiarity with federal security regulations and standards (e.g. HIPAA, FISMA, FIPS, NIST, and FedRAMP)
Experience with security, especially knowledge of FedRAMP, HIPAA, PII/PHI, is desirable
Experience in several of the following areas: database architecture, ETL, Business Intelligence, Big Data, Machine Learning, Advanced Analytics
Proven ability to work collaboratively with multi-disciplinary teams of business analysts, developers, data scientists, and subject matter experts
Strong written, verbal and interpersonal communication skills
AWS Certifications (such as AWS solutions architect or other specialty certifications) are a plus
Bachelor's degree or equivalent combination of education and experience; degree in computer science, mathematics or related field preferred
Experience with other cloud platforms like Google Cloud Platform (GCP) is a plus",4.8,"RICEFW Technologies Inc
4.8","Princeton, NJ","East Lansing, MI",51 to 200 employees,2009,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Senior Software Engineer / Team Lead,"$112K-$220K
(Glassdoor est.)","Join our team dedicated to developing and executing innovative solutions in support of customer mission success.

Job Description:

Novetta has an exciting opportunity for a self-motivated and accomplished Computer Scientist to lead our entity analytics team. You will work on complex projects involving data analysis, software engineering, and deploying software in a cloud computing environment. The team combines data from disparate sources to visualize the complex relationships between entities. This effort involves large scale data integration and entity resolution leveraging a best in class Novetta product. We are looking for a flexible problem solver with significant technical experience to lead a team providing unique solutions for our customers and stakeholders.

Responsibilities include:
Lead a technical team of software engineers and computer scientists, working within a larger ecosystem delivering an Enterprise capability.
Navigate customer and prime environment, manage resources within and across team, and assist team with professional and technical growth.
Deploy applications on a large-scale data processing cluster using AWS technologies.
Design and implement entity correlation strategies that are tailored to mission needs and unique data qualities.
Develop algorithms and visualization tools to help stakeholders understand their data and prioritize new data sources.
Develop and integrate applications to automate ingestion, processing and monitoring of data
Develop and maintain tools to support operations and maintenance of production and development computing clusters.
Basic Qualifications:
Experience leading a team of software engineers.
A Bachelor's degree in computer science or related field and a minimum of 5 years of experience; or a Master's degree in computer science or related field and a minimum of 3 years of experience.
Experience in software development/engineering including requirements analysis, software development, installation, integration, evaluation, enhancement, maintenance, testing and problem diagnosis/resolution.
Software development experience on Linux-based systems in Python or shell scripting or JavaScript.
Experience developing against full-featured REST APIs and using a command line interface
Desired Skills:

Should meet a minimum of 3:
Software development experience with JavaScript, Python, or other modern programming languages.
Hands-on experience with Spark.
Experience working with Databricks
Interest in statistical analysis, machine learning, or data science.
Experience with entity resolution products or a background in data matching theory and technologies.
Experience developing applications in AWS.
Security Clearance:
The candidate must have a TS/SCI with Poly.
Novetta, from complexity to clarity.

Novetta delivers highly scalable advanced analytics and secure technology solutions to address challenges of national and global significance. Focused on mission success, Novetta pioneers disruptive technologies in machine learning, data analytics, full-spectrum cyber, cloud engineering, open source analytics, and multi-INT fusion for Defense, Intelligence Community, and Federal Law Enforcement customers. Novetta is headquartered in McLean, VA with over 1,000 employees across the U.S.

Our culture is shaped by a commitment to our core values:

Integrity • We hold ourselves accountable to the highest standards of integrity and ethics.

Customer Success • We strive daily to exceed expectations and achieve customer mission success.

Employee Focus • We invest in our employees' professional development and training, respecting individuality and fostering a culture of diversity and inclusion.

Innovation • We know that discovering new and innovative ways to solve problems is critical to our success and makes us a great company.

Excellence in Execution • We take pride in flawless execution as we build a company that is best in class.

Earn a REFERRAL BONUS for the qualified people you know.

For more details, or to submit a referral: bit.ly/NovettaReferrals

Novetta is an equal opportunity/affirmative action employer.

All qualified applicants will receive consideration for employment without regard to sex, gender identity, sexual orientation, race, color, religion, national origin, disability, protected veteran status, age, or any other characteristic protected by law.",4.5,"Novetta
4.5","Chantilly, VA","Mc Lean, VA",501 to 1000 employees,2012,Company - Private,Enterprise Software & Network Solutions,Information Technology,$100 to $500 million (USD),"Leidos, CACI International, Booz Allen Hamilton"
Data Fusion Engineer with Security Clearance,"$48K-$109K
(Glassdoor est.)","Description Job Description: Looking for work-life balance? Leidos offers generous leave and accommodating flex-time to help you juggle your personal and professional life. Are you a Software Engineer with experience finding and aligning signals across multiple modalities (image, video, audio, lidar, etc..)? Do you want to implement and customize algorithms to fusion multiple data modalities? If so we are looking for you, our next Data Fusion Engineer to work in Arlington, VA. We need you to be competent in Python and have the ability to read code in other programming languages like Java and C++ as well as have experience working with ML libraries like SciKit Learn, TensorFlow, Keras along with experience implementing solutions with those libraries on both CPU and GPU compute architectures. Like what you are reading so far? Keep going. We want you to be intellectually adaptive, inquisitive, good at expressing your needs, and able to self-manage when necessary. Work alongside software/system engineers and research/data scientists with expertise in multi-modal information retrieval, UI development, computer vision, metrics, information science, artificial intelligence, and autonomous systems. The Department of Defense and the Intelligence Community will be the main recipients your hard work. Fun stuff you will do on the job: - Use cases requiring identifying entity/objects, determining object association, object disambiguation, anomaly detection, state estimations, etc.
Develop and maintain data models (both physical and logical)
Get to be responsible for extraction, transform, and load (ETL) tasks related to the different modalities and algorithms being applied. This data ETL includes identifying the data's relevant metadata to ensure consistency, quality, accuracy, integrity, and information assurance and security.
Performing anomaly detection using various AI/ML techniques
Use algorithms to identify complex patterns across multiple modalities
Increasing the efficiency and quality data alignment and fusion
Enhance and maintain analysis tools, including automation of current processes using AI/ML algorithms
Conduct quantitative data analysis including developing retrieval, processing, fusion, analysis, and visualization of various datasets Skills required to be successful in this role: - Bachelor's Degree in Aerospace Engineering, Computer Science, Mathematics, Statistics, Physics, Electrical Engineering, Computer Engineering or related fields with 5 years of relevant experience
Must be able to obtain and maintain a TS/SCI security clearance
Experience with Deep Learning Frameworks such as Keras, Tensorflow, PyTorch, Mxnet, etc. - Ability to apply these frameworks to real problems in the 'time -series' domain
Experience with interpretability of deep learning models
Big Data Skills (Azure, Hadoop, Spark, recent deep learning platforms)
Practical experience with statistical analysis
Experience with text mining tools and techniques including in areas of summarization, search (e.g. ELK Stack), entity extraction, training set generation (e.g. Snorkel) and anomaly detection
Expert software development skills lifecycle including developing and maintaining good production quality code
Hands-on Software Development Skills (Python-Preferred)
Experience or educational courses/projects in Machine Learning, and/or Text Mining Algorithms You will wow us even more if you have these skills: - Visualizations/Web Development Skills (e.g. Tableau, D3, etc).
Hands-on experience with prototype development
Hands-on experience with automating data cleansing, formatting, staging, and transforming data human
Hands-on experience applying data analytics
Hands-on experience with intelligent systems and machine learning LInC External Referral Bonus: Ineligible Potential for Telework: No Clearance Level Required: Top Secret/SCI Travel: Yes, 10% of the time Scheduled Weekly Hours: 40 Shift: Day Requisition Category: Professional Job Family: Software Engineering Leidos Leidos is a Fortune 500® information technology, engineering, and science solutions and services leader working to solve the world's toughest challenges in the defense, intelligence, homeland security, civil, and health markets. The company's 33,000 employees support vital missions for government and commercial customers. Headquartered in Reston, Virginia, Leidos reported annual revenues of approximately $10.19 billion for the fiscal year ended December 28, 2018. For more information, visit www.Leidos.com . Pay and Benefits Pay and benefits are fundamental to any career decision. That's why we craft compensation packages that reflect the importance of the work we do for our customers. Employment benefits include competitive compensation, Health and Wellness programs, Income Protection, Paid Leave and Retirement. More details are available here . Securing Your Data Leidos will never ask you to provide payment-related information at any part of the employment application process. And Leidos will communicate with you only through emails that are sent from a Leidos.com email address. If you receive an email purporting to be from Leidos that asks for payment-related information or any other personal information, please report the email to [email protected] . Commitment to Diversity All qualified applicants will receive consideration for employment without regard to sex, race, ethnicity, age, national origin, citizenship, religion, physical or mental disability, medical condition, genetic information, pregnancy, family structure, marital status, ancestry, domestic partner status, sexual orientation, gender identity or expression, veteran or military status, or any other basis prohibited by law. Leidos will also consider for employment qualified applicants with criminal histories consistent with relevant laws.",3.5,"Leidos
3.5","Arlington, VA","Reston, VA",10000+ employees,1969,Company - Public,Aerospace & Defense,Aerospace & Defense,$10+ billion (USD),-1
Software Engineer,"$64K-$132K
(Glassdoor est.)","Every Analyst a Scientist - One of our primary goals is to empower intelligence analysts to be able to study their data like scientists. The tools we develop focus on streamlining intelligence analysis through integrated algorithms and software that provide insight into the geopolitical landscape for use in operational intelligence missions around the world.

The Role:
As a Software Engineer, you will be part of a team that transforms large and complex customer data into real-world, high-impact solutions. You will work with researchers and engineers to design and implement solutions to challenging national security problems. You will be responsible for building the software infrastructure to clean, ingest, and expose datasets and algorithms to both developers and end users. You will deploy algorithms, generate workflows, create engineer-facing tools, and design customer-facing prototype systems. You will occasionally travel to customer sites to engage with end users, demonstrate prototypes, and integrate analytics into customer systems.

If you would like to help intelligence and defense analysts keep pace with technology-driven innovation, then this role is for you!

Who you are:
A U.S. Citizen with the ability to obtain a Security Clearance
A degree in a scientific or engineering field, such as Computer Science, Mathematics, Physics, or Software Engineering
Proficiency with a scientific programming language such as Python, Java, or C++
Experience with database management and common query syntax
Motivated collaborator and excellent communicator of ideas to both technical and non-technical audiences
Knowledge of AWS, Spark, Dask, and/or similar technologies for working with data at scale
Even better:
Active Security Clearance
Track record of architecting, developing, deploying, or maintaining enterprise software
Experience with software development best practices and tools
Understanding of web development and visualization technologies, such as d3, Leaflet, Bootstrap, or others
Familiarity with machine learning or statistical modeling techniques",4.5,"Systems & Technology Research
4.5","Woburn, MA","Woburn, MA",201 to 500 employees,2010,Company - Private,Aerospace & Defense,Aerospace & Defense,$100 to $500 million (USD),-1
Sr. Data Scientist,-1,"Background Information:

Innovative Defense Technologies (IDT), provider of automated software testing, data analysis, and cybersecurity solutions for complex defense systems, is currently accepting applications for an anticipated Sr. Data Scientist role requiring 7+ years of experience for a position in support of its efforts implementing Artificial Intelligence solutions for a variety of customers.

Overview:

The Sr. Data Scientist position offers an engineer the opportunity to utilize his/her knowledge and talents as part of a collaborative team developing AI solutions for a growing company. A few of the responsibilities include supporting feasibility studies, applying modern data storage techniques, discovering explanatory features in high-dimensionality collections of data, and exploring data using scientifically valid techniques to exploit patterns found in the data with state-of-the-art AI/ML/DL solutions.

All applicants must be able to obtain/maintain an active U.S. Security Clearance.

Responsibilities Include:
Lead development of solutions to deliver AI/ML/DL models from problem formulation to a productized, deployable, maintainable capability
Contribute to AI/ML/DL technical roadmap development
Use Deep Learning frameworks such as Tensorflow and Keras to build and validate ML/DL models
Establish and leverage Big Data frameworks to store, extract and analyze relevant data
Ensure development of software solutions meets customer needs and program intent
Work closely with the Program Manager and Chief Engineer to design and implement software requirements and solutions
Determine operational feasibility by evaluating analysis, problem definition, requirements, solution development, and proposed solutions for large, complex systems
Be responsible for a team’s products meeting software design, quality, and performance requirements
Pursue new technology development via the DoD Small Business Innovative Research (SBIR) program
Work with minimal supervision in a collaborative work environment to implement best-in-class solutions
Minimum Required Qualifications:
Bachelor’s Degree in Computer Science, Computer Engineering, Electrical Engineering, Systems Engineering, Physics, or Math Required; PhD in relevant field highly preferred
7+ years of experience in predictive modeling, data science and analysis
Required Skills:
Previous experience in a ML or data scientist role and a track record of building ML or DL models
Extensive experience working with data mining algorithms including decision trees, probability networks, association rules, clustering, and neural networks
Experience using Python (or equivalent)
Experience using ML libraries, such as scikit-learn,
Experience using data visualization tools
Experience handling terabyte size dataset
Experience working with GPUs to develop models
Ability to travel 10% or less
Preferred Skills:
Experience with MapReduce programming (Hadoop)
Skills with programming languages, such as Java or C/C++
Demonstrated ability to develop experimental and analytic plans for data modeling processes, use of strong baselines, ability to accurately determine cause and effect relations
Consulting experience and track record of helping customers with their AI needs
Publications or presentations in recognized Machine Learning, Deep Learning and Data Mining journals/conferences
Combination of deep technical skills and business savvy enough to interface with all levels and disciplines within our customer’s organization
Experience diving into data to discover hidden patterns
Experience with application container platforms
Familiarity with continuous integration/delivery tools (e.g. Jenkins)
Familiarity with version control tools (e.g. Subversion, Git, etc.)
Familiarity with VMware or other virtualization software
Experience developing applications for DOD command and control systems
Competencies:
Solid analytical abilities, coupled with a strong sense of ownership, urgency, and drive
Attention to detail
Initiative, creativity, reliability, teamwork
Ability to deal well with ambiguity, prioritize needs, and deliver results in a dynamic environment
EEO Statement:

IDT is an Equal Opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, creed, sex, sexual orientation, gender identity, national origin, disability, protected Veteran status, or any other basis protected by federal, state, or local law.",-1,Innovative Defense Technologies (IDT),"Mount Laurel, NJ",-1,-1,-1,-1,-1,-1,-1,-1
Full Stack Software Engineer (Python/Vue),-1,"Position Summary Full Stack Software Engineer (Python VueJS) Company Overview Our client is an automated underwriting platform for real estate professionals that was built to disrupt the commercial real estate industry. The software allows investors, brokers, and lenders to analyze rent, operating expenses and returns for multifamily properties by applying machine learning to a database of live multifamily transaction data from every U.S. market. Our client has a creative and entrepreneurial culture ndash everyone on the team interacts directly with customers each day, and we all contribute to the product and planning. If you have an idea to improve something, there is no red tapehellip just build what needs to be built! Innovation and passion for transforming the old-fashioned real estate industry are our highest priorities. Job Description As a full-stack (Python, PostgreSQL and HTMLCSSJavaScript) developer, you'll work on the interface and backend infrastructure of products and features used by hundreds of underwriters and real estate analysts every day. The work is challenging, fast-paced, and always changing. You must have demonstrated analytical skills, an unwavering commitment to quality, a collaborative work ethic, and cutting-edge coding skills. You must display solid proficiency in the fundamentals of Python, PostgreSQL, JavaScript, HTMLCSS, and popular front-end frameworks like Vue.js. The role will include the delivery of reliable, scalable new features to users, developed in Python, interacting with a PostgreSQL database and using the Vue.js frontend framework. You will work with the development team to develop, test and deliver finished, high quality, compelling features and products. Our team includes designers, engineers and data scientists who are passionate about quality, usability, and simplicity. If you are ready to join a company that fosters learning, growth, experimentation and innovation, our client's team is for you. Requirements Qualifications 3-5 years of experience in full stack Python development 1-3 years of experience with PostgreSQL 1-3 years of experience with JavaScript frameworks such as React, Angular or Vue.js (Vue.js is preferred, this is what our client uses), and CSS pre-processing frameworks (Sass or Less) 1-2 years of experience integrating with VBA and Excel integration preferred Experience using GitHub and solid understanding of software version control Familiarity with JIRA or equivalent product management software Familiarity with agile development best practices Driven self-starter able to work on a small team and take initiative on new tasks Familiarity with real estate or finance is a plus Responsibilities Collaborate with interdisciplinary team of data scientists, software engineers and real estate professionals Strive for high quality and rapid output utilizing agile development best practices Support, maintain, and document software functionality Maintain industry standard coding, compliance, security practices Proactively learn product frameworks and code base Our client is a startup company, and as such the responsibilities outlined above may change and evolve over time. Flexibility, curiosity, an entrepreneurial mindset, and strong work ethic are essential for this role. It is encouraged that everyone on the team continually research new technologies and analytical opportunities to improve the platform.",5.0,"CultureFit
5.0","Chicago, IL","Deerfield, IL",1 to 50 employees,1997,Company - Private,Advertising & Marketing,Business Services,$1 to $5 million (USD),-1
AWS Data Engineer,-1,"About Infinitive:

At Infinitive, we do mission-critical work for great companies. We specialize in digital marketing and digital advertising solutions, customer data & analytics, digital & business transformation, and Technology solutions. Our Technology solutions focus on Managed Cloud Services, Cloud Enablement, Digital Operations, Application Development, DevOps, Product Development, Cloud Security, Data Science and Analytics, AI/ML, IoT, and everything in between.

Our experts are results-obsessed, focused and flexible, highly engaged and hugely experienced having sat in our clients seats. Those qualities are what make us different than old-school consulting shops. And surely, they are why clients and partners describe us as the gold standard in client experience.

Infinitive has been named a Best Small Firms to Work For by Consulting Magazine seven times, a Washington Post Top Workplace three times, a Washington Business Journal Best

About this Role:

Infinitive is growing its team in the Northern Virginia area and is currently seeking an Data Scientist to join our growing Technology practice. This person will utilize their experience in analytics, IoT, machine learning, and artificial intelligence advances to create value from structured and unstructured data. The ideal candidate has experience designing novel data analytic methods and workflows, including full data pipelines from raw data through analysis results. They must also have exposure to a variety of data mining/data analysis methods, data tools, building and implementing models, using/creating algorithms, and creating/running simulations.

We are looking for candidates who are accountable, passionate, assertive, proactive, open & honest, results oriented, and adaptable. Each project engagement represents a new challenge that will give you exposure to new clients, business issues, technologies, and people and will involve a range of responsibilities to include:
Developing in Java, Python, R, or other high-level languages.
Managing disparate data sources with varying data structures of content and preparing these for data science and machine learning applications.
Working with distributed scalable Big Data storage, processing, and computation, including AWS EMR, Spark, etc.
Implementation knowledge of, or desire to learn AWS / Azure data science capabilities.
Developing solutions and integrating and extending free and Open-source software (FOSS) or COTS products.
Conduct MapReduce programming with Apache Hadoop, the Hadoop Distributed File System (HDFS), and processing large data stores.
Knowledge of SQL and query languages.
Utilize real-time, large-scale data processing engine, including Apache Spark.
Lead and create Data Science and Analytics methodologies and frameworks for implementation.
Ability to build and develop Data Science demonstrations for clients
Qualifications:
4+ years of development experience (Java, Python, R, SQL)
3+ years of experience with distributed scalable Big Data storage, including AWS EMR, Spark, etc.
Desire to become AWS / Azure Certified architect / engineer.
Experience performing data Management, modeling, and warehousing.
Hands on experience with Amazon analytic tools (preferred)
Interest in being involved internally and growing a small business (entrepreneurial spirit)
Ability to travel (up to 20%) and to work independently
Experience using Agile software development methods in a DevOps environment.
Excellent leadership, peer management, and communication skills
Management consulting experience (preferred)
Bachelor's degree in related field (preferred)
Applicants for employment in the U.S. must possess work authorization which does not require sponsorship by the employer for a visa.

Infinitive is an Equal Opportunity Employer.

Powered by JazzHR",3.4,"Infinitive Inc
3.4","Arlington, VA","Cedar Rapids, IA",201 to 500 employees,1997,Company - Private,Enterprise Software & Network Solutions,Information Technology,$10 to $25 million (USD),-1
"Senior SW Engineer, Data Science ( Kubernetes/ Docker ) Remote USA","$72K-$141K
(Glassdoor est.)","If you dream of a job working in a field where all the hard problems are solved and you get to re-use previous research to get your job done, you need not apply. If, however, you are someone who wants to tackle problems that truly are on the cutting edge, then we encourage you to keep reading.

Data Science is an emerging field within cyber security. FireEye, given its deep expertise and comprehensive view on the advanced threat landscape, is uniquely positioned to enable data scientists to have major impact within our industry, company, and across our customer base. Detecting security breaches using machine learning and data analytics is an unsolved problem (this is not handwriting recognition folks) and has huge potential.

If you are someone who wants to be on the cutting edge of a high profile industry, who wants to make an impact by pushing both fields of data science and cyber security forward, you may be the perfect candidate to help us on our mission.

What you will do:
Develop, and manage data systems to ingest and process data at massive scale
Identify data sources both internally and externally that we can use to find evil.
Contribute towards the architecture and design of software solutions for long-term storage and retrieval.
Identify and implement data exploration technologies. Create dashboards and implement analytical tools for exploration
Work with data scientists to productize ML models and assist product teams with ML model releases into end products.
Collect requirements, design, and build backend components and tools to run ML models, assess ML model efficacy, manage large scale datasets, and generate features for ML models
Contribute to the evolution of coding and design practices within the organization.
Review code base commits and contribute to the growth of team members.
Requirements
Ability to work in an iterative, agile development environment.
Experience implementing ETL processes and building data pipelines
Experience developing reliable distributed systems.
Experience in Data modeling and schema design
Strong knowledge of a variety of operating systems, networking fundamentals, software design and programming best practices.
Experience with use of a wide array of algorithms and data structures.
Deep understanding and experience of going through the entire life cycle of building software platforms and products
Deep knowledge of various AWS services and associated tools
Strong experience developing in Python 3
Experience developing in at least 1 of the following: C, Go or Java
Experience with RDBMS, such as PostgreSQL or MySQL, as well as NoSQL
Experience with Kubernetes and Docker.
Experience deploying products in AWS
Additional Qualification: *
Ability to pick up, work with and explore new analytical tools
Strong experience with DevOps practices and common tooling
Strong communication skills.
Ability to work with loosely defined requirements.
At FireEye we are committed to our #OneTeam approach combining diversity, collaboration, and excellence. All qualified applicants will receive consideration for employment without regard to race, sex, color, religion, sexual orientation, gender identity, national origin, protected veteran status, or on the basis of disability. Requests for accommodation due to disability can be sent directly to .",3.3,"FireEye Inc
3.3","Denver, CO","Milpitas, CA",1001 to 5000 employees,2004,Company - Public,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,"Palo Alto Networks, Tanium"
"Senior SW Engineer, Data Science","$72K-$141K
(Glassdoor est.)","Job Description

If you dream of a job working in a field where all the hard problems are solved and you get to re-use previous research to get your job done, you need not apply. If, however, you are someone who wants to tackle problems that truly are on the cutting edge, then we encourage you to keep reading.

Data Science is an emerging field within cyber security. FireEye, given its deep expertise and comprehensive view on the advanced threat landscape, is uniquely positioned to enable data scientists to have major impact within our industry, company, and across our customer base. Detecting security breaches using machine learning and data analytics is an unsolved problem (this is not handwriting recognition folks) and has huge potential.

If you are someone who wants to be on the cutting edge of a high profile industry, who wants to make an impact by pushing both fields of data science and cyber security forward, you may be the perfect candidate to help us on our mission.

What you will do:
Develop, and manage data systems to ingest and process data at massive scale
Identify data sources both internally and externally that we can use to find evil.
Contribute towards the architecture and design of software solutions for long-term storage and retrieval.
Identify and implement data exploration technologies. Create dashboards and implement analytical tools for exploration
Work with data scientists to productize ML models and assist product teams with ML model releases into end products.
Collect requirements, design, and build backend components and tools to run ML models, assess ML model efficacy, manage large scale datasets, and generate features for ML models
Contribute to the evolution of coding and design practices within the organization.
Review code base commits and contribute to the growth of team members.",3.3,"FireEye Inc
3.3","Denver, CO","Milpitas, CA",1001 to 5000 employees,2004,Company - Public,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,"Palo Alto Networks, Tanium"
"Senior Machine Learning Engineer, Early Stage Pipeline, X",-1,"Senior Machine Learning Engineer, Early Stage Pipeline, X

Software Engineering

Mountain View, CA

We're an early stage team at X with a growing, interdisciplinary portfolio. To prove our path to the moon, we make early contact with the real world through both internal and external partnerships.

In this role, you will be responsible for taking early stage investigations from an idea stage to first prototypes to a full-blown projects. You'll be rapidly iterating through a set of prototypes to evaluate possible product directions. This is an extremely dynamic role and requires high cross-functional communication, organization, and planning. The ideal candidate is a self-starter and has a track record of effectively operating in a dynamic loosely structured environment (e.g. startup, new products within a larger company). The candidate will work on multiple projects/investigations.

Responsibilities:
Identify and implement a set of machine learning prototypes to aggressively de-risk projects building the whole solution: data acquisition, data processing pipelines, ML modeling.
Setup technical direction for investigations/projects working with the early stage leadership team.
Team lead investigations that grow to become projects.
Qualifications:
Hands-on experience with machine learning, one or more of; natural language processing (semantic understanding, sentiment analysis), computer vision, time series analysis.
Experience with building robust data pipelines.
Tech Lead experience.
Startup or early-stage product development experience.
Preferred Qualifications:
Experience with the Google Cloud Platform
About X, the Moonshot Factory

X creates radical new technologies to solve some of the world's biggest problems. We develop uncomfortably ambitious, potentially world-changing new ideas such as self-driving cars, balloon-powered Internet and smart contact lenses. We're a team of makers, entrepreneurs, engineers, designers and scientists with deep technical expertise who love the challenge of the seemingly impossible. We believe that a culture of psychological safety creates the foundation of trust and respect necessary to build moonshots. X was formerly known as Google[x] and is part of Alphabet .

At X, we don't just accept difference - we celebrate it, we support it, and we thrive on it for the benefit of our employees, our products and our community. We are proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements.

If you have a disability or special need that requires accommodation, please contact us at: (see application details) .",-1,"X, the moonshot factory","Mountain View, CA",-1,-1,-1,-1,-1,-1,-1,-1
"Senior/Staff Software Engineer, Data Infrastructure","$116K-$227K
(Glassdoor est.)","Senior/Staff Software Engineer, Data Infrastructure job posting

Every year, while Americans wait for their paychecks, more than $1 trillion of their hard-earned money is held up in the pay cycle. As a result, we accumulate over $50 billion in late and overdraft fees and turn to high-interest loans. Overdraft charges and bank fees often trap people in a cycle of debt that can lead to unhealthy decisions and falling victim to predatory businesses disguised as helpful services. We don't accept that.

Earnin is an app that creates products that help people gain control of their finances. Cash Out lets people get paid as soon as they leave work, with no fees, interest, or hidden costs. With Health Aid, Earnin negotiates on behalf of community members to lower their total unpaid medical bill and work out a budget-friendly payment plan. Cash Back Rewards is a way for members to earn up to 10% cash back on purchases from over a thousand local and national businesses without needing a credit card or having to reach spend thresholds to earn cash rewards — and they can withdraw the money at any time. We also offer free tools to help avoid overdrafts, to remind people when recurring bills are due, and we're working on more! There is never any required cost to use any of these products or services, users can choose to tip what they think is fair to support the service and pay it forward to keep the movement going.

Earnin is supported by funding partners including Andreessen Horowitz, Matrix Partners, Ribbit Capital, Felicis Venture, Thrive Capital, and others. Join us and help build a new financial system focused on fairness and people's needs.

You can help make a difference.

About the Team:

We are a data driven mobile financial tech company. The Data Infrastructure team builds the data services and data infrastructure that powers data science, analytics, and product development throughout Earnin. We are looking for a product-minded, self-driven Senior Software Engineer to own multiple large-scale projects that advance our mission of enabling people to gain access to their paycheck on demand.

What sets us apart:
High impact roles at a relatively small company that's aggressively growing our user base.
We are a collaborative team and genuinely enjoy working with each other.
We believe in empowering our people to be successful.
We're building a product that inspires fairness across the financial world and helps people not get taken advantage of.
As a Senior Engineer you will:
Break down complex problems into their bare essentials, translate this complexity into elegant design and create high quality, maintainable code.
Build massively scalable, production-grade data services.
Champion data quality and governance throughout the organization.
Build a world class data lake and data warehouse.
Design and develop new systems and tools to enable all of Earnin to consume and understand data faster.
Own the end to end design, build, and maintenance of platform services, data pipelines, and data products.
Implement comprehensive monitoring, logging, and alerting across our data infrastructure.
Work cross functionally with other teams (data science, design, product, marketing, and analytics) in high visibility roles as an engineering leader.
Build and deploy the data architecture that supports machine learning model development and actionable analytics.
Work with product engineering and data science teams to design scalable, performance model deployment architectures.
Communicate the tradeoffs of technical decisions to multiple stakeholders, including non-technical audiences.
Collaborate with and mentor other engineers and provide engineering direction to data scientists and analysts.
Actively engage and drive design reviews and code reviews.
Some skills we consider critical to being a Senior Engineer:
BS or MS degree in Computer Science, Engineering, or a related technical field.
8+ years of development experience in a fast-paced environment, especially startups.
5+ years of experience working with data systems.
Strong Python and SQL skills.
Strong programming and architecture skills.
Excellent written and verbal communication skills, including the ability to identify and communicate data driven insight.
Taking pride in your code quality and helping others elevate their own code quality.
Substantial experience with testing, data validation, and data quality assurance.
You can articulate the tradeoffs of different deployment architectures (e.g. streaming vs. batch vs. service-based).
Experience designing data platforms and services on cloud infrastructure, preferably AWS.
Hands-on experience designing and building large-scale solutions with the Hadoop stack and/or Spark.
Experience tuning and optimizing Spark-based applications.
Experience deploying and/or using query engines like AWS Athena, Presto, and Impala.
Experience with AWS analytical services like Redshift.
Hands-on experience working with a varied set of data storage technologies (e.g. Mysql, Postgres, DynamoDB, S3, etc.). You know where and when to use each.
Extensive experience with data modeling for multiple use cases and application styles, including NoSQL data modeling.
Experience working with data formats such as Avro and Parquet.
Experience working with alerting and monitoring tools like DataDog and PagerDuty.
Nice to haves:
You have experience building and deploying machine learning models.
You have experience using Terraform.
You have substantial experience working at a startup.
You have experience with data modeling in Redshift.
Experience with streaming infrastructure like Kafka.
Experience working with Kubernetes.
Experience building and deploying AWS Lambda applications.",3.1,"Earnin
3.1","Palo Alto, CA","Palo Alto, CA",201 to 500 employees,2012,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Engineer (open level),"$43K-$69K
(Glassdoor est.)","Title
Data Engineer (open level)

07/08/2020

What you'll do...
At H&R Block, your contributions will go far beyond any job description. When you join our team, you'll add to the momentum of a forward-thinking company - one that defined an industry and is now leading its transformation.

H&R Block is transforming tax preparation through data to ensure that every client we serve gets the best tax outcome possible.

We are building a new Data Engineering Team in the Data Science & Analytics organization. This new team will own the technology and data capabilities of the end-to-end data-and-analytics function. It will take responsibility for building and maintaining the analytical technologies that the data science teams use, managing data at an enterprise scale, leveraging relationships with IT teams throughout the enterprise, and leading information architecture.

We are looking for talented, curious, and creative data engineers of all levels to help launch this team. You will be a good match for our organization if you are:
Motivated by the idea of building something innovative, transformative, and impactful.
Committed to the idea that data can drive experiences and products that wow our business partners and clients
Obsessed with defying expectations and raising the bar
Driven by an innate sense of ownership for the products you create.
Day to day, you'll...
Design and deploy architecture, solutions, and software to capture, manage, store, and use structured and unstructured data from internal and external sources in both on-prem and cloud environments.
Deploy machine-learning models and other data-science products across the enterprise.
Navigate the balance between business needs, data governance best practices, and technical requirements.
Select or develop tools to cleanse, organize, and transform data and to maintain, defend, and update data structures and integrity on an automated basis.
Develop data products to facilitate self-service capabilities and assist the data teams to increase their efficiency and effectiveness.
Collaborate and communicate effectively within cross-functional teams that span internal Data Science & Analytics teams, IT, business groups, and executive stakeholders.
Be a positive force to cultivate a culture that is passionate about developing data tools as a business driver.
Job ID
368348BR

Address1
ONE H&R BLOCK WAY

City
KANSAS CITY

State
Missouri

Employee Type
Regular

What you'll bring to the team...
Education / work experience should include most of these, depending on level:
Bachelor’s degree in Computer Science or a related technical field (or equivalent work experience and technical skills)
Data warehousing and ETL solutions
APIs in a microservices architecture
Big-data technologies and the Hadoop stack (MapReduce, Hive, Pig, Hbase
NoSQL implementations (MongoDB)
Developing Java-based software solution
At least one scripting language (Python, Perl, JavaScript, Shell
Developing software solutions to solve complex business problems
Working with data scientists and other data users
Posting Title
Data Engineer (open level)

Sponsored Job
#hrbjob

Job Family
Corporate Analytics",3.6,"H&R Block
3.6","Kansas City, MO","Kansas City, MO",10000+ employees,1955,Company - Public,Other Retail Stores,Retail,$2 to $5 billion (USD),"Intuit, Jackson Hewitt, Liberty Tax Service"
Senior Modeling & Simulation Engineer,-1,"Applied Research Associates, Inc. is looking for a Senior Modeling and Simulation Engineer to join our multi-disciplinary team of engineers and scientists in the Capital Area Division, located in Alexandria, VA. The ideal candidate has a passion for predicting the behavior of physical systems in challenging environments and operational impact on mission success. Models will be developed, used, and improved to support a Department of Homeland Security customer to safeguard the nation’s borders and interior from chemical, biological, radiological, nuclear, and explosive materials, equipment, technologies, and their actors. Models may be based on the underlying physics or may be process or agent based to predict operational performance and impact. Modeling and analysis may require the use and development of 3D virtual worlds or geospatial data. Models will be verified and validated, and they will be used in support of test and evaluation activities of systems intended to detect and identify threats. The candidate may participate in test and evaluation activities to support the verification, validation, and overall improvement of models. Models may become part of larger, integrated modeling and simulation activities, and may require the use of high performance computing technologies and federated simulations.

This position is contingent upon award of a contract expected in Summer 2020 supporting the Department of Homeland Security.

Required Qualifications:
Ability to program in a high level programming language, such as Fortran, C++, or Java
Eagerness to learn new tools and techniques
Strong verbal and written communication skills
Must be a U.S. Citizen with the ability to obtain and maintain a security clearance
Bachelor’s degree with minimum of 10 years of experience or greater in a physical science (physics, chemistry, biology), engineering-related discipline (nuclear, chemical, civil, mechanical, electrical), or modeling& simulation disciple (computer modeling, computational science, operations research)
Ability to present to senior leadership on the status and issues associated with research or test efforts in preparation for acquisition decision meetings
Desired Experience and Qualifications:
Experience modeling CBRNE detectors or effects
Experience using multiple software tools such as MCNP, GadRas, SWORD, ExtendSim, Arena, SolidWorks, Fluent, ArcGIS, QGIS, VisIt, ParaView, or Cubit
Experience creating 3D models of systems, i.e., CAD
Experience using high performance computers (i.e., supercomputers)
Experience developing and using discrete event or agent based models and simulations to predict and assess system performance
Experience developing machine learning models
Background in a physical science or engineering discipline, such as Physics, Chemistry, Biology, Mechanical Engineering, Nuclear Engineering
Active DoD Secret or Top Secret clearance, DoE Q clearance, or DHS Suitability
COMPANY INFORMATION:

Applied Research Associates, Inc. is an employee-owned international research and engineering company recognized for providing technically superior solutions to complex and challenging problems in the physical sciences. The company, founded in Albuquerque, NM, in 1979, currently employs over 1200 professionals. ARA offices throughout the United States and Canada provide a broad range of technical expertise in defense technologies, civil technologies, computer software and simulation, systems analysis, environmental technologies, and testing and measurement. The corporation also provides sophisticated technical products for environmental site characterization, pavement analysis, and robotics.

At ARA, employees are our greatest assets. The corporation realizes that employee ownership spawns greater creativity and initiative along with higher performance and customer satisfaction levels. ARA gives its employees the tools, training, and opportunities to take more active roles as owners. The culture is challenging; innovation and experimentation are the norm. Employees are eligible for contributions which not only add to the company’s success, but also their own through the Employee Stock Ownership Plan (ESOP). The motto,“Engineering and Science for Fun and Profit” sums up the ARA experience. For additional information and an opportunity to join this unique workplace, please visit our website atwww.ara.com.",3.5,"Applied Research Associates
3.5","Alexandria, VA","Albuquerque, NM",1001 to 5000 employees,1979,Company - Private,Federal Agencies,Government,$100 to $500 million (USD),-1
Senior Data Engineer,-1,"This is a Data Engineer position for supporting a Navy program located in Quantico, Virginia.

We are seeking a Data Engineer to join our team of committed technical professionals to protect those who serve against criminal, terrorism and emerging threats. Are you passionate about analytics and innovation? Our employees enjoy a fast-paced, collaborative culture and the ability to directly impact our business. You will identify technical issues and opportunities for efficiency and provide technical insights through system design and configuration perspectives. This role is both challenging and rewarding.

You will support the mission through the implementation of a modern, integrated internal data infrastructure with a focus primarily on exploiting the established data foundation to make internal and customer-centric business processes as effective and efficient as possible, laying the foundation for cognitive capabilities that can sense and respond to both internal and external customer data needs. The candidate will also focus on expanding the organization’s data ecosystem to include context-rich data while maintaining the agility needed to spark innovation.

How you will make a difference:
Establish shared operational data and integrated enterprise data, all while managing and/or improving data quality and security through the creation of business-driven governance structures and culture change management.
Establish data policies, standards, and procedures that improve data quality, availability, accessibility, security, usability, and enforcement of enterprise information management (EIM) program requirements.
Establish enterprise standards – including a uniform and repeatable system development lifecycle methodology for Reference Data and Master Data (e.g., a common set of standards for data naming, abbreviations, and acronyms).
Develop a Master Data Management (MDM) Plan that focuses on the technology, tools, and processes ensuring master data is coordinated across the enterprise. MDM is a method used to define and manage the critical data of an organization to provide, with data integration, a single point of reference. The data that is mastered may include reference data – the set of permissible values, and the analytical data supporting decision making. MDM provides a unified master data service intended to provide accurate, consistent and complete master data across the enterprise and to business partners.
Recommend solutions based on performing industry-specific analysis, such as case studies describing data management best practices, identifying trends across the industry.
Make recommendations to improve the efficiency and effectiveness in how the agency acquires, stores, manages, shares and applies its data.
Engage business users and stakeholders for the increased release of actionable high-quality data on key operational and tactical activities at NCIS.
Develop technology solutions to provide the platform, training, and standardized tools enabling querying, data mining, statistical analysis, reporting, scenario modeling, data visualization, and dash-boarding, and processes for a centralized, or analytics as a service model, allowing for the sharing of data across the enterprise from a common hub, facilitates cross-organizational data initiatives due to its enterprise-wide view of data assets and needs.
Basic Qualifications
Required: A bachelor’s or master’s degree in computer science, data science, operations research, statistics, applied mathematics, or a related quantitative field [or equivalent work experience such as, economics, engineering and physics] is [preferred/required]. Alternate experience and education in equivalent areas such as economics, engineering or physics, is acceptable. Experience in more than one area is strongly preferred.
Required: Three to six (midlevel) of relevant project experience in successfully launching, planning, and executing data science projects. Preferably in the domains of risk modelling and quality assessment.
Preferred: Specialization in text analytics, image recognition, graph analysis or other specialized ML techniques such as deep learning, etc.
Preferred: the candidates are adept in agile methodologies and well-versed in applying DevOps/MLOps methods to the construction of ML and data science pipelines.
Coding knowledge and experience in several languages: for example, R, Python, Java, C++, Excel, MATLAB, etc.
Experience with popular database programming languages including SQL, PL/SQL, others for relational databases and upcoming non-relational databases such as NoSQL/Hadoop-oriented databases such as MongoDB, Cassandra, others.
Preferred: Specialized/operational data scientists may need further high-performance computing (HPC)/compute skills; larger data science teams, in particular, may require further degrees of specialization such as:
Experience with distributed data/computing tools such as MapReduce, Hadoop, Hive, Kafka, and MySQL
Experience of working across multiple deployment environments including cloud, on-premises and hybrid environments, multiple operating systems and through containerization techniques such as Docker, Kubernetes, AWS Elastic Container Service, and others.
Experience in one or more of the following commercial/open-source data discovery/analysis platforms: RStudio, Spark, KNIME, RapidMiner, Alteryx, Dataiku, H2O, SAS Enterprise Miner (SAS EM) and/or SAS Visual Data Mining and Machine Learning, Microsoft AzureML, IBM Watson Studio or SPSS Modeler, Amazon SageMaker, Google Cloud ML, SAP Predictive Analytics.
Preferred: Expertise in solving vision, text analytics, credit scoring, and failure prediction problems.
Knowledge and experience in statistical and data mining techniques such as generalized linear model (GLM)/regression, random forest, boosting, trees, text mining, hierarchical clustering, deep learning, convolutional neural network (CNN), recurrent neural network (RNN), T-distributed Stochastic Neighbor Embedding (t-SNE), graph analysis, etc.
Strong documentation skills. Required: Certifications as per Cybersecurity Workforce Management and Qualification Manual, SECNAV M-5239.2.
Required: Eligible AND adjudicated to the Top Secret (TS SCI) clearance level is required to start.
About Inventium.io:

Inventium.io LLC is a technical consulting and software development services company dedicated to protecting and advancing our national defense and scientific capabilities. Based out of the Washington DC area, we rely on innovation to continually advance our employees' skills and provide digital transformation solutions to our customers.

With proven records of successfully delivering quality services and solutions to multiple federal agencies, our technical competencies include Emerging Technology Solutions, DevSecOps, Cloud Migration, Machine Learning, System Modernization, and Technology Management.

Benefits and Perks
Employer paid Health Benefits (Medical, Dental and Vision)
Retirement Plan
Paid Time Off and Federal Holidays
Training and Development
Employee Referral Program
Awards and Recognition",5.0,"inventium.io LLC
5.0","Quantico, VA","Washington, DC",1 to 50 employees,2016,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Senior Software Engineer,-1,"At Pacific Biosciences, our R&D team is committed to developing innovative products that enable scientists to excel in a wide variety of life science research fields, including human biomedical, plant and animal sciences, and microbiology and infectious disease. Our unique Single Molecule, Real-Time (SMRT) sequencing platforms generate true high-quality long reads, giving researchers a more comprehensive view of genomes, transcriptomes, and epigenomes from any organism.

The Primary Analysis group, as part of the larger software engineering team at PacBio, develops algorithms and HPC solutions for decoding the raw data streams, generated through high-speed optical detection of the SMRT sequencing reactions, into DNA sequence reads. We operate at the intersection of cutting-edge nanotechnology and state-of-the-art bioinformatics tools, and our responsibilities span the full product development life cycle in an aggressive time-to-market environment. These include analysis and algorithm development in coordination with chemistry and systems R&D; the development of real-time analysis pipelines; and the development of validation and support infrastructure geared towards product system reliability and internal R&D support. We are seeking a talented algorithm engineer with a strong background in the physical or machine-learning/data sciences who also has a passion for designing and developing performance-critical data analysis solutions.

Responsibilities:

Design, develop, and test signal- and sequence-analysis algorithms that will drive fundamental improvements in basecalling accuracy and yield.
Work collaboratively in a team environment to solve challenging problems in software architecture and scalability of real-time analysis pipelines for our next-generation sequencing platforms.
All listed tasks and responsibilities are deemed as essential functions to this position; however, business conditions may require reasonable accommodations for additional tasks and responsibilities.

Key Skills and Background:

3+ years of experience shipping product software in a scientific or quantitative domain.
Demonstrated skills applying numerical methods, statistical signal processing, or machine-learning techniques to high-throughput, performance-critical analysis applications.
Linux-based systems programming experience with knowledge of OS, toolchain and hardware constraints.
Strong C++ programming experience in applications geared towards performance and scalability; previous experience in CUDA programming for GPU is a plus.
MS, PhD or equivalent experience in a quantitative field (physics, CS, etc.), preferably with an applied math or algorithmic focus.
Engineering instincts to efficiently investigate and solve the problem at hand, from prototype development (Python, R, MATLAB, etc.) to production designs.
Team player, with strong communication skills, and comfortable as a self-starter in an agile, fast-paced development environment.
All qualified applicants will receive consideration for employment without regard to race, sex, color, religion, national origin, protected veteran status, or on the basis of disability, gender identity, and sexual orientation.",3.7,"Pacific Biosciences
3.7","Menlo Park, CA","Menlo Park, CA",201 to 500 employees,2000,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,$50 to $100 million (USD),Illumina
Senior Data Engineer,-1,"ABOUT 605

At 605 we are engineers, analysts, data scientists, media experts, marketing strategists and political operatives. Our team of data scientists pioneered the field of TV data analytics. We offer unique, independent audience measurement and analytics to build better marketing and programming initiatives within the media and entertainment industries.

The Sr. Data Engineer at 605 must have a broad and deep data skillset as well as strong analytical capabilities . In addition to being a hands on individual contributor, the ideal candidate is a productive team player and a mentor to Junior. Data Engineers. Additionally, we are looking for strong technical experts.

Responsibilities include:
Actively participate in team technical discussions in all things data
Identify and address issues with data sets from multiple vendors
Identify and address code and data quality issues
Actively participate in code reviews and grooming sessions
Actively participate in technology architecture discussions for product development
Translate business requirements into strategy
Advocate for software best practices within your team as well as across engineering
Be ultra-responsive and capable of making instant decisions, always kicking the ball forward
Work on unique and interesting data challenges around architecting, building and managing pipelines that securely process hundreds of terabytes of data
Work closely with analysts and statisticians to ensure the validity of our processes
Our engineers are expected to wear a number of hats and have the opportunity to touch all parts of the stack. Our stack includes Apache Spark, Scala, Redshift and an ever-growing list of many other cool technologies.

Requirements
Skillful user of Apache Spark
Experience wrangling terabytes of big, complicated, imperfect data
Experience with AWS products (Redshift, EMR, S3, IAM, RDS, etc)
You have a deep understanding of scalable systems and you have large-scale engineering experience in an Agile development environment
Bachelor's degree in Computer Science or a related field (or 4 additional years of relevant work experience)
A strong understanding of data structures, algorithms, and effective software design
Significant development experience with a major modern language (e.g. Java, Scala, Python, Ruby, C/C++, etc.)
Significant experience working with structured and unstructured data at scale and comfort with a variety of different stores (key-value, document, columnar, etc.) as well as traditional RDBMSes and data warehouses
Experience with or interest in AWS Glue, Redshift Spectrum and any other tools that enable data querying at scale
Experience writing unit, functional and integration tests
Comfort with version control systems (e.g. Git, SVN)
Excellent verbal and written communication skills; must work well in an agile, collaborative team environment
Preferred Qualifications
Master's in Computer Science or a related field
Practical experience with supervised machine learning techniques
Strong background with test-driven development
Basic understanding of statistics and experience with statistical packages such as R, Matlab, SPSS, etc
Benefits

Important and Standard
Comprehensive health, dental and vision insurance for employees and their families
Life & Disability insurance
401k plan with match, eligible for match after one year
Pre-tax flexible compensation plan for medical, transit, parking or dependent care expenses
Up to 15 paid vacation days depending on grade level
7 paid sick days in a calendar year - if you’re sick, you stay home
Other cool benefits
4 work from home days/month
A kitchen stocked with sodas, snacks, yogurt and other goodies
A tight knit start up community who likes to eat! We celebrate everyone’s birthdays, have frequent team lunches, and do events in and out of the office
605 is an active participant in conferences
EEO STATEMENT

At 605, we’re just as passionate about diversity as we are about pioneering the field of TV data analytics. We are committed to cultivating an environment of mutual respect and equal opportunity. All hiring and advancement decisions are made on the basis of qualification, merit, and business need.",-1,605,"New York, NY",-1,-1,-1,-1,-1,-1,-1,-1
Sr Innovation Engineer,"$75K-$134K
(Glassdoor est.)","Company Information

Solid reputation, passionate people and endless opportunities. Thats Travelers. Our superior financial strength and consistent record of strong operating returns mean security for our customers and opportunities for our employees. You will find Travelers to be full of energy and a workplace in which you truly can make a difference.

Target Openings

1

Job Description Summary

Innovation is at the core of everything we do. We continue to ask ourselves, whats next? as we navigate the ever-changing insurance landscape. Continuing our customer journey toward the cutting-edge, we are looking for a forward-thinking individual that thrives in ambiguity, who believes that with every challenge comes a new opportunity for solutions.

As a member of the Innovation Technology team, you will partner with research scientists and product managers to discover, invent, and build solutions at scale. As a team, you will work on challenges in machine perception, data mining, machine learning, and natural language understanding.

We are looking for a hands-on individual with strong foundational knowledge highly scalable architectures and platforms. If you like using a variety of skills in technology and solving complex problems, work collaboratively in a small agile team environment, you might just be the person we need on our team!

Primary Job Duties & Responsibilities
Work closely with Cloud Engineering to build an innovation platform; a collection of reusable and extensible containers and tools specific to developing insurance products and platforms.
Recommend integration strategies, enterprise architectures, platforms and application infrastructure required to successfully implement a complete solution using best practices.
Produce quality output for highly visible IT products, services and future business development.
Assist in hands-on remediation of application stability and performance.
Adopt and communicate new concepts, ideas, techniques.
Manage multiple projects simultaneously.
Provide 'Shrink Wrap' solutions to solve business and technical needs. As part of our innovation process, be able to scale Minimum Viable Product to production systems.
Design and lead integration of analytic data products, including pilots and proof of concepts.
Frequently present and translate complex information in relevant business terms.
Constantly learn new skills within small teams.
No direct HR people management but will lead teams in project & program contexts.
Education, Work Experience, & Knowledge
Bachelors Degree in STEM (Science, Technology, Engineering, Mathematics) related field and 3+ years of experience or 10+ years of experience building highly scalable platforms and reusable components
Job Specific Technical Skills & Competencies
2+ years of experience working with Amazon Web Services (AWS) or equivalent cloud. Must be recent experience.
5+ years of designing and developing on-premise and cloud solutions.
3+ years of experience as a technical lead.
Experience in software engineering with relevant technologies (Java, JavaScript, Python etc.).
Experience with the application delivery process.
End-to-end experience with data, including querying, aggregation, analysis, and visualization.
Preferred Qualifications
AWS certified developer and/or architect
Proven ability to work creatively and analytically in a continuously evolving environment.
Exhibits high levels of learning agility in which they seek out and learn from unfamiliar experiences and then apply those lessons to succeed in the next new situation.
Ability to leverage business knowledge to determine approaches to execution.
Strong communication and presentation skills with the ability to present and translate complex information to leadership and non-technical teams in relevant business terms.
Uses effective listening skills and communication to build relationships across the organization.
Ability to Influence with experience working with matrixed staff to complete tasks in a timely manner.
Environmental / Work Schedules / Other
Travel Required
Equal Employment Opportunity Statement

Travelers is an equal opportunity employer.",4.1,"Travelers
4.1","Hartford, CT","Hartford, CT",10000+ employees,1853,Company - Public,Insurance Carriers,Insurance,$10+ billion (USD),-1
Senior AI Software Engineer,-1,"Company Overview

Calling the adventurers ready to join a company that's pushing the limits of nanotechnology to keep the digital revolution rolling. At KLA, we're making technology advancements that are bigger—and tinier—than the world has ever seen.

Who are we? We research, develop, and manufacture the world's most advanced inspection and measurement equipment for the semiconductor and nanoelectronics industries. We enable the digital age by pushing the boundaries of technology, creating tools capable of finding defects smaller than a wavelength of visible light. We create smarter processes so that technology leaders can manufacture high-performance chips—the kind in that phone in your pocket, the tablet on your desk and nearly every electronic device you own—faster and better. We're passionate about creating solutions that drive progress and help people do what wouldn't be possible without us. The future is calling. Will you answer?

Responsibilities

Group/Division
KLA has always had a close relationship with physics and data. Our optical and electron beam inspection and measurement tools use cutting edge physics models, both for hardware design and as part of their algorithms. AI, including several traditional machine learning techniques and deep learning are routinely used to process this data to meet application requirements.

The AI & Modeling Center of Excellence, centered in KLA’s R&D facility in Ann Arbor, MI, was setup with the mission of advancing KLA’s traditional strengths in physics and data and providing implementation solutions for multiple KLA Inspection and Metrology products targeted at the semiconductor manufacturing industry.

As a part of this group, you will be part of a world class team of physicists, HPC system designers, machine learning and application engineers who build cutting edge solutions for modeling complex imaging techniques and semiconductor processes. You will also work with a data scientists and AI infrastructure engineers whose mission is to build and scale machine learning based solutions for our semiconductor customers.

We are looking for engineers in a few different fields. If you are passionate about Physics Modeling, High Performance Computing - HPC (including GPU), ML, Data, or Cloud technologies – this is the place for you!

Responsibilities:
Software Engineers in the AI and Physics Modeling team may work on a variety of tasks including platform for large scale experimentation, scaleout of physics models, data management and inference solutions for KLA products.

Although familiarity with Machine Learning and Deep Learning solutions would be a big plus, this is primarily a Software Engineering position. Successful candidates are passionate about software, and will have exceptional skills and hands on experience with development in C/C++ and Python in a Unix environment. Deep conceptual understanding of multi threaded and multi process software systems is also necessary.

In addition to the above fundamental software skills, any of the following technical hands-on skills are highly desirable.

1) System Programming and Operating Systems.
2) Distributed systems for data management.
3) Distributed computing infrastructure.
4) Cloud technologies for storage, containerization and compute clusters.
5) Data Structures and algorithms
6) GPU architectures and data management.
7) Traditional machine learning using Random Forest, XG Boost, Logistic Regression.
8) Deep Learning for regression, classification. Generative models.
9) TensorFlow, NumPy, scikit-learn, and other ML and DL frameworks.
10) MPI and similar distributed computing framework.
11) GPU Architectures and CUDA (CuGraph, CuData, CuML etc).
12) GO Systems Programming, Java Programming.

Successful candidates for this position will also demonstrate the following non-technical skills.

1) Capability to formulate creative solutions through analyzing complex data
2) Good communication skills
3) Strong team player and motivated by team success
4) Strong problem solving skills

Minimum Qualifications

Doctorate (Academic) with at least 2 years of experience.
OR
Master's Level Degree with at least 4 years of experience.
OR
Bachelor's Level Degree with at least 5 years of experience.

Equal Employment Opportunity

KLA is an Equal Opportunity Employer. Applicants will be considered for employment without regard to age, race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability, or any other characteristics protected by applicable law.",3.8,"KLA-Tencor
3.8","Ann Arbor, MI","Milpitas, CA",5001 to 10000 employees,1976,Company - Public,Industrial Manufacturing,Manufacturing,$2 to $5 billion (USD),"Applied Materials, Nanometrics"
"Senior SDE, Catalog Big Data and Machine Learning",-1,"Amazon's Catalog DataWorks team is looking for highly motivated engineers. We are embarking on multiple new initiatives to re-organize Amazon's catalog of billions of products, in new and interesting views, that drive several features Amazon's customers love. Today, these views drive hundreds of popular features like product recommendations, clustering of similar products, and shopping with Alexa. We will build a new near real-time Catalog Data Lake on AWS, to enable engineers and scientists across Amazon to solve customer problems faster. Come join us on this exciting journey!

As an engineer on this team, you will own the Catalog Data Lake end-to-end. You will work closely with business partners to synthesize technical requirements. You will design and implement significant parts of the platform. You will learn and use industry standards like Spark and Parquet as well as modern AWS offerings like EMR, Glue, Athena, and Redshift. We are fortunate to be at the cusp of innovation in both the e-commerce business as well as cloud technology. As a key stakeholder, you will constantly learn new patterns, solve key customer problems and strive to make AWS better along the way.Basic Qualifications
Bachelor's degree or higher in computer science or math is required.
Strong computer science fundamentals - algorithms, data structures and design patterns.
At least 8 years of software development experience.
At least 3 years of experience building and operating Big Data systems.
Experience mentoring, guiding and influencing peers.
Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.",-1,Amazon Corporate LLC,"Seattle, WA",-1,-1,-1,-1,-1,-1,-1,-1
SENIOR SOFTWARE ENGINEER & SOFTWARE ARCHITECT,-1,"Job Description
Senior Software Engineer, Software Architect
JOB SUMMARY

The Senior Software Engineer, Software Architect will develop software for Company innovative semiconductor X-Ray inspection system. The Senior Software Engineer will collaborate with Applications, QA, and Algo teams for high performance solutions and optimization per customer issues. It will be important to be comfortable working in a small company environment and a typical startup with engineers and scientists.

ABOUT THE CLIENT

Based in San Jose, California, client was founded in 2013 expressly to bring high speed inspection and metrology technology to the semiconductor packaging industry. Client founders anticipated the need to deploy inline 100% transmissive inspection into the semiconductor packaging manufacturing process and developed the company’s technology with this end in mind. The results, Client’s HR-AXI technology suite brings together the company’s unique data acquisition architecture with proprietary machine learning analysis techniques to provide customers with process monitoring and defect detection capabilities not found on any other products in the market. This job description can be updated at any time.

RESPONSIBILITIES
Designs, develops, troubleshoots, and debugs software programs for enhancements and new products, focused on creating high quality and high-performance solutions while maintaining high-level coding standards.
Develops software and tools in support of design, infrastructure, and technology platforms. Develops software solutions by studying information needs, conferring with users, and studying systems flow, data usage, and work processes
Supports hardware compatibility and/or influences hardware design based on software needs; work as part of cross-functional team to solve and implement system level problems.
Monitor application stability, performance, and availability. Promptly resolve issues impacting operations.
Work with engineering, documentation, and applications departments to ensure successful development and delivery of overall product.
Provide appropriate project feedback to management in a timely and appropriate format.
QUALIFICATIONS AND REQUIRED SKILLS
Education requirement: Bachelor’s degree in Computer Science, Electrical Engineering, or similar technical field required. Master’s or PhD strongly preferred.
Experience requirement: Minimum of 8 years of related experience working in software development.
Strong expertise in C# .NET. WCF, WPF, Database development. In addition, Python experience a plus.
Experience with Image processing algorithms implementations is a plus
Experience with software development for Factory Automation for Semiconductor equipment, a plus.
Self-starter able to think and act independently to translate general objectives into tangible results, with a record of delivering successful designs on schedule.
Demonstrated ability to organize, manage, and complete multiple assignments with challenging timelines independently and effectively.
Demonstrated analytical and problem-solving skills with high attention to detail.
Proactive approach to problem-solving. Build relationships with stakeholders to support successful design, build and testing.
Strong verbal and written communication, good attitude, and work ethic. Ability to communicate technical concepts and results clearly.
Experience with Git and Azure DevOps, a plus.",3.0,"Simple Solutions
3.0","San Jose, CA","Morgantown, WV",1 to 50 employees,2006,Company - Private,IT Services,Information Technology,Less than $1 million (USD),-1
Cloud Engineer,-1,"Job Description
Responsibilities:
Develop and implement technical efforts to design, build, and deploy AWS applications at the direction of lead architects, including large scale data processing, computationally intensive statistical modeling, and advanced analytics
Participate in all aspects of the software development life cycle for AWS solutions, including planning, requirements, development, testing, and quality assurance
Provide guidance, thought leadership and mentorship to development teams to build cloud competencies
Provide innovative thought leadership around Mathematica’s cloud solutions strategy and approach, including AWS best practices and market trends
Position Requirements:

6+ years of experience architecting, designing, developing and implementing cloud solutions on AWS platforms
Demonstrated experience with designing and implementing solutions using AWS platform and tools, such as: EC2, S3, Redshift, API Gateway, Lambda, DynamoDB, CloudFormation, RDS, VPC, IAM and security, QuickSight, CloudTrail, Config, CloudWatch, SNS, AMI generation
Understanding of and experience with the five pillars of a well-architected framework
Knowledge of SQL, R, and Python for data manipulation and statistical analysis is desirable
Familiarity with federal security regulations and standards (e.g. HIPAA, FISMA, FIPS, NIST, and FedRAMP)
Experience with security, especially knowledge of FedRAMP, HIPAA, PII/PHI, is desirable
Experience in several of the following areas: database architecture, ETL, Business Intelligence, Big Data, Machine Learning, Advanced Analytics
Proven ability to work collaboratively with multi-disciplinary teams of business analysts, developers, data scientists, and subject matter experts
Strong written, verbal and interpersonal communication skills
AWS Certifications (such as AWS solutions architect or other specialty certifications) are a plus
Bachelor's degree or equivalent combination of education and experience; degree in computer science, mathematics or related field preferred
Experience with other cloud platforms like Google Cloud Platform (GCP) is a plus",4.8,"RICEFW Technologies Inc
4.8","Princeton, NJ","East Lansing, MI",51 to 200 employees,2009,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Senior Software Engineer / Team Lead,"$112K-$220K
(Glassdoor est.)","Join our team dedicated to developing and executing innovative solutions in support of customer mission success.

Job Description:

Novetta has an exciting opportunity for a self-motivated and accomplished Computer Scientist to lead our entity analytics team. You will work on complex projects involving data analysis, software engineering, and deploying software in a cloud computing environment. The team combines data from disparate sources to visualize the complex relationships between entities. This effort involves large scale data integration and entity resolution leveraging a best in class Novetta product. We are looking for a flexible problem solver with significant technical experience to lead a team providing unique solutions for our customers and stakeholders.

Responsibilities include:
Lead a technical team of software engineers and computer scientists, working within a larger ecosystem delivering an Enterprise capability.
Navigate customer and prime environment, manage resources within and across team, and assist team with professional and technical growth.
Deploy applications on a large-scale data processing cluster using AWS technologies.
Design and implement entity correlation strategies that are tailored to mission needs and unique data qualities.
Develop algorithms and visualization tools to help stakeholders understand their data and prioritize new data sources.
Develop and integrate applications to automate ingestion, processing and monitoring of data
Develop and maintain tools to support operations and maintenance of production and development computing clusters.
Basic Qualifications:
Experience leading a team of software engineers.
A Bachelor's degree in computer science or related field and a minimum of 5 years of experience; or a Master's degree in computer science or related field and a minimum of 3 years of experience.
Experience in software development/engineering including requirements analysis, software development, installation, integration, evaluation, enhancement, maintenance, testing and problem diagnosis/resolution.
Software development experience on Linux-based systems in Python or shell scripting or JavaScript.
Experience developing against full-featured REST APIs and using a command line interface
Desired Skills:

Should meet a minimum of 3:
Software development experience with JavaScript, Python, or other modern programming languages.
Hands-on experience with Spark.
Experience working with Databricks
Interest in statistical analysis, machine learning, or data science.
Experience with entity resolution products or a background in data matching theory and technologies.
Experience developing applications in AWS.
Security Clearance:
The candidate must have a TS/SCI with Poly.
Novetta, from complexity to clarity.

Novetta delivers highly scalable advanced analytics and secure technology solutions to address challenges of national and global significance. Focused on mission success, Novetta pioneers disruptive technologies in machine learning, data analytics, full-spectrum cyber, cloud engineering, open source analytics, and multi-INT fusion for Defense, Intelligence Community, and Federal Law Enforcement customers. Novetta is headquartered in McLean, VA with over 1,000 employees across the U.S.

Our culture is shaped by a commitment to our core values:

Integrity • We hold ourselves accountable to the highest standards of integrity and ethics.

Customer Success • We strive daily to exceed expectations and achieve customer mission success.

Employee Focus • We invest in our employees' professional development and training, respecting individuality and fostering a culture of diversity and inclusion.

Innovation • We know that discovering new and innovative ways to solve problems is critical to our success and makes us a great company.

Excellence in Execution • We take pride in flawless execution as we build a company that is best in class.

Earn a REFERRAL BONUS for the qualified people you know.

For more details, or to submit a referral: bit.ly/NovettaReferrals

Novetta is an equal opportunity/affirmative action employer.

All qualified applicants will receive consideration for employment without regard to sex, gender identity, sexual orientation, race, color, religion, national origin, disability, protected veteran status, age, or any other characteristic protected by law.",4.5,"Novetta
4.5","Chantilly, VA","Mc Lean, VA",501 to 1000 employees,2012,Company - Private,Enterprise Software & Network Solutions,Information Technology,$100 to $500 million (USD),"Leidos, CACI International, Booz Allen Hamilton"
Data Fusion Engineer with Security Clearance,"$48K-$109K
(Glassdoor est.)","Description Job Description: Looking for work-life balance? Leidos offers generous leave and accommodating flex-time to help you juggle your personal and professional life. Are you a Software Engineer with experience finding and aligning signals across multiple modalities (image, video, audio, lidar, etc..)? Do you want to implement and customize algorithms to fusion multiple data modalities? If so we are looking for you, our next Data Fusion Engineer to work in Arlington, VA. We need you to be competent in Python and have the ability to read code in other programming languages like Java and C++ as well as have experience working with ML libraries like SciKit Learn, TensorFlow, Keras along with experience implementing solutions with those libraries on both CPU and GPU compute architectures. Like what you are reading so far? Keep going. We want you to be intellectually adaptive, inquisitive, good at expressing your needs, and able to self-manage when necessary. Work alongside software/system engineers and research/data scientists with expertise in multi-modal information retrieval, UI development, computer vision, metrics, information science, artificial intelligence, and autonomous systems. The Department of Defense and the Intelligence Community will be the main recipients your hard work. Fun stuff you will do on the job: - Use cases requiring identifying entity/objects, determining object association, object disambiguation, anomaly detection, state estimations, etc.
Develop and maintain data models (both physical and logical)
Get to be responsible for extraction, transform, and load (ETL) tasks related to the different modalities and algorithms being applied. This data ETL includes identifying the data's relevant metadata to ensure consistency, quality, accuracy, integrity, and information assurance and security.
Performing anomaly detection using various AI/ML techniques
Use algorithms to identify complex patterns across multiple modalities
Increasing the efficiency and quality data alignment and fusion
Enhance and maintain analysis tools, including automation of current processes using AI/ML algorithms
Conduct quantitative data analysis including developing retrieval, processing, fusion, analysis, and visualization of various datasets Skills required to be successful in this role: - Bachelor's Degree in Aerospace Engineering, Computer Science, Mathematics, Statistics, Physics, Electrical Engineering, Computer Engineering or related fields with 5 years of relevant experience
Must be able to obtain and maintain a TS/SCI security clearance
Experience with Deep Learning Frameworks such as Keras, Tensorflow, PyTorch, Mxnet, etc. - Ability to apply these frameworks to real problems in the 'time -series' domain
Experience with interpretability of deep learning models
Big Data Skills (Azure, Hadoop, Spark, recent deep learning platforms)
Practical experience with statistical analysis
Experience with text mining tools and techniques including in areas of summarization, search (e.g. ELK Stack), entity extraction, training set generation (e.g. Snorkel) and anomaly detection
Expert software development skills lifecycle including developing and maintaining good production quality code
Hands-on Software Development Skills (Python-Preferred)
Experience or educational courses/projects in Machine Learning, and/or Text Mining Algorithms You will wow us even more if you have these skills: - Visualizations/Web Development Skills (e.g. Tableau, D3, etc).
Hands-on experience with prototype development
Hands-on experience with automating data cleansing, formatting, staging, and transforming data human
Hands-on experience applying data analytics
Hands-on experience with intelligent systems and machine learning LInC External Referral Bonus: Ineligible Potential for Telework: No Clearance Level Required: Top Secret/SCI Travel: Yes, 10% of the time Scheduled Weekly Hours: 40 Shift: Day Requisition Category: Professional Job Family: Software Engineering Leidos Leidos is a Fortune 500® information technology, engineering, and science solutions and services leader working to solve the world's toughest challenges in the defense, intelligence, homeland security, civil, and health markets. The company's 33,000 employees support vital missions for government and commercial customers. Headquartered in Reston, Virginia, Leidos reported annual revenues of approximately $10.19 billion for the fiscal year ended December 28, 2018. For more information, visit www.Leidos.com . Pay and Benefits Pay and benefits are fundamental to any career decision. That's why we craft compensation packages that reflect the importance of the work we do for our customers. Employment benefits include competitive compensation, Health and Wellness programs, Income Protection, Paid Leave and Retirement. More details are available here . Securing Your Data Leidos will never ask you to provide payment-related information at any part of the employment application process. And Leidos will communicate with you only through emails that are sent from a Leidos.com email address. If you receive an email purporting to be from Leidos that asks for payment-related information or any other personal information, please report the email to [email protected] . Commitment to Diversity All qualified applicants will receive consideration for employment without regard to sex, race, ethnicity, age, national origin, citizenship, religion, physical or mental disability, medical condition, genetic information, pregnancy, family structure, marital status, ancestry, domestic partner status, sexual orientation, gender identity or expression, veteran or military status, or any other basis prohibited by law. Leidos will also consider for employment qualified applicants with criminal histories consistent with relevant laws.",3.5,"Leidos
3.5","Arlington, VA","Reston, VA",10000+ employees,1969,Company - Public,Aerospace & Defense,Aerospace & Defense,$10+ billion (USD),-1
Software Engineer,"$64K-$132K
(Glassdoor est.)","Every Analyst a Scientist - One of our primary goals is to empower intelligence analysts to be able to study their data like scientists. The tools we develop focus on streamlining intelligence analysis through integrated algorithms and software that provide insight into the geopolitical landscape for use in operational intelligence missions around the world.

The Role:
As a Software Engineer, you will be part of a team that transforms large and complex customer data into real-world, high-impact solutions. You will work with researchers and engineers to design and implement solutions to challenging national security problems. You will be responsible for building the software infrastructure to clean, ingest, and expose datasets and algorithms to both developers and end users. You will deploy algorithms, generate workflows, create engineer-facing tools, and design customer-facing prototype systems. You will occasionally travel to customer sites to engage with end users, demonstrate prototypes, and integrate analytics into customer systems.

If you would like to help intelligence and defense analysts keep pace with technology-driven innovation, then this role is for you!

Who you are:
A U.S. Citizen with the ability to obtain a Security Clearance
A degree in a scientific or engineering field, such as Computer Science, Mathematics, Physics, or Software Engineering
Proficiency with a scientific programming language such as Python, Java, or C++
Experience with database management and common query syntax
Motivated collaborator and excellent communicator of ideas to both technical and non-technical audiences
Knowledge of AWS, Spark, Dask, and/or similar technologies for working with data at scale
Even better:
Active Security Clearance
Track record of architecting, developing, deploying, or maintaining enterprise software
Experience with software development best practices and tools
Understanding of web development and visualization technologies, such as d3, Leaflet, Bootstrap, or others
Familiarity with machine learning or statistical modeling techniques",4.5,"Systems & Technology Research
4.5","Woburn, MA","Woburn, MA",201 to 500 employees,2010,Company - Private,Aerospace & Defense,Aerospace & Defense,$100 to $500 million (USD),-1
Sr. Data Scientist,-1,"Background Information:

Innovative Defense Technologies (IDT), provider of automated software testing, data analysis, and cybersecurity solutions for complex defense systems, is currently accepting applications for an anticipated Sr. Data Scientist role requiring 7+ years of experience for a position in support of its efforts implementing Artificial Intelligence solutions for a variety of customers.

Overview:

The Sr. Data Scientist position offers an engineer the opportunity to utilize his/her knowledge and talents as part of a collaborative team developing AI solutions for a growing company. A few of the responsibilities include supporting feasibility studies, applying modern data storage techniques, discovering explanatory features in high-dimensionality collections of data, and exploring data using scientifically valid techniques to exploit patterns found in the data with state-of-the-art AI/ML/DL solutions.

All applicants must be able to obtain/maintain an active U.S. Security Clearance.

Responsibilities Include:
Lead development of solutions to deliver AI/ML/DL models from problem formulation to a productized, deployable, maintainable capability
Contribute to AI/ML/DL technical roadmap development
Use Deep Learning frameworks such as Tensorflow and Keras to build and validate ML/DL models
Establish and leverage Big Data frameworks to store, extract and analyze relevant data
Ensure development of software solutions meets customer needs and program intent
Work closely with the Program Manager and Chief Engineer to design and implement software requirements and solutions
Determine operational feasibility by evaluating analysis, problem definition, requirements, solution development, and proposed solutions for large, complex systems
Be responsible for a team’s products meeting software design, quality, and performance requirements
Pursue new technology development via the DoD Small Business Innovative Research (SBIR) program
Work with minimal supervision in a collaborative work environment to implement best-in-class solutions
Minimum Required Qualifications:
Bachelor’s Degree in Computer Science, Computer Engineering, Electrical Engineering, Systems Engineering, Physics, or Math Required; PhD in relevant field highly preferred
7+ years of experience in predictive modeling, data science and analysis
Required Skills:
Previous experience in a ML or data scientist role and a track record of building ML or DL models
Extensive experience working with data mining algorithms including decision trees, probability networks, association rules, clustering, and neural networks
Experience using Python (or equivalent)
Experience using ML libraries, such as scikit-learn,
Experience using data visualization tools
Experience handling terabyte size dataset
Experience working with GPUs to develop models
Ability to travel 10% or less
Preferred Skills:
Experience with MapReduce programming (Hadoop)
Skills with programming languages, such as Java or C/C++
Demonstrated ability to develop experimental and analytic plans for data modeling processes, use of strong baselines, ability to accurately determine cause and effect relations
Consulting experience and track record of helping customers with their AI needs
Publications or presentations in recognized Machine Learning, Deep Learning and Data Mining journals/conferences
Combination of deep technical skills and business savvy enough to interface with all levels and disciplines within our customer’s organization
Experience diving into data to discover hidden patterns
Experience with application container platforms
Familiarity with continuous integration/delivery tools (e.g. Jenkins)
Familiarity with version control tools (e.g. Subversion, Git, etc.)
Familiarity with VMware or other virtualization software
Experience developing applications for DOD command and control systems
Competencies:
Solid analytical abilities, coupled with a strong sense of ownership, urgency, and drive
Attention to detail
Initiative, creativity, reliability, teamwork
Ability to deal well with ambiguity, prioritize needs, and deliver results in a dynamic environment
EEO Statement:

IDT is an Equal Opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, creed, sex, sexual orientation, gender identity, national origin, disability, protected Veteran status, or any other basis protected by federal, state, or local law.",-1,Innovative Defense Technologies (IDT),"Mount Laurel, NJ",-1,-1,-1,-1,-1,-1,-1,-1
Full Stack Software Engineer (Python/Vue),-1,"Position Summary Full Stack Software Engineer (Python VueJS) Company Overview Our client is an automated underwriting platform for real estate professionals that was built to disrupt the commercial real estate industry. The software allows investors, brokers, and lenders to analyze rent, operating expenses and returns for multifamily properties by applying machine learning to a database of live multifamily transaction data from every U.S. market. Our client has a creative and entrepreneurial culture ndash everyone on the team interacts directly with customers each day, and we all contribute to the product and planning. If you have an idea to improve something, there is no red tapehellip just build what needs to be built! Innovation and passion for transforming the old-fashioned real estate industry are our highest priorities. Job Description As a full-stack (Python, PostgreSQL and HTMLCSSJavaScript) developer, you'll work on the interface and backend infrastructure of products and features used by hundreds of underwriters and real estate analysts every day. The work is challenging, fast-paced, and always changing. You must have demonstrated analytical skills, an unwavering commitment to quality, a collaborative work ethic, and cutting-edge coding skills. You must display solid proficiency in the fundamentals of Python, PostgreSQL, JavaScript, HTMLCSS, and popular front-end frameworks like Vue.js. The role will include the delivery of reliable, scalable new features to users, developed in Python, interacting with a PostgreSQL database and using the Vue.js frontend framework. You will work with the development team to develop, test and deliver finished, high quality, compelling features and products. Our team includes designers, engineers and data scientists who are passionate about quality, usability, and simplicity. If you are ready to join a company that fosters learning, growth, experimentation and innovation, our client's team is for you. Requirements Qualifications 3-5 years of experience in full stack Python development 1-3 years of experience with PostgreSQL 1-3 years of experience with JavaScript frameworks such as React, Angular or Vue.js (Vue.js is preferred, this is what our client uses), and CSS pre-processing frameworks (Sass or Less) 1-2 years of experience integrating with VBA and Excel integration preferred Experience using GitHub and solid understanding of software version control Familiarity with JIRA or equivalent product management software Familiarity with agile development best practices Driven self-starter able to work on a small team and take initiative on new tasks Familiarity with real estate or finance is a plus Responsibilities Collaborate with interdisciplinary team of data scientists, software engineers and real estate professionals Strive for high quality and rapid output utilizing agile development best practices Support, maintain, and document software functionality Maintain industry standard coding, compliance, security practices Proactively learn product frameworks and code base Our client is a startup company, and as such the responsibilities outlined above may change and evolve over time. Flexibility, curiosity, an entrepreneurial mindset, and strong work ethic are essential for this role. It is encouraged that everyone on the team continually research new technologies and analytical opportunities to improve the platform.",5.0,"CultureFit
5.0","Chicago, IL","Deerfield, IL",1 to 50 employees,1997,Company - Private,Advertising & Marketing,Business Services,$1 to $5 million (USD),-1
AWS Data Engineer,-1,"About Infinitive:

At Infinitive, we do mission-critical work for great companies. We specialize in digital marketing and digital advertising solutions, customer data & analytics, digital & business transformation, and Technology solutions. Our Technology solutions focus on Managed Cloud Services, Cloud Enablement, Digital Operations, Application Development, DevOps, Product Development, Cloud Security, Data Science and Analytics, AI/ML, IoT, and everything in between.

Our experts are results-obsessed, focused and flexible, highly engaged and hugely experienced having sat in our clients seats. Those qualities are what make us different than old-school consulting shops. And surely, they are why clients and partners describe us as the gold standard in client experience.

Infinitive has been named a Best Small Firms to Work For by Consulting Magazine seven times, a Washington Post Top Workplace three times, a Washington Business Journal Best

About this Role:

Infinitive is growing its team in the Northern Virginia area and is currently seeking an Data Scientist to join our growing Technology practice. This person will utilize their experience in analytics, IoT, machine learning, and artificial intelligence advances to create value from structured and unstructured data. The ideal candidate has experience designing novel data analytic methods and workflows, including full data pipelines from raw data through analysis results. They must also have exposure to a variety of data mining/data analysis methods, data tools, building and implementing models, using/creating algorithms, and creating/running simulations.

We are looking for candidates who are accountable, passionate, assertive, proactive, open & honest, results oriented, and adaptable. Each project engagement represents a new challenge that will give you exposure to new clients, business issues, technologies, and people and will involve a range of responsibilities to include:
Developing in Java, Python, R, or other high-level languages.
Managing disparate data sources with varying data structures of content and preparing these for data science and machine learning applications.
Working with distributed scalable Big Data storage, processing, and computation, including AWS EMR, Spark, etc.
Implementation knowledge of, or desire to learn AWS / Azure data science capabilities.
Developing solutions and integrating and extending free and Open-source software (FOSS) or COTS products.
Conduct MapReduce programming with Apache Hadoop, the Hadoop Distributed File System (HDFS), and processing large data stores.
Knowledge of SQL and query languages.
Utilize real-time, large-scale data processing engine, including Apache Spark.
Lead and create Data Science and Analytics methodologies and frameworks for implementation.
Ability to build and develop Data Science demonstrations for clients
Qualifications:
4+ years of development experience (Java, Python, R, SQL)
3+ years of experience with distributed scalable Big Data storage, including AWS EMR, Spark, etc.
Desire to become AWS / Azure Certified architect / engineer.
Experience performing data Management, modeling, and warehousing.
Hands on experience with Amazon analytic tools (preferred)
Interest in being involved internally and growing a small business (entrepreneurial spirit)
Ability to travel (up to 20%) and to work independently
Experience using Agile software development methods in a DevOps environment.
Excellent leadership, peer management, and communication skills
Management consulting experience (preferred)
Bachelor's degree in related field (preferred)
Applicants for employment in the U.S. must possess work authorization which does not require sponsorship by the employer for a visa.

Infinitive is an Equal Opportunity Employer.

Powered by JazzHR",3.4,"Infinitive Inc
3.4","Arlington, VA","Cedar Rapids, IA",201 to 500 employees,1997,Company - Private,Enterprise Software & Network Solutions,Information Technology,$10 to $25 million (USD),-1
"Senior SW Engineer, Data Science ( Kubernetes/ Docker ) Remote USA","$72K-$141K
(Glassdoor est.)","If you dream of a job working in a field where all the hard problems are solved and you get to re-use previous research to get your job done, you need not apply. If, however, you are someone who wants to tackle problems that truly are on the cutting edge, then we encourage you to keep reading.

Data Science is an emerging field within cyber security. FireEye, given its deep expertise and comprehensive view on the advanced threat landscape, is uniquely positioned to enable data scientists to have major impact within our industry, company, and across our customer base. Detecting security breaches using machine learning and data analytics is an unsolved problem (this is not handwriting recognition folks) and has huge potential.

If you are someone who wants to be on the cutting edge of a high profile industry, who wants to make an impact by pushing both fields of data science and cyber security forward, you may be the perfect candidate to help us on our mission.

What you will do:
Develop, and manage data systems to ingest and process data at massive scale
Identify data sources both internally and externally that we can use to find evil.
Contribute towards the architecture and design of software solutions for long-term storage and retrieval.
Identify and implement data exploration technologies. Create dashboards and implement analytical tools for exploration
Work with data scientists to productize ML models and assist product teams with ML model releases into end products.
Collect requirements, design, and build backend components and tools to run ML models, assess ML model efficacy, manage large scale datasets, and generate features for ML models
Contribute to the evolution of coding and design practices within the organization.
Review code base commits and contribute to the growth of team members.
Requirements
Ability to work in an iterative, agile development environment.
Experience implementing ETL processes and building data pipelines
Experience developing reliable distributed systems.
Experience in Data modeling and schema design
Strong knowledge of a variety of operating systems, networking fundamentals, software design and programming best practices.
Experience with use of a wide array of algorithms and data structures.
Deep understanding and experience of going through the entire life cycle of building software platforms and products
Deep knowledge of various AWS services and associated tools
Strong experience developing in Python 3
Experience developing in at least 1 of the following: C, Go or Java
Experience with RDBMS, such as PostgreSQL or MySQL, as well as NoSQL
Experience with Kubernetes and Docker.
Experience deploying products in AWS
Additional Qualification: *
Ability to pick up, work with and explore new analytical tools
Strong experience with DevOps practices and common tooling
Strong communication skills.
Ability to work with loosely defined requirements.
At FireEye we are committed to our #OneTeam approach combining diversity, collaboration, and excellence. All qualified applicants will receive consideration for employment without regard to race, sex, color, religion, sexual orientation, gender identity, national origin, protected veteran status, or on the basis of disability. Requests for accommodation due to disability can be sent directly to .",3.3,"FireEye Inc
3.3","Denver, CO","Milpitas, CA",1001 to 5000 employees,2004,Company - Public,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,"Palo Alto Networks, Tanium"
"Senior SW Engineer, Data Science","$72K-$141K
(Glassdoor est.)","Job Description

If you dream of a job working in a field where all the hard problems are solved and you get to re-use previous research to get your job done, you need not apply. If, however, you are someone who wants to tackle problems that truly are on the cutting edge, then we encourage you to keep reading.

Data Science is an emerging field within cyber security. FireEye, given its deep expertise and comprehensive view on the advanced threat landscape, is uniquely positioned to enable data scientists to have major impact within our industry, company, and across our customer base. Detecting security breaches using machine learning and data analytics is an unsolved problem (this is not handwriting recognition folks) and has huge potential.

If you are someone who wants to be on the cutting edge of a high profile industry, who wants to make an impact by pushing both fields of data science and cyber security forward, you may be the perfect candidate to help us on our mission.

What you will do:
Develop, and manage data systems to ingest and process data at massive scale
Identify data sources both internally and externally that we can use to find evil.
Contribute towards the architecture and design of software solutions for long-term storage and retrieval.
Identify and implement data exploration technologies. Create dashboards and implement analytical tools for exploration
Work with data scientists to productize ML models and assist product teams with ML model releases into end products.
Collect requirements, design, and build backend components and tools to run ML models, assess ML model efficacy, manage large scale datasets, and generate features for ML models
Contribute to the evolution of coding and design practices within the organization.
Review code base commits and contribute to the growth of team members.",3.3,"FireEye Inc
3.3","Denver, CO","Milpitas, CA",1001 to 5000 employees,2004,Company - Public,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,"Palo Alto Networks, Tanium"
"Senior Machine Learning Engineer, Early Stage Pipeline, X",-1,"Senior Machine Learning Engineer, Early Stage Pipeline, X

Software Engineering

Mountain View, CA

We're an early stage team at X with a growing, interdisciplinary portfolio. To prove our path to the moon, we make early contact with the real world through both internal and external partnerships.

In this role, you will be responsible for taking early stage investigations from an idea stage to first prototypes to a full-blown projects. You'll be rapidly iterating through a set of prototypes to evaluate possible product directions. This is an extremely dynamic role and requires high cross-functional communication, organization, and planning. The ideal candidate is a self-starter and has a track record of effectively operating in a dynamic loosely structured environment (e.g. startup, new products within a larger company). The candidate will work on multiple projects/investigations.

Responsibilities:
Identify and implement a set of machine learning prototypes to aggressively de-risk projects building the whole solution: data acquisition, data processing pipelines, ML modeling.
Setup technical direction for investigations/projects working with the early stage leadership team.
Team lead investigations that grow to become projects.
Qualifications:
Hands-on experience with machine learning, one or more of; natural language processing (semantic understanding, sentiment analysis), computer vision, time series analysis.
Experience with building robust data pipelines.
Tech Lead experience.
Startup or early-stage product development experience.
Preferred Qualifications:
Experience with the Google Cloud Platform
About X, the Moonshot Factory

X creates radical new technologies to solve some of the world's biggest problems. We develop uncomfortably ambitious, potentially world-changing new ideas such as self-driving cars, balloon-powered Internet and smart contact lenses. We're a team of makers, entrepreneurs, engineers, designers and scientists with deep technical expertise who love the challenge of the seemingly impossible. We believe that a culture of psychological safety creates the foundation of trust and respect necessary to build moonshots. X was formerly known as Google[x] and is part of Alphabet .

At X, we don't just accept difference - we celebrate it, we support it, and we thrive on it for the benefit of our employees, our products and our community. We are proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements.

If you have a disability or special need that requires accommodation, please contact us at: (see application details) .",-1,"X, the moonshot factory","Mountain View, CA",-1,-1,-1,-1,-1,-1,-1,-1
"Senior/Staff Software Engineer, Data Infrastructure","$116K-$227K
(Glassdoor est.)","Senior/Staff Software Engineer, Data Infrastructure job posting

Every year, while Americans wait for their paychecks, more than $1 trillion of their hard-earned money is held up in the pay cycle. As a result, we accumulate over $50 billion in late and overdraft fees and turn to high-interest loans. Overdraft charges and bank fees often trap people in a cycle of debt that can lead to unhealthy decisions and falling victim to predatory businesses disguised as helpful services. We don't accept that.

Earnin is an app that creates products that help people gain control of their finances. Cash Out lets people get paid as soon as they leave work, with no fees, interest, or hidden costs. With Health Aid, Earnin negotiates on behalf of community members to lower their total unpaid medical bill and work out a budget-friendly payment plan. Cash Back Rewards is a way for members to earn up to 10% cash back on purchases from over a thousand local and national businesses without needing a credit card or having to reach spend thresholds to earn cash rewards — and they can withdraw the money at any time. We also offer free tools to help avoid overdrafts, to remind people when recurring bills are due, and we're working on more! There is never any required cost to use any of these products or services, users can choose to tip what they think is fair to support the service and pay it forward to keep the movement going.

Earnin is supported by funding partners including Andreessen Horowitz, Matrix Partners, Ribbit Capital, Felicis Venture, Thrive Capital, and others. Join us and help build a new financial system focused on fairness and people's needs.

You can help make a difference.

About the Team:

We are a data driven mobile financial tech company. The Data Infrastructure team builds the data services and data infrastructure that powers data science, analytics, and product development throughout Earnin. We are looking for a product-minded, self-driven Senior Software Engineer to own multiple large-scale projects that advance our mission of enabling people to gain access to their paycheck on demand.

What sets us apart:
High impact roles at a relatively small company that's aggressively growing our user base.
We are a collaborative team and genuinely enjoy working with each other.
We believe in empowering our people to be successful.
We're building a product that inspires fairness across the financial world and helps people not get taken advantage of.
As a Senior Engineer you will:
Break down complex problems into their bare essentials, translate this complexity into elegant design and create high quality, maintainable code.
Build massively scalable, production-grade data services.
Champion data quality and governance throughout the organization.
Build a world class data lake and data warehouse.
Design and develop new systems and tools to enable all of Earnin to consume and understand data faster.
Own the end to end design, build, and maintenance of platform services, data pipelines, and data products.
Implement comprehensive monitoring, logging, and alerting across our data infrastructure.
Work cross functionally with other teams (data science, design, product, marketing, and analytics) in high visibility roles as an engineering leader.
Build and deploy the data architecture that supports machine learning model development and actionable analytics.
Work with product engineering and data science teams to design scalable, performance model deployment architectures.
Communicate the tradeoffs of technical decisions to multiple stakeholders, including non-technical audiences.
Collaborate with and mentor other engineers and provide engineering direction to data scientists and analysts.
Actively engage and drive design reviews and code reviews.
Some skills we consider critical to being a Senior Engineer:
BS or MS degree in Computer Science, Engineering, or a related technical field.
8+ years of development experience in a fast-paced environment, especially startups.
5+ years of experience working with data systems.
Strong Python and SQL skills.
Strong programming and architecture skills.
Excellent written and verbal communication skills, including the ability to identify and communicate data driven insight.
Taking pride in your code quality and helping others elevate their own code quality.
Substantial experience with testing, data validation, and data quality assurance.
You can articulate the tradeoffs of different deployment architectures (e.g. streaming vs. batch vs. service-based).
Experience designing data platforms and services on cloud infrastructure, preferably AWS.
Hands-on experience designing and building large-scale solutions with the Hadoop stack and/or Spark.
Experience tuning and optimizing Spark-based applications.
Experience deploying and/or using query engines like AWS Athena, Presto, and Impala.
Experience with AWS analytical services like Redshift.
Hands-on experience working with a varied set of data storage technologies (e.g. Mysql, Postgres, DynamoDB, S3, etc.). You know where and when to use each.
Extensive experience with data modeling for multiple use cases and application styles, including NoSQL data modeling.
Experience working with data formats such as Avro and Parquet.
Experience working with alerting and monitoring tools like DataDog and PagerDuty.
Nice to haves:
You have experience building and deploying machine learning models.
You have experience using Terraform.
You have substantial experience working at a startup.
You have experience with data modeling in Redshift.
Experience with streaming infrastructure like Kafka.
Experience working with Kubernetes.
Experience building and deploying AWS Lambda applications.",3.1,"Earnin
3.1","Palo Alto, CA","Palo Alto, CA",201 to 500 employees,2012,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Engineer (open level),"$43K-$69K
(Glassdoor est.)","Title
Data Engineer (open level)

07/08/2020

What you'll do...
At H&R Block, your contributions will go far beyond any job description. When you join our team, you'll add to the momentum of a forward-thinking company - one that defined an industry and is now leading its transformation.

H&R Block is transforming tax preparation through data to ensure that every client we serve gets the best tax outcome possible.

We are building a new Data Engineering Team in the Data Science & Analytics organization. This new team will own the technology and data capabilities of the end-to-end data-and-analytics function. It will take responsibility for building and maintaining the analytical technologies that the data science teams use, managing data at an enterprise scale, leveraging relationships with IT teams throughout the enterprise, and leading information architecture.

We are looking for talented, curious, and creative data engineers of all levels to help launch this team. You will be a good match for our organization if you are:
Motivated by the idea of building something innovative, transformative, and impactful.
Committed to the idea that data can drive experiences and products that wow our business partners and clients
Obsessed with defying expectations and raising the bar
Driven by an innate sense of ownership for the products you create.
Day to day, you'll...
Design and deploy architecture, solutions, and software to capture, manage, store, and use structured and unstructured data from internal and external sources in both on-prem and cloud environments.
Deploy machine-learning models and other data-science products across the enterprise.
Navigate the balance between business needs, data governance best practices, and technical requirements.
Select or develop tools to cleanse, organize, and transform data and to maintain, defend, and update data structures and integrity on an automated basis.
Develop data products to facilitate self-service capabilities and assist the data teams to increase their efficiency and effectiveness.
Collaborate and communicate effectively within cross-functional teams that span internal Data Science & Analytics teams, IT, business groups, and executive stakeholders.
Be a positive force to cultivate a culture that is passionate about developing data tools as a business driver.
Job ID
368348BR

Address1
ONE H&R BLOCK WAY

City
KANSAS CITY

State
Missouri

Employee Type
Regular

What you'll bring to the team...
Education / work experience should include most of these, depending on level:
Bachelor’s degree in Computer Science or a related technical field (or equivalent work experience and technical skills)
Data warehousing and ETL solutions
APIs in a microservices architecture
Big-data technologies and the Hadoop stack (MapReduce, Hive, Pig, Hbase
NoSQL implementations (MongoDB)
Developing Java-based software solution
At least one scripting language (Python, Perl, JavaScript, Shell
Developing software solutions to solve complex business problems
Working with data scientists and other data users
Posting Title
Data Engineer (open level)

Sponsored Job
#hrbjob

Job Family
Corporate Analytics",3.6,"H&R Block
3.6","Kansas City, MO","Kansas City, MO",10000+ employees,1955,Company - Public,Other Retail Stores,Retail,$2 to $5 billion (USD),"Intuit, Jackson Hewitt, Liberty Tax Service"
Senior Modeling & Simulation Engineer,-1,"Applied Research Associates, Inc. is looking for a Senior Modeling and Simulation Engineer to join our multi-disciplinary team of engineers and scientists in the Capital Area Division, located in Alexandria, VA. The ideal candidate has a passion for predicting the behavior of physical systems in challenging environments and operational impact on mission success. Models will be developed, used, and improved to support a Department of Homeland Security customer to safeguard the nation’s borders and interior from chemical, biological, radiological, nuclear, and explosive materials, equipment, technologies, and their actors. Models may be based on the underlying physics or may be process or agent based to predict operational performance and impact. Modeling and analysis may require the use and development of 3D virtual worlds or geospatial data. Models will be verified and validated, and they will be used in support of test and evaluation activities of systems intended to detect and identify threats. The candidate may participate in test and evaluation activities to support the verification, validation, and overall improvement of models. Models may become part of larger, integrated modeling and simulation activities, and may require the use of high performance computing technologies and federated simulations.

This position is contingent upon award of a contract expected in Summer 2020 supporting the Department of Homeland Security.

Required Qualifications:
Ability to program in a high level programming language, such as Fortran, C++, or Java
Eagerness to learn new tools and techniques
Strong verbal and written communication skills
Must be a U.S. Citizen with the ability to obtain and maintain a security clearance
Bachelor’s degree with minimum of 10 years of experience or greater in a physical science (physics, chemistry, biology), engineering-related discipline (nuclear, chemical, civil, mechanical, electrical), or modeling& simulation disciple (computer modeling, computational science, operations research)
Ability to present to senior leadership on the status and issues associated with research or test efforts in preparation for acquisition decision meetings
Desired Experience and Qualifications:
Experience modeling CBRNE detectors or effects
Experience using multiple software tools such as MCNP, GadRas, SWORD, ExtendSim, Arena, SolidWorks, Fluent, ArcGIS, QGIS, VisIt, ParaView, or Cubit
Experience creating 3D models of systems, i.e., CAD
Experience using high performance computers (i.e., supercomputers)
Experience developing and using discrete event or agent based models and simulations to predict and assess system performance
Experience developing machine learning models
Background in a physical science or engineering discipline, such as Physics, Chemistry, Biology, Mechanical Engineering, Nuclear Engineering
Active DoD Secret or Top Secret clearance, DoE Q clearance, or DHS Suitability
COMPANY INFORMATION:

Applied Research Associates, Inc. is an employee-owned international research and engineering company recognized for providing technically superior solutions to complex and challenging problems in the physical sciences. The company, founded in Albuquerque, NM, in 1979, currently employs over 1200 professionals. ARA offices throughout the United States and Canada provide a broad range of technical expertise in defense technologies, civil technologies, computer software and simulation, systems analysis, environmental technologies, and testing and measurement. The corporation also provides sophisticated technical products for environmental site characterization, pavement analysis, and robotics.

At ARA, employees are our greatest assets. The corporation realizes that employee ownership spawns greater creativity and initiative along with higher performance and customer satisfaction levels. ARA gives its employees the tools, training, and opportunities to take more active roles as owners. The culture is challenging; innovation and experimentation are the norm. Employees are eligible for contributions which not only add to the company’s success, but also their own through the Employee Stock Ownership Plan (ESOP). The motto,“Engineering and Science for Fun and Profit” sums up the ARA experience. For additional information and an opportunity to join this unique workplace, please visit our website atwww.ara.com.",3.5,"Applied Research Associates
3.5","Alexandria, VA","Albuquerque, NM",1001 to 5000 employees,1979,Company - Private,Federal Agencies,Government,$100 to $500 million (USD),-1
Senior Data Engineer,-1,"This is a Data Engineer position for supporting a Navy program located in Quantico, Virginia.

We are seeking a Data Engineer to join our team of committed technical professionals to protect those who serve against criminal, terrorism and emerging threats. Are you passionate about analytics and innovation? Our employees enjoy a fast-paced, collaborative culture and the ability to directly impact our business. You will identify technical issues and opportunities for efficiency and provide technical insights through system design and configuration perspectives. This role is both challenging and rewarding.

You will support the mission through the implementation of a modern, integrated internal data infrastructure with a focus primarily on exploiting the established data foundation to make internal and customer-centric business processes as effective and efficient as possible, laying the foundation for cognitive capabilities that can sense and respond to both internal and external customer data needs. The candidate will also focus on expanding the organization’s data ecosystem to include context-rich data while maintaining the agility needed to spark innovation.

How you will make a difference:
Establish shared operational data and integrated enterprise data, all while managing and/or improving data quality and security through the creation of business-driven governance structures and culture change management.
Establish data policies, standards, and procedures that improve data quality, availability, accessibility, security, usability, and enforcement of enterprise information management (EIM) program requirements.
Establish enterprise standards – including a uniform and repeatable system development lifecycle methodology for Reference Data and Master Data (e.g., a common set of standards for data naming, abbreviations, and acronyms).
Develop a Master Data Management (MDM) Plan that focuses on the technology, tools, and processes ensuring master data is coordinated across the enterprise. MDM is a method used to define and manage the critical data of an organization to provide, with data integration, a single point of reference. The data that is mastered may include reference data – the set of permissible values, and the analytical data supporting decision making. MDM provides a unified master data service intended to provide accurate, consistent and complete master data across the enterprise and to business partners.
Recommend solutions based on performing industry-specific analysis, such as case studies describing data management best practices, identifying trends across the industry.
Make recommendations to improve the efficiency and effectiveness in how the agency acquires, stores, manages, shares and applies its data.
Engage business users and stakeholders for the increased release of actionable high-quality data on key operational and tactical activities at NCIS.
Develop technology solutions to provide the platform, training, and standardized tools enabling querying, data mining, statistical analysis, reporting, scenario modeling, data visualization, and dash-boarding, and processes for a centralized, or analytics as a service model, allowing for the sharing of data across the enterprise from a common hub, facilitates cross-organizational data initiatives due to its enterprise-wide view of data assets and needs.
Basic Qualifications
Required: A bachelor’s or master’s degree in computer science, data science, operations research, statistics, applied mathematics, or a related quantitative field [or equivalent work experience such as, economics, engineering and physics] is [preferred/required]. Alternate experience and education in equivalent areas such as economics, engineering or physics, is acceptable. Experience in more than one area is strongly preferred.
Required: Three to six (midlevel) of relevant project experience in successfully launching, planning, and executing data science projects. Preferably in the domains of risk modelling and quality assessment.
Preferred: Specialization in text analytics, image recognition, graph analysis or other specialized ML techniques such as deep learning, etc.
Preferred: the candidates are adept in agile methodologies and well-versed in applying DevOps/MLOps methods to the construction of ML and data science pipelines.
Coding knowledge and experience in several languages: for example, R, Python, Java, C++, Excel, MATLAB, etc.
Experience with popular database programming languages including SQL, PL/SQL, others for relational databases and upcoming non-relational databases such as NoSQL/Hadoop-oriented databases such as MongoDB, Cassandra, others.
Preferred: Specialized/operational data scientists may need further high-performance computing (HPC)/compute skills; larger data science teams, in particular, may require further degrees of specialization such as:
Experience with distributed data/computing tools such as MapReduce, Hadoop, Hive, Kafka, and MySQL
Experience of working across multiple deployment environments including cloud, on-premises and hybrid environments, multiple operating systems and through containerization techniques such as Docker, Kubernetes, AWS Elastic Container Service, and others.
Experience in one or more of the following commercial/open-source data discovery/analysis platforms: RStudio, Spark, KNIME, RapidMiner, Alteryx, Dataiku, H2O, SAS Enterprise Miner (SAS EM) and/or SAS Visual Data Mining and Machine Learning, Microsoft AzureML, IBM Watson Studio or SPSS Modeler, Amazon SageMaker, Google Cloud ML, SAP Predictive Analytics.
Preferred: Expertise in solving vision, text analytics, credit scoring, and failure prediction problems.
Knowledge and experience in statistical and data mining techniques such as generalized linear model (GLM)/regression, random forest, boosting, trees, text mining, hierarchical clustering, deep learning, convolutional neural network (CNN), recurrent neural network (RNN), T-distributed Stochastic Neighbor Embedding (t-SNE), graph analysis, etc.
Strong documentation skills. Required: Certifications as per Cybersecurity Workforce Management and Qualification Manual, SECNAV M-5239.2.
Required: Eligible AND adjudicated to the Top Secret (TS SCI) clearance level is required to start.
About Inventium.io:

Inventium.io LLC is a technical consulting and software development services company dedicated to protecting and advancing our national defense and scientific capabilities. Based out of the Washington DC area, we rely on innovation to continually advance our employees' skills and provide digital transformation solutions to our customers.

With proven records of successfully delivering quality services and solutions to multiple federal agencies, our technical competencies include Emerging Technology Solutions, DevSecOps, Cloud Migration, Machine Learning, System Modernization, and Technology Management.

Benefits and Perks
Employer paid Health Benefits (Medical, Dental and Vision)
Retirement Plan
Paid Time Off and Federal Holidays
Training and Development
Employee Referral Program
Awards and Recognition",5.0,"inventium.io LLC
5.0","Quantico, VA","Washington, DC",1 to 50 employees,2016,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Senior Software Engineer,-1,"At Pacific Biosciences, our R&D team is committed to developing innovative products that enable scientists to excel in a wide variety of life science research fields, including human biomedical, plant and animal sciences, and microbiology and infectious disease. Our unique Single Molecule, Real-Time (SMRT) sequencing platforms generate true high-quality long reads, giving researchers a more comprehensive view of genomes, transcriptomes, and epigenomes from any organism.

The Primary Analysis group, as part of the larger software engineering team at PacBio, develops algorithms and HPC solutions for decoding the raw data streams, generated through high-speed optical detection of the SMRT sequencing reactions, into DNA sequence reads. We operate at the intersection of cutting-edge nanotechnology and state-of-the-art bioinformatics tools, and our responsibilities span the full product development life cycle in an aggressive time-to-market environment. These include analysis and algorithm development in coordination with chemistry and systems R&D; the development of real-time analysis pipelines; and the development of validation and support infrastructure geared towards product system reliability and internal R&D support. We are seeking a talented algorithm engineer with a strong background in the physical or machine-learning/data sciences who also has a passion for designing and developing performance-critical data analysis solutions.

Responsibilities:

Design, develop, and test signal- and sequence-analysis algorithms that will drive fundamental improvements in basecalling accuracy and yield.
Work collaboratively in a team environment to solve challenging problems in software architecture and scalability of real-time analysis pipelines for our next-generation sequencing platforms.
All listed tasks and responsibilities are deemed as essential functions to this position; however, business conditions may require reasonable accommodations for additional tasks and responsibilities.

Key Skills and Background:

3+ years of experience shipping product software in a scientific or quantitative domain.
Demonstrated skills applying numerical methods, statistical signal processing, or machine-learning techniques to high-throughput, performance-critical analysis applications.
Linux-based systems programming experience with knowledge of OS, toolchain and hardware constraints.
Strong C++ programming experience in applications geared towards performance and scalability; previous experience in CUDA programming for GPU is a plus.
MS, PhD or equivalent experience in a quantitative field (physics, CS, etc.), preferably with an applied math or algorithmic focus.
Engineering instincts to efficiently investigate and solve the problem at hand, from prototype development (Python, R, MATLAB, etc.) to production designs.
Team player, with strong communication skills, and comfortable as a self-starter in an agile, fast-paced development environment.
All qualified applicants will receive consideration for employment without regard to race, sex, color, religion, national origin, protected veteran status, or on the basis of disability, gender identity, and sexual orientation.",3.7,"Pacific Biosciences
3.7","Menlo Park, CA","Menlo Park, CA",201 to 500 employees,2000,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,$50 to $100 million (USD),Illumina
Senior Data Engineer,-1,"ABOUT 605

At 605 we are engineers, analysts, data scientists, media experts, marketing strategists and political operatives. Our team of data scientists pioneered the field of TV data analytics. We offer unique, independent audience measurement and analytics to build better marketing and programming initiatives within the media and entertainment industries.

The Sr. Data Engineer at 605 must have a broad and deep data skillset as well as strong analytical capabilities . In addition to being a hands on individual contributor, the ideal candidate is a productive team player and a mentor to Junior. Data Engineers. Additionally, we are looking for strong technical experts.

Responsibilities include:
Actively participate in team technical discussions in all things data
Identify and address issues with data sets from multiple vendors
Identify and address code and data quality issues
Actively participate in code reviews and grooming sessions
Actively participate in technology architecture discussions for product development
Translate business requirements into strategy
Advocate for software best practices within your team as well as across engineering
Be ultra-responsive and capable of making instant decisions, always kicking the ball forward
Work on unique and interesting data challenges around architecting, building and managing pipelines that securely process hundreds of terabytes of data
Work closely with analysts and statisticians to ensure the validity of our processes
Our engineers are expected to wear a number of hats and have the opportunity to touch all parts of the stack. Our stack includes Apache Spark, Scala, Redshift and an ever-growing list of many other cool technologies.

Requirements
Skillful user of Apache Spark
Experience wrangling terabytes of big, complicated, imperfect data
Experience with AWS products (Redshift, EMR, S3, IAM, RDS, etc)
You have a deep understanding of scalable systems and you have large-scale engineering experience in an Agile development environment
Bachelor's degree in Computer Science or a related field (or 4 additional years of relevant work experience)
A strong understanding of data structures, algorithms, and effective software design
Significant development experience with a major modern language (e.g. Java, Scala, Python, Ruby, C/C++, etc.)
Significant experience working with structured and unstructured data at scale and comfort with a variety of different stores (key-value, document, columnar, etc.) as well as traditional RDBMSes and data warehouses
Experience with or interest in AWS Glue, Redshift Spectrum and any other tools that enable data querying at scale
Experience writing unit, functional and integration tests
Comfort with version control systems (e.g. Git, SVN)
Excellent verbal and written communication skills; must work well in an agile, collaborative team environment
Preferred Qualifications
Master's in Computer Science or a related field
Practical experience with supervised machine learning techniques
Strong background with test-driven development
Basic understanding of statistics and experience with statistical packages such as R, Matlab, SPSS, etc
Benefits

Important and Standard
Comprehensive health, dental and vision insurance for employees and their families
Life & Disability insurance
401k plan with match, eligible for match after one year
Pre-tax flexible compensation plan for medical, transit, parking or dependent care expenses
Up to 15 paid vacation days depending on grade level
7 paid sick days in a calendar year - if you’re sick, you stay home
Other cool benefits
4 work from home days/month
A kitchen stocked with sodas, snacks, yogurt and other goodies
A tight knit start up community who likes to eat! We celebrate everyone’s birthdays, have frequent team lunches, and do events in and out of the office
605 is an active participant in conferences
EEO STATEMENT

At 605, we’re just as passionate about diversity as we are about pioneering the field of TV data analytics. We are committed to cultivating an environment of mutual respect and equal opportunity. All hiring and advancement decisions are made on the basis of qualification, merit, and business need.",-1,605,"New York, NY",-1,-1,-1,-1,-1,-1,-1,-1
Sr Innovation Engineer,"$75K-$134K
(Glassdoor est.)","Company Information

Solid reputation, passionate people and endless opportunities. Thats Travelers. Our superior financial strength and consistent record of strong operating returns mean security for our customers and opportunities for our employees. You will find Travelers to be full of energy and a workplace in which you truly can make a difference.

Target Openings

1

Job Description Summary

Innovation is at the core of everything we do. We continue to ask ourselves, whats next? as we navigate the ever-changing insurance landscape. Continuing our customer journey toward the cutting-edge, we are looking for a forward-thinking individual that thrives in ambiguity, who believes that with every challenge comes a new opportunity for solutions.

As a member of the Innovation Technology team, you will partner with research scientists and product managers to discover, invent, and build solutions at scale. As a team, you will work on challenges in machine perception, data mining, machine learning, and natural language understanding.

We are looking for a hands-on individual with strong foundational knowledge highly scalable architectures and platforms. If you like using a variety of skills in technology and solving complex problems, work collaboratively in a small agile team environment, you might just be the person we need on our team!

Primary Job Duties & Responsibilities
Work closely with Cloud Engineering to build an innovation platform; a collection of reusable and extensible containers and tools specific to developing insurance products and platforms.
Recommend integration strategies, enterprise architectures, platforms and application infrastructure required to successfully implement a complete solution using best practices.
Produce quality output for highly visible IT products, services and future business development.
Assist in hands-on remediation of application stability and performance.
Adopt and communicate new concepts, ideas, techniques.
Manage multiple projects simultaneously.
Provide 'Shrink Wrap' solutions to solve business and technical needs. As part of our innovation process, be able to scale Minimum Viable Product to production systems.
Design and lead integration of analytic data products, including pilots and proof of concepts.
Frequently present and translate complex information in relevant business terms.
Constantly learn new skills within small teams.
No direct HR people management but will lead teams in project & program contexts.
Education, Work Experience, & Knowledge
Bachelors Degree in STEM (Science, Technology, Engineering, Mathematics) related field and 3+ years of experience or 10+ years of experience building highly scalable platforms and reusable components
Job Specific Technical Skills & Competencies
2+ years of experience working with Amazon Web Services (AWS) or equivalent cloud. Must be recent experience.
5+ years of designing and developing on-premise and cloud solutions.
3+ years of experience as a technical lead.
Experience in software engineering with relevant technologies (Java, JavaScript, Python etc.).
Experience with the application delivery process.
End-to-end experience with data, including querying, aggregation, analysis, and visualization.
Preferred Qualifications
AWS certified developer and/or architect
Proven ability to work creatively and analytically in a continuously evolving environment.
Exhibits high levels of learning agility in which they seek out and learn from unfamiliar experiences and then apply those lessons to succeed in the next new situation.
Ability to leverage business knowledge to determine approaches to execution.
Strong communication and presentation skills with the ability to present and translate complex information to leadership and non-technical teams in relevant business terms.
Uses effective listening skills and communication to build relationships across the organization.
Ability to Influence with experience working with matrixed staff to complete tasks in a timely manner.
Environmental / Work Schedules / Other
Travel Required
Equal Employment Opportunity Statement

Travelers is an equal opportunity employer.",4.1,"Travelers
4.1","Hartford, CT","Hartford, CT",10000+ employees,1853,Company - Public,Insurance Carriers,Insurance,$10+ billion (USD),-1
Senior AI Software Engineer,-1,"Company Overview

Calling the adventurers ready to join a company that's pushing the limits of nanotechnology to keep the digital revolution rolling. At KLA, we're making technology advancements that are bigger—and tinier—than the world has ever seen.

Who are we? We research, develop, and manufacture the world's most advanced inspection and measurement equipment for the semiconductor and nanoelectronics industries. We enable the digital age by pushing the boundaries of technology, creating tools capable of finding defects smaller than a wavelength of visible light. We create smarter processes so that technology leaders can manufacture high-performance chips—the kind in that phone in your pocket, the tablet on your desk and nearly every electronic device you own—faster and better. We're passionate about creating solutions that drive progress and help people do what wouldn't be possible without us. The future is calling. Will you answer?

Responsibilities

Group/Division
KLA has always had a close relationship with physics and data. Our optical and electron beam inspection and measurement tools use cutting edge physics models, both for hardware design and as part of their algorithms. AI, including several traditional machine learning techniques and deep learning are routinely used to process this data to meet application requirements.

The AI & Modeling Center of Excellence, centered in KLA’s R&D facility in Ann Arbor, MI, was setup with the mission of advancing KLA’s traditional strengths in physics and data and providing implementation solutions for multiple KLA Inspection and Metrology products targeted at the semiconductor manufacturing industry.

As a part of this group, you will be part of a world class team of physicists, HPC system designers, machine learning and application engineers who build cutting edge solutions for modeling complex imaging techniques and semiconductor processes. You will also work with a data scientists and AI infrastructure engineers whose mission is to build and scale machine learning based solutions for our semiconductor customers.

We are looking for engineers in a few different fields. If you are passionate about Physics Modeling, High Performance Computing - HPC (including GPU), ML, Data, or Cloud technologies – this is the place for you!

Responsibilities:
Software Engineers in the AI and Physics Modeling team may work on a variety of tasks including platform for large scale experimentation, scaleout of physics models, data management and inference solutions for KLA products.

Although familiarity with Machine Learning and Deep Learning solutions would be a big plus, this is primarily a Software Engineering position. Successful candidates are passionate about software, and will have exceptional skills and hands on experience with development in C/C++ and Python in a Unix environment. Deep conceptual understanding of multi threaded and multi process software systems is also necessary.

In addition to the above fundamental software skills, any of the following technical hands-on skills are highly desirable.

1) System Programming and Operating Systems.
2) Distributed systems for data management.
3) Distributed computing infrastructure.
4) Cloud technologies for storage, containerization and compute clusters.
5) Data Structures and algorithms
6) GPU architectures and data management.
7) Traditional machine learning using Random Forest, XG Boost, Logistic Regression.
8) Deep Learning for regression, classification. Generative models.
9) TensorFlow, NumPy, scikit-learn, and other ML and DL frameworks.
10) MPI and similar distributed computing framework.
11) GPU Architectures and CUDA (CuGraph, CuData, CuML etc).
12) GO Systems Programming, Java Programming.

Successful candidates for this position will also demonstrate the following non-technical skills.

1) Capability to formulate creative solutions through analyzing complex data
2) Good communication skills
3) Strong team player and motivated by team success
4) Strong problem solving skills

Minimum Qualifications

Doctorate (Academic) with at least 2 years of experience.
OR
Master's Level Degree with at least 4 years of experience.
OR
Bachelor's Level Degree with at least 5 years of experience.

Equal Employment Opportunity

KLA is an Equal Opportunity Employer. Applicants will be considered for employment without regard to age, race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability, or any other characteristics protected by applicable law.",3.8,"KLA-Tencor
3.8","Ann Arbor, MI","Milpitas, CA",5001 to 10000 employees,1976,Company - Public,Industrial Manufacturing,Manufacturing,$2 to $5 billion (USD),"Applied Materials, Nanometrics"
"Senior SDE, Catalog Big Data and Machine Learning",-1,"Amazon's Catalog DataWorks team is looking for highly motivated engineers. We are embarking on multiple new initiatives to re-organize Amazon's catalog of billions of products, in new and interesting views, that drive several features Amazon's customers love. Today, these views drive hundreds of popular features like product recommendations, clustering of similar products, and shopping with Alexa. We will build a new near real-time Catalog Data Lake on AWS, to enable engineers and scientists across Amazon to solve customer problems faster. Come join us on this exciting journey!

As an engineer on this team, you will own the Catalog Data Lake end-to-end. You will work closely with business partners to synthesize technical requirements. You will design and implement significant parts of the platform. You will learn and use industry standards like Spark and Parquet as well as modern AWS offerings like EMR, Glue, Athena, and Redshift. We are fortunate to be at the cusp of innovation in both the e-commerce business as well as cloud technology. As a key stakeholder, you will constantly learn new patterns, solve key customer problems and strive to make AWS better along the way.Basic Qualifications
Bachelor's degree or higher in computer science or math is required.
Strong computer science fundamentals - algorithms, data structures and design patterns.
At least 8 years of software development experience.
At least 3 years of experience building and operating Big Data systems.
Experience mentoring, guiding and influencing peers.
Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.",-1,Amazon Corporate LLC,"Seattle, WA",-1,-1,-1,-1,-1,-1,-1,-1
SENIOR SOFTWARE ENGINEER & SOFTWARE ARCHITECT,-1,"Job Description
Senior Software Engineer, Software Architect
JOB SUMMARY

The Senior Software Engineer, Software Architect will develop software for Company innovative semiconductor X-Ray inspection system. The Senior Software Engineer will collaborate with Applications, QA, and Algo teams for high performance solutions and optimization per customer issues. It will be important to be comfortable working in a small company environment and a typical startup with engineers and scientists.

ABOUT THE CLIENT

Based in San Jose, California, client was founded in 2013 expressly to bring high speed inspection and metrology technology to the semiconductor packaging industry. Client founders anticipated the need to deploy inline 100% transmissive inspection into the semiconductor packaging manufacturing process and developed the company’s technology with this end in mind. The results, Client’s HR-AXI technology suite brings together the company’s unique data acquisition architecture with proprietary machine learning analysis techniques to provide customers with process monitoring and defect detection capabilities not found on any other products in the market. This job description can be updated at any time.

RESPONSIBILITIES
Designs, develops, troubleshoots, and debugs software programs for enhancements and new products, focused on creating high quality and high-performance solutions while maintaining high-level coding standards.
Develops software and tools in support of design, infrastructure, and technology platforms. Develops software solutions by studying information needs, conferring with users, and studying systems flow, data usage, and work processes
Supports hardware compatibility and/or influences hardware design based on software needs; work as part of cross-functional team to solve and implement system level problems.
Monitor application stability, performance, and availability. Promptly resolve issues impacting operations.
Work with engineering, documentation, and applications departments to ensure successful development and delivery of overall product.
Provide appropriate project feedback to management in a timely and appropriate format.
QUALIFICATIONS AND REQUIRED SKILLS
Education requirement: Bachelor’s degree in Computer Science, Electrical Engineering, or similar technical field required. Master’s or PhD strongly preferred.
Experience requirement: Minimum of 8 years of related experience working in software development.
Strong expertise in C# .NET. WCF, WPF, Database development. In addition, Python experience a plus.
Experience with Image processing algorithms implementations is a plus
Experience with software development for Factory Automation for Semiconductor equipment, a plus.
Self-starter able to think and act independently to translate general objectives into tangible results, with a record of delivering successful designs on schedule.
Demonstrated ability to organize, manage, and complete multiple assignments with challenging timelines independently and effectively.
Demonstrated analytical and problem-solving skills with high attention to detail.
Proactive approach to problem-solving. Build relationships with stakeholders to support successful design, build and testing.
Strong verbal and written communication, good attitude, and work ethic. Ability to communicate technical concepts and results clearly.
Experience with Git and Azure DevOps, a plus.",3.0,"Simple Solutions
3.0","San Jose, CA","Morgantown, WV",1 to 50 employees,2006,Company - Private,IT Services,Information Technology,Less than $1 million (USD),-1
Cloud Engineer,-1,"Job Description
Responsibilities:
Develop and implement technical efforts to design, build, and deploy AWS applications at the direction of lead architects, including large scale data processing, computationally intensive statistical modeling, and advanced analytics
Participate in all aspects of the software development life cycle for AWS solutions, including planning, requirements, development, testing, and quality assurance
Provide guidance, thought leadership and mentorship to development teams to build cloud competencies
Provide innovative thought leadership around Mathematica’s cloud solutions strategy and approach, including AWS best practices and market trends
Position Requirements:

6+ years of experience architecting, designing, developing and implementing cloud solutions on AWS platforms
Demonstrated experience with designing and implementing solutions using AWS platform and tools, such as: EC2, S3, Redshift, API Gateway, Lambda, DynamoDB, CloudFormation, RDS, VPC, IAM and security, QuickSight, CloudTrail, Config, CloudWatch, SNS, AMI generation
Understanding of and experience with the five pillars of a well-architected framework
Knowledge of SQL, R, and Python for data manipulation and statistical analysis is desirable
Familiarity with federal security regulations and standards (e.g. HIPAA, FISMA, FIPS, NIST, and FedRAMP)
Experience with security, especially knowledge of FedRAMP, HIPAA, PII/PHI, is desirable
Experience in several of the following areas: database architecture, ETL, Business Intelligence, Big Data, Machine Learning, Advanced Analytics
Proven ability to work collaboratively with multi-disciplinary teams of business analysts, developers, data scientists, and subject matter experts
Strong written, verbal and interpersonal communication skills
AWS Certifications (such as AWS solutions architect or other specialty certifications) are a plus
Bachelor's degree or equivalent combination of education and experience; degree in computer science, mathematics or related field preferred
Experience with other cloud platforms like Google Cloud Platform (GCP) is a plus",4.8,"RICEFW Technologies Inc
4.8","Princeton, NJ","East Lansing, MI",51 to 200 employees,2009,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Senior Software Engineer / Team Lead,"$112K-$220K
(Glassdoor est.)","Join our team dedicated to developing and executing innovative solutions in support of customer mission success.

Job Description:

Novetta has an exciting opportunity for a self-motivated and accomplished Computer Scientist to lead our entity analytics team. You will work on complex projects involving data analysis, software engineering, and deploying software in a cloud computing environment. The team combines data from disparate sources to visualize the complex relationships between entities. This effort involves large scale data integration and entity resolution leveraging a best in class Novetta product. We are looking for a flexible problem solver with significant technical experience to lead a team providing unique solutions for our customers and stakeholders.

Responsibilities include:
Lead a technical team of software engineers and computer scientists, working within a larger ecosystem delivering an Enterprise capability.
Navigate customer and prime environment, manage resources within and across team, and assist team with professional and technical growth.
Deploy applications on a large-scale data processing cluster using AWS technologies.
Design and implement entity correlation strategies that are tailored to mission needs and unique data qualities.
Develop algorithms and visualization tools to help stakeholders understand their data and prioritize new data sources.
Develop and integrate applications to automate ingestion, processing and monitoring of data
Develop and maintain tools to support operations and maintenance of production and development computing clusters.
Basic Qualifications:
Experience leading a team of software engineers.
A Bachelor's degree in computer science or related field and a minimum of 5 years of experience; or a Master's degree in computer science or related field and a minimum of 3 years of experience.
Experience in software development/engineering including requirements analysis, software development, installation, integration, evaluation, enhancement, maintenance, testing and problem diagnosis/resolution.
Software development experience on Linux-based systems in Python or shell scripting or JavaScript.
Experience developing against full-featured REST APIs and using a command line interface
Desired Skills:

Should meet a minimum of 3:
Software development experience with JavaScript, Python, or other modern programming languages.
Hands-on experience with Spark.
Experience working with Databricks
Interest in statistical analysis, machine learning, or data science.
Experience with entity resolution products or a background in data matching theory and technologies.
Experience developing applications in AWS.
Security Clearance:
The candidate must have a TS/SCI with Poly.
Novetta, from complexity to clarity.

Novetta delivers highly scalable advanced analytics and secure technology solutions to address challenges of national and global significance. Focused on mission success, Novetta pioneers disruptive technologies in machine learning, data analytics, full-spectrum cyber, cloud engineering, open source analytics, and multi-INT fusion for Defense, Intelligence Community, and Federal Law Enforcement customers. Novetta is headquartered in McLean, VA with over 1,000 employees across the U.S.

Our culture is shaped by a commitment to our core values:

Integrity • We hold ourselves accountable to the highest standards of integrity and ethics.

Customer Success • We strive daily to exceed expectations and achieve customer mission success.

Employee Focus • We invest in our employees' professional development and training, respecting individuality and fostering a culture of diversity and inclusion.

Innovation • We know that discovering new and innovative ways to solve problems is critical to our success and makes us a great company.

Excellence in Execution • We take pride in flawless execution as we build a company that is best in class.

Earn a REFERRAL BONUS for the qualified people you know.

For more details, or to submit a referral: bit.ly/NovettaReferrals

Novetta is an equal opportunity/affirmative action employer.

All qualified applicants will receive consideration for employment without regard to sex, gender identity, sexual orientation, race, color, religion, national origin, disability, protected veteran status, age, or any other characteristic protected by law.",4.5,"Novetta
4.5","Chantilly, VA","Mc Lean, VA",501 to 1000 employees,2012,Company - Private,Enterprise Software & Network Solutions,Information Technology,$100 to $500 million (USD),"Leidos, CACI International, Booz Allen Hamilton"
Data Fusion Engineer with Security Clearance,"$48K-$109K
(Glassdoor est.)","Description Job Description: Looking for work-life balance? Leidos offers generous leave and accommodating flex-time to help you juggle your personal and professional life. Are you a Software Engineer with experience finding and aligning signals across multiple modalities (image, video, audio, lidar, etc..)? Do you want to implement and customize algorithms to fusion multiple data modalities? If so we are looking for you, our next Data Fusion Engineer to work in Arlington, VA. We need you to be competent in Python and have the ability to read code in other programming languages like Java and C++ as well as have experience working with ML libraries like SciKit Learn, TensorFlow, Keras along with experience implementing solutions with those libraries on both CPU and GPU compute architectures. Like what you are reading so far? Keep going. We want you to be intellectually adaptive, inquisitive, good at expressing your needs, and able to self-manage when necessary. Work alongside software/system engineers and research/data scientists with expertise in multi-modal information retrieval, UI development, computer vision, metrics, information science, artificial intelligence, and autonomous systems. The Department of Defense and the Intelligence Community will be the main recipients your hard work. Fun stuff you will do on the job: - Use cases requiring identifying entity/objects, determining object association, object disambiguation, anomaly detection, state estimations, etc.
Develop and maintain data models (both physical and logical)
Get to be responsible for extraction, transform, and load (ETL) tasks related to the different modalities and algorithms being applied. This data ETL includes identifying the data's relevant metadata to ensure consistency, quality, accuracy, integrity, and information assurance and security.
Performing anomaly detection using various AI/ML techniques
Use algorithms to identify complex patterns across multiple modalities
Increasing the efficiency and quality data alignment and fusion
Enhance and maintain analysis tools, including automation of current processes using AI/ML algorithms
Conduct quantitative data analysis including developing retrieval, processing, fusion, analysis, and visualization of various datasets Skills required to be successful in this role: - Bachelor's Degree in Aerospace Engineering, Computer Science, Mathematics, Statistics, Physics, Electrical Engineering, Computer Engineering or related fields with 5 years of relevant experience
Must be able to obtain and maintain a TS/SCI security clearance
Experience with Deep Learning Frameworks such as Keras, Tensorflow, PyTorch, Mxnet, etc. - Ability to apply these frameworks to real problems in the 'time -series' domain
Experience with interpretability of deep learning models
Big Data Skills (Azure, Hadoop, Spark, recent deep learning platforms)
Practical experience with statistical analysis
Experience with text mining tools and techniques including in areas of summarization, search (e.g. ELK Stack), entity extraction, training set generation (e.g. Snorkel) and anomaly detection
Expert software development skills lifecycle including developing and maintaining good production quality code
Hands-on Software Development Skills (Python-Preferred)
Experience or educational courses/projects in Machine Learning, and/or Text Mining Algorithms You will wow us even more if you have these skills: - Visualizations/Web Development Skills (e.g. Tableau, D3, etc).
Hands-on experience with prototype development
Hands-on experience with automating data cleansing, formatting, staging, and transforming data human
Hands-on experience applying data analytics
Hands-on experience with intelligent systems and machine learning LInC External Referral Bonus: Ineligible Potential for Telework: No Clearance Level Required: Top Secret/SCI Travel: Yes, 10% of the time Scheduled Weekly Hours: 40 Shift: Day Requisition Category: Professional Job Family: Software Engineering Leidos Leidos is a Fortune 500® information technology, engineering, and science solutions and services leader working to solve the world's toughest challenges in the defense, intelligence, homeland security, civil, and health markets. The company's 33,000 employees support vital missions for government and commercial customers. Headquartered in Reston, Virginia, Leidos reported annual revenues of approximately $10.19 billion for the fiscal year ended December 28, 2018. For more information, visit www.Leidos.com . Pay and Benefits Pay and benefits are fundamental to any career decision. That's why we craft compensation packages that reflect the importance of the work we do for our customers. Employment benefits include competitive compensation, Health and Wellness programs, Income Protection, Paid Leave and Retirement. More details are available here . Securing Your Data Leidos will never ask you to provide payment-related information at any part of the employment application process. And Leidos will communicate with you only through emails that are sent from a Leidos.com email address. If you receive an email purporting to be from Leidos that asks for payment-related information or any other personal information, please report the email to [email protected] . Commitment to Diversity All qualified applicants will receive consideration for employment without regard to sex, race, ethnicity, age, national origin, citizenship, religion, physical or mental disability, medical condition, genetic information, pregnancy, family structure, marital status, ancestry, domestic partner status, sexual orientation, gender identity or expression, veteran or military status, or any other basis prohibited by law. Leidos will also consider for employment qualified applicants with criminal histories consistent with relevant laws.",3.5,"Leidos
3.5","Arlington, VA","Reston, VA",10000+ employees,1969,Company - Public,Aerospace & Defense,Aerospace & Defense,$10+ billion (USD),-1
Software Engineer,"$64K-$132K
(Glassdoor est.)","Every Analyst a Scientist - One of our primary goals is to empower intelligence analysts to be able to study their data like scientists. The tools we develop focus on streamlining intelligence analysis through integrated algorithms and software that provide insight into the geopolitical landscape for use in operational intelligence missions around the world.

The Role:
As a Software Engineer, you will be part of a team that transforms large and complex customer data into real-world, high-impact solutions. You will work with researchers and engineers to design and implement solutions to challenging national security problems. You will be responsible for building the software infrastructure to clean, ingest, and expose datasets and algorithms to both developers and end users. You will deploy algorithms, generate workflows, create engineer-facing tools, and design customer-facing prototype systems. You will occasionally travel to customer sites to engage with end users, demonstrate prototypes, and integrate analytics into customer systems.

If you would like to help intelligence and defense analysts keep pace with technology-driven innovation, then this role is for you!

Who you are:
A U.S. Citizen with the ability to obtain a Security Clearance
A degree in a scientific or engineering field, such as Computer Science, Mathematics, Physics, or Software Engineering
Proficiency with a scientific programming language such as Python, Java, or C++
Experience with database management and common query syntax
Motivated collaborator and excellent communicator of ideas to both technical and non-technical audiences
Knowledge of AWS, Spark, Dask, and/or similar technologies for working with data at scale
Even better:
Active Security Clearance
Track record of architecting, developing, deploying, or maintaining enterprise software
Experience with software development best practices and tools
Understanding of web development and visualization technologies, such as d3, Leaflet, Bootstrap, or others
Familiarity with machine learning or statistical modeling techniques",4.5,"Systems & Technology Research
4.5","Woburn, MA","Woburn, MA",201 to 500 employees,2010,Company - Private,Aerospace & Defense,Aerospace & Defense,$100 to $500 million (USD),-1
Sr. Data Scientist,-1,"Background Information:

Innovative Defense Technologies (IDT), provider of automated software testing, data analysis, and cybersecurity solutions for complex defense systems, is currently accepting applications for an anticipated Sr. Data Scientist role requiring 7+ years of experience for a position in support of its efforts implementing Artificial Intelligence solutions for a variety of customers.

Overview:

The Sr. Data Scientist position offers an engineer the opportunity to utilize his/her knowledge and talents as part of a collaborative team developing AI solutions for a growing company. A few of the responsibilities include supporting feasibility studies, applying modern data storage techniques, discovering explanatory features in high-dimensionality collections of data, and exploring data using scientifically valid techniques to exploit patterns found in the data with state-of-the-art AI/ML/DL solutions.

All applicants must be able to obtain/maintain an active U.S. Security Clearance.

Responsibilities Include:
Lead development of solutions to deliver AI/ML/DL models from problem formulation to a productized, deployable, maintainable capability
Contribute to AI/ML/DL technical roadmap development
Use Deep Learning frameworks such as Tensorflow and Keras to build and validate ML/DL models
Establish and leverage Big Data frameworks to store, extract and analyze relevant data
Ensure development of software solutions meets customer needs and program intent
Work closely with the Program Manager and Chief Engineer to design and implement software requirements and solutions
Determine operational feasibility by evaluating analysis, problem definition, requirements, solution development, and proposed solutions for large, complex systems
Be responsible for a team’s products meeting software design, quality, and performance requirements
Pursue new technology development via the DoD Small Business Innovative Research (SBIR) program
Work with minimal supervision in a collaborative work environment to implement best-in-class solutions
Minimum Required Qualifications:
Bachelor’s Degree in Computer Science, Computer Engineering, Electrical Engineering, Systems Engineering, Physics, or Math Required; PhD in relevant field highly preferred
7+ years of experience in predictive modeling, data science and analysis
Required Skills:
Previous experience in a ML or data scientist role and a track record of building ML or DL models
Extensive experience working with data mining algorithms including decision trees, probability networks, association rules, clustering, and neural networks
Experience using Python (or equivalent)
Experience using ML libraries, such as scikit-learn,
Experience using data visualization tools
Experience handling terabyte size dataset
Experience working with GPUs to develop models
Ability to travel 10% or less
Preferred Skills:
Experience with MapReduce programming (Hadoop)
Skills with programming languages, such as Java or C/C++
Demonstrated ability to develop experimental and analytic plans for data modeling processes, use of strong baselines, ability to accurately determine cause and effect relations
Consulting experience and track record of helping customers with their AI needs
Publications or presentations in recognized Machine Learning, Deep Learning and Data Mining journals/conferences
Combination of deep technical skills and business savvy enough to interface with all levels and disciplines within our customer’s organization
Experience diving into data to discover hidden patterns
Experience with application container platforms
Familiarity with continuous integration/delivery tools (e.g. Jenkins)
Familiarity with version control tools (e.g. Subversion, Git, etc.)
Familiarity with VMware or other virtualization software
Experience developing applications for DOD command and control systems
Competencies:
Solid analytical abilities, coupled with a strong sense of ownership, urgency, and drive
Attention to detail
Initiative, creativity, reliability, teamwork
Ability to deal well with ambiguity, prioritize needs, and deliver results in a dynamic environment
EEO Statement:

IDT is an Equal Opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, creed, sex, sexual orientation, gender identity, national origin, disability, protected Veteran status, or any other basis protected by federal, state, or local law.",-1,Innovative Defense Technologies (IDT),"Mount Laurel, NJ",-1,-1,-1,-1,-1,-1,-1,-1
Full Stack Software Engineer (Python/Vue),-1,"Position Summary Full Stack Software Engineer (Python VueJS) Company Overview Our client is an automated underwriting platform for real estate professionals that was built to disrupt the commercial real estate industry. The software allows investors, brokers, and lenders to analyze rent, operating expenses and returns for multifamily properties by applying machine learning to a database of live multifamily transaction data from every U.S. market. Our client has a creative and entrepreneurial culture ndash everyone on the team interacts directly with customers each day, and we all contribute to the product and planning. If you have an idea to improve something, there is no red tapehellip just build what needs to be built! Innovation and passion for transforming the old-fashioned real estate industry are our highest priorities. Job Description As a full-stack (Python, PostgreSQL and HTMLCSSJavaScript) developer, you'll work on the interface and backend infrastructure of products and features used by hundreds of underwriters and real estate analysts every day. The work is challenging, fast-paced, and always changing. You must have demonstrated analytical skills, an unwavering commitment to quality, a collaborative work ethic, and cutting-edge coding skills. You must display solid proficiency in the fundamentals of Python, PostgreSQL, JavaScript, HTMLCSS, and popular front-end frameworks like Vue.js. The role will include the delivery of reliable, scalable new features to users, developed in Python, interacting with a PostgreSQL database and using the Vue.js frontend framework. You will work with the development team to develop, test and deliver finished, high quality, compelling features and products. Our team includes designers, engineers and data scientists who are passionate about quality, usability, and simplicity. If you are ready to join a company that fosters learning, growth, experimentation and innovation, our client's team is for you. Requirements Qualifications 3-5 years of experience in full stack Python development 1-3 years of experience with PostgreSQL 1-3 years of experience with JavaScript frameworks such as React, Angular or Vue.js (Vue.js is preferred, this is what our client uses), and CSS pre-processing frameworks (Sass or Less) 1-2 years of experience integrating with VBA and Excel integration preferred Experience using GitHub and solid understanding of software version control Familiarity with JIRA or equivalent product management software Familiarity with agile development best practices Driven self-starter able to work on a small team and take initiative on new tasks Familiarity with real estate or finance is a plus Responsibilities Collaborate with interdisciplinary team of data scientists, software engineers and real estate professionals Strive for high quality and rapid output utilizing agile development best practices Support, maintain, and document software functionality Maintain industry standard coding, compliance, security practices Proactively learn product frameworks and code base Our client is a startup company, and as such the responsibilities outlined above may change and evolve over time. Flexibility, curiosity, an entrepreneurial mindset, and strong work ethic are essential for this role. It is encouraged that everyone on the team continually research new technologies and analytical opportunities to improve the platform.",5.0,"CultureFit
5.0","Chicago, IL","Deerfield, IL",1 to 50 employees,1997,Company - Private,Advertising & Marketing,Business Services,$1 to $5 million (USD),-1
AWS Data Engineer,-1,"About Infinitive:

At Infinitive, we do mission-critical work for great companies. We specialize in digital marketing and digital advertising solutions, customer data & analytics, digital & business transformation, and Technology solutions. Our Technology solutions focus on Managed Cloud Services, Cloud Enablement, Digital Operations, Application Development, DevOps, Product Development, Cloud Security, Data Science and Analytics, AI/ML, IoT, and everything in between.

Our experts are results-obsessed, focused and flexible, highly engaged and hugely experienced having sat in our clients seats. Those qualities are what make us different than old-school consulting shops. And surely, they are why clients and partners describe us as the gold standard in client experience.

Infinitive has been named a Best Small Firms to Work For by Consulting Magazine seven times, a Washington Post Top Workplace three times, a Washington Business Journal Best

About this Role:

Infinitive is growing its team in the Northern Virginia area and is currently seeking an Data Scientist to join our growing Technology practice. This person will utilize their experience in analytics, IoT, machine learning, and artificial intelligence advances to create value from structured and unstructured data. The ideal candidate has experience designing novel data analytic methods and workflows, including full data pipelines from raw data through analysis results. They must also have exposure to a variety of data mining/data analysis methods, data tools, building and implementing models, using/creating algorithms, and creating/running simulations.

We are looking for candidates who are accountable, passionate, assertive, proactive, open & honest, results oriented, and adaptable. Each project engagement represents a new challenge that will give you exposure to new clients, business issues, technologies, and people and will involve a range of responsibilities to include:
Developing in Java, Python, R, or other high-level languages.
Managing disparate data sources with varying data structures of content and preparing these for data science and machine learning applications.
Working with distributed scalable Big Data storage, processing, and computation, including AWS EMR, Spark, etc.
Implementation knowledge of, or desire to learn AWS / Azure data science capabilities.
Developing solutions and integrating and extending free and Open-source software (FOSS) or COTS products.
Conduct MapReduce programming with Apache Hadoop, the Hadoop Distributed File System (HDFS), and processing large data stores.
Knowledge of SQL and query languages.
Utilize real-time, large-scale data processing engine, including Apache Spark.
Lead and create Data Science and Analytics methodologies and frameworks for implementation.
Ability to build and develop Data Science demonstrations for clients
Qualifications:
4+ years of development experience (Java, Python, R, SQL)
3+ years of experience with distributed scalable Big Data storage, including AWS EMR, Spark, etc.
Desire to become AWS / Azure Certified architect / engineer.
Experience performing data Management, modeling, and warehousing.
Hands on experience with Amazon analytic tools (preferred)
Interest in being involved internally and growing a small business (entrepreneurial spirit)
Ability to travel (up to 20%) and to work independently
Experience using Agile software development methods in a DevOps environment.
Excellent leadership, peer management, and communication skills
Management consulting experience (preferred)
Bachelor's degree in related field (preferred)
Applicants for employment in the U.S. must possess work authorization which does not require sponsorship by the employer for a visa.

Infinitive is an Equal Opportunity Employer.

Powered by JazzHR",3.4,"Infinitive Inc
3.4","Arlington, VA","Cedar Rapids, IA",201 to 500 employees,1997,Company - Private,Enterprise Software & Network Solutions,Information Technology,$10 to $25 million (USD),-1
"Senior SW Engineer, Data Science ( Kubernetes/ Docker ) Remote USA","$72K-$141K
(Glassdoor est.)","If you dream of a job working in a field where all the hard problems are solved and you get to re-use previous research to get your job done, you need not apply. If, however, you are someone who wants to tackle problems that truly are on the cutting edge, then we encourage you to keep reading.

Data Science is an emerging field within cyber security. FireEye, given its deep expertise and comprehensive view on the advanced threat landscape, is uniquely positioned to enable data scientists to have major impact within our industry, company, and across our customer base. Detecting security breaches using machine learning and data analytics is an unsolved problem (this is not handwriting recognition folks) and has huge potential.

If you are someone who wants to be on the cutting edge of a high profile industry, who wants to make an impact by pushing both fields of data science and cyber security forward, you may be the perfect candidate to help us on our mission.

What you will do:
Develop, and manage data systems to ingest and process data at massive scale
Identify data sources both internally and externally that we can use to find evil.
Contribute towards the architecture and design of software solutions for long-term storage and retrieval.
Identify and implement data exploration technologies. Create dashboards and implement analytical tools for exploration
Work with data scientists to productize ML models and assist product teams with ML model releases into end products.
Collect requirements, design, and build backend components and tools to run ML models, assess ML model efficacy, manage large scale datasets, and generate features for ML models
Contribute to the evolution of coding and design practices within the organization.
Review code base commits and contribute to the growth of team members.
Requirements
Ability to work in an iterative, agile development environment.
Experience implementing ETL processes and building data pipelines
Experience developing reliable distributed systems.
Experience in Data modeling and schema design
Strong knowledge of a variety of operating systems, networking fundamentals, software design and programming best practices.
Experience with use of a wide array of algorithms and data structures.
Deep understanding and experience of going through the entire life cycle of building software platforms and products
Deep knowledge of various AWS services and associated tools
Strong experience developing in Python 3
Experience developing in at least 1 of the following: C, Go or Java
Experience with RDBMS, such as PostgreSQL or MySQL, as well as NoSQL
Experience with Kubernetes and Docker.
Experience deploying products in AWS
Additional Qualification: *
Ability to pick up, work with and explore new analytical tools
Strong experience with DevOps practices and common tooling
Strong communication skills.
Ability to work with loosely defined requirements.
At FireEye we are committed to our #OneTeam approach combining diversity, collaboration, and excellence. All qualified applicants will receive consideration for employment without regard to race, sex, color, religion, sexual orientation, gender identity, national origin, protected veteran status, or on the basis of disability. Requests for accommodation due to disability can be sent directly to .",3.3,"FireEye Inc
3.3","Denver, CO","Milpitas, CA",1001 to 5000 employees,2004,Company - Public,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,"Palo Alto Networks, Tanium"
"Senior SW Engineer, Data Science","$72K-$141K
(Glassdoor est.)","Job Description

If you dream of a job working in a field where all the hard problems are solved and you get to re-use previous research to get your job done, you need not apply. If, however, you are someone who wants to tackle problems that truly are on the cutting edge, then we encourage you to keep reading.

Data Science is an emerging field within cyber security. FireEye, given its deep expertise and comprehensive view on the advanced threat landscape, is uniquely positioned to enable data scientists to have major impact within our industry, company, and across our customer base. Detecting security breaches using machine learning and data analytics is an unsolved problem (this is not handwriting recognition folks) and has huge potential.

If you are someone who wants to be on the cutting edge of a high profile industry, who wants to make an impact by pushing both fields of data science and cyber security forward, you may be the perfect candidate to help us on our mission.

What you will do:
Develop, and manage data systems to ingest and process data at massive scale
Identify data sources both internally and externally that we can use to find evil.
Contribute towards the architecture and design of software solutions for long-term storage and retrieval.
Identify and implement data exploration technologies. Create dashboards and implement analytical tools for exploration
Work with data scientists to productize ML models and assist product teams with ML model releases into end products.
Collect requirements, design, and build backend components and tools to run ML models, assess ML model efficacy, manage large scale datasets, and generate features for ML models
Contribute to the evolution of coding and design practices within the organization.
Review code base commits and contribute to the growth of team members.",3.3,"FireEye Inc
3.3","Denver, CO","Milpitas, CA",1001 to 5000 employees,2004,Company - Public,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,"Palo Alto Networks, Tanium"
"Senior Machine Learning Engineer, Early Stage Pipeline, X",-1,"Senior Machine Learning Engineer, Early Stage Pipeline, X

Software Engineering

Mountain View, CA

We're an early stage team at X with a growing, interdisciplinary portfolio. To prove our path to the moon, we make early contact with the real world through both internal and external partnerships.

In this role, you will be responsible for taking early stage investigations from an idea stage to first prototypes to a full-blown projects. You'll be rapidly iterating through a set of prototypes to evaluate possible product directions. This is an extremely dynamic role and requires high cross-functional communication, organization, and planning. The ideal candidate is a self-starter and has a track record of effectively operating in a dynamic loosely structured environment (e.g. startup, new products within a larger company). The candidate will work on multiple projects/investigations.

Responsibilities:
Identify and implement a set of machine learning prototypes to aggressively de-risk projects building the whole solution: data acquisition, data processing pipelines, ML modeling.
Setup technical direction for investigations/projects working with the early stage leadership team.
Team lead investigations that grow to become projects.
Qualifications:
Hands-on experience with machine learning, one or more of; natural language processing (semantic understanding, sentiment analysis), computer vision, time series analysis.
Experience with building robust data pipelines.
Tech Lead experience.
Startup or early-stage product development experience.
Preferred Qualifications:
Experience with the Google Cloud Platform
About X, the Moonshot Factory

X creates radical new technologies to solve some of the world's biggest problems. We develop uncomfortably ambitious, potentially world-changing new ideas such as self-driving cars, balloon-powered Internet and smart contact lenses. We're a team of makers, entrepreneurs, engineers, designers and scientists with deep technical expertise who love the challenge of the seemingly impossible. We believe that a culture of psychological safety creates the foundation of trust and respect necessary to build moonshots. X was formerly known as Google[x] and is part of Alphabet .

At X, we don't just accept difference - we celebrate it, we support it, and we thrive on it for the benefit of our employees, our products and our community. We are proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements.

If you have a disability or special need that requires accommodation, please contact us at: (see application details) .",-1,"X, the moonshot factory","Mountain View, CA",-1,-1,-1,-1,-1,-1,-1,-1
"Senior/Staff Software Engineer, Data Infrastructure","$116K-$227K
(Glassdoor est.)","Senior/Staff Software Engineer, Data Infrastructure job posting

Every year, while Americans wait for their paychecks, more than $1 trillion of their hard-earned money is held up in the pay cycle. As a result, we accumulate over $50 billion in late and overdraft fees and turn to high-interest loans. Overdraft charges and bank fees often trap people in a cycle of debt that can lead to unhealthy decisions and falling victim to predatory businesses disguised as helpful services. We don't accept that.

Earnin is an app that creates products that help people gain control of their finances. Cash Out lets people get paid as soon as they leave work, with no fees, interest, or hidden costs. With Health Aid, Earnin negotiates on behalf of community members to lower their total unpaid medical bill and work out a budget-friendly payment plan. Cash Back Rewards is a way for members to earn up to 10% cash back on purchases from over a thousand local and national businesses without needing a credit card or having to reach spend thresholds to earn cash rewards — and they can withdraw the money at any time. We also offer free tools to help avoid overdrafts, to remind people when recurring bills are due, and we're working on more! There is never any required cost to use any of these products or services, users can choose to tip what they think is fair to support the service and pay it forward to keep the movement going.

Earnin is supported by funding partners including Andreessen Horowitz, Matrix Partners, Ribbit Capital, Felicis Venture, Thrive Capital, and others. Join us and help build a new financial system focused on fairness and people's needs.

You can help make a difference.

About the Team:

We are a data driven mobile financial tech company. The Data Infrastructure team builds the data services and data infrastructure that powers data science, analytics, and product development throughout Earnin. We are looking for a product-minded, self-driven Senior Software Engineer to own multiple large-scale projects that advance our mission of enabling people to gain access to their paycheck on demand.

What sets us apart:
High impact roles at a relatively small company that's aggressively growing our user base.
We are a collaborative team and genuinely enjoy working with each other.
We believe in empowering our people to be successful.
We're building a product that inspires fairness across the financial world and helps people not get taken advantage of.
As a Senior Engineer you will:
Break down complex problems into their bare essentials, translate this complexity into elegant design and create high quality, maintainable code.
Build massively scalable, production-grade data services.
Champion data quality and governance throughout the organization.
Build a world class data lake and data warehouse.
Design and develop new systems and tools to enable all of Earnin to consume and understand data faster.
Own the end to end design, build, and maintenance of platform services, data pipelines, and data products.
Implement comprehensive monitoring, logging, and alerting across our data infrastructure.
Work cross functionally with other teams (data science, design, product, marketing, and analytics) in high visibility roles as an engineering leader.
Build and deploy the data architecture that supports machine learning model development and actionable analytics.
Work with product engineering and data science teams to design scalable, performance model deployment architectures.
Communicate the tradeoffs of technical decisions to multiple stakeholders, including non-technical audiences.
Collaborate with and mentor other engineers and provide engineering direction to data scientists and analysts.
Actively engage and drive design reviews and code reviews.
Some skills we consider critical to being a Senior Engineer:
BS or MS degree in Computer Science, Engineering, or a related technical field.
8+ years of development experience in a fast-paced environment, especially startups.
5+ years of experience working with data systems.
Strong Python and SQL skills.
Strong programming and architecture skills.
Excellent written and verbal communication skills, including the ability to identify and communicate data driven insight.
Taking pride in your code quality and helping others elevate their own code quality.
Substantial experience with testing, data validation, and data quality assurance.
You can articulate the tradeoffs of different deployment architectures (e.g. streaming vs. batch vs. service-based).
Experience designing data platforms and services on cloud infrastructure, preferably AWS.
Hands-on experience designing and building large-scale solutions with the Hadoop stack and/or Spark.
Experience tuning and optimizing Spark-based applications.
Experience deploying and/or using query engines like AWS Athena, Presto, and Impala.
Experience with AWS analytical services like Redshift.
Hands-on experience working with a varied set of data storage technologies (e.g. Mysql, Postgres, DynamoDB, S3, etc.). You know where and when to use each.
Extensive experience with data modeling for multiple use cases and application styles, including NoSQL data modeling.
Experience working with data formats such as Avro and Parquet.
Experience working with alerting and monitoring tools like DataDog and PagerDuty.
Nice to haves:
You have experience building and deploying machine learning models.
You have experience using Terraform.
You have substantial experience working at a startup.
You have experience with data modeling in Redshift.
Experience with streaming infrastructure like Kafka.
Experience working with Kubernetes.
Experience building and deploying AWS Lambda applications.",3.1,"Earnin
3.1","Palo Alto, CA","Palo Alto, CA",201 to 500 employees,2012,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Engineer (open level),"$43K-$69K
(Glassdoor est.)","Title
Data Engineer (open level)

07/08/2020

What you'll do...
At H&R Block, your contributions will go far beyond any job description. When you join our team, you'll add to the momentum of a forward-thinking company - one that defined an industry and is now leading its transformation.

H&R Block is transforming tax preparation through data to ensure that every client we serve gets the best tax outcome possible.

We are building a new Data Engineering Team in the Data Science & Analytics organization. This new team will own the technology and data capabilities of the end-to-end data-and-analytics function. It will take responsibility for building and maintaining the analytical technologies that the data science teams use, managing data at an enterprise scale, leveraging relationships with IT teams throughout the enterprise, and leading information architecture.

We are looking for talented, curious, and creative data engineers of all levels to help launch this team. You will be a good match for our organization if you are:
Motivated by the idea of building something innovative, transformative, and impactful.
Committed to the idea that data can drive experiences and products that wow our business partners and clients
Obsessed with defying expectations and raising the bar
Driven by an innate sense of ownership for the products you create.
Day to day, you'll...
Design and deploy architecture, solutions, and software to capture, manage, store, and use structured and unstructured data from internal and external sources in both on-prem and cloud environments.
Deploy machine-learning models and other data-science products across the enterprise.
Navigate the balance between business needs, data governance best practices, and technical requirements.
Select or develop tools to cleanse, organize, and transform data and to maintain, defend, and update data structures and integrity on an automated basis.
Develop data products to facilitate self-service capabilities and assist the data teams to increase their efficiency and effectiveness.
Collaborate and communicate effectively within cross-functional teams that span internal Data Science & Analytics teams, IT, business groups, and executive stakeholders.
Be a positive force to cultivate a culture that is passionate about developing data tools as a business driver.
Job ID
368348BR

Address1
ONE H&R BLOCK WAY

City
KANSAS CITY

State
Missouri

Employee Type
Regular

What you'll bring to the team...
Education / work experience should include most of these, depending on level:
Bachelor’s degree in Computer Science or a related technical field (or equivalent work experience and technical skills)
Data warehousing and ETL solutions
APIs in a microservices architecture
Big-data technologies and the Hadoop stack (MapReduce, Hive, Pig, Hbase
NoSQL implementations (MongoDB)
Developing Java-based software solution
At least one scripting language (Python, Perl, JavaScript, Shell
Developing software solutions to solve complex business problems
Working with data scientists and other data users
Posting Title
Data Engineer (open level)

Sponsored Job
#hrbjob

Job Family
Corporate Analytics",3.6,"H&R Block
3.6","Kansas City, MO","Kansas City, MO",10000+ employees,1955,Company - Public,Other Retail Stores,Retail,$2 to $5 billion (USD),"Intuit, Jackson Hewitt, Liberty Tax Service"
Senior Modeling & Simulation Engineer,-1,"Applied Research Associates, Inc. is looking for a Senior Modeling and Simulation Engineer to join our multi-disciplinary team of engineers and scientists in the Capital Area Division, located in Alexandria, VA. The ideal candidate has a passion for predicting the behavior of physical systems in challenging environments and operational impact on mission success. Models will be developed, used, and improved to support a Department of Homeland Security customer to safeguard the nation’s borders and interior from chemical, biological, radiological, nuclear, and explosive materials, equipment, technologies, and their actors. Models may be based on the underlying physics or may be process or agent based to predict operational performance and impact. Modeling and analysis may require the use and development of 3D virtual worlds or geospatial data. Models will be verified and validated, and they will be used in support of test and evaluation activities of systems intended to detect and identify threats. The candidate may participate in test and evaluation activities to support the verification, validation, and overall improvement of models. Models may become part of larger, integrated modeling and simulation activities, and may require the use of high performance computing technologies and federated simulations.

This position is contingent upon award of a contract expected in Summer 2020 supporting the Department of Homeland Security.

Required Qualifications:
Ability to program in a high level programming language, such as Fortran, C++, or Java
Eagerness to learn new tools and techniques
Strong verbal and written communication skills
Must be a U.S. Citizen with the ability to obtain and maintain a security clearance
Bachelor’s degree with minimum of 10 years of experience or greater in a physical science (physics, chemistry, biology), engineering-related discipline (nuclear, chemical, civil, mechanical, electrical), or modeling& simulation disciple (computer modeling, computational science, operations research)
Ability to present to senior leadership on the status and issues associated with research or test efforts in preparation for acquisition decision meetings
Desired Experience and Qualifications:
Experience modeling CBRNE detectors or effects
Experience using multiple software tools such as MCNP, GadRas, SWORD, ExtendSim, Arena, SolidWorks, Fluent, ArcGIS, QGIS, VisIt, ParaView, or Cubit
Experience creating 3D models of systems, i.e., CAD
Experience using high performance computers (i.e., supercomputers)
Experience developing and using discrete event or agent based models and simulations to predict and assess system performance
Experience developing machine learning models
Background in a physical science or engineering discipline, such as Physics, Chemistry, Biology, Mechanical Engineering, Nuclear Engineering
Active DoD Secret or Top Secret clearance, DoE Q clearance, or DHS Suitability
COMPANY INFORMATION:

Applied Research Associates, Inc. is an employee-owned international research and engineering company recognized for providing technically superior solutions to complex and challenging problems in the physical sciences. The company, founded in Albuquerque, NM, in 1979, currently employs over 1200 professionals. ARA offices throughout the United States and Canada provide a broad range of technical expertise in defense technologies, civil technologies, computer software and simulation, systems analysis, environmental technologies, and testing and measurement. The corporation also provides sophisticated technical products for environmental site characterization, pavement analysis, and robotics.

At ARA, employees are our greatest assets. The corporation realizes that employee ownership spawns greater creativity and initiative along with higher performance and customer satisfaction levels. ARA gives its employees the tools, training, and opportunities to take more active roles as owners. The culture is challenging; innovation and experimentation are the norm. Employees are eligible for contributions which not only add to the company’s success, but also their own through the Employee Stock Ownership Plan (ESOP). The motto,“Engineering and Science for Fun and Profit” sums up the ARA experience. For additional information and an opportunity to join this unique workplace, please visit our website atwww.ara.com.",3.5,"Applied Research Associates
3.5","Alexandria, VA","Albuquerque, NM",1001 to 5000 employees,1979,Company - Private,Federal Agencies,Government,$100 to $500 million (USD),-1
Senior Data Engineer,-1,"This is a Data Engineer position for supporting a Navy program located in Quantico, Virginia.

We are seeking a Data Engineer to join our team of committed technical professionals to protect those who serve against criminal, terrorism and emerging threats. Are you passionate about analytics and innovation? Our employees enjoy a fast-paced, collaborative culture and the ability to directly impact our business. You will identify technical issues and opportunities for efficiency and provide technical insights through system design and configuration perspectives. This role is both challenging and rewarding.

You will support the mission through the implementation of a modern, integrated internal data infrastructure with a focus primarily on exploiting the established data foundation to make internal and customer-centric business processes as effective and efficient as possible, laying the foundation for cognitive capabilities that can sense and respond to both internal and external customer data needs. The candidate will also focus on expanding the organization’s data ecosystem to include context-rich data while maintaining the agility needed to spark innovation.

How you will make a difference:
Establish shared operational data and integrated enterprise data, all while managing and/or improving data quality and security through the creation of business-driven governance structures and culture change management.
Establish data policies, standards, and procedures that improve data quality, availability, accessibility, security, usability, and enforcement of enterprise information management (EIM) program requirements.
Establish enterprise standards – including a uniform and repeatable system development lifecycle methodology for Reference Data and Master Data (e.g., a common set of standards for data naming, abbreviations, and acronyms).
Develop a Master Data Management (MDM) Plan that focuses on the technology, tools, and processes ensuring master data is coordinated across the enterprise. MDM is a method used to define and manage the critical data of an organization to provide, with data integration, a single point of reference. The data that is mastered may include reference data – the set of permissible values, and the analytical data supporting decision making. MDM provides a unified master data service intended to provide accurate, consistent and complete master data across the enterprise and to business partners.
Recommend solutions based on performing industry-specific analysis, such as case studies describing data management best practices, identifying trends across the industry.
Make recommendations to improve the efficiency and effectiveness in how the agency acquires, stores, manages, shares and applies its data.
Engage business users and stakeholders for the increased release of actionable high-quality data on key operational and tactical activities at NCIS.
Develop technology solutions to provide the platform, training, and standardized tools enabling querying, data mining, statistical analysis, reporting, scenario modeling, data visualization, and dash-boarding, and processes for a centralized, or analytics as a service model, allowing for the sharing of data across the enterprise from a common hub, facilitates cross-organizational data initiatives due to its enterprise-wide view of data assets and needs.
Basic Qualifications
Required: A bachelor’s or master’s degree in computer science, data science, operations research, statistics, applied mathematics, or a related quantitative field [or equivalent work experience such as, economics, engineering and physics] is [preferred/required]. Alternate experience and education in equivalent areas such as economics, engineering or physics, is acceptable. Experience in more than one area is strongly preferred.
Required: Three to six (midlevel) of relevant project experience in successfully launching, planning, and executing data science projects. Preferably in the domains of risk modelling and quality assessment.
Preferred: Specialization in text analytics, image recognition, graph analysis or other specialized ML techniques such as deep learning, etc.
Preferred: the candidates are adept in agile methodologies and well-versed in applying DevOps/MLOps methods to the construction of ML and data science pipelines.
Coding knowledge and experience in several languages: for example, R, Python, Java, C++, Excel, MATLAB, etc.
Experience with popular database programming languages including SQL, PL/SQL, others for relational databases and upcoming non-relational databases such as NoSQL/Hadoop-oriented databases such as MongoDB, Cassandra, others.
Preferred: Specialized/operational data scientists may need further high-performance computing (HPC)/compute skills; larger data science teams, in particular, may require further degrees of specialization such as:
Experience with distributed data/computing tools such as MapReduce, Hadoop, Hive, Kafka, and MySQL
Experience of working across multiple deployment environments including cloud, on-premises and hybrid environments, multiple operating systems and through containerization techniques such as Docker, Kubernetes, AWS Elastic Container Service, and others.
Experience in one or more of the following commercial/open-source data discovery/analysis platforms: RStudio, Spark, KNIME, RapidMiner, Alteryx, Dataiku, H2O, SAS Enterprise Miner (SAS EM) and/or SAS Visual Data Mining and Machine Learning, Microsoft AzureML, IBM Watson Studio or SPSS Modeler, Amazon SageMaker, Google Cloud ML, SAP Predictive Analytics.
Preferred: Expertise in solving vision, text analytics, credit scoring, and failure prediction problems.
Knowledge and experience in statistical and data mining techniques such as generalized linear model (GLM)/regression, random forest, boosting, trees, text mining, hierarchical clustering, deep learning, convolutional neural network (CNN), recurrent neural network (RNN), T-distributed Stochastic Neighbor Embedding (t-SNE), graph analysis, etc.
Strong documentation skills. Required: Certifications as per Cybersecurity Workforce Management and Qualification Manual, SECNAV M-5239.2.
Required: Eligible AND adjudicated to the Top Secret (TS SCI) clearance level is required to start.
About Inventium.io:

Inventium.io LLC is a technical consulting and software development services company dedicated to protecting and advancing our national defense and scientific capabilities. Based out of the Washington DC area, we rely on innovation to continually advance our employees' skills and provide digital transformation solutions to our customers.

With proven records of successfully delivering quality services and solutions to multiple federal agencies, our technical competencies include Emerging Technology Solutions, DevSecOps, Cloud Migration, Machine Learning, System Modernization, and Technology Management.

Benefits and Perks
Employer paid Health Benefits (Medical, Dental and Vision)
Retirement Plan
Paid Time Off and Federal Holidays
Training and Development
Employee Referral Program
Awards and Recognition",5.0,"inventium.io LLC
5.0","Quantico, VA","Washington, DC",1 to 50 employees,2016,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Senior Software Engineer,-1,"At Pacific Biosciences, our R&D team is committed to developing innovative products that enable scientists to excel in a wide variety of life science research fields, including human biomedical, plant and animal sciences, and microbiology and infectious disease. Our unique Single Molecule, Real-Time (SMRT) sequencing platforms generate true high-quality long reads, giving researchers a more comprehensive view of genomes, transcriptomes, and epigenomes from any organism.

The Primary Analysis group, as part of the larger software engineering team at PacBio, develops algorithms and HPC solutions for decoding the raw data streams, generated through high-speed optical detection of the SMRT sequencing reactions, into DNA sequence reads. We operate at the intersection of cutting-edge nanotechnology and state-of-the-art bioinformatics tools, and our responsibilities span the full product development life cycle in an aggressive time-to-market environment. These include analysis and algorithm development in coordination with chemistry and systems R&D; the development of real-time analysis pipelines; and the development of validation and support infrastructure geared towards product system reliability and internal R&D support. We are seeking a talented algorithm engineer with a strong background in the physical or machine-learning/data sciences who also has a passion for designing and developing performance-critical data analysis solutions.

Responsibilities:

Design, develop, and test signal- and sequence-analysis algorithms that will drive fundamental improvements in basecalling accuracy and yield.
Work collaboratively in a team environment to solve challenging problems in software architecture and scalability of real-time analysis pipelines for our next-generation sequencing platforms.
All listed tasks and responsibilities are deemed as essential functions to this position; however, business conditions may require reasonable accommodations for additional tasks and responsibilities.

Key Skills and Background:

3+ years of experience shipping product software in a scientific or quantitative domain.
Demonstrated skills applying numerical methods, statistical signal processing, or machine-learning techniques to high-throughput, performance-critical analysis applications.
Linux-based systems programming experience with knowledge of OS, toolchain and hardware constraints.
Strong C++ programming experience in applications geared towards performance and scalability; previous experience in CUDA programming for GPU is a plus.
MS, PhD or equivalent experience in a quantitative field (physics, CS, etc.), preferably with an applied math or algorithmic focus.
Engineering instincts to efficiently investigate and solve the problem at hand, from prototype development (Python, R, MATLAB, etc.) to production designs.
Team player, with strong communication skills, and comfortable as a self-starter in an agile, fast-paced development environment.
All qualified applicants will receive consideration for employment without regard to race, sex, color, religion, national origin, protected veteran status, or on the basis of disability, gender identity, and sexual orientation.",3.7,"Pacific Biosciences
3.7","Menlo Park, CA","Menlo Park, CA",201 to 500 employees,2000,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,$50 to $100 million (USD),Illumina
Senior Data Engineer,-1,"ABOUT 605

At 605 we are engineers, analysts, data scientists, media experts, marketing strategists and political operatives. Our team of data scientists pioneered the field of TV data analytics. We offer unique, independent audience measurement and analytics to build better marketing and programming initiatives within the media and entertainment industries.

The Sr. Data Engineer at 605 must have a broad and deep data skillset as well as strong analytical capabilities . In addition to being a hands on individual contributor, the ideal candidate is a productive team player and a mentor to Junior. Data Engineers. Additionally, we are looking for strong technical experts.

Responsibilities include:
Actively participate in team technical discussions in all things data
Identify and address issues with data sets from multiple vendors
Identify and address code and data quality issues
Actively participate in code reviews and grooming sessions
Actively participate in technology architecture discussions for product development
Translate business requirements into strategy
Advocate for software best practices within your team as well as across engineering
Be ultra-responsive and capable of making instant decisions, always kicking the ball forward
Work on unique and interesting data challenges around architecting, building and managing pipelines that securely process hundreds of terabytes of data
Work closely with analysts and statisticians to ensure the validity of our processes
Our engineers are expected to wear a number of hats and have the opportunity to touch all parts of the stack. Our stack includes Apache Spark, Scala, Redshift and an ever-growing list of many other cool technologies.

Requirements
Skillful user of Apache Spark
Experience wrangling terabytes of big, complicated, imperfect data
Experience with AWS products (Redshift, EMR, S3, IAM, RDS, etc)
You have a deep understanding of scalable systems and you have large-scale engineering experience in an Agile development environment
Bachelor's degree in Computer Science or a related field (or 4 additional years of relevant work experience)
A strong understanding of data structures, algorithms, and effective software design
Significant development experience with a major modern language (e.g. Java, Scala, Python, Ruby, C/C++, etc.)
Significant experience working with structured and unstructured data at scale and comfort with a variety of different stores (key-value, document, columnar, etc.) as well as traditional RDBMSes and data warehouses
Experience with or interest in AWS Glue, Redshift Spectrum and any other tools that enable data querying at scale
Experience writing unit, functional and integration tests
Comfort with version control systems (e.g. Git, SVN)
Excellent verbal and written communication skills; must work well in an agile, collaborative team environment
Preferred Qualifications
Master's in Computer Science or a related field
Practical experience with supervised machine learning techniques
Strong background with test-driven development
Basic understanding of statistics and experience with statistical packages such as R, Matlab, SPSS, etc
Benefits

Important and Standard
Comprehensive health, dental and vision insurance for employees and their families
Life & Disability insurance
401k plan with match, eligible for match after one year
Pre-tax flexible compensation plan for medical, transit, parking or dependent care expenses
Up to 15 paid vacation days depending on grade level
7 paid sick days in a calendar year - if you’re sick, you stay home
Other cool benefits
4 work from home days/month
A kitchen stocked with sodas, snacks, yogurt and other goodies
A tight knit start up community who likes to eat! We celebrate everyone’s birthdays, have frequent team lunches, and do events in and out of the office
605 is an active participant in conferences
EEO STATEMENT

At 605, we’re just as passionate about diversity as we are about pioneering the field of TV data analytics. We are committed to cultivating an environment of mutual respect and equal opportunity. All hiring and advancement decisions are made on the basis of qualification, merit, and business need.",-1,605,"New York, NY",-1,-1,-1,-1,-1,-1,-1,-1
Sr Innovation Engineer,"$75K-$134K
(Glassdoor est.)","Company Information

Solid reputation, passionate people and endless opportunities. Thats Travelers. Our superior financial strength and consistent record of strong operating returns mean security for our customers and opportunities for our employees. You will find Travelers to be full of energy and a workplace in which you truly can make a difference.

Target Openings

1

Job Description Summary

Innovation is at the core of everything we do. We continue to ask ourselves, whats next? as we navigate the ever-changing insurance landscape. Continuing our customer journey toward the cutting-edge, we are looking for a forward-thinking individual that thrives in ambiguity, who believes that with every challenge comes a new opportunity for solutions.

As a member of the Innovation Technology team, you will partner with research scientists and product managers to discover, invent, and build solutions at scale. As a team, you will work on challenges in machine perception, data mining, machine learning, and natural language understanding.

We are looking for a hands-on individual with strong foundational knowledge highly scalable architectures and platforms. If you like using a variety of skills in technology and solving complex problems, work collaboratively in a small agile team environment, you might just be the person we need on our team!

Primary Job Duties & Responsibilities
Work closely with Cloud Engineering to build an innovation platform; a collection of reusable and extensible containers and tools specific to developing insurance products and platforms.
Recommend integration strategies, enterprise architectures, platforms and application infrastructure required to successfully implement a complete solution using best practices.
Produce quality output for highly visible IT products, services and future business development.
Assist in hands-on remediation of application stability and performance.
Adopt and communicate new concepts, ideas, techniques.
Manage multiple projects simultaneously.
Provide 'Shrink Wrap' solutions to solve business and technical needs. As part of our innovation process, be able to scale Minimum Viable Product to production systems.
Design and lead integration of analytic data products, including pilots and proof of concepts.
Frequently present and translate complex information in relevant business terms.
Constantly learn new skills within small teams.
No direct HR people management but will lead teams in project & program contexts.
Education, Work Experience, & Knowledge
Bachelors Degree in STEM (Science, Technology, Engineering, Mathematics) related field and 3+ years of experience or 10+ years of experience building highly scalable platforms and reusable components
Job Specific Technical Skills & Competencies
2+ years of experience working with Amazon Web Services (AWS) or equivalent cloud. Must be recent experience.
5+ years of designing and developing on-premise and cloud solutions.
3+ years of experience as a technical lead.
Experience in software engineering with relevant technologies (Java, JavaScript, Python etc.).
Experience with the application delivery process.
End-to-end experience with data, including querying, aggregation, analysis, and visualization.
Preferred Qualifications
AWS certified developer and/or architect
Proven ability to work creatively and analytically in a continuously evolving environment.
Exhibits high levels of learning agility in which they seek out and learn from unfamiliar experiences and then apply those lessons to succeed in the next new situation.
Ability to leverage business knowledge to determine approaches to execution.
Strong communication and presentation skills with the ability to present and translate complex information to leadership and non-technical teams in relevant business terms.
Uses effective listening skills and communication to build relationships across the organization.
Ability to Influence with experience working with matrixed staff to complete tasks in a timely manner.
Environmental / Work Schedules / Other
Travel Required
Equal Employment Opportunity Statement

Travelers is an equal opportunity employer.",4.1,"Travelers
4.1","Hartford, CT","Hartford, CT",10000+ employees,1853,Company - Public,Insurance Carriers,Insurance,$10+ billion (USD),-1
Senior AI Software Engineer,-1,"Company Overview

Calling the adventurers ready to join a company that's pushing the limits of nanotechnology to keep the digital revolution rolling. At KLA, we're making technology advancements that are bigger—and tinier—than the world has ever seen.

Who are we? We research, develop, and manufacture the world's most advanced inspection and measurement equipment for the semiconductor and nanoelectronics industries. We enable the digital age by pushing the boundaries of technology, creating tools capable of finding defects smaller than a wavelength of visible light. We create smarter processes so that technology leaders can manufacture high-performance chips—the kind in that phone in your pocket, the tablet on your desk and nearly every electronic device you own—faster and better. We're passionate about creating solutions that drive progress and help people do what wouldn't be possible without us. The future is calling. Will you answer?

Responsibilities

Group/Division
KLA has always had a close relationship with physics and data. Our optical and electron beam inspection and measurement tools use cutting edge physics models, both for hardware design and as part of their algorithms. AI, including several traditional machine learning techniques and deep learning are routinely used to process this data to meet application requirements.

The AI & Modeling Center of Excellence, centered in KLA’s R&D facility in Ann Arbor, MI, was setup with the mission of advancing KLA’s traditional strengths in physics and data and providing implementation solutions for multiple KLA Inspection and Metrology products targeted at the semiconductor manufacturing industry.

As a part of this group, you will be part of a world class team of physicists, HPC system designers, machine learning and application engineers who build cutting edge solutions for modeling complex imaging techniques and semiconductor processes. You will also work with a data scientists and AI infrastructure engineers whose mission is to build and scale machine learning based solutions for our semiconductor customers.

We are looking for engineers in a few different fields. If you are passionate about Physics Modeling, High Performance Computing - HPC (including GPU), ML, Data, or Cloud technologies – this is the place for you!

Responsibilities:
Software Engineers in the AI and Physics Modeling team may work on a variety of tasks including platform for large scale experimentation, scaleout of physics models, data management and inference solutions for KLA products.

Although familiarity with Machine Learning and Deep Learning solutions would be a big plus, this is primarily a Software Engineering position. Successful candidates are passionate about software, and will have exceptional skills and hands on experience with development in C/C++ and Python in a Unix environment. Deep conceptual understanding of multi threaded and multi process software systems is also necessary.

In addition to the above fundamental software skills, any of the following technical hands-on skills are highly desirable.

1) System Programming and Operating Systems.
2) Distributed systems for data management.
3) Distributed computing infrastructure.
4) Cloud technologies for storage, containerization and compute clusters.
5) Data Structures and algorithms
6) GPU architectures and data management.
7) Traditional machine learning using Random Forest, XG Boost, Logistic Regression.
8) Deep Learning for regression, classification. Generative models.
9) TensorFlow, NumPy, scikit-learn, and other ML and DL frameworks.
10) MPI and similar distributed computing framework.
11) GPU Architectures and CUDA (CuGraph, CuData, CuML etc).
12) GO Systems Programming, Java Programming.

Successful candidates for this position will also demonstrate the following non-technical skills.

1) Capability to formulate creative solutions through analyzing complex data
2) Good communication skills
3) Strong team player and motivated by team success
4) Strong problem solving skills

Minimum Qualifications

Doctorate (Academic) with at least 2 years of experience.
OR
Master's Level Degree with at least 4 years of experience.
OR
Bachelor's Level Degree with at least 5 years of experience.

Equal Employment Opportunity

KLA is an Equal Opportunity Employer. Applicants will be considered for employment without regard to age, race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability, or any other characteristics protected by applicable law.",3.8,"KLA-Tencor
3.8","Ann Arbor, MI","Milpitas, CA",5001 to 10000 employees,1976,Company - Public,Industrial Manufacturing,Manufacturing,$2 to $5 billion (USD),"Applied Materials, Nanometrics"
"Senior SDE, Catalog Big Data and Machine Learning",-1,"Amazon's Catalog DataWorks team is looking for highly motivated engineers. We are embarking on multiple new initiatives to re-organize Amazon's catalog of billions of products, in new and interesting views, that drive several features Amazon's customers love. Today, these views drive hundreds of popular features like product recommendations, clustering of similar products, and shopping with Alexa. We will build a new near real-time Catalog Data Lake on AWS, to enable engineers and scientists across Amazon to solve customer problems faster. Come join us on this exciting journey!

As an engineer on this team, you will own the Catalog Data Lake end-to-end. You will work closely with business partners to synthesize technical requirements. You will design and implement significant parts of the platform. You will learn and use industry standards like Spark and Parquet as well as modern AWS offerings like EMR, Glue, Athena, and Redshift. We are fortunate to be at the cusp of innovation in both the e-commerce business as well as cloud technology. As a key stakeholder, you will constantly learn new patterns, solve key customer problems and strive to make AWS better along the way.Basic Qualifications
Bachelor's degree or higher in computer science or math is required.
Strong computer science fundamentals - algorithms, data structures and design patterns.
At least 8 years of software development experience.
At least 3 years of experience building and operating Big Data systems.
Experience mentoring, guiding and influencing peers.
Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.",-1,Amazon Corporate LLC,"Seattle, WA",-1,-1,-1,-1,-1,-1,-1,-1
SENIOR SOFTWARE ENGINEER & SOFTWARE ARCHITECT,-1,"Job Description
Senior Software Engineer, Software Architect
JOB SUMMARY

The Senior Software Engineer, Software Architect will develop software for Company innovative semiconductor X-Ray inspection system. The Senior Software Engineer will collaborate with Applications, QA, and Algo teams for high performance solutions and optimization per customer issues. It will be important to be comfortable working in a small company environment and a typical startup with engineers and scientists.

ABOUT THE CLIENT

Based in San Jose, California, client was founded in 2013 expressly to bring high speed inspection and metrology technology to the semiconductor packaging industry. Client founders anticipated the need to deploy inline 100% transmissive inspection into the semiconductor packaging manufacturing process and developed the company’s technology with this end in mind. The results, Client’s HR-AXI technology suite brings together the company’s unique data acquisition architecture with proprietary machine learning analysis techniques to provide customers with process monitoring and defect detection capabilities not found on any other products in the market. This job description can be updated at any time.

RESPONSIBILITIES
Designs, develops, troubleshoots, and debugs software programs for enhancements and new products, focused on creating high quality and high-performance solutions while maintaining high-level coding standards.
Develops software and tools in support of design, infrastructure, and technology platforms. Develops software solutions by studying information needs, conferring with users, and studying systems flow, data usage, and work processes
Supports hardware compatibility and/or influences hardware design based on software needs; work as part of cross-functional team to solve and implement system level problems.
Monitor application stability, performance, and availability. Promptly resolve issues impacting operations.
Work with engineering, documentation, and applications departments to ensure successful development and delivery of overall product.
Provide appropriate project feedback to management in a timely and appropriate format.
QUALIFICATIONS AND REQUIRED SKILLS
Education requirement: Bachelor’s degree in Computer Science, Electrical Engineering, or similar technical field required. Master’s or PhD strongly preferred.
Experience requirement: Minimum of 8 years of related experience working in software development.
Strong expertise in C# .NET. WCF, WPF, Database development. In addition, Python experience a plus.
Experience with Image processing algorithms implementations is a plus
Experience with software development for Factory Automation for Semiconductor equipment, a plus.
Self-starter able to think and act independently to translate general objectives into tangible results, with a record of delivering successful designs on schedule.
Demonstrated ability to organize, manage, and complete multiple assignments with challenging timelines independently and effectively.
Demonstrated analytical and problem-solving skills with high attention to detail.
Proactive approach to problem-solving. Build relationships with stakeholders to support successful design, build and testing.
Strong verbal and written communication, good attitude, and work ethic. Ability to communicate technical concepts and results clearly.
Experience with Git and Azure DevOps, a plus.",3.0,"Simple Solutions
3.0","San Jose, CA","Morgantown, WV",1 to 50 employees,2006,Company - Private,IT Services,Information Technology,Less than $1 million (USD),-1
Cloud Engineer,-1,"Job Description
Responsibilities:
Develop and implement technical efforts to design, build, and deploy AWS applications at the direction of lead architects, including large scale data processing, computationally intensive statistical modeling, and advanced analytics
Participate in all aspects of the software development life cycle for AWS solutions, including planning, requirements, development, testing, and quality assurance
Provide guidance, thought leadership and mentorship to development teams to build cloud competencies
Provide innovative thought leadership around Mathematica’s cloud solutions strategy and approach, including AWS best practices and market trends
Position Requirements:

6+ years of experience architecting, designing, developing and implementing cloud solutions on AWS platforms
Demonstrated experience with designing and implementing solutions using AWS platform and tools, such as: EC2, S3, Redshift, API Gateway, Lambda, DynamoDB, CloudFormation, RDS, VPC, IAM and security, QuickSight, CloudTrail, Config, CloudWatch, SNS, AMI generation
Understanding of and experience with the five pillars of a well-architected framework
Knowledge of SQL, R, and Python for data manipulation and statistical analysis is desirable
Familiarity with federal security regulations and standards (e.g. HIPAA, FISMA, FIPS, NIST, and FedRAMP)
Experience with security, especially knowledge of FedRAMP, HIPAA, PII/PHI, is desirable
Experience in several of the following areas: database architecture, ETL, Business Intelligence, Big Data, Machine Learning, Advanced Analytics
Proven ability to work collaboratively with multi-disciplinary teams of business analysts, developers, data scientists, and subject matter experts
Strong written, verbal and interpersonal communication skills
AWS Certifications (such as AWS solutions architect or other specialty certifications) are a plus
Bachelor's degree or equivalent combination of education and experience; degree in computer science, mathematics or related field preferred
Experience with other cloud platforms like Google Cloud Platform (GCP) is a plus",4.8,"RICEFW Technologies Inc
4.8","Princeton, NJ","East Lansing, MI",51 to 200 employees,2009,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Senior Software Engineer / Team Lead,"$112K-$220K
(Glassdoor est.)","Join our team dedicated to developing and executing innovative solutions in support of customer mission success.

Job Description:

Novetta has an exciting opportunity for a self-motivated and accomplished Computer Scientist to lead our entity analytics team. You will work on complex projects involving data analysis, software engineering, and deploying software in a cloud computing environment. The team combines data from disparate sources to visualize the complex relationships between entities. This effort involves large scale data integration and entity resolution leveraging a best in class Novetta product. We are looking for a flexible problem solver with significant technical experience to lead a team providing unique solutions for our customers and stakeholders.

Responsibilities include:
Lead a technical team of software engineers and computer scientists, working within a larger ecosystem delivering an Enterprise capability.
Navigate customer and prime environment, manage resources within and across team, and assist team with professional and technical growth.
Deploy applications on a large-scale data processing cluster using AWS technologies.
Design and implement entity correlation strategies that are tailored to mission needs and unique data qualities.
Develop algorithms and visualization tools to help stakeholders understand their data and prioritize new data sources.
Develop and integrate applications to automate ingestion, processing and monitoring of data
Develop and maintain tools to support operations and maintenance of production and development computing clusters.
Basic Qualifications:
Experience leading a team of software engineers.
A Bachelor's degree in computer science or related field and a minimum of 5 years of experience; or a Master's degree in computer science or related field and a minimum of 3 years of experience.
Experience in software development/engineering including requirements analysis, software development, installation, integration, evaluation, enhancement, maintenance, testing and problem diagnosis/resolution.
Software development experience on Linux-based systems in Python or shell scripting or JavaScript.
Experience developing against full-featured REST APIs and using a command line interface
Desired Skills:

Should meet a minimum of 3:
Software development experience with JavaScript, Python, or other modern programming languages.
Hands-on experience with Spark.
Experience working with Databricks
Interest in statistical analysis, machine learning, or data science.
Experience with entity resolution products or a background in data matching theory and technologies.
Experience developing applications in AWS.
Security Clearance:
The candidate must have a TS/SCI with Poly.
Novetta, from complexity to clarity.

Novetta delivers highly scalable advanced analytics and secure technology solutions to address challenges of national and global significance. Focused on mission success, Novetta pioneers disruptive technologies in machine learning, data analytics, full-spectrum cyber, cloud engineering, open source analytics, and multi-INT fusion for Defense, Intelligence Community, and Federal Law Enforcement customers. Novetta is headquartered in McLean, VA with over 1,000 employees across the U.S.

Our culture is shaped by a commitment to our core values:

Integrity • We hold ourselves accountable to the highest standards of integrity and ethics.

Customer Success • We strive daily to exceed expectations and achieve customer mission success.

Employee Focus • We invest in our employees' professional development and training, respecting individuality and fostering a culture of diversity and inclusion.

Innovation • We know that discovering new and innovative ways to solve problems is critical to our success and makes us a great company.

Excellence in Execution • We take pride in flawless execution as we build a company that is best in class.

Earn a REFERRAL BONUS for the qualified people you know.

For more details, or to submit a referral: bit.ly/NovettaReferrals

Novetta is an equal opportunity/affirmative action employer.

All qualified applicants will receive consideration for employment without regard to sex, gender identity, sexual orientation, race, color, religion, national origin, disability, protected veteran status, age, or any other characteristic protected by law.",4.5,"Novetta
4.5","Chantilly, VA","Mc Lean, VA",501 to 1000 employees,2012,Company - Private,Enterprise Software & Network Solutions,Information Technology,$100 to $500 million (USD),"Leidos, CACI International, Booz Allen Hamilton"
Data Fusion Engineer with Security Clearance,"$48K-$109K
(Glassdoor est.)","Description Job Description: Looking for work-life balance? Leidos offers generous leave and accommodating flex-time to help you juggle your personal and professional life. Are you a Software Engineer with experience finding and aligning signals across multiple modalities (image, video, audio, lidar, etc..)? Do you want to implement and customize algorithms to fusion multiple data modalities? If so we are looking for you, our next Data Fusion Engineer to work in Arlington, VA. We need you to be competent in Python and have the ability to read code in other programming languages like Java and C++ as well as have experience working with ML libraries like SciKit Learn, TensorFlow, Keras along with experience implementing solutions with those libraries on both CPU and GPU compute architectures. Like what you are reading so far? Keep going. We want you to be intellectually adaptive, inquisitive, good at expressing your needs, and able to self-manage when necessary. Work alongside software/system engineers and research/data scientists with expertise in multi-modal information retrieval, UI development, computer vision, metrics, information science, artificial intelligence, and autonomous systems. The Department of Defense and the Intelligence Community will be the main recipients your hard work. Fun stuff you will do on the job: - Use cases requiring identifying entity/objects, determining object association, object disambiguation, anomaly detection, state estimations, etc.
Develop and maintain data models (both physical and logical)
Get to be responsible for extraction, transform, and load (ETL) tasks related to the different modalities and algorithms being applied. This data ETL includes identifying the data's relevant metadata to ensure consistency, quality, accuracy, integrity, and information assurance and security.
Performing anomaly detection using various AI/ML techniques
Use algorithms to identify complex patterns across multiple modalities
Increasing the efficiency and quality data alignment and fusion
Enhance and maintain analysis tools, including automation of current processes using AI/ML algorithms
Conduct quantitative data analysis including developing retrieval, processing, fusion, analysis, and visualization of various datasets Skills required to be successful in this role: - Bachelor's Degree in Aerospace Engineering, Computer Science, Mathematics, Statistics, Physics, Electrical Engineering, Computer Engineering or related fields with 5 years of relevant experience
Must be able to obtain and maintain a TS/SCI security clearance
Experience with Deep Learning Frameworks such as Keras, Tensorflow, PyTorch, Mxnet, etc. - Ability to apply these frameworks to real problems in the 'time -series' domain
Experience with interpretability of deep learning models
Big Data Skills (Azure, Hadoop, Spark, recent deep learning platforms)
Practical experience with statistical analysis
Experience with text mining tools and techniques including in areas of summarization, search (e.g. ELK Stack), entity extraction, training set generation (e.g. Snorkel) and anomaly detection
Expert software development skills lifecycle including developing and maintaining good production quality code
Hands-on Software Development Skills (Python-Preferred)
Experience or educational courses/projects in Machine Learning, and/or Text Mining Algorithms You will wow us even more if you have these skills: - Visualizations/Web Development Skills (e.g. Tableau, D3, etc).
Hands-on experience with prototype development
Hands-on experience with automating data cleansing, formatting, staging, and transforming data human
Hands-on experience applying data analytics
Hands-on experience with intelligent systems and machine learning LInC External Referral Bonus: Ineligible Potential for Telework: No Clearance Level Required: Top Secret/SCI Travel: Yes, 10% of the time Scheduled Weekly Hours: 40 Shift: Day Requisition Category: Professional Job Family: Software Engineering Leidos Leidos is a Fortune 500® information technology, engineering, and science solutions and services leader working to solve the world's toughest challenges in the defense, intelligence, homeland security, civil, and health markets. The company's 33,000 employees support vital missions for government and commercial customers. Headquartered in Reston, Virginia, Leidos reported annual revenues of approximately $10.19 billion for the fiscal year ended December 28, 2018. For more information, visit www.Leidos.com . Pay and Benefits Pay and benefits are fundamental to any career decision. That's why we craft compensation packages that reflect the importance of the work we do for our customers. Employment benefits include competitive compensation, Health and Wellness programs, Income Protection, Paid Leave and Retirement. More details are available here . Securing Your Data Leidos will never ask you to provide payment-related information at any part of the employment application process. And Leidos will communicate with you only through emails that are sent from a Leidos.com email address. If you receive an email purporting to be from Leidos that asks for payment-related information or any other personal information, please report the email to [email protected] . Commitment to Diversity All qualified applicants will receive consideration for employment without regard to sex, race, ethnicity, age, national origin, citizenship, religion, physical or mental disability, medical condition, genetic information, pregnancy, family structure, marital status, ancestry, domestic partner status, sexual orientation, gender identity or expression, veteran or military status, or any other basis prohibited by law. Leidos will also consider for employment qualified applicants with criminal histories consistent with relevant laws.",3.5,"Leidos
3.5","Arlington, VA","Reston, VA",10000+ employees,1969,Company - Public,Aerospace & Defense,Aerospace & Defense,$10+ billion (USD),-1
Software Engineer,"$64K-$132K
(Glassdoor est.)","Every Analyst a Scientist - One of our primary goals is to empower intelligence analysts to be able to study their data like scientists. The tools we develop focus on streamlining intelligence analysis through integrated algorithms and software that provide insight into the geopolitical landscape for use in operational intelligence missions around the world.

The Role:
As a Software Engineer, you will be part of a team that transforms large and complex customer data into real-world, high-impact solutions. You will work with researchers and engineers to design and implement solutions to challenging national security problems. You will be responsible for building the software infrastructure to clean, ingest, and expose datasets and algorithms to both developers and end users. You will deploy algorithms, generate workflows, create engineer-facing tools, and design customer-facing prototype systems. You will occasionally travel to customer sites to engage with end users, demonstrate prototypes, and integrate analytics into customer systems.

If you would like to help intelligence and defense analysts keep pace with technology-driven innovation, then this role is for you!

Who you are:
A U.S. Citizen with the ability to obtain a Security Clearance
A degree in a scientific or engineering field, such as Computer Science, Mathematics, Physics, or Software Engineering
Proficiency with a scientific programming language such as Python, Java, or C++
Experience with database management and common query syntax
Motivated collaborator and excellent communicator of ideas to both technical and non-technical audiences
Knowledge of AWS, Spark, Dask, and/or similar technologies for working with data at scale
Even better:
Active Security Clearance
Track record of architecting, developing, deploying, or maintaining enterprise software
Experience with software development best practices and tools
Understanding of web development and visualization technologies, such as d3, Leaflet, Bootstrap, or others
Familiarity with machine learning or statistical modeling techniques",4.5,"Systems & Technology Research
4.5","Woburn, MA","Woburn, MA",201 to 500 employees,2010,Company - Private,Aerospace & Defense,Aerospace & Defense,$100 to $500 million (USD),-1
Sr. Data Scientist,-1,"Background Information:

Innovative Defense Technologies (IDT), provider of automated software testing, data analysis, and cybersecurity solutions for complex defense systems, is currently accepting applications for an anticipated Sr. Data Scientist role requiring 7+ years of experience for a position in support of its efforts implementing Artificial Intelligence solutions for a variety of customers.

Overview:

The Sr. Data Scientist position offers an engineer the opportunity to utilize his/her knowledge and talents as part of a collaborative team developing AI solutions for a growing company. A few of the responsibilities include supporting feasibility studies, applying modern data storage techniques, discovering explanatory features in high-dimensionality collections of data, and exploring data using scientifically valid techniques to exploit patterns found in the data with state-of-the-art AI/ML/DL solutions.

All applicants must be able to obtain/maintain an active U.S. Security Clearance.

Responsibilities Include:
Lead development of solutions to deliver AI/ML/DL models from problem formulation to a productized, deployable, maintainable capability
Contribute to AI/ML/DL technical roadmap development
Use Deep Learning frameworks such as Tensorflow and Keras to build and validate ML/DL models
Establish and leverage Big Data frameworks to store, extract and analyze relevant data
Ensure development of software solutions meets customer needs and program intent
Work closely with the Program Manager and Chief Engineer to design and implement software requirements and solutions
Determine operational feasibility by evaluating analysis, problem definition, requirements, solution development, and proposed solutions for large, complex systems
Be responsible for a team’s products meeting software design, quality, and performance requirements
Pursue new technology development via the DoD Small Business Innovative Research (SBIR) program
Work with minimal supervision in a collaborative work environment to implement best-in-class solutions
Minimum Required Qualifications:
Bachelor’s Degree in Computer Science, Computer Engineering, Electrical Engineering, Systems Engineering, Physics, or Math Required; PhD in relevant field highly preferred
7+ years of experience in predictive modeling, data science and analysis
Required Skills:
Previous experience in a ML or data scientist role and a track record of building ML or DL models
Extensive experience working with data mining algorithms including decision trees, probability networks, association rules, clustering, and neural networks
Experience using Python (or equivalent)
Experience using ML libraries, such as scikit-learn,
Experience using data visualization tools
Experience handling terabyte size dataset
Experience working with GPUs to develop models
Ability to travel 10% or less
Preferred Skills:
Experience with MapReduce programming (Hadoop)
Skills with programming languages, such as Java or C/C++
Demonstrated ability to develop experimental and analytic plans for data modeling processes, use of strong baselines, ability to accurately determine cause and effect relations
Consulting experience and track record of helping customers with their AI needs
Publications or presentations in recognized Machine Learning, Deep Learning and Data Mining journals/conferences
Combination of deep technical skills and business savvy enough to interface with all levels and disciplines within our customer’s organization
Experience diving into data to discover hidden patterns
Experience with application container platforms
Familiarity with continuous integration/delivery tools (e.g. Jenkins)
Familiarity with version control tools (e.g. Subversion, Git, etc.)
Familiarity with VMware or other virtualization software
Experience developing applications for DOD command and control systems
Competencies:
Solid analytical abilities, coupled with a strong sense of ownership, urgency, and drive
Attention to detail
Initiative, creativity, reliability, teamwork
Ability to deal well with ambiguity, prioritize needs, and deliver results in a dynamic environment
EEO Statement:

IDT is an Equal Opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, creed, sex, sexual orientation, gender identity, national origin, disability, protected Veteran status, or any other basis protected by federal, state, or local law.",-1,Innovative Defense Technologies (IDT),"Mount Laurel, NJ",-1,-1,-1,-1,-1,-1,-1,-1
Full Stack Software Engineer (Python/Vue),-1,"Position Summary Full Stack Software Engineer (Python VueJS) Company Overview Our client is an automated underwriting platform for real estate professionals that was built to disrupt the commercial real estate industry. The software allows investors, brokers, and lenders to analyze rent, operating expenses and returns for multifamily properties by applying machine learning to a database of live multifamily transaction data from every U.S. market. Our client has a creative and entrepreneurial culture ndash everyone on the team interacts directly with customers each day, and we all contribute to the product and planning. If you have an idea to improve something, there is no red tapehellip just build what needs to be built! Innovation and passion for transforming the old-fashioned real estate industry are our highest priorities. Job Description As a full-stack (Python, PostgreSQL and HTMLCSSJavaScript) developer, you'll work on the interface and backend infrastructure of products and features used by hundreds of underwriters and real estate analysts every day. The work is challenging, fast-paced, and always changing. You must have demonstrated analytical skills, an unwavering commitment to quality, a collaborative work ethic, and cutting-edge coding skills. You must display solid proficiency in the fundamentals of Python, PostgreSQL, JavaScript, HTMLCSS, and popular front-end frameworks like Vue.js. The role will include the delivery of reliable, scalable new features to users, developed in Python, interacting with a PostgreSQL database and using the Vue.js frontend framework. You will work with the development team to develop, test and deliver finished, high quality, compelling features and products. Our team includes designers, engineers and data scientists who are passionate about quality, usability, and simplicity. If you are ready to join a company that fosters learning, growth, experimentation and innovation, our client's team is for you. Requirements Qualifications 3-5 years of experience in full stack Python development 1-3 years of experience with PostgreSQL 1-3 years of experience with JavaScript frameworks such as React, Angular or Vue.js (Vue.js is preferred, this is what our client uses), and CSS pre-processing frameworks (Sass or Less) 1-2 years of experience integrating with VBA and Excel integration preferred Experience using GitHub and solid understanding of software version control Familiarity with JIRA or equivalent product management software Familiarity with agile development best practices Driven self-starter able to work on a small team and take initiative on new tasks Familiarity with real estate or finance is a plus Responsibilities Collaborate with interdisciplinary team of data scientists, software engineers and real estate professionals Strive for high quality and rapid output utilizing agile development best practices Support, maintain, and document software functionality Maintain industry standard coding, compliance, security practices Proactively learn product frameworks and code base Our client is a startup company, and as such the responsibilities outlined above may change and evolve over time. Flexibility, curiosity, an entrepreneurial mindset, and strong work ethic are essential for this role. It is encouraged that everyone on the team continually research new technologies and analytical opportunities to improve the platform.",5.0,"CultureFit
5.0","Chicago, IL","Deerfield, IL",1 to 50 employees,1997,Company - Private,Advertising & Marketing,Business Services,$1 to $5 million (USD),-1
AWS Data Engineer,-1,"About Infinitive:

At Infinitive, we do mission-critical work for great companies. We specialize in digital marketing and digital advertising solutions, customer data & analytics, digital & business transformation, and Technology solutions. Our Technology solutions focus on Managed Cloud Services, Cloud Enablement, Digital Operations, Application Development, DevOps, Product Development, Cloud Security, Data Science and Analytics, AI/ML, IoT, and everything in between.

Our experts are results-obsessed, focused and flexible, highly engaged and hugely experienced having sat in our clients seats. Those qualities are what make us different than old-school consulting shops. And surely, they are why clients and partners describe us as the gold standard in client experience.

Infinitive has been named a Best Small Firms to Work For by Consulting Magazine seven times, a Washington Post Top Workplace three times, a Washington Business Journal Best

About this Role:

Infinitive is growing its team in the Northern Virginia area and is currently seeking an Data Scientist to join our growing Technology practice. This person will utilize their experience in analytics, IoT, machine learning, and artificial intelligence advances to create value from structured and unstructured data. The ideal candidate has experience designing novel data analytic methods and workflows, including full data pipelines from raw data through analysis results. They must also have exposure to a variety of data mining/data analysis methods, data tools, building and implementing models, using/creating algorithms, and creating/running simulations.

We are looking for candidates who are accountable, passionate, assertive, proactive, open & honest, results oriented, and adaptable. Each project engagement represents a new challenge that will give you exposure to new clients, business issues, technologies, and people and will involve a range of responsibilities to include:
Developing in Java, Python, R, or other high-level languages.
Managing disparate data sources with varying data structures of content and preparing these for data science and machine learning applications.
Working with distributed scalable Big Data storage, processing, and computation, including AWS EMR, Spark, etc.
Implementation knowledge of, or desire to learn AWS / Azure data science capabilities.
Developing solutions and integrating and extending free and Open-source software (FOSS) or COTS products.
Conduct MapReduce programming with Apache Hadoop, the Hadoop Distributed File System (HDFS), and processing large data stores.
Knowledge of SQL and query languages.
Utilize real-time, large-scale data processing engine, including Apache Spark.
Lead and create Data Science and Analytics methodologies and frameworks for implementation.
Ability to build and develop Data Science demonstrations for clients
Qualifications:
4+ years of development experience (Java, Python, R, SQL)
3+ years of experience with distributed scalable Big Data storage, including AWS EMR, Spark, etc.
Desire to become AWS / Azure Certified architect / engineer.
Experience performing data Management, modeling, and warehousing.
Hands on experience with Amazon analytic tools (preferred)
Interest in being involved internally and growing a small business (entrepreneurial spirit)
Ability to travel (up to 20%) and to work independently
Experience using Agile software development methods in a DevOps environment.
Excellent leadership, peer management, and communication skills
Management consulting experience (preferred)
Bachelor's degree in related field (preferred)
Applicants for employment in the U.S. must possess work authorization which does not require sponsorship by the employer for a visa.

Infinitive is an Equal Opportunity Employer.

Powered by JazzHR",3.4,"Infinitive Inc
3.4","Arlington, VA","Cedar Rapids, IA",201 to 500 employees,1997,Company - Private,Enterprise Software & Network Solutions,Information Technology,$10 to $25 million (USD),-1
"Senior SW Engineer, Data Science ( Kubernetes/ Docker ) Remote USA","$72K-$141K
(Glassdoor est.)","If you dream of a job working in a field where all the hard problems are solved and you get to re-use previous research to get your job done, you need not apply. If, however, you are someone who wants to tackle problems that truly are on the cutting edge, then we encourage you to keep reading.

Data Science is an emerging field within cyber security. FireEye, given its deep expertise and comprehensive view on the advanced threat landscape, is uniquely positioned to enable data scientists to have major impact within our industry, company, and across our customer base. Detecting security breaches using machine learning and data analytics is an unsolved problem (this is not handwriting recognition folks) and has huge potential.

If you are someone who wants to be on the cutting edge of a high profile industry, who wants to make an impact by pushing both fields of data science and cyber security forward, you may be the perfect candidate to help us on our mission.

What you will do:
Develop, and manage data systems to ingest and process data at massive scale
Identify data sources both internally and externally that we can use to find evil.
Contribute towards the architecture and design of software solutions for long-term storage and retrieval.
Identify and implement data exploration technologies. Create dashboards and implement analytical tools for exploration
Work with data scientists to productize ML models and assist product teams with ML model releases into end products.
Collect requirements, design, and build backend components and tools to run ML models, assess ML model efficacy, manage large scale datasets, and generate features for ML models
Contribute to the evolution of coding and design practices within the organization.
Review code base commits and contribute to the growth of team members.
Requirements
Ability to work in an iterative, agile development environment.
Experience implementing ETL processes and building data pipelines
Experience developing reliable distributed systems.
Experience in Data modeling and schema design
Strong knowledge of a variety of operating systems, networking fundamentals, software design and programming best practices.
Experience with use of a wide array of algorithms and data structures.
Deep understanding and experience of going through the entire life cycle of building software platforms and products
Deep knowledge of various AWS services and associated tools
Strong experience developing in Python 3
Experience developing in at least 1 of the following: C, Go or Java
Experience with RDBMS, such as PostgreSQL or MySQL, as well as NoSQL
Experience with Kubernetes and Docker.
Experience deploying products in AWS
Additional Qualification: *
Ability to pick up, work with and explore new analytical tools
Strong experience with DevOps practices and common tooling
Strong communication skills.
Ability to work with loosely defined requirements.
At FireEye we are committed to our #OneTeam approach combining diversity, collaboration, and excellence. All qualified applicants will receive consideration for employment without regard to race, sex, color, religion, sexual orientation, gender identity, national origin, protected veteran status, or on the basis of disability. Requests for accommodation due to disability can be sent directly to .",3.3,"FireEye Inc
3.3","Denver, CO","Milpitas, CA",1001 to 5000 employees,2004,Company - Public,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,"Palo Alto Networks, Tanium"
"Senior SW Engineer, Data Science","$72K-$141K
(Glassdoor est.)","Job Description

If you dream of a job working in a field where all the hard problems are solved and you get to re-use previous research to get your job done, you need not apply. If, however, you are someone who wants to tackle problems that truly are on the cutting edge, then we encourage you to keep reading.

Data Science is an emerging field within cyber security. FireEye, given its deep expertise and comprehensive view on the advanced threat landscape, is uniquely positioned to enable data scientists to have major impact within our industry, company, and across our customer base. Detecting security breaches using machine learning and data analytics is an unsolved problem (this is not handwriting recognition folks) and has huge potential.

If you are someone who wants to be on the cutting edge of a high profile industry, who wants to make an impact by pushing both fields of data science and cyber security forward, you may be the perfect candidate to help us on our mission.

What you will do:
Develop, and manage data systems to ingest and process data at massive scale
Identify data sources both internally and externally that we can use to find evil.
Contribute towards the architecture and design of software solutions for long-term storage and retrieval.
Identify and implement data exploration technologies. Create dashboards and implement analytical tools for exploration
Work with data scientists to productize ML models and assist product teams with ML model releases into end products.
Collect requirements, design, and build backend components and tools to run ML models, assess ML model efficacy, manage large scale datasets, and generate features for ML models
Contribute to the evolution of coding and design practices within the organization.
Review code base commits and contribute to the growth of team members.",3.3,"FireEye Inc
3.3","Denver, CO","Milpitas, CA",1001 to 5000 employees,2004,Company - Public,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,"Palo Alto Networks, Tanium"
"Senior Machine Learning Engineer, Early Stage Pipeline, X",-1,"Senior Machine Learning Engineer, Early Stage Pipeline, X

Software Engineering

Mountain View, CA

We're an early stage team at X with a growing, interdisciplinary portfolio. To prove our path to the moon, we make early contact with the real world through both internal and external partnerships.

In this role, you will be responsible for taking early stage investigations from an idea stage to first prototypes to a full-blown projects. You'll be rapidly iterating through a set of prototypes to evaluate possible product directions. This is an extremely dynamic role and requires high cross-functional communication, organization, and planning. The ideal candidate is a self-starter and has a track record of effectively operating in a dynamic loosely structured environment (e.g. startup, new products within a larger company). The candidate will work on multiple projects/investigations.

Responsibilities:
Identify and implement a set of machine learning prototypes to aggressively de-risk projects building the whole solution: data acquisition, data processing pipelines, ML modeling.
Setup technical direction for investigations/projects working with the early stage leadership team.
Team lead investigations that grow to become projects.
Qualifications:
Hands-on experience with machine learning, one or more of; natural language processing (semantic understanding, sentiment analysis), computer vision, time series analysis.
Experience with building robust data pipelines.
Tech Lead experience.
Startup or early-stage product development experience.
Preferred Qualifications:
Experience with the Google Cloud Platform
About X, the Moonshot Factory

X creates radical new technologies to solve some of the world's biggest problems. We develop uncomfortably ambitious, potentially world-changing new ideas such as self-driving cars, balloon-powered Internet and smart contact lenses. We're a team of makers, entrepreneurs, engineers, designers and scientists with deep technical expertise who love the challenge of the seemingly impossible. We believe that a culture of psychological safety creates the foundation of trust and respect necessary to build moonshots. X was formerly known as Google[x] and is part of Alphabet .

At X, we don't just accept difference - we celebrate it, we support it, and we thrive on it for the benefit of our employees, our products and our community. We are proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements.

If you have a disability or special need that requires accommodation, please contact us at: (see application details) .",-1,"X, the moonshot factory","Mountain View, CA",-1,-1,-1,-1,-1,-1,-1,-1
"Senior/Staff Software Engineer, Data Infrastructure","$116K-$227K
(Glassdoor est.)","Senior/Staff Software Engineer, Data Infrastructure job posting

Every year, while Americans wait for their paychecks, more than $1 trillion of their hard-earned money is held up in the pay cycle. As a result, we accumulate over $50 billion in late and overdraft fees and turn to high-interest loans. Overdraft charges and bank fees often trap people in a cycle of debt that can lead to unhealthy decisions and falling victim to predatory businesses disguised as helpful services. We don't accept that.

Earnin is an app that creates products that help people gain control of their finances. Cash Out lets people get paid as soon as they leave work, with no fees, interest, or hidden costs. With Health Aid, Earnin negotiates on behalf of community members to lower their total unpaid medical bill and work out a budget-friendly payment plan. Cash Back Rewards is a way for members to earn up to 10% cash back on purchases from over a thousand local and national businesses without needing a credit card or having to reach spend thresholds to earn cash rewards — and they can withdraw the money at any time. We also offer free tools to help avoid overdrafts, to remind people when recurring bills are due, and we're working on more! There is never any required cost to use any of these products or services, users can choose to tip what they think is fair to support the service and pay it forward to keep the movement going.

Earnin is supported by funding partners including Andreessen Horowitz, Matrix Partners, Ribbit Capital, Felicis Venture, Thrive Capital, and others. Join us and help build a new financial system focused on fairness and people's needs.

You can help make a difference.

About the Team:

We are a data driven mobile financial tech company. The Data Infrastructure team builds the data services and data infrastructure that powers data science, analytics, and product development throughout Earnin. We are looking for a product-minded, self-driven Senior Software Engineer to own multiple large-scale projects that advance our mission of enabling people to gain access to their paycheck on demand.

What sets us apart:
High impact roles at a relatively small company that's aggressively growing our user base.
We are a collaborative team and genuinely enjoy working with each other.
We believe in empowering our people to be successful.
We're building a product that inspires fairness across the financial world and helps people not get taken advantage of.
As a Senior Engineer you will:
Break down complex problems into their bare essentials, translate this complexity into elegant design and create high quality, maintainable code.
Build massively scalable, production-grade data services.
Champion data quality and governance throughout the organization.
Build a world class data lake and data warehouse.
Design and develop new systems and tools to enable all of Earnin to consume and understand data faster.
Own the end to end design, build, and maintenance of platform services, data pipelines, and data products.
Implement comprehensive monitoring, logging, and alerting across our data infrastructure.
Work cross functionally with other teams (data science, design, product, marketing, and analytics) in high visibility roles as an engineering leader.
Build and deploy the data architecture that supports machine learning model development and actionable analytics.
Work with product engineering and data science teams to design scalable, performance model deployment architectures.
Communicate the tradeoffs of technical decisions to multiple stakeholders, including non-technical audiences.
Collaborate with and mentor other engineers and provide engineering direction to data scientists and analysts.
Actively engage and drive design reviews and code reviews.
Some skills we consider critical to being a Senior Engineer:
BS or MS degree in Computer Science, Engineering, or a related technical field.
8+ years of development experience in a fast-paced environment, especially startups.
5+ years of experience working with data systems.
Strong Python and SQL skills.
Strong programming and architecture skills.
Excellent written and verbal communication skills, including the ability to identify and communicate data driven insight.
Taking pride in your code quality and helping others elevate their own code quality.
Substantial experience with testing, data validation, and data quality assurance.
You can articulate the tradeoffs of different deployment architectures (e.g. streaming vs. batch vs. service-based).
Experience designing data platforms and services on cloud infrastructure, preferably AWS.
Hands-on experience designing and building large-scale solutions with the Hadoop stack and/or Spark.
Experience tuning and optimizing Spark-based applications.
Experience deploying and/or using query engines like AWS Athena, Presto, and Impala.
Experience with AWS analytical services like Redshift.
Hands-on experience working with a varied set of data storage technologies (e.g. Mysql, Postgres, DynamoDB, S3, etc.). You know where and when to use each.
Extensive experience with data modeling for multiple use cases and application styles, including NoSQL data modeling.
Experience working with data formats such as Avro and Parquet.
Experience working with alerting and monitoring tools like DataDog and PagerDuty.
Nice to haves:
You have experience building and deploying machine learning models.
You have experience using Terraform.
You have substantial experience working at a startup.
You have experience with data modeling in Redshift.
Experience with streaming infrastructure like Kafka.
Experience working with Kubernetes.
Experience building and deploying AWS Lambda applications.",3.1,"Earnin
3.1","Palo Alto, CA","Palo Alto, CA",201 to 500 employees,2012,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Engineer (open level),"$43K-$69K
(Glassdoor est.)","Title
Data Engineer (open level)

07/08/2020

What you'll do...
At H&R Block, your contributions will go far beyond any job description. When you join our team, you'll add to the momentum of a forward-thinking company - one that defined an industry and is now leading its transformation.

H&R Block is transforming tax preparation through data to ensure that every client we serve gets the best tax outcome possible.

We are building a new Data Engineering Team in the Data Science & Analytics organization. This new team will own the technology and data capabilities of the end-to-end data-and-analytics function. It will take responsibility for building and maintaining the analytical technologies that the data science teams use, managing data at an enterprise scale, leveraging relationships with IT teams throughout the enterprise, and leading information architecture.

We are looking for talented, curious, and creative data engineers of all levels to help launch this team. You will be a good match for our organization if you are:
Motivated by the idea of building something innovative, transformative, and impactful.
Committed to the idea that data can drive experiences and products that wow our business partners and clients
Obsessed with defying expectations and raising the bar
Driven by an innate sense of ownership for the products you create.
Day to day, you'll...
Design and deploy architecture, solutions, and software to capture, manage, store, and use structured and unstructured data from internal and external sources in both on-prem and cloud environments.
Deploy machine-learning models and other data-science products across the enterprise.
Navigate the balance between business needs, data governance best practices, and technical requirements.
Select or develop tools to cleanse, organize, and transform data and to maintain, defend, and update data structures and integrity on an automated basis.
Develop data products to facilitate self-service capabilities and assist the data teams to increase their efficiency and effectiveness.
Collaborate and communicate effectively within cross-functional teams that span internal Data Science & Analytics teams, IT, business groups, and executive stakeholders.
Be a positive force to cultivate a culture that is passionate about developing data tools as a business driver.
Job ID
368348BR

Address1
ONE H&R BLOCK WAY

City
KANSAS CITY

State
Missouri

Employee Type
Regular

What you'll bring to the team...
Education / work experience should include most of these, depending on level:
Bachelor’s degree in Computer Science or a related technical field (or equivalent work experience and technical skills)
Data warehousing and ETL solutions
APIs in a microservices architecture
Big-data technologies and the Hadoop stack (MapReduce, Hive, Pig, Hbase
NoSQL implementations (MongoDB)
Developing Java-based software solution
At least one scripting language (Python, Perl, JavaScript, Shell
Developing software solutions to solve complex business problems
Working with data scientists and other data users
Posting Title
Data Engineer (open level)

Sponsored Job
#hrbjob

Job Family
Corporate Analytics",3.6,"H&R Block
3.6","Kansas City, MO","Kansas City, MO",10000+ employees,1955,Company - Public,Other Retail Stores,Retail,$2 to $5 billion (USD),"Intuit, Jackson Hewitt, Liberty Tax Service"
Senior Modeling & Simulation Engineer,-1,"Applied Research Associates, Inc. is looking for a Senior Modeling and Simulation Engineer to join our multi-disciplinary team of engineers and scientists in the Capital Area Division, located in Alexandria, VA. The ideal candidate has a passion for predicting the behavior of physical systems in challenging environments and operational impact on mission success. Models will be developed, used, and improved to support a Department of Homeland Security customer to safeguard the nation’s borders and interior from chemical, biological, radiological, nuclear, and explosive materials, equipment, technologies, and their actors. Models may be based on the underlying physics or may be process or agent based to predict operational performance and impact. Modeling and analysis may require the use and development of 3D virtual worlds or geospatial data. Models will be verified and validated, and they will be used in support of test and evaluation activities of systems intended to detect and identify threats. The candidate may participate in test and evaluation activities to support the verification, validation, and overall improvement of models. Models may become part of larger, integrated modeling and simulation activities, and may require the use of high performance computing technologies and federated simulations.

This position is contingent upon award of a contract expected in Summer 2020 supporting the Department of Homeland Security.

Required Qualifications:
Ability to program in a high level programming language, such as Fortran, C++, or Java
Eagerness to learn new tools and techniques
Strong verbal and written communication skills
Must be a U.S. Citizen with the ability to obtain and maintain a security clearance
Bachelor’s degree with minimum of 10 years of experience or greater in a physical science (physics, chemistry, biology), engineering-related discipline (nuclear, chemical, civil, mechanical, electrical), or modeling& simulation disciple (computer modeling, computational science, operations research)
Ability to present to senior leadership on the status and issues associated with research or test efforts in preparation for acquisition decision meetings
Desired Experience and Qualifications:
Experience modeling CBRNE detectors or effects
Experience using multiple software tools such as MCNP, GadRas, SWORD, ExtendSim, Arena, SolidWorks, Fluent, ArcGIS, QGIS, VisIt, ParaView, or Cubit
Experience creating 3D models of systems, i.e., CAD
Experience using high performance computers (i.e., supercomputers)
Experience developing and using discrete event or agent based models and simulations to predict and assess system performance
Experience developing machine learning models
Background in a physical science or engineering discipline, such as Physics, Chemistry, Biology, Mechanical Engineering, Nuclear Engineering
Active DoD Secret or Top Secret clearance, DoE Q clearance, or DHS Suitability
COMPANY INFORMATION:

Applied Research Associates, Inc. is an employee-owned international research and engineering company recognized for providing technically superior solutions to complex and challenging problems in the physical sciences. The company, founded in Albuquerque, NM, in 1979, currently employs over 1200 professionals. ARA offices throughout the United States and Canada provide a broad range of technical expertise in defense technologies, civil technologies, computer software and simulation, systems analysis, environmental technologies, and testing and measurement. The corporation also provides sophisticated technical products for environmental site characterization, pavement analysis, and robotics.

At ARA, employees are our greatest assets. The corporation realizes that employee ownership spawns greater creativity and initiative along with higher performance and customer satisfaction levels. ARA gives its employees the tools, training, and opportunities to take more active roles as owners. The culture is challenging; innovation and experimentation are the norm. Employees are eligible for contributions which not only add to the company’s success, but also their own through the Employee Stock Ownership Plan (ESOP). The motto,“Engineering and Science for Fun and Profit” sums up the ARA experience. For additional information and an opportunity to join this unique workplace, please visit our website atwww.ara.com.",3.5,"Applied Research Associates
3.5","Alexandria, VA","Albuquerque, NM",1001 to 5000 employees,1979,Company - Private,Federal Agencies,Government,$100 to $500 million (USD),-1
Senior Data Engineer,-1,"This is a Data Engineer position for supporting a Navy program located in Quantico, Virginia.

We are seeking a Data Engineer to join our team of committed technical professionals to protect those who serve against criminal, terrorism and emerging threats. Are you passionate about analytics and innovation? Our employees enjoy a fast-paced, collaborative culture and the ability to directly impact our business. You will identify technical issues and opportunities for efficiency and provide technical insights through system design and configuration perspectives. This role is both challenging and rewarding.

You will support the mission through the implementation of a modern, integrated internal data infrastructure with a focus primarily on exploiting the established data foundation to make internal and customer-centric business processes as effective and efficient as possible, laying the foundation for cognitive capabilities that can sense and respond to both internal and external customer data needs. The candidate will also focus on expanding the organization’s data ecosystem to include context-rich data while maintaining the agility needed to spark innovation.

How you will make a difference:
Establish shared operational data and integrated enterprise data, all while managing and/or improving data quality and security through the creation of business-driven governance structures and culture change management.
Establish data policies, standards, and procedures that improve data quality, availability, accessibility, security, usability, and enforcement of enterprise information management (EIM) program requirements.
Establish enterprise standards – including a uniform and repeatable system development lifecycle methodology for Reference Data and Master Data (e.g., a common set of standards for data naming, abbreviations, and acronyms).
Develop a Master Data Management (MDM) Plan that focuses on the technology, tools, and processes ensuring master data is coordinated across the enterprise. MDM is a method used to define and manage the critical data of an organization to provide, with data integration, a single point of reference. The data that is mastered may include reference data – the set of permissible values, and the analytical data supporting decision making. MDM provides a unified master data service intended to provide accurate, consistent and complete master data across the enterprise and to business partners.
Recommend solutions based on performing industry-specific analysis, such as case studies describing data management best practices, identifying trends across the industry.
Make recommendations to improve the efficiency and effectiveness in how the agency acquires, stores, manages, shares and applies its data.
Engage business users and stakeholders for the increased release of actionable high-quality data on key operational and tactical activities at NCIS.
Develop technology solutions to provide the platform, training, and standardized tools enabling querying, data mining, statistical analysis, reporting, scenario modeling, data visualization, and dash-boarding, and processes for a centralized, or analytics as a service model, allowing for the sharing of data across the enterprise from a common hub, facilitates cross-organizational data initiatives due to its enterprise-wide view of data assets and needs.
Basic Qualifications
Required: A bachelor’s or master’s degree in computer science, data science, operations research, statistics, applied mathematics, or a related quantitative field [or equivalent work experience such as, economics, engineering and physics] is [preferred/required]. Alternate experience and education in equivalent areas such as economics, engineering or physics, is acceptable. Experience in more than one area is strongly preferred.
Required: Three to six (midlevel) of relevant project experience in successfully launching, planning, and executing data science projects. Preferably in the domains of risk modelling and quality assessment.
Preferred: Specialization in text analytics, image recognition, graph analysis or other specialized ML techniques such as deep learning, etc.
Preferred: the candidates are adept in agile methodologies and well-versed in applying DevOps/MLOps methods to the construction of ML and data science pipelines.
Coding knowledge and experience in several languages: for example, R, Python, Java, C++, Excel, MATLAB, etc.
Experience with popular database programming languages including SQL, PL/SQL, others for relational databases and upcoming non-relational databases such as NoSQL/Hadoop-oriented databases such as MongoDB, Cassandra, others.
Preferred: Specialized/operational data scientists may need further high-performance computing (HPC)/compute skills; larger data science teams, in particular, may require further degrees of specialization such as:
Experience with distributed data/computing tools such as MapReduce, Hadoop, Hive, Kafka, and MySQL
Experience of working across multiple deployment environments including cloud, on-premises and hybrid environments, multiple operating systems and through containerization techniques such as Docker, Kubernetes, AWS Elastic Container Service, and others.
Experience in one or more of the following commercial/open-source data discovery/analysis platforms: RStudio, Spark, KNIME, RapidMiner, Alteryx, Dataiku, H2O, SAS Enterprise Miner (SAS EM) and/or SAS Visual Data Mining and Machine Learning, Microsoft AzureML, IBM Watson Studio or SPSS Modeler, Amazon SageMaker, Google Cloud ML, SAP Predictive Analytics.
Preferred: Expertise in solving vision, text analytics, credit scoring, and failure prediction problems.
Knowledge and experience in statistical and data mining techniques such as generalized linear model (GLM)/regression, random forest, boosting, trees, text mining, hierarchical clustering, deep learning, convolutional neural network (CNN), recurrent neural network (RNN), T-distributed Stochastic Neighbor Embedding (t-SNE), graph analysis, etc.
Strong documentation skills. Required: Certifications as per Cybersecurity Workforce Management and Qualification Manual, SECNAV M-5239.2.
Required: Eligible AND adjudicated to the Top Secret (TS SCI) clearance level is required to start.
About Inventium.io:

Inventium.io LLC is a technical consulting and software development services company dedicated to protecting and advancing our national defense and scientific capabilities. Based out of the Washington DC area, we rely on innovation to continually advance our employees' skills and provide digital transformation solutions to our customers.

With proven records of successfully delivering quality services and solutions to multiple federal agencies, our technical competencies include Emerging Technology Solutions, DevSecOps, Cloud Migration, Machine Learning, System Modernization, and Technology Management.

Benefits and Perks
Employer paid Health Benefits (Medical, Dental and Vision)
Retirement Plan
Paid Time Off and Federal Holidays
Training and Development
Employee Referral Program
Awards and Recognition",5.0,"inventium.io LLC
5.0","Quantico, VA","Washington, DC",1 to 50 employees,2016,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Senior Software Engineer,-1,"At Pacific Biosciences, our R&D team is committed to developing innovative products that enable scientists to excel in a wide variety of life science research fields, including human biomedical, plant and animal sciences, and microbiology and infectious disease. Our unique Single Molecule, Real-Time (SMRT) sequencing platforms generate true high-quality long reads, giving researchers a more comprehensive view of genomes, transcriptomes, and epigenomes from any organism.

The Primary Analysis group, as part of the larger software engineering team at PacBio, develops algorithms and HPC solutions for decoding the raw data streams, generated through high-speed optical detection of the SMRT sequencing reactions, into DNA sequence reads. We operate at the intersection of cutting-edge nanotechnology and state-of-the-art bioinformatics tools, and our responsibilities span the full product development life cycle in an aggressive time-to-market environment. These include analysis and algorithm development in coordination with chemistry and systems R&D; the development of real-time analysis pipelines; and the development of validation and support infrastructure geared towards product system reliability and internal R&D support. We are seeking a talented algorithm engineer with a strong background in the physical or machine-learning/data sciences who also has a passion for designing and developing performance-critical data analysis solutions.

Responsibilities:

Design, develop, and test signal- and sequence-analysis algorithms that will drive fundamental improvements in basecalling accuracy and yield.
Work collaboratively in a team environment to solve challenging problems in software architecture and scalability of real-time analysis pipelines for our next-generation sequencing platforms.
All listed tasks and responsibilities are deemed as essential functions to this position; however, business conditions may require reasonable accommodations for additional tasks and responsibilities.

Key Skills and Background:

3+ years of experience shipping product software in a scientific or quantitative domain.
Demonstrated skills applying numerical methods, statistical signal processing, or machine-learning techniques to high-throughput, performance-critical analysis applications.
Linux-based systems programming experience with knowledge of OS, toolchain and hardware constraints.
Strong C++ programming experience in applications geared towards performance and scalability; previous experience in CUDA programming for GPU is a plus.
MS, PhD or equivalent experience in a quantitative field (physics, CS, etc.), preferably with an applied math or algorithmic focus.
Engineering instincts to efficiently investigate and solve the problem at hand, from prototype development (Python, R, MATLAB, etc.) to production designs.
Team player, with strong communication skills, and comfortable as a self-starter in an agile, fast-paced development environment.
All qualified applicants will receive consideration for employment without regard to race, sex, color, religion, national origin, protected veteran status, or on the basis of disability, gender identity, and sexual orientation.",3.7,"Pacific Biosciences
3.7","Menlo Park, CA","Menlo Park, CA",201 to 500 employees,2000,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,$50 to $100 million (USD),Illumina
Senior Data Engineer,-1,"ABOUT 605

At 605 we are engineers, analysts, data scientists, media experts, marketing strategists and political operatives. Our team of data scientists pioneered the field of TV data analytics. We offer unique, independent audience measurement and analytics to build better marketing and programming initiatives within the media and entertainment industries.

The Sr. Data Engineer at 605 must have a broad and deep data skillset as well as strong analytical capabilities . In addition to being a hands on individual contributor, the ideal candidate is a productive team player and a mentor to Junior. Data Engineers. Additionally, we are looking for strong technical experts.

Responsibilities include:
Actively participate in team technical discussions in all things data
Identify and address issues with data sets from multiple vendors
Identify and address code and data quality issues
Actively participate in code reviews and grooming sessions
Actively participate in technology architecture discussions for product development
Translate business requirements into strategy
Advocate for software best practices within your team as well as across engineering
Be ultra-responsive and capable of making instant decisions, always kicking the ball forward
Work on unique and interesting data challenges around architecting, building and managing pipelines that securely process hundreds of terabytes of data
Work closely with analysts and statisticians to ensure the validity of our processes
Our engineers are expected to wear a number of hats and have the opportunity to touch all parts of the stack. Our stack includes Apache Spark, Scala, Redshift and an ever-growing list of many other cool technologies.

Requirements
Skillful user of Apache Spark
Experience wrangling terabytes of big, complicated, imperfect data
Experience with AWS products (Redshift, EMR, S3, IAM, RDS, etc)
You have a deep understanding of scalable systems and you have large-scale engineering experience in an Agile development environment
Bachelor's degree in Computer Science or a related field (or 4 additional years of relevant work experience)
A strong understanding of data structures, algorithms, and effective software design
Significant development experience with a major modern language (e.g. Java, Scala, Python, Ruby, C/C++, etc.)
Significant experience working with structured and unstructured data at scale and comfort with a variety of different stores (key-value, document, columnar, etc.) as well as traditional RDBMSes and data warehouses
Experience with or interest in AWS Glue, Redshift Spectrum and any other tools that enable data querying at scale
Experience writing unit, functional and integration tests
Comfort with version control systems (e.g. Git, SVN)
Excellent verbal and written communication skills; must work well in an agile, collaborative team environment
Preferred Qualifications
Master's in Computer Science or a related field
Practical experience with supervised machine learning techniques
Strong background with test-driven development
Basic understanding of statistics and experience with statistical packages such as R, Matlab, SPSS, etc
Benefits

Important and Standard
Comprehensive health, dental and vision insurance for employees and their families
Life & Disability insurance
401k plan with match, eligible for match after one year
Pre-tax flexible compensation plan for medical, transit, parking or dependent care expenses
Up to 15 paid vacation days depending on grade level
7 paid sick days in a calendar year - if you’re sick, you stay home
Other cool benefits
4 work from home days/month
A kitchen stocked with sodas, snacks, yogurt and other goodies
A tight knit start up community who likes to eat! We celebrate everyone’s birthdays, have frequent team lunches, and do events in and out of the office
605 is an active participant in conferences
EEO STATEMENT

At 605, we’re just as passionate about diversity as we are about pioneering the field of TV data analytics. We are committed to cultivating an environment of mutual respect and equal opportunity. All hiring and advancement decisions are made on the basis of qualification, merit, and business need.",-1,605,"New York, NY",-1,-1,-1,-1,-1,-1,-1,-1
Sr Innovation Engineer,"$75K-$134K
(Glassdoor est.)","Company Information

Solid reputation, passionate people and endless opportunities. Thats Travelers. Our superior financial strength and consistent record of strong operating returns mean security for our customers and opportunities for our employees. You will find Travelers to be full of energy and a workplace in which you truly can make a difference.

Target Openings

1

Job Description Summary

Innovation is at the core of everything we do. We continue to ask ourselves, whats next? as we navigate the ever-changing insurance landscape. Continuing our customer journey toward the cutting-edge, we are looking for a forward-thinking individual that thrives in ambiguity, who believes that with every challenge comes a new opportunity for solutions.

As a member of the Innovation Technology team, you will partner with research scientists and product managers to discover, invent, and build solutions at scale. As a team, you will work on challenges in machine perception, data mining, machine learning, and natural language understanding.

We are looking for a hands-on individual with strong foundational knowledge highly scalable architectures and platforms. If you like using a variety of skills in technology and solving complex problems, work collaboratively in a small agile team environment, you might just be the person we need on our team!

Primary Job Duties & Responsibilities
Work closely with Cloud Engineering to build an innovation platform; a collection of reusable and extensible containers and tools specific to developing insurance products and platforms.
Recommend integration strategies, enterprise architectures, platforms and application infrastructure required to successfully implement a complete solution using best practices.
Produce quality output for highly visible IT products, services and future business development.
Assist in hands-on remediation of application stability and performance.
Adopt and communicate new concepts, ideas, techniques.
Manage multiple projects simultaneously.
Provide 'Shrink Wrap' solutions to solve business and technical needs. As part of our innovation process, be able to scale Minimum Viable Product to production systems.
Design and lead integration of analytic data products, including pilots and proof of concepts.
Frequently present and translate complex information in relevant business terms.
Constantly learn new skills within small teams.
No direct HR people management but will lead teams in project & program contexts.
Education, Work Experience, & Knowledge
Bachelors Degree in STEM (Science, Technology, Engineering, Mathematics) related field and 3+ years of experience or 10+ years of experience building highly scalable platforms and reusable components
Job Specific Technical Skills & Competencies
2+ years of experience working with Amazon Web Services (AWS) or equivalent cloud. Must be recent experience.
5+ years of designing and developing on-premise and cloud solutions.
3+ years of experience as a technical lead.
Experience in software engineering with relevant technologies (Java, JavaScript, Python etc.).
Experience with the application delivery process.
End-to-end experience with data, including querying, aggregation, analysis, and visualization.
Preferred Qualifications
AWS certified developer and/or architect
Proven ability to work creatively and analytically in a continuously evolving environment.
Exhibits high levels of learning agility in which they seek out and learn from unfamiliar experiences and then apply those lessons to succeed in the next new situation.
Ability to leverage business knowledge to determine approaches to execution.
Strong communication and presentation skills with the ability to present and translate complex information to leadership and non-technical teams in relevant business terms.
Uses effective listening skills and communication to build relationships across the organization.
Ability to Influence with experience working with matrixed staff to complete tasks in a timely manner.
Environmental / Work Schedules / Other
Travel Required
Equal Employment Opportunity Statement

Travelers is an equal opportunity employer.",4.1,"Travelers
4.1","Hartford, CT","Hartford, CT",10000+ employees,1853,Company - Public,Insurance Carriers,Insurance,$10+ billion (USD),-1
Senior AI Software Engineer,-1,"Company Overview

Calling the adventurers ready to join a company that's pushing the limits of nanotechnology to keep the digital revolution rolling. At KLA, we're making technology advancements that are bigger—and tinier—than the world has ever seen.

Who are we? We research, develop, and manufacture the world's most advanced inspection and measurement equipment for the semiconductor and nanoelectronics industries. We enable the digital age by pushing the boundaries of technology, creating tools capable of finding defects smaller than a wavelength of visible light. We create smarter processes so that technology leaders can manufacture high-performance chips—the kind in that phone in your pocket, the tablet on your desk and nearly every electronic device you own—faster and better. We're passionate about creating solutions that drive progress and help people do what wouldn't be possible without us. The future is calling. Will you answer?

Responsibilities

Group/Division
KLA has always had a close relationship with physics and data. Our optical and electron beam inspection and measurement tools use cutting edge physics models, both for hardware design and as part of their algorithms. AI, including several traditional machine learning techniques and deep learning are routinely used to process this data to meet application requirements.

The AI & Modeling Center of Excellence, centered in KLA’s R&D facility in Ann Arbor, MI, was setup with the mission of advancing KLA’s traditional strengths in physics and data and providing implementation solutions for multiple KLA Inspection and Metrology products targeted at the semiconductor manufacturing industry.

As a part of this group, you will be part of a world class team of physicists, HPC system designers, machine learning and application engineers who build cutting edge solutions for modeling complex imaging techniques and semiconductor processes. You will also work with a data scientists and AI infrastructure engineers whose mission is to build and scale machine learning based solutions for our semiconductor customers.

We are looking for engineers in a few different fields. If you are passionate about Physics Modeling, High Performance Computing - HPC (including GPU), ML, Data, or Cloud technologies – this is the place for you!

Responsibilities:
Software Engineers in the AI and Physics Modeling team may work on a variety of tasks including platform for large scale experimentation, scaleout of physics models, data management and inference solutions for KLA products.

Although familiarity with Machine Learning and Deep Learning solutions would be a big plus, this is primarily a Software Engineering position. Successful candidates are passionate about software, and will have exceptional skills and hands on experience with development in C/C++ and Python in a Unix environment. Deep conceptual understanding of multi threaded and multi process software systems is also necessary.

In addition to the above fundamental software skills, any of the following technical hands-on skills are highly desirable.

1) System Programming and Operating Systems.
2) Distributed systems for data management.
3) Distributed computing infrastructure.
4) Cloud technologies for storage, containerization and compute clusters.
5) Data Structures and algorithms
6) GPU architectures and data management.
7) Traditional machine learning using Random Forest, XG Boost, Logistic Regression.
8) Deep Learning for regression, classification. Generative models.
9) TensorFlow, NumPy, scikit-learn, and other ML and DL frameworks.
10) MPI and similar distributed computing framework.
11) GPU Architectures and CUDA (CuGraph, CuData, CuML etc).
12) GO Systems Programming, Java Programming.

Successful candidates for this position will also demonstrate the following non-technical skills.

1) Capability to formulate creative solutions through analyzing complex data
2) Good communication skills
3) Strong team player and motivated by team success
4) Strong problem solving skills

Minimum Qualifications

Doctorate (Academic) with at least 2 years of experience.
OR
Master's Level Degree with at least 4 years of experience.
OR
Bachelor's Level Degree with at least 5 years of experience.

Equal Employment Opportunity

KLA is an Equal Opportunity Employer. Applicants will be considered for employment without regard to age, race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability, or any other characteristics protected by applicable law.",3.8,"KLA-Tencor
3.8","Ann Arbor, MI","Milpitas, CA",5001 to 10000 employees,1976,Company - Public,Industrial Manufacturing,Manufacturing,$2 to $5 billion (USD),"Applied Materials, Nanometrics"
"Senior SDE, Catalog Big Data and Machine Learning",-1,"Amazon's Catalog DataWorks team is looking for highly motivated engineers. We are embarking on multiple new initiatives to re-organize Amazon's catalog of billions of products, in new and interesting views, that drive several features Amazon's customers love. Today, these views drive hundreds of popular features like product recommendations, clustering of similar products, and shopping with Alexa. We will build a new near real-time Catalog Data Lake on AWS, to enable engineers and scientists across Amazon to solve customer problems faster. Come join us on this exciting journey!

As an engineer on this team, you will own the Catalog Data Lake end-to-end. You will work closely with business partners to synthesize technical requirements. You will design and implement significant parts of the platform. You will learn and use industry standards like Spark and Parquet as well as modern AWS offerings like EMR, Glue, Athena, and Redshift. We are fortunate to be at the cusp of innovation in both the e-commerce business as well as cloud technology. As a key stakeholder, you will constantly learn new patterns, solve key customer problems and strive to make AWS better along the way.Basic Qualifications
Bachelor's degree or higher in computer science or math is required.
Strong computer science fundamentals - algorithms, data structures and design patterns.
At least 8 years of software development experience.
At least 3 years of experience building and operating Big Data systems.
Experience mentoring, guiding and influencing peers.
Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.",-1,Amazon Corporate LLC,"Seattle, WA",-1,-1,-1,-1,-1,-1,-1,-1
SENIOR SOFTWARE ENGINEER & SOFTWARE ARCHITECT,-1,"Job Description
Senior Software Engineer, Software Architect
JOB SUMMARY

The Senior Software Engineer, Software Architect will develop software for Company innovative semiconductor X-Ray inspection system. The Senior Software Engineer will collaborate with Applications, QA, and Algo teams for high performance solutions and optimization per customer issues. It will be important to be comfortable working in a small company environment and a typical startup with engineers and scientists.

ABOUT THE CLIENT

Based in San Jose, California, client was founded in 2013 expressly to bring high speed inspection and metrology technology to the semiconductor packaging industry. Client founders anticipated the need to deploy inline 100% transmissive inspection into the semiconductor packaging manufacturing process and developed the company’s technology with this end in mind. The results, Client’s HR-AXI technology suite brings together the company’s unique data acquisition architecture with proprietary machine learning analysis techniques to provide customers with process monitoring and defect detection capabilities not found on any other products in the market. This job description can be updated at any time.

RESPONSIBILITIES
Designs, develops, troubleshoots, and debugs software programs for enhancements and new products, focused on creating high quality and high-performance solutions while maintaining high-level coding standards.
Develops software and tools in support of design, infrastructure, and technology platforms. Develops software solutions by studying information needs, conferring with users, and studying systems flow, data usage, and work processes
Supports hardware compatibility and/or influences hardware design based on software needs; work as part of cross-functional team to solve and implement system level problems.
Monitor application stability, performance, and availability. Promptly resolve issues impacting operations.
Work with engineering, documentation, and applications departments to ensure successful development and delivery of overall product.
Provide appropriate project feedback to management in a timely and appropriate format.
QUALIFICATIONS AND REQUIRED SKILLS
Education requirement: Bachelor’s degree in Computer Science, Electrical Engineering, or similar technical field required. Master’s or PhD strongly preferred.
Experience requirement: Minimum of 8 years of related experience working in software development.
Strong expertise in C# .NET. WCF, WPF, Database development. In addition, Python experience a plus.
Experience with Image processing algorithms implementations is a plus
Experience with software development for Factory Automation for Semiconductor equipment, a plus.
Self-starter able to think and act independently to translate general objectives into tangible results, with a record of delivering successful designs on schedule.
Demonstrated ability to organize, manage, and complete multiple assignments with challenging timelines independently and effectively.
Demonstrated analytical and problem-solving skills with high attention to detail.
Proactive approach to problem-solving. Build relationships with stakeholders to support successful design, build and testing.
Strong verbal and written communication, good attitude, and work ethic. Ability to communicate technical concepts and results clearly.
Experience with Git and Azure DevOps, a plus.",3.0,"Simple Solutions
3.0","San Jose, CA","Morgantown, WV",1 to 50 employees,2006,Company - Private,IT Services,Information Technology,Less than $1 million (USD),-1
Cloud Engineer,-1,"Job Description
Responsibilities:
Develop and implement technical efforts to design, build, and deploy AWS applications at the direction of lead architects, including large scale data processing, computationally intensive statistical modeling, and advanced analytics
Participate in all aspects of the software development life cycle for AWS solutions, including planning, requirements, development, testing, and quality assurance
Provide guidance, thought leadership and mentorship to development teams to build cloud competencies
Provide innovative thought leadership around Mathematica’s cloud solutions strategy and approach, including AWS best practices and market trends
Position Requirements:

6+ years of experience architecting, designing, developing and implementing cloud solutions on AWS platforms
Demonstrated experience with designing and implementing solutions using AWS platform and tools, such as: EC2, S3, Redshift, API Gateway, Lambda, DynamoDB, CloudFormation, RDS, VPC, IAM and security, QuickSight, CloudTrail, Config, CloudWatch, SNS, AMI generation
Understanding of and experience with the five pillars of a well-architected framework
Knowledge of SQL, R, and Python for data manipulation and statistical analysis is desirable
Familiarity with federal security regulations and standards (e.g. HIPAA, FISMA, FIPS, NIST, and FedRAMP)
Experience with security, especially knowledge of FedRAMP, HIPAA, PII/PHI, is desirable
Experience in several of the following areas: database architecture, ETL, Business Intelligence, Big Data, Machine Learning, Advanced Analytics
Proven ability to work collaboratively with multi-disciplinary teams of business analysts, developers, data scientists, and subject matter experts
Strong written, verbal and interpersonal communication skills
AWS Certifications (such as AWS solutions architect or other specialty certifications) are a plus
Bachelor's degree or equivalent combination of education and experience; degree in computer science, mathematics or related field preferred
Experience with other cloud platforms like Google Cloud Platform (GCP) is a plus",4.8,"RICEFW Technologies Inc
4.8","Princeton, NJ","East Lansing, MI",51 to 200 employees,2009,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Senior Software Engineer / Team Lead,"$112K-$220K
(Glassdoor est.)","Join our team dedicated to developing and executing innovative solutions in support of customer mission success.

Job Description:

Novetta has an exciting opportunity for a self-motivated and accomplished Computer Scientist to lead our entity analytics team. You will work on complex projects involving data analysis, software engineering, and deploying software in a cloud computing environment. The team combines data from disparate sources to visualize the complex relationships between entities. This effort involves large scale data integration and entity resolution leveraging a best in class Novetta product. We are looking for a flexible problem solver with significant technical experience to lead a team providing unique solutions for our customers and stakeholders.

Responsibilities include:
Lead a technical team of software engineers and computer scientists, working within a larger ecosystem delivering an Enterprise capability.
Navigate customer and prime environment, manage resources within and across team, and assist team with professional and technical growth.
Deploy applications on a large-scale data processing cluster using AWS technologies.
Design and implement entity correlation strategies that are tailored to mission needs and unique data qualities.
Develop algorithms and visualization tools to help stakeholders understand their data and prioritize new data sources.
Develop and integrate applications to automate ingestion, processing and monitoring of data
Develop and maintain tools to support operations and maintenance of production and development computing clusters.
Basic Qualifications:
Experience leading a team of software engineers.
A Bachelor's degree in computer science or related field and a minimum of 5 years of experience; or a Master's degree in computer science or related field and a minimum of 3 years of experience.
Experience in software development/engineering including requirements analysis, software development, installation, integration, evaluation, enhancement, maintenance, testing and problem diagnosis/resolution.
Software development experience on Linux-based systems in Python or shell scripting or JavaScript.
Experience developing against full-featured REST APIs and using a command line interface
Desired Skills:

Should meet a minimum of 3:
Software development experience with JavaScript, Python, or other modern programming languages.
Hands-on experience with Spark.
Experience working with Databricks
Interest in statistical analysis, machine learning, or data science.
Experience with entity resolution products or a background in data matching theory and technologies.
Experience developing applications in AWS.
Security Clearance:
The candidate must have a TS/SCI with Poly.
Novetta, from complexity to clarity.

Novetta delivers highly scalable advanced analytics and secure technology solutions to address challenges of national and global significance. Focused on mission success, Novetta pioneers disruptive technologies in machine learning, data analytics, full-spectrum cyber, cloud engineering, open source analytics, and multi-INT fusion for Defense, Intelligence Community, and Federal Law Enforcement customers. Novetta is headquartered in McLean, VA with over 1,000 employees across the U.S.

Our culture is shaped by a commitment to our core values:

Integrity • We hold ourselves accountable to the highest standards of integrity and ethics.

Customer Success • We strive daily to exceed expectations and achieve customer mission success.

Employee Focus • We invest in our employees' professional development and training, respecting individuality and fostering a culture of diversity and inclusion.

Innovation • We know that discovering new and innovative ways to solve problems is critical to our success and makes us a great company.

Excellence in Execution • We take pride in flawless execution as we build a company that is best in class.

Earn a REFERRAL BONUS for the qualified people you know.

For more details, or to submit a referral: bit.ly/NovettaReferrals

Novetta is an equal opportunity/affirmative action employer.

All qualified applicants will receive consideration for employment without regard to sex, gender identity, sexual orientation, race, color, religion, national origin, disability, protected veteran status, age, or any other characteristic protected by law.",4.5,"Novetta
4.5","Chantilly, VA","Mc Lean, VA",501 to 1000 employees,2012,Company - Private,Enterprise Software & Network Solutions,Information Technology,$100 to $500 million (USD),"Leidos, CACI International, Booz Allen Hamilton"
Data Fusion Engineer with Security Clearance,"$48K-$109K
(Glassdoor est.)","Description Job Description: Looking for work-life balance? Leidos offers generous leave and accommodating flex-time to help you juggle your personal and professional life. Are you a Software Engineer with experience finding and aligning signals across multiple modalities (image, video, audio, lidar, etc..)? Do you want to implement and customize algorithms to fusion multiple data modalities? If so we are looking for you, our next Data Fusion Engineer to work in Arlington, VA. We need you to be competent in Python and have the ability to read code in other programming languages like Java and C++ as well as have experience working with ML libraries like SciKit Learn, TensorFlow, Keras along with experience implementing solutions with those libraries on both CPU and GPU compute architectures. Like what you are reading so far? Keep going. We want you to be intellectually adaptive, inquisitive, good at expressing your needs, and able to self-manage when necessary. Work alongside software/system engineers and research/data scientists with expertise in multi-modal information retrieval, UI development, computer vision, metrics, information science, artificial intelligence, and autonomous systems. The Department of Defense and the Intelligence Community will be the main recipients your hard work. Fun stuff you will do on the job: - Use cases requiring identifying entity/objects, determining object association, object disambiguation, anomaly detection, state estimations, etc.
Develop and maintain data models (both physical and logical)
Get to be responsible for extraction, transform, and load (ETL) tasks related to the different modalities and algorithms being applied. This data ETL includes identifying the data's relevant metadata to ensure consistency, quality, accuracy, integrity, and information assurance and security.
Performing anomaly detection using various AI/ML techniques
Use algorithms to identify complex patterns across multiple modalities
Increasing the efficiency and quality data alignment and fusion
Enhance and maintain analysis tools, including automation of current processes using AI/ML algorithms
Conduct quantitative data analysis including developing retrieval, processing, fusion, analysis, and visualization of various datasets Skills required to be successful in this role: - Bachelor's Degree in Aerospace Engineering, Computer Science, Mathematics, Statistics, Physics, Electrical Engineering, Computer Engineering or related fields with 5 years of relevant experience
Must be able to obtain and maintain a TS/SCI security clearance
Experience with Deep Learning Frameworks such as Keras, Tensorflow, PyTorch, Mxnet, etc. - Ability to apply these frameworks to real problems in the 'time -series' domain
Experience with interpretability of deep learning models
Big Data Skills (Azure, Hadoop, Spark, recent deep learning platforms)
Practical experience with statistical analysis
Experience with text mining tools and techniques including in areas of summarization, search (e.g. ELK Stack), entity extraction, training set generation (e.g. Snorkel) and anomaly detection
Expert software development skills lifecycle including developing and maintaining good production quality code
Hands-on Software Development Skills (Python-Preferred)
Experience or educational courses/projects in Machine Learning, and/or Text Mining Algorithms You will wow us even more if you have these skills: - Visualizations/Web Development Skills (e.g. Tableau, D3, etc).
Hands-on experience with prototype development
Hands-on experience with automating data cleansing, formatting, staging, and transforming data human
Hands-on experience applying data analytics
Hands-on experience with intelligent systems and machine learning LInC External Referral Bonus: Ineligible Potential for Telework: No Clearance Level Required: Top Secret/SCI Travel: Yes, 10% of the time Scheduled Weekly Hours: 40 Shift: Day Requisition Category: Professional Job Family: Software Engineering Leidos Leidos is a Fortune 500® information technology, engineering, and science solutions and services leader working to solve the world's toughest challenges in the defense, intelligence, homeland security, civil, and health markets. The company's 33,000 employees support vital missions for government and commercial customers. Headquartered in Reston, Virginia, Leidos reported annual revenues of approximately $10.19 billion for the fiscal year ended December 28, 2018. For more information, visit www.Leidos.com . Pay and Benefits Pay and benefits are fundamental to any career decision. That's why we craft compensation packages that reflect the importance of the work we do for our customers. Employment benefits include competitive compensation, Health and Wellness programs, Income Protection, Paid Leave and Retirement. More details are available here . Securing Your Data Leidos will never ask you to provide payment-related information at any part of the employment application process. And Leidos will communicate with you only through emails that are sent from a Leidos.com email address. If you receive an email purporting to be from Leidos that asks for payment-related information or any other personal information, please report the email to [email protected] . Commitment to Diversity All qualified applicants will receive consideration for employment without regard to sex, race, ethnicity, age, national origin, citizenship, religion, physical or mental disability, medical condition, genetic information, pregnancy, family structure, marital status, ancestry, domestic partner status, sexual orientation, gender identity or expression, veteran or military status, or any other basis prohibited by law. Leidos will also consider for employment qualified applicants with criminal histories consistent with relevant laws.",3.5,"Leidos
3.5","Arlington, VA","Reston, VA",10000+ employees,1969,Company - Public,Aerospace & Defense,Aerospace & Defense,$10+ billion (USD),-1
Software Engineer,"$64K-$132K
(Glassdoor est.)","Every Analyst a Scientist - One of our primary goals is to empower intelligence analysts to be able to study their data like scientists. The tools we develop focus on streamlining intelligence analysis through integrated algorithms and software that provide insight into the geopolitical landscape for use in operational intelligence missions around the world.

The Role:
As a Software Engineer, you will be part of a team that transforms large and complex customer data into real-world, high-impact solutions. You will work with researchers and engineers to design and implement solutions to challenging national security problems. You will be responsible for building the software infrastructure to clean, ingest, and expose datasets and algorithms to both developers and end users. You will deploy algorithms, generate workflows, create engineer-facing tools, and design customer-facing prototype systems. You will occasionally travel to customer sites to engage with end users, demonstrate prototypes, and integrate analytics into customer systems.

If you would like to help intelligence and defense analysts keep pace with technology-driven innovation, then this role is for you!

Who you are:
A U.S. Citizen with the ability to obtain a Security Clearance
A degree in a scientific or engineering field, such as Computer Science, Mathematics, Physics, or Software Engineering
Proficiency with a scientific programming language such as Python, Java, or C++
Experience with database management and common query syntax
Motivated collaborator and excellent communicator of ideas to both technical and non-technical audiences
Knowledge of AWS, Spark, Dask, and/or similar technologies for working with data at scale
Even better:
Active Security Clearance
Track record of architecting, developing, deploying, or maintaining enterprise software
Experience with software development best practices and tools
Understanding of web development and visualization technologies, such as d3, Leaflet, Bootstrap, or others
Familiarity with machine learning or statistical modeling techniques",4.5,"Systems & Technology Research
4.5","Woburn, MA","Woburn, MA",201 to 500 employees,2010,Company - Private,Aerospace & Defense,Aerospace & Defense,$100 to $500 million (USD),-1
Sr. Data Scientist,-1,"Background Information:

Innovative Defense Technologies (IDT), provider of automated software testing, data analysis, and cybersecurity solutions for complex defense systems, is currently accepting applications for an anticipated Sr. Data Scientist role requiring 7+ years of experience for a position in support of its efforts implementing Artificial Intelligence solutions for a variety of customers.

Overview:

The Sr. Data Scientist position offers an engineer the opportunity to utilize his/her knowledge and talents as part of a collaborative team developing AI solutions for a growing company. A few of the responsibilities include supporting feasibility studies, applying modern data storage techniques, discovering explanatory features in high-dimensionality collections of data, and exploring data using scientifically valid techniques to exploit patterns found in the data with state-of-the-art AI/ML/DL solutions.

All applicants must be able to obtain/maintain an active U.S. Security Clearance.

Responsibilities Include:
Lead development of solutions to deliver AI/ML/DL models from problem formulation to a productized, deployable, maintainable capability
Contribute to AI/ML/DL technical roadmap development
Use Deep Learning frameworks such as Tensorflow and Keras to build and validate ML/DL models
Establish and leverage Big Data frameworks to store, extract and analyze relevant data
Ensure development of software solutions meets customer needs and program intent
Work closely with the Program Manager and Chief Engineer to design and implement software requirements and solutions
Determine operational feasibility by evaluating analysis, problem definition, requirements, solution development, and proposed solutions for large, complex systems
Be responsible for a team’s products meeting software design, quality, and performance requirements
Pursue new technology development via the DoD Small Business Innovative Research (SBIR) program
Work with minimal supervision in a collaborative work environment to implement best-in-class solutions
Minimum Required Qualifications:
Bachelor’s Degree in Computer Science, Computer Engineering, Electrical Engineering, Systems Engineering, Physics, or Math Required; PhD in relevant field highly preferred
7+ years of experience in predictive modeling, data science and analysis
Required Skills:
Previous experience in a ML or data scientist role and a track record of building ML or DL models
Extensive experience working with data mining algorithms including decision trees, probability networks, association rules, clustering, and neural networks
Experience using Python (or equivalent)
Experience using ML libraries, such as scikit-learn,
Experience using data visualization tools
Experience handling terabyte size dataset
Experience working with GPUs to develop models
Ability to travel 10% or less
Preferred Skills:
Experience with MapReduce programming (Hadoop)
Skills with programming languages, such as Java or C/C++
Demonstrated ability to develop experimental and analytic plans for data modeling processes, use of strong baselines, ability to accurately determine cause and effect relations
Consulting experience and track record of helping customers with their AI needs
Publications or presentations in recognized Machine Learning, Deep Learning and Data Mining journals/conferences
Combination of deep technical skills and business savvy enough to interface with all levels and disciplines within our customer’s organization
Experience diving into data to discover hidden patterns
Experience with application container platforms
Familiarity with continuous integration/delivery tools (e.g. Jenkins)
Familiarity with version control tools (e.g. Subversion, Git, etc.)
Familiarity with VMware or other virtualization software
Experience developing applications for DOD command and control systems
Competencies:
Solid analytical abilities, coupled with a strong sense of ownership, urgency, and drive
Attention to detail
Initiative, creativity, reliability, teamwork
Ability to deal well with ambiguity, prioritize needs, and deliver results in a dynamic environment
EEO Statement:

IDT is an Equal Opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, creed, sex, sexual orientation, gender identity, national origin, disability, protected Veteran status, or any other basis protected by federal, state, or local law.",-1,Innovative Defense Technologies (IDT),"Mount Laurel, NJ",-1,-1,-1,-1,-1,-1,-1,-1
Full Stack Software Engineer (Python/Vue),-1,"Position Summary Full Stack Software Engineer (Python VueJS) Company Overview Our client is an automated underwriting platform for real estate professionals that was built to disrupt the commercial real estate industry. The software allows investors, brokers, and lenders to analyze rent, operating expenses and returns for multifamily properties by applying machine learning to a database of live multifamily transaction data from every U.S. market. Our client has a creative and entrepreneurial culture ndash everyone on the team interacts directly with customers each day, and we all contribute to the product and planning. If you have an idea to improve something, there is no red tapehellip just build what needs to be built! Innovation and passion for transforming the old-fashioned real estate industry are our highest priorities. Job Description As a full-stack (Python, PostgreSQL and HTMLCSSJavaScript) developer, you'll work on the interface and backend infrastructure of products and features used by hundreds of underwriters and real estate analysts every day. The work is challenging, fast-paced, and always changing. You must have demonstrated analytical skills, an unwavering commitment to quality, a collaborative work ethic, and cutting-edge coding skills. You must display solid proficiency in the fundamentals of Python, PostgreSQL, JavaScript, HTMLCSS, and popular front-end frameworks like Vue.js. The role will include the delivery of reliable, scalable new features to users, developed in Python, interacting with a PostgreSQL database and using the Vue.js frontend framework. You will work with the development team to develop, test and deliver finished, high quality, compelling features and products. Our team includes designers, engineers and data scientists who are passionate about quality, usability, and simplicity. If you are ready to join a company that fosters learning, growth, experimentation and innovation, our client's team is for you. Requirements Qualifications 3-5 years of experience in full stack Python development 1-3 years of experience with PostgreSQL 1-3 years of experience with JavaScript frameworks such as React, Angular or Vue.js (Vue.js is preferred, this is what our client uses), and CSS pre-processing frameworks (Sass or Less) 1-2 years of experience integrating with VBA and Excel integration preferred Experience using GitHub and solid understanding of software version control Familiarity with JIRA or equivalent product management software Familiarity with agile development best practices Driven self-starter able to work on a small team and take initiative on new tasks Familiarity with real estate or finance is a plus Responsibilities Collaborate with interdisciplinary team of data scientists, software engineers and real estate professionals Strive for high quality and rapid output utilizing agile development best practices Support, maintain, and document software functionality Maintain industry standard coding, compliance, security practices Proactively learn product frameworks and code base Our client is a startup company, and as such the responsibilities outlined above may change and evolve over time. Flexibility, curiosity, an entrepreneurial mindset, and strong work ethic are essential for this role. It is encouraged that everyone on the team continually research new technologies and analytical opportunities to improve the platform.",5.0,"CultureFit
5.0","Chicago, IL","Deerfield, IL",1 to 50 employees,1997,Company - Private,Advertising & Marketing,Business Services,$1 to $5 million (USD),-1
AWS Data Engineer,-1,"About Infinitive:

At Infinitive, we do mission-critical work for great companies. We specialize in digital marketing and digital advertising solutions, customer data & analytics, digital & business transformation, and Technology solutions. Our Technology solutions focus on Managed Cloud Services, Cloud Enablement, Digital Operations, Application Development, DevOps, Product Development, Cloud Security, Data Science and Analytics, AI/ML, IoT, and everything in between.

Our experts are results-obsessed, focused and flexible, highly engaged and hugely experienced having sat in our clients seats. Those qualities are what make us different than old-school consulting shops. And surely, they are why clients and partners describe us as the gold standard in client experience.

Infinitive has been named a Best Small Firms to Work For by Consulting Magazine seven times, a Washington Post Top Workplace three times, a Washington Business Journal Best

About this Role:

Infinitive is growing its team in the Northern Virginia area and is currently seeking an Data Scientist to join our growing Technology practice. This person will utilize their experience in analytics, IoT, machine learning, and artificial intelligence advances to create value from structured and unstructured data. The ideal candidate has experience designing novel data analytic methods and workflows, including full data pipelines from raw data through analysis results. They must also have exposure to a variety of data mining/data analysis methods, data tools, building and implementing models, using/creating algorithms, and creating/running simulations.

We are looking for candidates who are accountable, passionate, assertive, proactive, open & honest, results oriented, and adaptable. Each project engagement represents a new challenge that will give you exposure to new clients, business issues, technologies, and people and will involve a range of responsibilities to include:
Developing in Java, Python, R, or other high-level languages.
Managing disparate data sources with varying data structures of content and preparing these for data science and machine learning applications.
Working with distributed scalable Big Data storage, processing, and computation, including AWS EMR, Spark, etc.
Implementation knowledge of, or desire to learn AWS / Azure data science capabilities.
Developing solutions and integrating and extending free and Open-source software (FOSS) or COTS products.
Conduct MapReduce programming with Apache Hadoop, the Hadoop Distributed File System (HDFS), and processing large data stores.
Knowledge of SQL and query languages.
Utilize real-time, large-scale data processing engine, including Apache Spark.
Lead and create Data Science and Analytics methodologies and frameworks for implementation.
Ability to build and develop Data Science demonstrations for clients
Qualifications:
4+ years of development experience (Java, Python, R, SQL)
3+ years of experience with distributed scalable Big Data storage, including AWS EMR, Spark, etc.
Desire to become AWS / Azure Certified architect / engineer.
Experience performing data Management, modeling, and warehousing.
Hands on experience with Amazon analytic tools (preferred)
Interest in being involved internally and growing a small business (entrepreneurial spirit)
Ability to travel (up to 20%) and to work independently
Experience using Agile software development methods in a DevOps environment.
Excellent leadership, peer management, and communication skills
Management consulting experience (preferred)
Bachelor's degree in related field (preferred)
Applicants for employment in the U.S. must possess work authorization which does not require sponsorship by the employer for a visa.

Infinitive is an Equal Opportunity Employer.

Powered by JazzHR",3.4,"Infinitive Inc
3.4","Arlington, VA","Cedar Rapids, IA",201 to 500 employees,1997,Company - Private,Enterprise Software & Network Solutions,Information Technology,$10 to $25 million (USD),-1
"Senior SW Engineer, Data Science ( Kubernetes/ Docker ) Remote USA","$72K-$141K
(Glassdoor est.)","If you dream of a job working in a field where all the hard problems are solved and you get to re-use previous research to get your job done, you need not apply. If, however, you are someone who wants to tackle problems that truly are on the cutting edge, then we encourage you to keep reading.

Data Science is an emerging field within cyber security. FireEye, given its deep expertise and comprehensive view on the advanced threat landscape, is uniquely positioned to enable data scientists to have major impact within our industry, company, and across our customer base. Detecting security breaches using machine learning and data analytics is an unsolved problem (this is not handwriting recognition folks) and has huge potential.

If you are someone who wants to be on the cutting edge of a high profile industry, who wants to make an impact by pushing both fields of data science and cyber security forward, you may be the perfect candidate to help us on our mission.

What you will do:
Develop, and manage data systems to ingest and process data at massive scale
Identify data sources both internally and externally that we can use to find evil.
Contribute towards the architecture and design of software solutions for long-term storage and retrieval.
Identify and implement data exploration technologies. Create dashboards and implement analytical tools for exploration
Work with data scientists to productize ML models and assist product teams with ML model releases into end products.
Collect requirements, design, and build backend components and tools to run ML models, assess ML model efficacy, manage large scale datasets, and generate features for ML models
Contribute to the evolution of coding and design practices within the organization.
Review code base commits and contribute to the growth of team members.
Requirements
Ability to work in an iterative, agile development environment.
Experience implementing ETL processes and building data pipelines
Experience developing reliable distributed systems.
Experience in Data modeling and schema design
Strong knowledge of a variety of operating systems, networking fundamentals, software design and programming best practices.
Experience with use of a wide array of algorithms and data structures.
Deep understanding and experience of going through the entire life cycle of building software platforms and products
Deep knowledge of various AWS services and associated tools
Strong experience developing in Python 3
Experience developing in at least 1 of the following: C, Go or Java
Experience with RDBMS, such as PostgreSQL or MySQL, as well as NoSQL
Experience with Kubernetes and Docker.
Experience deploying products in AWS
Additional Qualification: *
Ability to pick up, work with and explore new analytical tools
Strong experience with DevOps practices and common tooling
Strong communication skills.
Ability to work with loosely defined requirements.
At FireEye we are committed to our #OneTeam approach combining diversity, collaboration, and excellence. All qualified applicants will receive consideration for employment without regard to race, sex, color, religion, sexual orientation, gender identity, national origin, protected veteran status, or on the basis of disability. Requests for accommodation due to disability can be sent directly to .",3.3,"FireEye Inc
3.3","Denver, CO","Milpitas, CA",1001 to 5000 employees,2004,Company - Public,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,"Palo Alto Networks, Tanium"
"Senior SW Engineer, Data Science","$72K-$141K
(Glassdoor est.)","Job Description

If you dream of a job working in a field where all the hard problems are solved and you get to re-use previous research to get your job done, you need not apply. If, however, you are someone who wants to tackle problems that truly are on the cutting edge, then we encourage you to keep reading.

Data Science is an emerging field within cyber security. FireEye, given its deep expertise and comprehensive view on the advanced threat landscape, is uniquely positioned to enable data scientists to have major impact within our industry, company, and across our customer base. Detecting security breaches using machine learning and data analytics is an unsolved problem (this is not handwriting recognition folks) and has huge potential.

If you are someone who wants to be on the cutting edge of a high profile industry, who wants to make an impact by pushing both fields of data science and cyber security forward, you may be the perfect candidate to help us on our mission.

What you will do:
Develop, and manage data systems to ingest and process data at massive scale
Identify data sources both internally and externally that we can use to find evil.
Contribute towards the architecture and design of software solutions for long-term storage and retrieval.
Identify and implement data exploration technologies. Create dashboards and implement analytical tools for exploration
Work with data scientists to productize ML models and assist product teams with ML model releases into end products.
Collect requirements, design, and build backend components and tools to run ML models, assess ML model efficacy, manage large scale datasets, and generate features for ML models
Contribute to the evolution of coding and design practices within the organization.
Review code base commits and contribute to the growth of team members.",3.3,"FireEye Inc
3.3","Denver, CO","Milpitas, CA",1001 to 5000 employees,2004,Company - Public,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,"Palo Alto Networks, Tanium"
"Senior Machine Learning Engineer, Early Stage Pipeline, X",-1,"Senior Machine Learning Engineer, Early Stage Pipeline, X

Software Engineering

Mountain View, CA

We're an early stage team at X with a growing, interdisciplinary portfolio. To prove our path to the moon, we make early contact with the real world through both internal and external partnerships.

In this role, you will be responsible for taking early stage investigations from an idea stage to first prototypes to a full-blown projects. You'll be rapidly iterating through a set of prototypes to evaluate possible product directions. This is an extremely dynamic role and requires high cross-functional communication, organization, and planning. The ideal candidate is a self-starter and has a track record of effectively operating in a dynamic loosely structured environment (e.g. startup, new products within a larger company). The candidate will work on multiple projects/investigations.

Responsibilities:
Identify and implement a set of machine learning prototypes to aggressively de-risk projects building the whole solution: data acquisition, data processing pipelines, ML modeling.
Setup technical direction for investigations/projects working with the early stage leadership team.
Team lead investigations that grow to become projects.
Qualifications:
Hands-on experience with machine learning, one or more of; natural language processing (semantic understanding, sentiment analysis), computer vision, time series analysis.
Experience with building robust data pipelines.
Tech Lead experience.
Startup or early-stage product development experience.
Preferred Qualifications:
Experience with the Google Cloud Platform
About X, the Moonshot Factory

X creates radical new technologies to solve some of the world's biggest problems. We develop uncomfortably ambitious, potentially world-changing new ideas such as self-driving cars, balloon-powered Internet and smart contact lenses. We're a team of makers, entrepreneurs, engineers, designers and scientists with deep technical expertise who love the challenge of the seemingly impossible. We believe that a culture of psychological safety creates the foundation of trust and respect necessary to build moonshots. X was formerly known as Google[x] and is part of Alphabet .

At X, we don't just accept difference - we celebrate it, we support it, and we thrive on it for the benefit of our employees, our products and our community. We are proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements.

If you have a disability or special need that requires accommodation, please contact us at: (see application details) .",-1,"X, the moonshot factory","Mountain View, CA",-1,-1,-1,-1,-1,-1,-1,-1
"Senior/Staff Software Engineer, Data Infrastructure","$116K-$227K
(Glassdoor est.)","Senior/Staff Software Engineer, Data Infrastructure job posting

Every year, while Americans wait for their paychecks, more than $1 trillion of their hard-earned money is held up in the pay cycle. As a result, we accumulate over $50 billion in late and overdraft fees and turn to high-interest loans. Overdraft charges and bank fees often trap people in a cycle of debt that can lead to unhealthy decisions and falling victim to predatory businesses disguised as helpful services. We don't accept that.

Earnin is an app that creates products that help people gain control of their finances. Cash Out lets people get paid as soon as they leave work, with no fees, interest, or hidden costs. With Health Aid, Earnin negotiates on behalf of community members to lower their total unpaid medical bill and work out a budget-friendly payment plan. Cash Back Rewards is a way for members to earn up to 10% cash back on purchases from over a thousand local and national businesses without needing a credit card or having to reach spend thresholds to earn cash rewards — and they can withdraw the money at any time. We also offer free tools to help avoid overdrafts, to remind people when recurring bills are due, and we're working on more! There is never any required cost to use any of these products or services, users can choose to tip what they think is fair to support the service and pay it forward to keep the movement going.

Earnin is supported by funding partners including Andreessen Horowitz, Matrix Partners, Ribbit Capital, Felicis Venture, Thrive Capital, and others. Join us and help build a new financial system focused on fairness and people's needs.

You can help make a difference.

About the Team:

We are a data driven mobile financial tech company. The Data Infrastructure team builds the data services and data infrastructure that powers data science, analytics, and product development throughout Earnin. We are looking for a product-minded, self-driven Senior Software Engineer to own multiple large-scale projects that advance our mission of enabling people to gain access to their paycheck on demand.

What sets us apart:
High impact roles at a relatively small company that's aggressively growing our user base.
We are a collaborative team and genuinely enjoy working with each other.
We believe in empowering our people to be successful.
We're building a product that inspires fairness across the financial world and helps people not get taken advantage of.
As a Senior Engineer you will:
Break down complex problems into their bare essentials, translate this complexity into elegant design and create high quality, maintainable code.
Build massively scalable, production-grade data services.
Champion data quality and governance throughout the organization.
Build a world class data lake and data warehouse.
Design and develop new systems and tools to enable all of Earnin to consume and understand data faster.
Own the end to end design, build, and maintenance of platform services, data pipelines, and data products.
Implement comprehensive monitoring, logging, and alerting across our data infrastructure.
Work cross functionally with other teams (data science, design, product, marketing, and analytics) in high visibility roles as an engineering leader.
Build and deploy the data architecture that supports machine learning model development and actionable analytics.
Work with product engineering and data science teams to design scalable, performance model deployment architectures.
Communicate the tradeoffs of technical decisions to multiple stakeholders, including non-technical audiences.
Collaborate with and mentor other engineers and provide engineering direction to data scientists and analysts.
Actively engage and drive design reviews and code reviews.
Some skills we consider critical to being a Senior Engineer:
BS or MS degree in Computer Science, Engineering, or a related technical field.
8+ years of development experience in a fast-paced environment, especially startups.
5+ years of experience working with data systems.
Strong Python and SQL skills.
Strong programming and architecture skills.
Excellent written and verbal communication skills, including the ability to identify and communicate data driven insight.
Taking pride in your code quality and helping others elevate their own code quality.
Substantial experience with testing, data validation, and data quality assurance.
You can articulate the tradeoffs of different deployment architectures (e.g. streaming vs. batch vs. service-based).
Experience designing data platforms and services on cloud infrastructure, preferably AWS.
Hands-on experience designing and building large-scale solutions with the Hadoop stack and/or Spark.
Experience tuning and optimizing Spark-based applications.
Experience deploying and/or using query engines like AWS Athena, Presto, and Impala.
Experience with AWS analytical services like Redshift.
Hands-on experience working with a varied set of data storage technologies (e.g. Mysql, Postgres, DynamoDB, S3, etc.). You know where and when to use each.
Extensive experience with data modeling for multiple use cases and application styles, including NoSQL data modeling.
Experience working with data formats such as Avro and Parquet.
Experience working with alerting and monitoring tools like DataDog and PagerDuty.
Nice to haves:
You have experience building and deploying machine learning models.
You have experience using Terraform.
You have substantial experience working at a startup.
You have experience with data modeling in Redshift.
Experience with streaming infrastructure like Kafka.
Experience working with Kubernetes.
Experience building and deploying AWS Lambda applications.",3.1,"Earnin
3.1","Palo Alto, CA","Palo Alto, CA",201 to 500 employees,2012,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Engineer (open level),"$43K-$69K
(Glassdoor est.)","Title
Data Engineer (open level)

07/08/2020

What you'll do...
At H&R Block, your contributions will go far beyond any job description. When you join our team, you'll add to the momentum of a forward-thinking company - one that defined an industry and is now leading its transformation.

H&R Block is transforming tax preparation through data to ensure that every client we serve gets the best tax outcome possible.

We are building a new Data Engineering Team in the Data Science & Analytics organization. This new team will own the technology and data capabilities of the end-to-end data-and-analytics function. It will take responsibility for building and maintaining the analytical technologies that the data science teams use, managing data at an enterprise scale, leveraging relationships with IT teams throughout the enterprise, and leading information architecture.

We are looking for talented, curious, and creative data engineers of all levels to help launch this team. You will be a good match for our organization if you are:
Motivated by the idea of building something innovative, transformative, and impactful.
Committed to the idea that data can drive experiences and products that wow our business partners and clients
Obsessed with defying expectations and raising the bar
Driven by an innate sense of ownership for the products you create.
Day to day, you'll...
Design and deploy architecture, solutions, and software to capture, manage, store, and use structured and unstructured data from internal and external sources in both on-prem and cloud environments.
Deploy machine-learning models and other data-science products across the enterprise.
Navigate the balance between business needs, data governance best practices, and technical requirements.
Select or develop tools to cleanse, organize, and transform data and to maintain, defend, and update data structures and integrity on an automated basis.
Develop data products to facilitate self-service capabilities and assist the data teams to increase their efficiency and effectiveness.
Collaborate and communicate effectively within cross-functional teams that span internal Data Science & Analytics teams, IT, business groups, and executive stakeholders.
Be a positive force to cultivate a culture that is passionate about developing data tools as a business driver.
Job ID
368348BR

Address1
ONE H&R BLOCK WAY

City
KANSAS CITY

State
Missouri

Employee Type
Regular

What you'll bring to the team...
Education / work experience should include most of these, depending on level:
Bachelor’s degree in Computer Science or a related technical field (or equivalent work experience and technical skills)
Data warehousing and ETL solutions
APIs in a microservices architecture
Big-data technologies and the Hadoop stack (MapReduce, Hive, Pig, Hbase
NoSQL implementations (MongoDB)
Developing Java-based software solution
At least one scripting language (Python, Perl, JavaScript, Shell
Developing software solutions to solve complex business problems
Working with data scientists and other data users
Posting Title
Data Engineer (open level)

Sponsored Job
#hrbjob

Job Family
Corporate Analytics",3.6,"H&R Block
3.6","Kansas City, MO","Kansas City, MO",10000+ employees,1955,Company - Public,Other Retail Stores,Retail,$2 to $5 billion (USD),"Intuit, Jackson Hewitt, Liberty Tax Service"
Senior Modeling & Simulation Engineer,-1,"Applied Research Associates, Inc. is looking for a Senior Modeling and Simulation Engineer to join our multi-disciplinary team of engineers and scientists in the Capital Area Division, located in Alexandria, VA. The ideal candidate has a passion for predicting the behavior of physical systems in challenging environments and operational impact on mission success. Models will be developed, used, and improved to support a Department of Homeland Security customer to safeguard the nation’s borders and interior from chemical, biological, radiological, nuclear, and explosive materials, equipment, technologies, and their actors. Models may be based on the underlying physics or may be process or agent based to predict operational performance and impact. Modeling and analysis may require the use and development of 3D virtual worlds or geospatial data. Models will be verified and validated, and they will be used in support of test and evaluation activities of systems intended to detect and identify threats. The candidate may participate in test and evaluation activities to support the verification, validation, and overall improvement of models. Models may become part of larger, integrated modeling and simulation activities, and may require the use of high performance computing technologies and federated simulations.

This position is contingent upon award of a contract expected in Summer 2020 supporting the Department of Homeland Security.

Required Qualifications:
Ability to program in a high level programming language, such as Fortran, C++, or Java
Eagerness to learn new tools and techniques
Strong verbal and written communication skills
Must be a U.S. Citizen with the ability to obtain and maintain a security clearance
Bachelor’s degree with minimum of 10 years of experience or greater in a physical science (physics, chemistry, biology), engineering-related discipline (nuclear, chemical, civil, mechanical, electrical), or modeling& simulation disciple (computer modeling, computational science, operations research)
Ability to present to senior leadership on the status and issues associated with research or test efforts in preparation for acquisition decision meetings
Desired Experience and Qualifications:
Experience modeling CBRNE detectors or effects
Experience using multiple software tools such as MCNP, GadRas, SWORD, ExtendSim, Arena, SolidWorks, Fluent, ArcGIS, QGIS, VisIt, ParaView, or Cubit
Experience creating 3D models of systems, i.e., CAD
Experience using high performance computers (i.e., supercomputers)
Experience developing and using discrete event or agent based models and simulations to predict and assess system performance
Experience developing machine learning models
Background in a physical science or engineering discipline, such as Physics, Chemistry, Biology, Mechanical Engineering, Nuclear Engineering
Active DoD Secret or Top Secret clearance, DoE Q clearance, or DHS Suitability
COMPANY INFORMATION:

Applied Research Associates, Inc. is an employee-owned international research and engineering company recognized for providing technically superior solutions to complex and challenging problems in the physical sciences. The company, founded in Albuquerque, NM, in 1979, currently employs over 1200 professionals. ARA offices throughout the United States and Canada provide a broad range of technical expertise in defense technologies, civil technologies, computer software and simulation, systems analysis, environmental technologies, and testing and measurement. The corporation also provides sophisticated technical products for environmental site characterization, pavement analysis, and robotics.

At ARA, employees are our greatest assets. The corporation realizes that employee ownership spawns greater creativity and initiative along with higher performance and customer satisfaction levels. ARA gives its employees the tools, training, and opportunities to take more active roles as owners. The culture is challenging; innovation and experimentation are the norm. Employees are eligible for contributions which not only add to the company’s success, but also their own through the Employee Stock Ownership Plan (ESOP). The motto,“Engineering and Science for Fun and Profit” sums up the ARA experience. For additional information and an opportunity to join this unique workplace, please visit our website atwww.ara.com.",3.5,"Applied Research Associates
3.5","Alexandria, VA","Albuquerque, NM",1001 to 5000 employees,1979,Company - Private,Federal Agencies,Government,$100 to $500 million (USD),-1
Senior Data Engineer,-1,"This is a Data Engineer position for supporting a Navy program located in Quantico, Virginia.

We are seeking a Data Engineer to join our team of committed technical professionals to protect those who serve against criminal, terrorism and emerging threats. Are you passionate about analytics and innovation? Our employees enjoy a fast-paced, collaborative culture and the ability to directly impact our business. You will identify technical issues and opportunities for efficiency and provide technical insights through system design and configuration perspectives. This role is both challenging and rewarding.

You will support the mission through the implementation of a modern, integrated internal data infrastructure with a focus primarily on exploiting the established data foundation to make internal and customer-centric business processes as effective and efficient as possible, laying the foundation for cognitive capabilities that can sense and respond to both internal and external customer data needs. The candidate will also focus on expanding the organization’s data ecosystem to include context-rich data while maintaining the agility needed to spark innovation.

How you will make a difference:
Establish shared operational data and integrated enterprise data, all while managing and/or improving data quality and security through the creation of business-driven governance structures and culture change management.
Establish data policies, standards, and procedures that improve data quality, availability, accessibility, security, usability, and enforcement of enterprise information management (EIM) program requirements.
Establish enterprise standards – including a uniform and repeatable system development lifecycle methodology for Reference Data and Master Data (e.g., a common set of standards for data naming, abbreviations, and acronyms).
Develop a Master Data Management (MDM) Plan that focuses on the technology, tools, and processes ensuring master data is coordinated across the enterprise. MDM is a method used to define and manage the critical data of an organization to provide, with data integration, a single point of reference. The data that is mastered may include reference data – the set of permissible values, and the analytical data supporting decision making. MDM provides a unified master data service intended to provide accurate, consistent and complete master data across the enterprise and to business partners.
Recommend solutions based on performing industry-specific analysis, such as case studies describing data management best practices, identifying trends across the industry.
Make recommendations to improve the efficiency and effectiveness in how the agency acquires, stores, manages, shares and applies its data.
Engage business users and stakeholders for the increased release of actionable high-quality data on key operational and tactical activities at NCIS.
Develop technology solutions to provide the platform, training, and standardized tools enabling querying, data mining, statistical analysis, reporting, scenario modeling, data visualization, and dash-boarding, and processes for a centralized, or analytics as a service model, allowing for the sharing of data across the enterprise from a common hub, facilitates cross-organizational data initiatives due to its enterprise-wide view of data assets and needs.
Basic Qualifications
Required: A bachelor’s or master’s degree in computer science, data science, operations research, statistics, applied mathematics, or a related quantitative field [or equivalent work experience such as, economics, engineering and physics] is [preferred/required]. Alternate experience and education in equivalent areas such as economics, engineering or physics, is acceptable. Experience in more than one area is strongly preferred.
Required: Three to six (midlevel) of relevant project experience in successfully launching, planning, and executing data science projects. Preferably in the domains of risk modelling and quality assessment.
Preferred: Specialization in text analytics, image recognition, graph analysis or other specialized ML techniques such as deep learning, etc.
Preferred: the candidates are adept in agile methodologies and well-versed in applying DevOps/MLOps methods to the construction of ML and data science pipelines.
Coding knowledge and experience in several languages: for example, R, Python, Java, C++, Excel, MATLAB, etc.
Experience with popular database programming languages including SQL, PL/SQL, others for relational databases and upcoming non-relational databases such as NoSQL/Hadoop-oriented databases such as MongoDB, Cassandra, others.
Preferred: Specialized/operational data scientists may need further high-performance computing (HPC)/compute skills; larger data science teams, in particular, may require further degrees of specialization such as:
Experience with distributed data/computing tools such as MapReduce, Hadoop, Hive, Kafka, and MySQL
Experience of working across multiple deployment environments including cloud, on-premises and hybrid environments, multiple operating systems and through containerization techniques such as Docker, Kubernetes, AWS Elastic Container Service, and others.
Experience in one or more of the following commercial/open-source data discovery/analysis platforms: RStudio, Spark, KNIME, RapidMiner, Alteryx, Dataiku, H2O, SAS Enterprise Miner (SAS EM) and/or SAS Visual Data Mining and Machine Learning, Microsoft AzureML, IBM Watson Studio or SPSS Modeler, Amazon SageMaker, Google Cloud ML, SAP Predictive Analytics.
Preferred: Expertise in solving vision, text analytics, credit scoring, and failure prediction problems.
Knowledge and experience in statistical and data mining techniques such as generalized linear model (GLM)/regression, random forest, boosting, trees, text mining, hierarchical clustering, deep learning, convolutional neural network (CNN), recurrent neural network (RNN), T-distributed Stochastic Neighbor Embedding (t-SNE), graph analysis, etc.
Strong documentation skills. Required: Certifications as per Cybersecurity Workforce Management and Qualification Manual, SECNAV M-5239.2.
Required: Eligible AND adjudicated to the Top Secret (TS SCI) clearance level is required to start.
About Inventium.io:

Inventium.io LLC is a technical consulting and software development services company dedicated to protecting and advancing our national defense and scientific capabilities. Based out of the Washington DC area, we rely on innovation to continually advance our employees' skills and provide digital transformation solutions to our customers.

With proven records of successfully delivering quality services and solutions to multiple federal agencies, our technical competencies include Emerging Technology Solutions, DevSecOps, Cloud Migration, Machine Learning, System Modernization, and Technology Management.

Benefits and Perks
Employer paid Health Benefits (Medical, Dental and Vision)
Retirement Plan
Paid Time Off and Federal Holidays
Training and Development
Employee Referral Program
Awards and Recognition",5.0,"inventium.io LLC
5.0","Quantico, VA","Washington, DC",1 to 50 employees,2016,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Senior Software Engineer,-1,"At Pacific Biosciences, our R&D team is committed to developing innovative products that enable scientists to excel in a wide variety of life science research fields, including human biomedical, plant and animal sciences, and microbiology and infectious disease. Our unique Single Molecule, Real-Time (SMRT) sequencing platforms generate true high-quality long reads, giving researchers a more comprehensive view of genomes, transcriptomes, and epigenomes from any organism.

The Primary Analysis group, as part of the larger software engineering team at PacBio, develops algorithms and HPC solutions for decoding the raw data streams, generated through high-speed optical detection of the SMRT sequencing reactions, into DNA sequence reads. We operate at the intersection of cutting-edge nanotechnology and state-of-the-art bioinformatics tools, and our responsibilities span the full product development life cycle in an aggressive time-to-market environment. These include analysis and algorithm development in coordination with chemistry and systems R&D; the development of real-time analysis pipelines; and the development of validation and support infrastructure geared towards product system reliability and internal R&D support. We are seeking a talented algorithm engineer with a strong background in the physical or machine-learning/data sciences who also has a passion for designing and developing performance-critical data analysis solutions.

Responsibilities:

Design, develop, and test signal- and sequence-analysis algorithms that will drive fundamental improvements in basecalling accuracy and yield.
Work collaboratively in a team environment to solve challenging problems in software architecture and scalability of real-time analysis pipelines for our next-generation sequencing platforms.
All listed tasks and responsibilities are deemed as essential functions to this position; however, business conditions may require reasonable accommodations for additional tasks and responsibilities.

Key Skills and Background:

3+ years of experience shipping product software in a scientific or quantitative domain.
Demonstrated skills applying numerical methods, statistical signal processing, or machine-learning techniques to high-throughput, performance-critical analysis applications.
Linux-based systems programming experience with knowledge of OS, toolchain and hardware constraints.
Strong C++ programming experience in applications geared towards performance and scalability; previous experience in CUDA programming for GPU is a plus.
MS, PhD or equivalent experience in a quantitative field (physics, CS, etc.), preferably with an applied math or algorithmic focus.
Engineering instincts to efficiently investigate and solve the problem at hand, from prototype development (Python, R, MATLAB, etc.) to production designs.
Team player, with strong communication skills, and comfortable as a self-starter in an agile, fast-paced development environment.
All qualified applicants will receive consideration for employment without regard to race, sex, color, religion, national origin, protected veteran status, or on the basis of disability, gender identity, and sexual orientation.",3.7,"Pacific Biosciences
3.7","Menlo Park, CA","Menlo Park, CA",201 to 500 employees,2000,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,$50 to $100 million (USD),Illumina
Senior Data Engineer,-1,"ABOUT 605

At 605 we are engineers, analysts, data scientists, media experts, marketing strategists and political operatives. Our team of data scientists pioneered the field of TV data analytics. We offer unique, independent audience measurement and analytics to build better marketing and programming initiatives within the media and entertainment industries.

The Sr. Data Engineer at 605 must have a broad and deep data skillset as well as strong analytical capabilities . In addition to being a hands on individual contributor, the ideal candidate is a productive team player and a mentor to Junior. Data Engineers. Additionally, we are looking for strong technical experts.

Responsibilities include:
Actively participate in team technical discussions in all things data
Identify and address issues with data sets from multiple vendors
Identify and address code and data quality issues
Actively participate in code reviews and grooming sessions
Actively participate in technology architecture discussions for product development
Translate business requirements into strategy
Advocate for software best practices within your team as well as across engineering
Be ultra-responsive and capable of making instant decisions, always kicking the ball forward
Work on unique and interesting data challenges around architecting, building and managing pipelines that securely process hundreds of terabytes of data
Work closely with analysts and statisticians to ensure the validity of our processes
Our engineers are expected to wear a number of hats and have the opportunity to touch all parts of the stack. Our stack includes Apache Spark, Scala, Redshift and an ever-growing list of many other cool technologies.

Requirements
Skillful user of Apache Spark
Experience wrangling terabytes of big, complicated, imperfect data
Experience with AWS products (Redshift, EMR, S3, IAM, RDS, etc)
You have a deep understanding of scalable systems and you have large-scale engineering experience in an Agile development environment
Bachelor's degree in Computer Science or a related field (or 4 additional years of relevant work experience)
A strong understanding of data structures, algorithms, and effective software design
Significant development experience with a major modern language (e.g. Java, Scala, Python, Ruby, C/C++, etc.)
Significant experience working with structured and unstructured data at scale and comfort with a variety of different stores (key-value, document, columnar, etc.) as well as traditional RDBMSes and data warehouses
Experience with or interest in AWS Glue, Redshift Spectrum and any other tools that enable data querying at scale
Experience writing unit, functional and integration tests
Comfort with version control systems (e.g. Git, SVN)
Excellent verbal and written communication skills; must work well in an agile, collaborative team environment
Preferred Qualifications
Master's in Computer Science or a related field
Practical experience with supervised machine learning techniques
Strong background with test-driven development
Basic understanding of statistics and experience with statistical packages such as R, Matlab, SPSS, etc
Benefits

Important and Standard
Comprehensive health, dental and vision insurance for employees and their families
Life & Disability insurance
401k plan with match, eligible for match after one year
Pre-tax flexible compensation plan for medical, transit, parking or dependent care expenses
Up to 15 paid vacation days depending on grade level
7 paid sick days in a calendar year - if you’re sick, you stay home
Other cool benefits
4 work from home days/month
A kitchen stocked with sodas, snacks, yogurt and other goodies
A tight knit start up community who likes to eat! We celebrate everyone’s birthdays, have frequent team lunches, and do events in and out of the office
605 is an active participant in conferences
EEO STATEMENT

At 605, we’re just as passionate about diversity as we are about pioneering the field of TV data analytics. We are committed to cultivating an environment of mutual respect and equal opportunity. All hiring and advancement decisions are made on the basis of qualification, merit, and business need.",-1,605,"New York, NY",-1,-1,-1,-1,-1,-1,-1,-1
Sr Innovation Engineer,"$75K-$134K
(Glassdoor est.)","Company Information

Solid reputation, passionate people and endless opportunities. Thats Travelers. Our superior financial strength and consistent record of strong operating returns mean security for our customers and opportunities for our employees. You will find Travelers to be full of energy and a workplace in which you truly can make a difference.

Target Openings

1

Job Description Summary

Innovation is at the core of everything we do. We continue to ask ourselves, whats next? as we navigate the ever-changing insurance landscape. Continuing our customer journey toward the cutting-edge, we are looking for a forward-thinking individual that thrives in ambiguity, who believes that with every challenge comes a new opportunity for solutions.

As a member of the Innovation Technology team, you will partner with research scientists and product managers to discover, invent, and build solutions at scale. As a team, you will work on challenges in machine perception, data mining, machine learning, and natural language understanding.

We are looking for a hands-on individual with strong foundational knowledge highly scalable architectures and platforms. If you like using a variety of skills in technology and solving complex problems, work collaboratively in a small agile team environment, you might just be the person we need on our team!

Primary Job Duties & Responsibilities
Work closely with Cloud Engineering to build an innovation platform; a collection of reusable and extensible containers and tools specific to developing insurance products and platforms.
Recommend integration strategies, enterprise architectures, platforms and application infrastructure required to successfully implement a complete solution using best practices.
Produce quality output for highly visible IT products, services and future business development.
Assist in hands-on remediation of application stability and performance.
Adopt and communicate new concepts, ideas, techniques.
Manage multiple projects simultaneously.
Provide 'Shrink Wrap' solutions to solve business and technical needs. As part of our innovation process, be able to scale Minimum Viable Product to production systems.
Design and lead integration of analytic data products, including pilots and proof of concepts.
Frequently present and translate complex information in relevant business terms.
Constantly learn new skills within small teams.
No direct HR people management but will lead teams in project & program contexts.
Education, Work Experience, & Knowledge
Bachelors Degree in STEM (Science, Technology, Engineering, Mathematics) related field and 3+ years of experience or 10+ years of experience building highly scalable platforms and reusable components
Job Specific Technical Skills & Competencies
2+ years of experience working with Amazon Web Services (AWS) or equivalent cloud. Must be recent experience.
5+ years of designing and developing on-premise and cloud solutions.
3+ years of experience as a technical lead.
Experience in software engineering with relevant technologies (Java, JavaScript, Python etc.).
Experience with the application delivery process.
End-to-end experience with data, including querying, aggregation, analysis, and visualization.
Preferred Qualifications
AWS certified developer and/or architect
Proven ability to work creatively and analytically in a continuously evolving environment.
Exhibits high levels of learning agility in which they seek out and learn from unfamiliar experiences and then apply those lessons to succeed in the next new situation.
Ability to leverage business knowledge to determine approaches to execution.
Strong communication and presentation skills with the ability to present and translate complex information to leadership and non-technical teams in relevant business terms.
Uses effective listening skills and communication to build relationships across the organization.
Ability to Influence with experience working with matrixed staff to complete tasks in a timely manner.
Environmental / Work Schedules / Other
Travel Required
Equal Employment Opportunity Statement

Travelers is an equal opportunity employer.",4.1,"Travelers
4.1","Hartford, CT","Hartford, CT",10000+ employees,1853,Company - Public,Insurance Carriers,Insurance,$10+ billion (USD),-1
Senior AI Software Engineer,-1,"Company Overview

Calling the adventurers ready to join a company that's pushing the limits of nanotechnology to keep the digital revolution rolling. At KLA, we're making technology advancements that are bigger—and tinier—than the world has ever seen.

Who are we? We research, develop, and manufacture the world's most advanced inspection and measurement equipment for the semiconductor and nanoelectronics industries. We enable the digital age by pushing the boundaries of technology, creating tools capable of finding defects smaller than a wavelength of visible light. We create smarter processes so that technology leaders can manufacture high-performance chips—the kind in that phone in your pocket, the tablet on your desk and nearly every electronic device you own—faster and better. We're passionate about creating solutions that drive progress and help people do what wouldn't be possible without us. The future is calling. Will you answer?

Responsibilities

Group/Division
KLA has always had a close relationship with physics and data. Our optical and electron beam inspection and measurement tools use cutting edge physics models, both for hardware design and as part of their algorithms. AI, including several traditional machine learning techniques and deep learning are routinely used to process this data to meet application requirements.

The AI & Modeling Center of Excellence, centered in KLA’s R&D facility in Ann Arbor, MI, was setup with the mission of advancing KLA’s traditional strengths in physics and data and providing implementation solutions for multiple KLA Inspection and Metrology products targeted at the semiconductor manufacturing industry.

As a part of this group, you will be part of a world class team of physicists, HPC system designers, machine learning and application engineers who build cutting edge solutions for modeling complex imaging techniques and semiconductor processes. You will also work with a data scientists and AI infrastructure engineers whose mission is to build and scale machine learning based solutions for our semiconductor customers.

We are looking for engineers in a few different fields. If you are passionate about Physics Modeling, High Performance Computing - HPC (including GPU), ML, Data, or Cloud technologies – this is the place for you!

Responsibilities:
Software Engineers in the AI and Physics Modeling team may work on a variety of tasks including platform for large scale experimentation, scaleout of physics models, data management and inference solutions for KLA products.

Although familiarity with Machine Learning and Deep Learning solutions would be a big plus, this is primarily a Software Engineering position. Successful candidates are passionate about software, and will have exceptional skills and hands on experience with development in C/C++ and Python in a Unix environment. Deep conceptual understanding of multi threaded and multi process software systems is also necessary.

In addition to the above fundamental software skills, any of the following technical hands-on skills are highly desirable.

1) System Programming and Operating Systems.
2) Distributed systems for data management.
3) Distributed computing infrastructure.
4) Cloud technologies for storage, containerization and compute clusters.
5) Data Structures and algorithms
6) GPU architectures and data management.
7) Traditional machine learning using Random Forest, XG Boost, Logistic Regression.
8) Deep Learning for regression, classification. Generative models.
9) TensorFlow, NumPy, scikit-learn, and other ML and DL frameworks.
10) MPI and similar distributed computing framework.
11) GPU Architectures and CUDA (CuGraph, CuData, CuML etc).
12) GO Systems Programming, Java Programming.

Successful candidates for this position will also demonstrate the following non-technical skills.

1) Capability to formulate creative solutions through analyzing complex data
2) Good communication skills
3) Strong team player and motivated by team success
4) Strong problem solving skills

Minimum Qualifications

Doctorate (Academic) with at least 2 years of experience.
OR
Master's Level Degree with at least 4 years of experience.
OR
Bachelor's Level Degree with at least 5 years of experience.

Equal Employment Opportunity

KLA is an Equal Opportunity Employer. Applicants will be considered for employment without regard to age, race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability, or any other characteristics protected by applicable law.",3.8,"KLA-Tencor
3.8","Ann Arbor, MI","Milpitas, CA",5001 to 10000 employees,1976,Company - Public,Industrial Manufacturing,Manufacturing,$2 to $5 billion (USD),"Applied Materials, Nanometrics"
"Senior SDE, Catalog Big Data and Machine Learning",-1,"Amazon's Catalog DataWorks team is looking for highly motivated engineers. We are embarking on multiple new initiatives to re-organize Amazon's catalog of billions of products, in new and interesting views, that drive several features Amazon's customers love. Today, these views drive hundreds of popular features like product recommendations, clustering of similar products, and shopping with Alexa. We will build a new near real-time Catalog Data Lake on AWS, to enable engineers and scientists across Amazon to solve customer problems faster. Come join us on this exciting journey!

As an engineer on this team, you will own the Catalog Data Lake end-to-end. You will work closely with business partners to synthesize technical requirements. You will design and implement significant parts of the platform. You will learn and use industry standards like Spark and Parquet as well as modern AWS offerings like EMR, Glue, Athena, and Redshift. We are fortunate to be at the cusp of innovation in both the e-commerce business as well as cloud technology. As a key stakeholder, you will constantly learn new patterns, solve key customer problems and strive to make AWS better along the way.Basic Qualifications
Bachelor's degree or higher in computer science or math is required.
Strong computer science fundamentals - algorithms, data structures and design patterns.
At least 8 years of software development experience.
At least 3 years of experience building and operating Big Data systems.
Experience mentoring, guiding and influencing peers.
Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.",-1,Amazon Corporate LLC,"Seattle, WA",-1,-1,-1,-1,-1,-1,-1,-1
SENIOR SOFTWARE ENGINEER & SOFTWARE ARCHITECT,-1,"Job Description
Senior Software Engineer, Software Architect
JOB SUMMARY

The Senior Software Engineer, Software Architect will develop software for Company innovative semiconductor X-Ray inspection system. The Senior Software Engineer will collaborate with Applications, QA, and Algo teams for high performance solutions and optimization per customer issues. It will be important to be comfortable working in a small company environment and a typical startup with engineers and scientists.

ABOUT THE CLIENT

Based in San Jose, California, client was founded in 2013 expressly to bring high speed inspection and metrology technology to the semiconductor packaging industry. Client founders anticipated the need to deploy inline 100% transmissive inspection into the semiconductor packaging manufacturing process and developed the company’s technology with this end in mind. The results, Client’s HR-AXI technology suite brings together the company’s unique data acquisition architecture with proprietary machine learning analysis techniques to provide customers with process monitoring and defect detection capabilities not found on any other products in the market. This job description can be updated at any time.

RESPONSIBILITIES
Designs, develops, troubleshoots, and debugs software programs for enhancements and new products, focused on creating high quality and high-performance solutions while maintaining high-level coding standards.
Develops software and tools in support of design, infrastructure, and technology platforms. Develops software solutions by studying information needs, conferring with users, and studying systems flow, data usage, and work processes
Supports hardware compatibility and/or influences hardware design based on software needs; work as part of cross-functional team to solve and implement system level problems.
Monitor application stability, performance, and availability. Promptly resolve issues impacting operations.
Work with engineering, documentation, and applications departments to ensure successful development and delivery of overall product.
Provide appropriate project feedback to management in a timely and appropriate format.
QUALIFICATIONS AND REQUIRED SKILLS
Education requirement: Bachelor’s degree in Computer Science, Electrical Engineering, or similar technical field required. Master’s or PhD strongly preferred.
Experience requirement: Minimum of 8 years of related experience working in software development.
Strong expertise in C# .NET. WCF, WPF, Database development. In addition, Python experience a plus.
Experience with Image processing algorithms implementations is a plus
Experience with software development for Factory Automation for Semiconductor equipment, a plus.
Self-starter able to think and act independently to translate general objectives into tangible results, with a record of delivering successful designs on schedule.
Demonstrated ability to organize, manage, and complete multiple assignments with challenging timelines independently and effectively.
Demonstrated analytical and problem-solving skills with high attention to detail.
Proactive approach to problem-solving. Build relationships with stakeholders to support successful design, build and testing.
Strong verbal and written communication, good attitude, and work ethic. Ability to communicate technical concepts and results clearly.
Experience with Git and Azure DevOps, a plus.",3.0,"Simple Solutions
3.0","San Jose, CA","Morgantown, WV",1 to 50 employees,2006,Company - Private,IT Services,Information Technology,Less than $1 million (USD),-1
Cloud Engineer,-1,"Job Description
Responsibilities:
Develop and implement technical efforts to design, build, and deploy AWS applications at the direction of lead architects, including large scale data processing, computationally intensive statistical modeling, and advanced analytics
Participate in all aspects of the software development life cycle for AWS solutions, including planning, requirements, development, testing, and quality assurance
Provide guidance, thought leadership and mentorship to development teams to build cloud competencies
Provide innovative thought leadership around Mathematica’s cloud solutions strategy and approach, including AWS best practices and market trends
Position Requirements:

6+ years of experience architecting, designing, developing and implementing cloud solutions on AWS platforms
Demonstrated experience with designing and implementing solutions using AWS platform and tools, such as: EC2, S3, Redshift, API Gateway, Lambda, DynamoDB, CloudFormation, RDS, VPC, IAM and security, QuickSight, CloudTrail, Config, CloudWatch, SNS, AMI generation
Understanding of and experience with the five pillars of a well-architected framework
Knowledge of SQL, R, and Python for data manipulation and statistical analysis is desirable
Familiarity with federal security regulations and standards (e.g. HIPAA, FISMA, FIPS, NIST, and FedRAMP)
Experience with security, especially knowledge of FedRAMP, HIPAA, PII/PHI, is desirable
Experience in several of the following areas: database architecture, ETL, Business Intelligence, Big Data, Machine Learning, Advanced Analytics
Proven ability to work collaboratively with multi-disciplinary teams of business analysts, developers, data scientists, and subject matter experts
Strong written, verbal and interpersonal communication skills
AWS Certifications (such as AWS solutions architect or other specialty certifications) are a plus
Bachelor's degree or equivalent combination of education and experience; degree in computer science, mathematics or related field preferred
Experience with other cloud platforms like Google Cloud Platform (GCP) is a plus",4.8,"RICEFW Technologies Inc
4.8","Princeton, NJ","East Lansing, MI",51 to 200 employees,2009,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Senior Software Engineer / Team Lead,"$112K-$220K
(Glassdoor est.)","Join our team dedicated to developing and executing innovative solutions in support of customer mission success.

Job Description:

Novetta has an exciting opportunity for a self-motivated and accomplished Computer Scientist to lead our entity analytics team. You will work on complex projects involving data analysis, software engineering, and deploying software in a cloud computing environment. The team combines data from disparate sources to visualize the complex relationships between entities. This effort involves large scale data integration and entity resolution leveraging a best in class Novetta product. We are looking for a flexible problem solver with significant technical experience to lead a team providing unique solutions for our customers and stakeholders.

Responsibilities include:
Lead a technical team of software engineers and computer scientists, working within a larger ecosystem delivering an Enterprise capability.
Navigate customer and prime environment, manage resources within and across team, and assist team with professional and technical growth.
Deploy applications on a large-scale data processing cluster using AWS technologies.
Design and implement entity correlation strategies that are tailored to mission needs and unique data qualities.
Develop algorithms and visualization tools to help stakeholders understand their data and prioritize new data sources.
Develop and integrate applications to automate ingestion, processing and monitoring of data
Develop and maintain tools to support operations and maintenance of production and development computing clusters.
Basic Qualifications:
Experience leading a team of software engineers.
A Bachelor's degree in computer science or related field and a minimum of 5 years of experience; or a Master's degree in computer science or related field and a minimum of 3 years of experience.
Experience in software development/engineering including requirements analysis, software development, installation, integration, evaluation, enhancement, maintenance, testing and problem diagnosis/resolution.
Software development experience on Linux-based systems in Python or shell scripting or JavaScript.
Experience developing against full-featured REST APIs and using a command line interface
Desired Skills:

Should meet a minimum of 3:
Software development experience with JavaScript, Python, or other modern programming languages.
Hands-on experience with Spark.
Experience working with Databricks
Interest in statistical analysis, machine learning, or data science.
Experience with entity resolution products or a background in data matching theory and technologies.
Experience developing applications in AWS.
Security Clearance:
The candidate must have a TS/SCI with Poly.
Novetta, from complexity to clarity.

Novetta delivers highly scalable advanced analytics and secure technology solutions to address challenges of national and global significance. Focused on mission success, Novetta pioneers disruptive technologies in machine learning, data analytics, full-spectrum cyber, cloud engineering, open source analytics, and multi-INT fusion for Defense, Intelligence Community, and Federal Law Enforcement customers. Novetta is headquartered in McLean, VA with over 1,000 employees across the U.S.

Our culture is shaped by a commitment to our core values:

Integrity • We hold ourselves accountable to the highest standards of integrity and ethics.

Customer Success • We strive daily to exceed expectations and achieve customer mission success.

Employee Focus • We invest in our employees' professional development and training, respecting individuality and fostering a culture of diversity and inclusion.

Innovation • We know that discovering new and innovative ways to solve problems is critical to our success and makes us a great company.

Excellence in Execution • We take pride in flawless execution as we build a company that is best in class.

Earn a REFERRAL BONUS for the qualified people you know.

For more details, or to submit a referral: bit.ly/NovettaReferrals

Novetta is an equal opportunity/affirmative action employer.

All qualified applicants will receive consideration for employment without regard to sex, gender identity, sexual orientation, race, color, religion, national origin, disability, protected veteran status, age, or any other characteristic protected by law.",4.5,"Novetta
4.5","Chantilly, VA","Mc Lean, VA",501 to 1000 employees,2012,Company - Private,Enterprise Software & Network Solutions,Information Technology,$100 to $500 million (USD),"Leidos, CACI International, Booz Allen Hamilton"
Data Fusion Engineer with Security Clearance,"$48K-$109K
(Glassdoor est.)","Description Job Description: Looking for work-life balance? Leidos offers generous leave and accommodating flex-time to help you juggle your personal and professional life. Are you a Software Engineer with experience finding and aligning signals across multiple modalities (image, video, audio, lidar, etc..)? Do you want to implement and customize algorithms to fusion multiple data modalities? If so we are looking for you, our next Data Fusion Engineer to work in Arlington, VA. We need you to be competent in Python and have the ability to read code in other programming languages like Java and C++ as well as have experience working with ML libraries like SciKit Learn, TensorFlow, Keras along with experience implementing solutions with those libraries on both CPU and GPU compute architectures. Like what you are reading so far? Keep going. We want you to be intellectually adaptive, inquisitive, good at expressing your needs, and able to self-manage when necessary. Work alongside software/system engineers and research/data scientists with expertise in multi-modal information retrieval, UI development, computer vision, metrics, information science, artificial intelligence, and autonomous systems. The Department of Defense and the Intelligence Community will be the main recipients your hard work. Fun stuff you will do on the job: - Use cases requiring identifying entity/objects, determining object association, object disambiguation, anomaly detection, state estimations, etc.
Develop and maintain data models (both physical and logical)
Get to be responsible for extraction, transform, and load (ETL) tasks related to the different modalities and algorithms being applied. This data ETL includes identifying the data's relevant metadata to ensure consistency, quality, accuracy, integrity, and information assurance and security.
Performing anomaly detection using various AI/ML techniques
Use algorithms to identify complex patterns across multiple modalities
Increasing the efficiency and quality data alignment and fusion
Enhance and maintain analysis tools, including automation of current processes using AI/ML algorithms
Conduct quantitative data analysis including developing retrieval, processing, fusion, analysis, and visualization of various datasets Skills required to be successful in this role: - Bachelor's Degree in Aerospace Engineering, Computer Science, Mathematics, Statistics, Physics, Electrical Engineering, Computer Engineering or related fields with 5 years of relevant experience
Must be able to obtain and maintain a TS/SCI security clearance
Experience with Deep Learning Frameworks such as Keras, Tensorflow, PyTorch, Mxnet, etc. - Ability to apply these frameworks to real problems in the 'time -series' domain
Experience with interpretability of deep learning models
Big Data Skills (Azure, Hadoop, Spark, recent deep learning platforms)
Practical experience with statistical analysis
Experience with text mining tools and techniques including in areas of summarization, search (e.g. ELK Stack), entity extraction, training set generation (e.g. Snorkel) and anomaly detection
Expert software development skills lifecycle including developing and maintaining good production quality code
Hands-on Software Development Skills (Python-Preferred)
Experience or educational courses/projects in Machine Learning, and/or Text Mining Algorithms You will wow us even more if you have these skills: - Visualizations/Web Development Skills (e.g. Tableau, D3, etc).
Hands-on experience with prototype development
Hands-on experience with automating data cleansing, formatting, staging, and transforming data human
Hands-on experience applying data analytics
Hands-on experience with intelligent systems and machine learning LInC External Referral Bonus: Ineligible Potential for Telework: No Clearance Level Required: Top Secret/SCI Travel: Yes, 10% of the time Scheduled Weekly Hours: 40 Shift: Day Requisition Category: Professional Job Family: Software Engineering Leidos Leidos is a Fortune 500® information technology, engineering, and science solutions and services leader working to solve the world's toughest challenges in the defense, intelligence, homeland security, civil, and health markets. The company's 33,000 employees support vital missions for government and commercial customers. Headquartered in Reston, Virginia, Leidos reported annual revenues of approximately $10.19 billion for the fiscal year ended December 28, 2018. For more information, visit www.Leidos.com . Pay and Benefits Pay and benefits are fundamental to any career decision. That's why we craft compensation packages that reflect the importance of the work we do for our customers. Employment benefits include competitive compensation, Health and Wellness programs, Income Protection, Paid Leave and Retirement. More details are available here . Securing Your Data Leidos will never ask you to provide payment-related information at any part of the employment application process. And Leidos will communicate with you only through emails that are sent from a Leidos.com email address. If you receive an email purporting to be from Leidos that asks for payment-related information or any other personal information, please report the email to [email protected] . Commitment to Diversity All qualified applicants will receive consideration for employment without regard to sex, race, ethnicity, age, national origin, citizenship, religion, physical or mental disability, medical condition, genetic information, pregnancy, family structure, marital status, ancestry, domestic partner status, sexual orientation, gender identity or expression, veteran or military status, or any other basis prohibited by law. Leidos will also consider for employment qualified applicants with criminal histories consistent with relevant laws.",3.5,"Leidos
3.5","Arlington, VA","Reston, VA",10000+ employees,1969,Company - Public,Aerospace & Defense,Aerospace & Defense,$10+ billion (USD),-1
Software Engineer,"$64K-$132K
(Glassdoor est.)","Every Analyst a Scientist - One of our primary goals is to empower intelligence analysts to be able to study their data like scientists. The tools we develop focus on streamlining intelligence analysis through integrated algorithms and software that provide insight into the geopolitical landscape for use in operational intelligence missions around the world.

The Role:
As a Software Engineer, you will be part of a team that transforms large and complex customer data into real-world, high-impact solutions. You will work with researchers and engineers to design and implement solutions to challenging national security problems. You will be responsible for building the software infrastructure to clean, ingest, and expose datasets and algorithms to both developers and end users. You will deploy algorithms, generate workflows, create engineer-facing tools, and design customer-facing prototype systems. You will occasionally travel to customer sites to engage with end users, demonstrate prototypes, and integrate analytics into customer systems.

If you would like to help intelligence and defense analysts keep pace with technology-driven innovation, then this role is for you!

Who you are:
A U.S. Citizen with the ability to obtain a Security Clearance
A degree in a scientific or engineering field, such as Computer Science, Mathematics, Physics, or Software Engineering
Proficiency with a scientific programming language such as Python, Java, or C++
Experience with database management and common query syntax
Motivated collaborator and excellent communicator of ideas to both technical and non-technical audiences
Knowledge of AWS, Spark, Dask, and/or similar technologies for working with data at scale
Even better:
Active Security Clearance
Track record of architecting, developing, deploying, or maintaining enterprise software
Experience with software development best practices and tools
Understanding of web development and visualization technologies, such as d3, Leaflet, Bootstrap, or others
Familiarity with machine learning or statistical modeling techniques",4.5,"Systems & Technology Research
4.5","Woburn, MA","Woburn, MA",201 to 500 employees,2010,Company - Private,Aerospace & Defense,Aerospace & Defense,$100 to $500 million (USD),-1
Sr. Data Scientist,-1,"Background Information:

Innovative Defense Technologies (IDT), provider of automated software testing, data analysis, and cybersecurity solutions for complex defense systems, is currently accepting applications for an anticipated Sr. Data Scientist role requiring 7+ years of experience for a position in support of its efforts implementing Artificial Intelligence solutions for a variety of customers.

Overview:

The Sr. Data Scientist position offers an engineer the opportunity to utilize his/her knowledge and talents as part of a collaborative team developing AI solutions for a growing company. A few of the responsibilities include supporting feasibility studies, applying modern data storage techniques, discovering explanatory features in high-dimensionality collections of data, and exploring data using scientifically valid techniques to exploit patterns found in the data with state-of-the-art AI/ML/DL solutions.

All applicants must be able to obtain/maintain an active U.S. Security Clearance.

Responsibilities Include:
Lead development of solutions to deliver AI/ML/DL models from problem formulation to a productized, deployable, maintainable capability
Contribute to AI/ML/DL technical roadmap development
Use Deep Learning frameworks such as Tensorflow and Keras to build and validate ML/DL models
Establish and leverage Big Data frameworks to store, extract and analyze relevant data
Ensure development of software solutions meets customer needs and program intent
Work closely with the Program Manager and Chief Engineer to design and implement software requirements and solutions
Determine operational feasibility by evaluating analysis, problem definition, requirements, solution development, and proposed solutions for large, complex systems
Be responsible for a team’s products meeting software design, quality, and performance requirements
Pursue new technology development via the DoD Small Business Innovative Research (SBIR) program
Work with minimal supervision in a collaborative work environment to implement best-in-class solutions
Minimum Required Qualifications:
Bachelor’s Degree in Computer Science, Computer Engineering, Electrical Engineering, Systems Engineering, Physics, or Math Required; PhD in relevant field highly preferred
7+ years of experience in predictive modeling, data science and analysis
Required Skills:
Previous experience in a ML or data scientist role and a track record of building ML or DL models
Extensive experience working with data mining algorithms including decision trees, probability networks, association rules, clustering, and neural networks
Experience using Python (or equivalent)
Experience using ML libraries, such as scikit-learn,
Experience using data visualization tools
Experience handling terabyte size dataset
Experience working with GPUs to develop models
Ability to travel 10% or less
Preferred Skills:
Experience with MapReduce programming (Hadoop)
Skills with programming languages, such as Java or C/C++
Demonstrated ability to develop experimental and analytic plans for data modeling processes, use of strong baselines, ability to accurately determine cause and effect relations
Consulting experience and track record of helping customers with their AI needs
Publications or presentations in recognized Machine Learning, Deep Learning and Data Mining journals/conferences
Combination of deep technical skills and business savvy enough to interface with all levels and disciplines within our customer’s organization
Experience diving into data to discover hidden patterns
Experience with application container platforms
Familiarity with continuous integration/delivery tools (e.g. Jenkins)
Familiarity with version control tools (e.g. Subversion, Git, etc.)
Familiarity with VMware or other virtualization software
Experience developing applications for DOD command and control systems
Competencies:
Solid analytical abilities, coupled with a strong sense of ownership, urgency, and drive
Attention to detail
Initiative, creativity, reliability, teamwork
Ability to deal well with ambiguity, prioritize needs, and deliver results in a dynamic environment
EEO Statement:

IDT is an Equal Opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, creed, sex, sexual orientation, gender identity, national origin, disability, protected Veteran status, or any other basis protected by federal, state, or local law.",-1,Innovative Defense Technologies (IDT),"Mount Laurel, NJ",-1,-1,-1,-1,-1,-1,-1,-1
Full Stack Software Engineer (Python/Vue),-1,"Position Summary Full Stack Software Engineer (Python VueJS) Company Overview Our client is an automated underwriting platform for real estate professionals that was built to disrupt the commercial real estate industry. The software allows investors, brokers, and lenders to analyze rent, operating expenses and returns for multifamily properties by applying machine learning to a database of live multifamily transaction data from every U.S. market. Our client has a creative and entrepreneurial culture ndash everyone on the team interacts directly with customers each day, and we all contribute to the product and planning. If you have an idea to improve something, there is no red tapehellip just build what needs to be built! Innovation and passion for transforming the old-fashioned real estate industry are our highest priorities. Job Description As a full-stack (Python, PostgreSQL and HTMLCSSJavaScript) developer, you'll work on the interface and backend infrastructure of products and features used by hundreds of underwriters and real estate analysts every day. The work is challenging, fast-paced, and always changing. You must have demonstrated analytical skills, an unwavering commitment to quality, a collaborative work ethic, and cutting-edge coding skills. You must display solid proficiency in the fundamentals of Python, PostgreSQL, JavaScript, HTMLCSS, and popular front-end frameworks like Vue.js. The role will include the delivery of reliable, scalable new features to users, developed in Python, interacting with a PostgreSQL database and using the Vue.js frontend framework. You will work with the development team to develop, test and deliver finished, high quality, compelling features and products. Our team includes designers, engineers and data scientists who are passionate about quality, usability, and simplicity. If you are ready to join a company that fosters learning, growth, experimentation and innovation, our client's team is for you. Requirements Qualifications 3-5 years of experience in full stack Python development 1-3 years of experience with PostgreSQL 1-3 years of experience with JavaScript frameworks such as React, Angular or Vue.js (Vue.js is preferred, this is what our client uses), and CSS pre-processing frameworks (Sass or Less) 1-2 years of experience integrating with VBA and Excel integration preferred Experience using GitHub and solid understanding of software version control Familiarity with JIRA or equivalent product management software Familiarity with agile development best practices Driven self-starter able to work on a small team and take initiative on new tasks Familiarity with real estate or finance is a plus Responsibilities Collaborate with interdisciplinary team of data scientists, software engineers and real estate professionals Strive for high quality and rapid output utilizing agile development best practices Support, maintain, and document software functionality Maintain industry standard coding, compliance, security practices Proactively learn product frameworks and code base Our client is a startup company, and as such the responsibilities outlined above may change and evolve over time. Flexibility, curiosity, an entrepreneurial mindset, and strong work ethic are essential for this role. It is encouraged that everyone on the team continually research new technologies and analytical opportunities to improve the platform.",5.0,"CultureFit
5.0","Chicago, IL","Deerfield, IL",1 to 50 employees,1997,Company - Private,Advertising & Marketing,Business Services,$1 to $5 million (USD),-1
AWS Data Engineer,-1,"About Infinitive:

At Infinitive, we do mission-critical work for great companies. We specialize in digital marketing and digital advertising solutions, customer data & analytics, digital & business transformation, and Technology solutions. Our Technology solutions focus on Managed Cloud Services, Cloud Enablement, Digital Operations, Application Development, DevOps, Product Development, Cloud Security, Data Science and Analytics, AI/ML, IoT, and everything in between.

Our experts are results-obsessed, focused and flexible, highly engaged and hugely experienced having sat in our clients seats. Those qualities are what make us different than old-school consulting shops. And surely, they are why clients and partners describe us as the gold standard in client experience.

Infinitive has been named a Best Small Firms to Work For by Consulting Magazine seven times, a Washington Post Top Workplace three times, a Washington Business Journal Best

About this Role:

Infinitive is growing its team in the Northern Virginia area and is currently seeking an Data Scientist to join our growing Technology practice. This person will utilize their experience in analytics, IoT, machine learning, and artificial intelligence advances to create value from structured and unstructured data. The ideal candidate has experience designing novel data analytic methods and workflows, including full data pipelines from raw data through analysis results. They must also have exposure to a variety of data mining/data analysis methods, data tools, building and implementing models, using/creating algorithms, and creating/running simulations.

We are looking for candidates who are accountable, passionate, assertive, proactive, open & honest, results oriented, and adaptable. Each project engagement represents a new challenge that will give you exposure to new clients, business issues, technologies, and people and will involve a range of responsibilities to include:
Developing in Java, Python, R, or other high-level languages.
Managing disparate data sources with varying data structures of content and preparing these for data science and machine learning applications.
Working with distributed scalable Big Data storage, processing, and computation, including AWS EMR, Spark, etc.
Implementation knowledge of, or desire to learn AWS / Azure data science capabilities.
Developing solutions and integrating and extending free and Open-source software (FOSS) or COTS products.
Conduct MapReduce programming with Apache Hadoop, the Hadoop Distributed File System (HDFS), and processing large data stores.
Knowledge of SQL and query languages.
Utilize real-time, large-scale data processing engine, including Apache Spark.
Lead and create Data Science and Analytics methodologies and frameworks for implementation.
Ability to build and develop Data Science demonstrations for clients
Qualifications:
4+ years of development experience (Java, Python, R, SQL)
3+ years of experience with distributed scalable Big Data storage, including AWS EMR, Spark, etc.
Desire to become AWS / Azure Certified architect / engineer.
Experience performing data Management, modeling, and warehousing.
Hands on experience with Amazon analytic tools (preferred)
Interest in being involved internally and growing a small business (entrepreneurial spirit)
Ability to travel (up to 20%) and to work independently
Experience using Agile software development methods in a DevOps environment.
Excellent leadership, peer management, and communication skills
Management consulting experience (preferred)
Bachelor's degree in related field (preferred)
Applicants for employment in the U.S. must possess work authorization which does not require sponsorship by the employer for a visa.

Infinitive is an Equal Opportunity Employer.

Powered by JazzHR",3.4,"Infinitive Inc
3.4","Arlington, VA","Cedar Rapids, IA",201 to 500 employees,1997,Company - Private,Enterprise Software & Network Solutions,Information Technology,$10 to $25 million (USD),-1
"Senior SW Engineer, Data Science ( Kubernetes/ Docker ) Remote USA","$72K-$141K
(Glassdoor est.)","If you dream of a job working in a field where all the hard problems are solved and you get to re-use previous research to get your job done, you need not apply. If, however, you are someone who wants to tackle problems that truly are on the cutting edge, then we encourage you to keep reading.

Data Science is an emerging field within cyber security. FireEye, given its deep expertise and comprehensive view on the advanced threat landscape, is uniquely positioned to enable data scientists to have major impact within our industry, company, and across our customer base. Detecting security breaches using machine learning and data analytics is an unsolved problem (this is not handwriting recognition folks) and has huge potential.

If you are someone who wants to be on the cutting edge of a high profile industry, who wants to make an impact by pushing both fields of data science and cyber security forward, you may be the perfect candidate to help us on our mission.

What you will do:
Develop, and manage data systems to ingest and process data at massive scale
Identify data sources both internally and externally that we can use to find evil.
Contribute towards the architecture and design of software solutions for long-term storage and retrieval.
Identify and implement data exploration technologies. Create dashboards and implement analytical tools for exploration
Work with data scientists to productize ML models and assist product teams with ML model releases into end products.
Collect requirements, design, and build backend components and tools to run ML models, assess ML model efficacy, manage large scale datasets, and generate features for ML models
Contribute to the evolution of coding and design practices within the organization.
Review code base commits and contribute to the growth of team members.
Requirements
Ability to work in an iterative, agile development environment.
Experience implementing ETL processes and building data pipelines
Experience developing reliable distributed systems.
Experience in Data modeling and schema design
Strong knowledge of a variety of operating systems, networking fundamentals, software design and programming best practices.
Experience with use of a wide array of algorithms and data structures.
Deep understanding and experience of going through the entire life cycle of building software platforms and products
Deep knowledge of various AWS services and associated tools
Strong experience developing in Python 3
Experience developing in at least 1 of the following: C, Go or Java
Experience with RDBMS, such as PostgreSQL or MySQL, as well as NoSQL
Experience with Kubernetes and Docker.
Experience deploying products in AWS
Additional Qualification: *
Ability to pick up, work with and explore new analytical tools
Strong experience with DevOps practices and common tooling
Strong communication skills.
Ability to work with loosely defined requirements.
At FireEye we are committed to our #OneTeam approach combining diversity, collaboration, and excellence. All qualified applicants will receive consideration for employment without regard to race, sex, color, religion, sexual orientation, gender identity, national origin, protected veteran status, or on the basis of disability. Requests for accommodation due to disability can be sent directly to .",3.3,"FireEye Inc
3.3","Denver, CO","Milpitas, CA",1001 to 5000 employees,2004,Company - Public,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,"Palo Alto Networks, Tanium"
"Senior SW Engineer, Data Science","$72K-$141K
(Glassdoor est.)","Job Description

If you dream of a job working in a field where all the hard problems are solved and you get to re-use previous research to get your job done, you need not apply. If, however, you are someone who wants to tackle problems that truly are on the cutting edge, then we encourage you to keep reading.

Data Science is an emerging field within cyber security. FireEye, given its deep expertise and comprehensive view on the advanced threat landscape, is uniquely positioned to enable data scientists to have major impact within our industry, company, and across our customer base. Detecting security breaches using machine learning and data analytics is an unsolved problem (this is not handwriting recognition folks) and has huge potential.

If you are someone who wants to be on the cutting edge of a high profile industry, who wants to make an impact by pushing both fields of data science and cyber security forward, you may be the perfect candidate to help us on our mission.

What you will do:
Develop, and manage data systems to ingest and process data at massive scale
Identify data sources both internally and externally that we can use to find evil.
Contribute towards the architecture and design of software solutions for long-term storage and retrieval.
Identify and implement data exploration technologies. Create dashboards and implement analytical tools for exploration
Work with data scientists to productize ML models and assist product teams with ML model releases into end products.
Collect requirements, design, and build backend components and tools to run ML models, assess ML model efficacy, manage large scale datasets, and generate features for ML models
Contribute to the evolution of coding and design practices within the organization.
Review code base commits and contribute to the growth of team members.",3.3,"FireEye Inc
3.3","Denver, CO","Milpitas, CA",1001 to 5000 employees,2004,Company - Public,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,"Palo Alto Networks, Tanium"
"Senior Machine Learning Engineer, Early Stage Pipeline, X",-1,"Senior Machine Learning Engineer, Early Stage Pipeline, X

Software Engineering

Mountain View, CA

We're an early stage team at X with a growing, interdisciplinary portfolio. To prove our path to the moon, we make early contact with the real world through both internal and external partnerships.

In this role, you will be responsible for taking early stage investigations from an idea stage to first prototypes to a full-blown projects. You'll be rapidly iterating through a set of prototypes to evaluate possible product directions. This is an extremely dynamic role and requires high cross-functional communication, organization, and planning. The ideal candidate is a self-starter and has a track record of effectively operating in a dynamic loosely structured environment (e.g. startup, new products within a larger company). The candidate will work on multiple projects/investigations.

Responsibilities:
Identify and implement a set of machine learning prototypes to aggressively de-risk projects building the whole solution: data acquisition, data processing pipelines, ML modeling.
Setup technical direction for investigations/projects working with the early stage leadership team.
Team lead investigations that grow to become projects.
Qualifications:
Hands-on experience with machine learning, one or more of; natural language processing (semantic understanding, sentiment analysis), computer vision, time series analysis.
Experience with building robust data pipelines.
Tech Lead experience.
Startup or early-stage product development experience.
Preferred Qualifications:
Experience with the Google Cloud Platform
About X, the Moonshot Factory

X creates radical new technologies to solve some of the world's biggest problems. We develop uncomfortably ambitious, potentially world-changing new ideas such as self-driving cars, balloon-powered Internet and smart contact lenses. We're a team of makers, entrepreneurs, engineers, designers and scientists with deep technical expertise who love the challenge of the seemingly impossible. We believe that a culture of psychological safety creates the foundation of trust and respect necessary to build moonshots. X was formerly known as Google[x] and is part of Alphabet .

At X, we don't just accept difference - we celebrate it, we support it, and we thrive on it for the benefit of our employees, our products and our community. We are proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements.

If you have a disability or special need that requires accommodation, please contact us at: (see application details) .",-1,"X, the moonshot factory","Mountain View, CA",-1,-1,-1,-1,-1,-1,-1,-1
"Senior/Staff Software Engineer, Data Infrastructure","$116K-$227K
(Glassdoor est.)","Senior/Staff Software Engineer, Data Infrastructure job posting

Every year, while Americans wait for their paychecks, more than $1 trillion of their hard-earned money is held up in the pay cycle. As a result, we accumulate over $50 billion in late and overdraft fees and turn to high-interest loans. Overdraft charges and bank fees often trap people in a cycle of debt that can lead to unhealthy decisions and falling victim to predatory businesses disguised as helpful services. We don't accept that.

Earnin is an app that creates products that help people gain control of their finances. Cash Out lets people get paid as soon as they leave work, with no fees, interest, or hidden costs. With Health Aid, Earnin negotiates on behalf of community members to lower their total unpaid medical bill and work out a budget-friendly payment plan. Cash Back Rewards is a way for members to earn up to 10% cash back on purchases from over a thousand local and national businesses without needing a credit card or having to reach spend thresholds to earn cash rewards — and they can withdraw the money at any time. We also offer free tools to help avoid overdrafts, to remind people when recurring bills are due, and we're working on more! There is never any required cost to use any of these products or services, users can choose to tip what they think is fair to support the service and pay it forward to keep the movement going.

Earnin is supported by funding partners including Andreessen Horowitz, Matrix Partners, Ribbit Capital, Felicis Venture, Thrive Capital, and others. Join us and help build a new financial system focused on fairness and people's needs.

You can help make a difference.

About the Team:

We are a data driven mobile financial tech company. The Data Infrastructure team builds the data services and data infrastructure that powers data science, analytics, and product development throughout Earnin. We are looking for a product-minded, self-driven Senior Software Engineer to own multiple large-scale projects that advance our mission of enabling people to gain access to their paycheck on demand.

What sets us apart:
High impact roles at a relatively small company that's aggressively growing our user base.
We are a collaborative team and genuinely enjoy working with each other.
We believe in empowering our people to be successful.
We're building a product that inspires fairness across the financial world and helps people not get taken advantage of.
As a Senior Engineer you will:
Break down complex problems into their bare essentials, translate this complexity into elegant design and create high quality, maintainable code.
Build massively scalable, production-grade data services.
Champion data quality and governance throughout the organization.
Build a world class data lake and data warehouse.
Design and develop new systems and tools to enable all of Earnin to consume and understand data faster.
Own the end to end design, build, and maintenance of platform services, data pipelines, and data products.
Implement comprehensive monitoring, logging, and alerting across our data infrastructure.
Work cross functionally with other teams (data science, design, product, marketing, and analytics) in high visibility roles as an engineering leader.
Build and deploy the data architecture that supports machine learning model development and actionable analytics.
Work with product engineering and data science teams to design scalable, performance model deployment architectures.
Communicate the tradeoffs of technical decisions to multiple stakeholders, including non-technical audiences.
Collaborate with and mentor other engineers and provide engineering direction to data scientists and analysts.
Actively engage and drive design reviews and code reviews.
Some skills we consider critical to being a Senior Engineer:
BS or MS degree in Computer Science, Engineering, or a related technical field.
8+ years of development experience in a fast-paced environment, especially startups.
5+ years of experience working with data systems.
Strong Python and SQL skills.
Strong programming and architecture skills.
Excellent written and verbal communication skills, including the ability to identify and communicate data driven insight.
Taking pride in your code quality and helping others elevate their own code quality.
Substantial experience with testing, data validation, and data quality assurance.
You can articulate the tradeoffs of different deployment architectures (e.g. streaming vs. batch vs. service-based).
Experience designing data platforms and services on cloud infrastructure, preferably AWS.
Hands-on experience designing and building large-scale solutions with the Hadoop stack and/or Spark.
Experience tuning and optimizing Spark-based applications.
Experience deploying and/or using query engines like AWS Athena, Presto, and Impala.
Experience with AWS analytical services like Redshift.
Hands-on experience working with a varied set of data storage technologies (e.g. Mysql, Postgres, DynamoDB, S3, etc.). You know where and when to use each.
Extensive experience with data modeling for multiple use cases and application styles, including NoSQL data modeling.
Experience working with data formats such as Avro and Parquet.
Experience working with alerting and monitoring tools like DataDog and PagerDuty.
Nice to haves:
You have experience building and deploying machine learning models.
You have experience using Terraform.
You have substantial experience working at a startup.
You have experience with data modeling in Redshift.
Experience with streaming infrastructure like Kafka.
Experience working with Kubernetes.
Experience building and deploying AWS Lambda applications.",3.1,"Earnin
3.1","Palo Alto, CA","Palo Alto, CA",201 to 500 employees,2012,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Engineer (open level),"$43K-$69K
(Glassdoor est.)","Title
Data Engineer (open level)

07/08/2020

What you'll do...
At H&R Block, your contributions will go far beyond any job description. When you join our team, you'll add to the momentum of a forward-thinking company - one that defined an industry and is now leading its transformation.

H&R Block is transforming tax preparation through data to ensure that every client we serve gets the best tax outcome possible.

We are building a new Data Engineering Team in the Data Science & Analytics organization. This new team will own the technology and data capabilities of the end-to-end data-and-analytics function. It will take responsibility for building and maintaining the analytical technologies that the data science teams use, managing data at an enterprise scale, leveraging relationships with IT teams throughout the enterprise, and leading information architecture.

We are looking for talented, curious, and creative data engineers of all levels to help launch this team. You will be a good match for our organization if you are:
Motivated by the idea of building something innovative, transformative, and impactful.
Committed to the idea that data can drive experiences and products that wow our business partners and clients
Obsessed with defying expectations and raising the bar
Driven by an innate sense of ownership for the products you create.
Day to day, you'll...
Design and deploy architecture, solutions, and software to capture, manage, store, and use structured and unstructured data from internal and external sources in both on-prem and cloud environments.
Deploy machine-learning models and other data-science products across the enterprise.
Navigate the balance between business needs, data governance best practices, and technical requirements.
Select or develop tools to cleanse, organize, and transform data and to maintain, defend, and update data structures and integrity on an automated basis.
Develop data products to facilitate self-service capabilities and assist the data teams to increase their efficiency and effectiveness.
Collaborate and communicate effectively within cross-functional teams that span internal Data Science & Analytics teams, IT, business groups, and executive stakeholders.
Be a positive force to cultivate a culture that is passionate about developing data tools as a business driver.
Job ID
368348BR

Address1
ONE H&R BLOCK WAY

City
KANSAS CITY

State
Missouri

Employee Type
Regular

What you'll bring to the team...
Education / work experience should include most of these, depending on level:
Bachelor’s degree in Computer Science or a related technical field (or equivalent work experience and technical skills)
Data warehousing and ETL solutions
APIs in a microservices architecture
Big-data technologies and the Hadoop stack (MapReduce, Hive, Pig, Hbase
NoSQL implementations (MongoDB)
Developing Java-based software solution
At least one scripting language (Python, Perl, JavaScript, Shell
Developing software solutions to solve complex business problems
Working with data scientists and other data users
Posting Title
Data Engineer (open level)

Sponsored Job
#hrbjob

Job Family
Corporate Analytics",3.6,"H&R Block
3.6","Kansas City, MO","Kansas City, MO",10000+ employees,1955,Company - Public,Other Retail Stores,Retail,$2 to $5 billion (USD),"Intuit, Jackson Hewitt, Liberty Tax Service"
Senior Modeling & Simulation Engineer,-1,"Applied Research Associates, Inc. is looking for a Senior Modeling and Simulation Engineer to join our multi-disciplinary team of engineers and scientists in the Capital Area Division, located in Alexandria, VA. The ideal candidate has a passion for predicting the behavior of physical systems in challenging environments and operational impact on mission success. Models will be developed, used, and improved to support a Department of Homeland Security customer to safeguard the nation’s borders and interior from chemical, biological, radiological, nuclear, and explosive materials, equipment, technologies, and their actors. Models may be based on the underlying physics or may be process or agent based to predict operational performance and impact. Modeling and analysis may require the use and development of 3D virtual worlds or geospatial data. Models will be verified and validated, and they will be used in support of test and evaluation activities of systems intended to detect and identify threats. The candidate may participate in test and evaluation activities to support the verification, validation, and overall improvement of models. Models may become part of larger, integrated modeling and simulation activities, and may require the use of high performance computing technologies and federated simulations.

This position is contingent upon award of a contract expected in Summer 2020 supporting the Department of Homeland Security.

Required Qualifications:
Ability to program in a high level programming language, such as Fortran, C++, or Java
Eagerness to learn new tools and techniques
Strong verbal and written communication skills
Must be a U.S. Citizen with the ability to obtain and maintain a security clearance
Bachelor’s degree with minimum of 10 years of experience or greater in a physical science (physics, chemistry, biology), engineering-related discipline (nuclear, chemical, civil, mechanical, electrical), or modeling& simulation disciple (computer modeling, computational science, operations research)
Ability to present to senior leadership on the status and issues associated with research or test efforts in preparation for acquisition decision meetings
Desired Experience and Qualifications:
Experience modeling CBRNE detectors or effects
Experience using multiple software tools such as MCNP, GadRas, SWORD, ExtendSim, Arena, SolidWorks, Fluent, ArcGIS, QGIS, VisIt, ParaView, or Cubit
Experience creating 3D models of systems, i.e., CAD
Experience using high performance computers (i.e., supercomputers)
Experience developing and using discrete event or agent based models and simulations to predict and assess system performance
Experience developing machine learning models
Background in a physical science or engineering discipline, such as Physics, Chemistry, Biology, Mechanical Engineering, Nuclear Engineering
Active DoD Secret or Top Secret clearance, DoE Q clearance, or DHS Suitability
COMPANY INFORMATION:

Applied Research Associates, Inc. is an employee-owned international research and engineering company recognized for providing technically superior solutions to complex and challenging problems in the physical sciences. The company, founded in Albuquerque, NM, in 1979, currently employs over 1200 professionals. ARA offices throughout the United States and Canada provide a broad range of technical expertise in defense technologies, civil technologies, computer software and simulation, systems analysis, environmental technologies, and testing and measurement. The corporation also provides sophisticated technical products for environmental site characterization, pavement analysis, and robotics.

At ARA, employees are our greatest assets. The corporation realizes that employee ownership spawns greater creativity and initiative along with higher performance and customer satisfaction levels. ARA gives its employees the tools, training, and opportunities to take more active roles as owners. The culture is challenging; innovation and experimentation are the norm. Employees are eligible for contributions which not only add to the company’s success, but also their own through the Employee Stock Ownership Plan (ESOP). The motto,“Engineering and Science for Fun and Profit” sums up the ARA experience. For additional information and an opportunity to join this unique workplace, please visit our website atwww.ara.com.",3.5,"Applied Research Associates
3.5","Alexandria, VA","Albuquerque, NM",1001 to 5000 employees,1979,Company - Private,Federal Agencies,Government,$100 to $500 million (USD),-1
Senior Data Engineer,-1,"This is a Data Engineer position for supporting a Navy program located in Quantico, Virginia.

We are seeking a Data Engineer to join our team of committed technical professionals to protect those who serve against criminal, terrorism and emerging threats. Are you passionate about analytics and innovation? Our employees enjoy a fast-paced, collaborative culture and the ability to directly impact our business. You will identify technical issues and opportunities for efficiency and provide technical insights through system design and configuration perspectives. This role is both challenging and rewarding.

You will support the mission through the implementation of a modern, integrated internal data infrastructure with a focus primarily on exploiting the established data foundation to make internal and customer-centric business processes as effective and efficient as possible, laying the foundation for cognitive capabilities that can sense and respond to both internal and external customer data needs. The candidate will also focus on expanding the organization’s data ecosystem to include context-rich data while maintaining the agility needed to spark innovation.

How you will make a difference:
Establish shared operational data and integrated enterprise data, all while managing and/or improving data quality and security through the creation of business-driven governance structures and culture change management.
Establish data policies, standards, and procedures that improve data quality, availability, accessibility, security, usability, and enforcement of enterprise information management (EIM) program requirements.
Establish enterprise standards – including a uniform and repeatable system development lifecycle methodology for Reference Data and Master Data (e.g., a common set of standards for data naming, abbreviations, and acronyms).
Develop a Master Data Management (MDM) Plan that focuses on the technology, tools, and processes ensuring master data is coordinated across the enterprise. MDM is a method used to define and manage the critical data of an organization to provide, with data integration, a single point of reference. The data that is mastered may include reference data – the set of permissible values, and the analytical data supporting decision making. MDM provides a unified master data service intended to provide accurate, consistent and complete master data across the enterprise and to business partners.
Recommend solutions based on performing industry-specific analysis, such as case studies describing data management best practices, identifying trends across the industry.
Make recommendations to improve the efficiency and effectiveness in how the agency acquires, stores, manages, shares and applies its data.
Engage business users and stakeholders for the increased release of actionable high-quality data on key operational and tactical activities at NCIS.
Develop technology solutions to provide the platform, training, and standardized tools enabling querying, data mining, statistical analysis, reporting, scenario modeling, data visualization, and dash-boarding, and processes for a centralized, or analytics as a service model, allowing for the sharing of data across the enterprise from a common hub, facilitates cross-organizational data initiatives due to its enterprise-wide view of data assets and needs.
Basic Qualifications
Required: A bachelor’s or master’s degree in computer science, data science, operations research, statistics, applied mathematics, or a related quantitative field [or equivalent work experience such as, economics, engineering and physics] is [preferred/required]. Alternate experience and education in equivalent areas such as economics, engineering or physics, is acceptable. Experience in more than one area is strongly preferred.
Required: Three to six (midlevel) of relevant project experience in successfully launching, planning, and executing data science projects. Preferably in the domains of risk modelling and quality assessment.
Preferred: Specialization in text analytics, image recognition, graph analysis or other specialized ML techniques such as deep learning, etc.
Preferred: the candidates are adept in agile methodologies and well-versed in applying DevOps/MLOps methods to the construction of ML and data science pipelines.
Coding knowledge and experience in several languages: for example, R, Python, Java, C++, Excel, MATLAB, etc.
Experience with popular database programming languages including SQL, PL/SQL, others for relational databases and upcoming non-relational databases such as NoSQL/Hadoop-oriented databases such as MongoDB, Cassandra, others.
Preferred: Specialized/operational data scientists may need further high-performance computing (HPC)/compute skills; larger data science teams, in particular, may require further degrees of specialization such as:
Experience with distributed data/computing tools such as MapReduce, Hadoop, Hive, Kafka, and MySQL
Experience of working across multiple deployment environments including cloud, on-premises and hybrid environments, multiple operating systems and through containerization techniques such as Docker, Kubernetes, AWS Elastic Container Service, and others.
Experience in one or more of the following commercial/open-source data discovery/analysis platforms: RStudio, Spark, KNIME, RapidMiner, Alteryx, Dataiku, H2O, SAS Enterprise Miner (SAS EM) and/or SAS Visual Data Mining and Machine Learning, Microsoft AzureML, IBM Watson Studio or SPSS Modeler, Amazon SageMaker, Google Cloud ML, SAP Predictive Analytics.
Preferred: Expertise in solving vision, text analytics, credit scoring, and failure prediction problems.
Knowledge and experience in statistical and data mining techniques such as generalized linear model (GLM)/regression, random forest, boosting, trees, text mining, hierarchical clustering, deep learning, convolutional neural network (CNN), recurrent neural network (RNN), T-distributed Stochastic Neighbor Embedding (t-SNE), graph analysis, etc.
Strong documentation skills. Required: Certifications as per Cybersecurity Workforce Management and Qualification Manual, SECNAV M-5239.2.
Required: Eligible AND adjudicated to the Top Secret (TS SCI) clearance level is required to start.
About Inventium.io:

Inventium.io LLC is a technical consulting and software development services company dedicated to protecting and advancing our national defense and scientific capabilities. Based out of the Washington DC area, we rely on innovation to continually advance our employees' skills and provide digital transformation solutions to our customers.

With proven records of successfully delivering quality services and solutions to multiple federal agencies, our technical competencies include Emerging Technology Solutions, DevSecOps, Cloud Migration, Machine Learning, System Modernization, and Technology Management.

Benefits and Perks
Employer paid Health Benefits (Medical, Dental and Vision)
Retirement Plan
Paid Time Off and Federal Holidays
Training and Development
Employee Referral Program
Awards and Recognition",5.0,"inventium.io LLC
5.0","Quantico, VA","Washington, DC",1 to 50 employees,2016,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Senior Software Engineer,-1,"At Pacific Biosciences, our R&D team is committed to developing innovative products that enable scientists to excel in a wide variety of life science research fields, including human biomedical, plant and animal sciences, and microbiology and infectious disease. Our unique Single Molecule, Real-Time (SMRT) sequencing platforms generate true high-quality long reads, giving researchers a more comprehensive view of genomes, transcriptomes, and epigenomes from any organism.

The Primary Analysis group, as part of the larger software engineering team at PacBio, develops algorithms and HPC solutions for decoding the raw data streams, generated through high-speed optical detection of the SMRT sequencing reactions, into DNA sequence reads. We operate at the intersection of cutting-edge nanotechnology and state-of-the-art bioinformatics tools, and our responsibilities span the full product development life cycle in an aggressive time-to-market environment. These include analysis and algorithm development in coordination with chemistry and systems R&D; the development of real-time analysis pipelines; and the development of validation and support infrastructure geared towards product system reliability and internal R&D support. We are seeking a talented algorithm engineer with a strong background in the physical or machine-learning/data sciences who also has a passion for designing and developing performance-critical data analysis solutions.

Responsibilities:

Design, develop, and test signal- and sequence-analysis algorithms that will drive fundamental improvements in basecalling accuracy and yield.
Work collaboratively in a team environment to solve challenging problems in software architecture and scalability of real-time analysis pipelines for our next-generation sequencing platforms.
All listed tasks and responsibilities are deemed as essential functions to this position; however, business conditions may require reasonable accommodations for additional tasks and responsibilities.

Key Skills and Background:

3+ years of experience shipping product software in a scientific or quantitative domain.
Demonstrated skills applying numerical methods, statistical signal processing, or machine-learning techniques to high-throughput, performance-critical analysis applications.
Linux-based systems programming experience with knowledge of OS, toolchain and hardware constraints.
Strong C++ programming experience in applications geared towards performance and scalability; previous experience in CUDA programming for GPU is a plus.
MS, PhD or equivalent experience in a quantitative field (physics, CS, etc.), preferably with an applied math or algorithmic focus.
Engineering instincts to efficiently investigate and solve the problem at hand, from prototype development (Python, R, MATLAB, etc.) to production designs.
Team player, with strong communication skills, and comfortable as a self-starter in an agile, fast-paced development environment.
All qualified applicants will receive consideration for employment without regard to race, sex, color, religion, national origin, protected veteran status, or on the basis of disability, gender identity, and sexual orientation.",3.7,"Pacific Biosciences
3.7","Menlo Park, CA","Menlo Park, CA",201 to 500 employees,2000,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,$50 to $100 million (USD),Illumina
Senior Data Engineer,-1,"ABOUT 605

At 605 we are engineers, analysts, data scientists, media experts, marketing strategists and political operatives. Our team of data scientists pioneered the field of TV data analytics. We offer unique, independent audience measurement and analytics to build better marketing and programming initiatives within the media and entertainment industries.

The Sr. Data Engineer at 605 must have a broad and deep data skillset as well as strong analytical capabilities . In addition to being a hands on individual contributor, the ideal candidate is a productive team player and a mentor to Junior. Data Engineers. Additionally, we are looking for strong technical experts.

Responsibilities include:
Actively participate in team technical discussions in all things data
Identify and address issues with data sets from multiple vendors
Identify and address code and data quality issues
Actively participate in code reviews and grooming sessions
Actively participate in technology architecture discussions for product development
Translate business requirements into strategy
Advocate for software best practices within your team as well as across engineering
Be ultra-responsive and capable of making instant decisions, always kicking the ball forward
Work on unique and interesting data challenges around architecting, building and managing pipelines that securely process hundreds of terabytes of data
Work closely with analysts and statisticians to ensure the validity of our processes
Our engineers are expected to wear a number of hats and have the opportunity to touch all parts of the stack. Our stack includes Apache Spark, Scala, Redshift and an ever-growing list of many other cool technologies.

Requirements
Skillful user of Apache Spark
Experience wrangling terabytes of big, complicated, imperfect data
Experience with AWS products (Redshift, EMR, S3, IAM, RDS, etc)
You have a deep understanding of scalable systems and you have large-scale engineering experience in an Agile development environment
Bachelor's degree in Computer Science or a related field (or 4 additional years of relevant work experience)
A strong understanding of data structures, algorithms, and effective software design
Significant development experience with a major modern language (e.g. Java, Scala, Python, Ruby, C/C++, etc.)
Significant experience working with structured and unstructured data at scale and comfort with a variety of different stores (key-value, document, columnar, etc.) as well as traditional RDBMSes and data warehouses
Experience with or interest in AWS Glue, Redshift Spectrum and any other tools that enable data querying at scale
Experience writing unit, functional and integration tests
Comfort with version control systems (e.g. Git, SVN)
Excellent verbal and written communication skills; must work well in an agile, collaborative team environment
Preferred Qualifications
Master's in Computer Science or a related field
Practical experience with supervised machine learning techniques
Strong background with test-driven development
Basic understanding of statistics and experience with statistical packages such as R, Matlab, SPSS, etc
Benefits

Important and Standard
Comprehensive health, dental and vision insurance for employees and their families
Life & Disability insurance
401k plan with match, eligible for match after one year
Pre-tax flexible compensation plan for medical, transit, parking or dependent care expenses
Up to 15 paid vacation days depending on grade level
7 paid sick days in a calendar year - if you’re sick, you stay home
Other cool benefits
4 work from home days/month
A kitchen stocked with sodas, snacks, yogurt and other goodies
A tight knit start up community who likes to eat! We celebrate everyone’s birthdays, have frequent team lunches, and do events in and out of the office
605 is an active participant in conferences
EEO STATEMENT

At 605, we’re just as passionate about diversity as we are about pioneering the field of TV data analytics. We are committed to cultivating an environment of mutual respect and equal opportunity. All hiring and advancement decisions are made on the basis of qualification, merit, and business need.",-1,605,"New York, NY",-1,-1,-1,-1,-1,-1,-1,-1
Sr Innovation Engineer,"$75K-$134K
(Glassdoor est.)","Company Information

Solid reputation, passionate people and endless opportunities. Thats Travelers. Our superior financial strength and consistent record of strong operating returns mean security for our customers and opportunities for our employees. You will find Travelers to be full of energy and a workplace in which you truly can make a difference.

Target Openings

1

Job Description Summary

Innovation is at the core of everything we do. We continue to ask ourselves, whats next? as we navigate the ever-changing insurance landscape. Continuing our customer journey toward the cutting-edge, we are looking for a forward-thinking individual that thrives in ambiguity, who believes that with every challenge comes a new opportunity for solutions.

As a member of the Innovation Technology team, you will partner with research scientists and product managers to discover, invent, and build solutions at scale. As a team, you will work on challenges in machine perception, data mining, machine learning, and natural language understanding.

We are looking for a hands-on individual with strong foundational knowledge highly scalable architectures and platforms. If you like using a variety of skills in technology and solving complex problems, work collaboratively in a small agile team environment, you might just be the person we need on our team!

Primary Job Duties & Responsibilities
Work closely with Cloud Engineering to build an innovation platform; a collection of reusable and extensible containers and tools specific to developing insurance products and platforms.
Recommend integration strategies, enterprise architectures, platforms and application infrastructure required to successfully implement a complete solution using best practices.
Produce quality output for highly visible IT products, services and future business development.
Assist in hands-on remediation of application stability and performance.
Adopt and communicate new concepts, ideas, techniques.
Manage multiple projects simultaneously.
Provide 'Shrink Wrap' solutions to solve business and technical needs. As part of our innovation process, be able to scale Minimum Viable Product to production systems.
Design and lead integration of analytic data products, including pilots and proof of concepts.
Frequently present and translate complex information in relevant business terms.
Constantly learn new skills within small teams.
No direct HR people management but will lead teams in project & program contexts.
Education, Work Experience, & Knowledge
Bachelors Degree in STEM (Science, Technology, Engineering, Mathematics) related field and 3+ years of experience or 10+ years of experience building highly scalable platforms and reusable components
Job Specific Technical Skills & Competencies
2+ years of experience working with Amazon Web Services (AWS) or equivalent cloud. Must be recent experience.
5+ years of designing and developing on-premise and cloud solutions.
3+ years of experience as a technical lead.
Experience in software engineering with relevant technologies (Java, JavaScript, Python etc.).
Experience with the application delivery process.
End-to-end experience with data, including querying, aggregation, analysis, and visualization.
Preferred Qualifications
AWS certified developer and/or architect
Proven ability to work creatively and analytically in a continuously evolving environment.
Exhibits high levels of learning agility in which they seek out and learn from unfamiliar experiences and then apply those lessons to succeed in the next new situation.
Ability to leverage business knowledge to determine approaches to execution.
Strong communication and presentation skills with the ability to present and translate complex information to leadership and non-technical teams in relevant business terms.
Uses effective listening skills and communication to build relationships across the organization.
Ability to Influence with experience working with matrixed staff to complete tasks in a timely manner.
Environmental / Work Schedules / Other
Travel Required
Equal Employment Opportunity Statement

Travelers is an equal opportunity employer.",4.1,"Travelers
4.1","Hartford, CT","Hartford, CT",10000+ employees,1853,Company - Public,Insurance Carriers,Insurance,$10+ billion (USD),-1
Senior AI Software Engineer,-1,"Company Overview

Calling the adventurers ready to join a company that's pushing the limits of nanotechnology to keep the digital revolution rolling. At KLA, we're making technology advancements that are bigger—and tinier—than the world has ever seen.

Who are we? We research, develop, and manufacture the world's most advanced inspection and measurement equipment for the semiconductor and nanoelectronics industries. We enable the digital age by pushing the boundaries of technology, creating tools capable of finding defects smaller than a wavelength of visible light. We create smarter processes so that technology leaders can manufacture high-performance chips—the kind in that phone in your pocket, the tablet on your desk and nearly every electronic device you own—faster and better. We're passionate about creating solutions that drive progress and help people do what wouldn't be possible without us. The future is calling. Will you answer?

Responsibilities

Group/Division
KLA has always had a close relationship with physics and data. Our optical and electron beam inspection and measurement tools use cutting edge physics models, both for hardware design and as part of their algorithms. AI, including several traditional machine learning techniques and deep learning are routinely used to process this data to meet application requirements.

The AI & Modeling Center of Excellence, centered in KLA’s R&D facility in Ann Arbor, MI, was setup with the mission of advancing KLA’s traditional strengths in physics and data and providing implementation solutions for multiple KLA Inspection and Metrology products targeted at the semiconductor manufacturing industry.

As a part of this group, you will be part of a world class team of physicists, HPC system designers, machine learning and application engineers who build cutting edge solutions for modeling complex imaging techniques and semiconductor processes. You will also work with a data scientists and AI infrastructure engineers whose mission is to build and scale machine learning based solutions for our semiconductor customers.

We are looking for engineers in a few different fields. If you are passionate about Physics Modeling, High Performance Computing - HPC (including GPU), ML, Data, or Cloud technologies – this is the place for you!

Responsibilities:
Software Engineers in the AI and Physics Modeling team may work on a variety of tasks including platform for large scale experimentation, scaleout of physics models, data management and inference solutions for KLA products.

Although familiarity with Machine Learning and Deep Learning solutions would be a big plus, this is primarily a Software Engineering position. Successful candidates are passionate about software, and will have exceptional skills and hands on experience with development in C/C++ and Python in a Unix environment. Deep conceptual understanding of multi threaded and multi process software systems is also necessary.

In addition to the above fundamental software skills, any of the following technical hands-on skills are highly desirable.

1) System Programming and Operating Systems.
2) Distributed systems for data management.
3) Distributed computing infrastructure.
4) Cloud technologies for storage, containerization and compute clusters.
5) Data Structures and algorithms
6) GPU architectures and data management.
7) Traditional machine learning using Random Forest, XG Boost, Logistic Regression.
8) Deep Learning for regression, classification. Generative models.
9) TensorFlow, NumPy, scikit-learn, and other ML and DL frameworks.
10) MPI and similar distributed computing framework.
11) GPU Architectures and CUDA (CuGraph, CuData, CuML etc).
12) GO Systems Programming, Java Programming.

Successful candidates for this position will also demonstrate the following non-technical skills.

1) Capability to formulate creative solutions through analyzing complex data
2) Good communication skills
3) Strong team player and motivated by team success
4) Strong problem solving skills

Minimum Qualifications

Doctorate (Academic) with at least 2 years of experience.
OR
Master's Level Degree with at least 4 years of experience.
OR
Bachelor's Level Degree with at least 5 years of experience.

Equal Employment Opportunity

KLA is an Equal Opportunity Employer. Applicants will be considered for employment without regard to age, race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability, or any other characteristics protected by applicable law.",3.8,"KLA-Tencor
3.8","Ann Arbor, MI","Milpitas, CA",5001 to 10000 employees,1976,Company - Public,Industrial Manufacturing,Manufacturing,$2 to $5 billion (USD),"Applied Materials, Nanometrics"
"Senior SDE, Catalog Big Data and Machine Learning",-1,"Amazon's Catalog DataWorks team is looking for highly motivated engineers. We are embarking on multiple new initiatives to re-organize Amazon's catalog of billions of products, in new and interesting views, that drive several features Amazon's customers love. Today, these views drive hundreds of popular features like product recommendations, clustering of similar products, and shopping with Alexa. We will build a new near real-time Catalog Data Lake on AWS, to enable engineers and scientists across Amazon to solve customer problems faster. Come join us on this exciting journey!

As an engineer on this team, you will own the Catalog Data Lake end-to-end. You will work closely with business partners to synthesize technical requirements. You will design and implement significant parts of the platform. You will learn and use industry standards like Spark and Parquet as well as modern AWS offerings like EMR, Glue, Athena, and Redshift. We are fortunate to be at the cusp of innovation in both the e-commerce business as well as cloud technology. As a key stakeholder, you will constantly learn new patterns, solve key customer problems and strive to make AWS better along the way.Basic Qualifications
Bachelor's degree or higher in computer science or math is required.
Strong computer science fundamentals - algorithms, data structures and design patterns.
At least 8 years of software development experience.
At least 3 years of experience building and operating Big Data systems.
Experience mentoring, guiding and influencing peers.
Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.",-1,Amazon Corporate LLC,"Seattle, WA",-1,-1,-1,-1,-1,-1,-1,-1
SENIOR SOFTWARE ENGINEER & SOFTWARE ARCHITECT,-1,"Job Description
Senior Software Engineer, Software Architect
JOB SUMMARY

The Senior Software Engineer, Software Architect will develop software for Company innovative semiconductor X-Ray inspection system. The Senior Software Engineer will collaborate with Applications, QA, and Algo teams for high performance solutions and optimization per customer issues. It will be important to be comfortable working in a small company environment and a typical startup with engineers and scientists.

ABOUT THE CLIENT

Based in San Jose, California, client was founded in 2013 expressly to bring high speed inspection and metrology technology to the semiconductor packaging industry. Client founders anticipated the need to deploy inline 100% transmissive inspection into the semiconductor packaging manufacturing process and developed the company’s technology with this end in mind. The results, Client’s HR-AXI technology suite brings together the company’s unique data acquisition architecture with proprietary machine learning analysis techniques to provide customers with process monitoring and defect detection capabilities not found on any other products in the market. This job description can be updated at any time.

RESPONSIBILITIES
Designs, develops, troubleshoots, and debugs software programs for enhancements and new products, focused on creating high quality and high-performance solutions while maintaining high-level coding standards.
Develops software and tools in support of design, infrastructure, and technology platforms. Develops software solutions by studying information needs, conferring with users, and studying systems flow, data usage, and work processes
Supports hardware compatibility and/or influences hardware design based on software needs; work as part of cross-functional team to solve and implement system level problems.
Monitor application stability, performance, and availability. Promptly resolve issues impacting operations.
Work with engineering, documentation, and applications departments to ensure successful development and delivery of overall product.
Provide appropriate project feedback to management in a timely and appropriate format.
QUALIFICATIONS AND REQUIRED SKILLS
Education requirement: Bachelor’s degree in Computer Science, Electrical Engineering, or similar technical field required. Master’s or PhD strongly preferred.
Experience requirement: Minimum of 8 years of related experience working in software development.
Strong expertise in C# .NET. WCF, WPF, Database development. In addition, Python experience a plus.
Experience with Image processing algorithms implementations is a plus
Experience with software development for Factory Automation for Semiconductor equipment, a plus.
Self-starter able to think and act independently to translate general objectives into tangible results, with a record of delivering successful designs on schedule.
Demonstrated ability to organize, manage, and complete multiple assignments with challenging timelines independently and effectively.
Demonstrated analytical and problem-solving skills with high attention to detail.
Proactive approach to problem-solving. Build relationships with stakeholders to support successful design, build and testing.
Strong verbal and written communication, good attitude, and work ethic. Ability to communicate technical concepts and results clearly.
Experience with Git and Azure DevOps, a plus.",3.0,"Simple Solutions
3.0","San Jose, CA","Morgantown, WV",1 to 50 employees,2006,Company - Private,IT Services,Information Technology,Less than $1 million (USD),-1
Cloud Engineer,-1,"Job Description
Responsibilities:
Develop and implement technical efforts to design, build, and deploy AWS applications at the direction of lead architects, including large scale data processing, computationally intensive statistical modeling, and advanced analytics
Participate in all aspects of the software development life cycle for AWS solutions, including planning, requirements, development, testing, and quality assurance
Provide guidance, thought leadership and mentorship to development teams to build cloud competencies
Provide innovative thought leadership around Mathematica’s cloud solutions strategy and approach, including AWS best practices and market trends
Position Requirements:

6+ years of experience architecting, designing, developing and implementing cloud solutions on AWS platforms
Demonstrated experience with designing and implementing solutions using AWS platform and tools, such as: EC2, S3, Redshift, API Gateway, Lambda, DynamoDB, CloudFormation, RDS, VPC, IAM and security, QuickSight, CloudTrail, Config, CloudWatch, SNS, AMI generation
Understanding of and experience with the five pillars of a well-architected framework
Knowledge of SQL, R, and Python for data manipulation and statistical analysis is desirable
Familiarity with federal security regulations and standards (e.g. HIPAA, FISMA, FIPS, NIST, and FedRAMP)
Experience with security, especially knowledge of FedRAMP, HIPAA, PII/PHI, is desirable
Experience in several of the following areas: database architecture, ETL, Business Intelligence, Big Data, Machine Learning, Advanced Analytics
Proven ability to work collaboratively with multi-disciplinary teams of business analysts, developers, data scientists, and subject matter experts
Strong written, verbal and interpersonal communication skills
AWS Certifications (such as AWS solutions architect or other specialty certifications) are a plus
Bachelor's degree or equivalent combination of education and experience; degree in computer science, mathematics or related field preferred
Experience with other cloud platforms like Google Cloud Platform (GCP) is a plus",4.8,"RICEFW Technologies Inc
4.8","Princeton, NJ","East Lansing, MI",51 to 200 employees,2009,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Senior Software Engineer / Team Lead,"$112K-$220K
(Glassdoor est.)","Join our team dedicated to developing and executing innovative solutions in support of customer mission success.

Job Description:

Novetta has an exciting opportunity for a self-motivated and accomplished Computer Scientist to lead our entity analytics team. You will work on complex projects involving data analysis, software engineering, and deploying software in a cloud computing environment. The team combines data from disparate sources to visualize the complex relationships between entities. This effort involves large scale data integration and entity resolution leveraging a best in class Novetta product. We are looking for a flexible problem solver with significant technical experience to lead a team providing unique solutions for our customers and stakeholders.

Responsibilities include:
Lead a technical team of software engineers and computer scientists, working within a larger ecosystem delivering an Enterprise capability.
Navigate customer and prime environment, manage resources within and across team, and assist team with professional and technical growth.
Deploy applications on a large-scale data processing cluster using AWS technologies.
Design and implement entity correlation strategies that are tailored to mission needs and unique data qualities.
Develop algorithms and visualization tools to help stakeholders understand their data and prioritize new data sources.
Develop and integrate applications to automate ingestion, processing and monitoring of data
Develop and maintain tools to support operations and maintenance of production and development computing clusters.
Basic Qualifications:
Experience leading a team of software engineers.
A Bachelor's degree in computer science or related field and a minimum of 5 years of experience; or a Master's degree in computer science or related field and a minimum of 3 years of experience.
Experience in software development/engineering including requirements analysis, software development, installation, integration, evaluation, enhancement, maintenance, testing and problem diagnosis/resolution.
Software development experience on Linux-based systems in Python or shell scripting or JavaScript.
Experience developing against full-featured REST APIs and using a command line interface
Desired Skills:

Should meet a minimum of 3:
Software development experience with JavaScript, Python, or other modern programming languages.
Hands-on experience with Spark.
Experience working with Databricks
Interest in statistical analysis, machine learning, or data science.
Experience with entity resolution products or a background in data matching theory and technologies.
Experience developing applications in AWS.
Security Clearance:
The candidate must have a TS/SCI with Poly.
Novetta, from complexity to clarity.

Novetta delivers highly scalable advanced analytics and secure technology solutions to address challenges of national and global significance. Focused on mission success, Novetta pioneers disruptive technologies in machine learning, data analytics, full-spectrum cyber, cloud engineering, open source analytics, and multi-INT fusion for Defense, Intelligence Community, and Federal Law Enforcement customers. Novetta is headquartered in McLean, VA with over 1,000 employees across the U.S.

Our culture is shaped by a commitment to our core values:

Integrity • We hold ourselves accountable to the highest standards of integrity and ethics.

Customer Success • We strive daily to exceed expectations and achieve customer mission success.

Employee Focus • We invest in our employees' professional development and training, respecting individuality and fostering a culture of diversity and inclusion.

Innovation • We know that discovering new and innovative ways to solve problems is critical to our success and makes us a great company.

Excellence in Execution • We take pride in flawless execution as we build a company that is best in class.

Earn a REFERRAL BONUS for the qualified people you know.

For more details, or to submit a referral: bit.ly/NovettaReferrals

Novetta is an equal opportunity/affirmative action employer.

All qualified applicants will receive consideration for employment without regard to sex, gender identity, sexual orientation, race, color, religion, national origin, disability, protected veteran status, age, or any other characteristic protected by law.",4.5,"Novetta
4.5","Chantilly, VA","Mc Lean, VA",501 to 1000 employees,2012,Company - Private,Enterprise Software & Network Solutions,Information Technology,$100 to $500 million (USD),"Leidos, CACI International, Booz Allen Hamilton"
Data Fusion Engineer with Security Clearance,"$48K-$109K
(Glassdoor est.)","Description Job Description: Looking for work-life balance? Leidos offers generous leave and accommodating flex-time to help you juggle your personal and professional life. Are you a Software Engineer with experience finding and aligning signals across multiple modalities (image, video, audio, lidar, etc..)? Do you want to implement and customize algorithms to fusion multiple data modalities? If so we are looking for you, our next Data Fusion Engineer to work in Arlington, VA. We need you to be competent in Python and have the ability to read code in other programming languages like Java and C++ as well as have experience working with ML libraries like SciKit Learn, TensorFlow, Keras along with experience implementing solutions with those libraries on both CPU and GPU compute architectures. Like what you are reading so far? Keep going. We want you to be intellectually adaptive, inquisitive, good at expressing your needs, and able to self-manage when necessary. Work alongside software/system engineers and research/data scientists with expertise in multi-modal information retrieval, UI development, computer vision, metrics, information science, artificial intelligence, and autonomous systems. The Department of Defense and the Intelligence Community will be the main recipients your hard work. Fun stuff you will do on the job: - Use cases requiring identifying entity/objects, determining object association, object disambiguation, anomaly detection, state estimations, etc.
Develop and maintain data models (both physical and logical)
Get to be responsible for extraction, transform, and load (ETL) tasks related to the different modalities and algorithms being applied. This data ETL includes identifying the data's relevant metadata to ensure consistency, quality, accuracy, integrity, and information assurance and security.
Performing anomaly detection using various AI/ML techniques
Use algorithms to identify complex patterns across multiple modalities
Increasing the efficiency and quality data alignment and fusion
Enhance and maintain analysis tools, including automation of current processes using AI/ML algorithms
Conduct quantitative data analysis including developing retrieval, processing, fusion, analysis, and visualization of various datasets Skills required to be successful in this role: - Bachelor's Degree in Aerospace Engineering, Computer Science, Mathematics, Statistics, Physics, Electrical Engineering, Computer Engineering or related fields with 5 years of relevant experience
Must be able to obtain and maintain a TS/SCI security clearance
Experience with Deep Learning Frameworks such as Keras, Tensorflow, PyTorch, Mxnet, etc. - Ability to apply these frameworks to real problems in the 'time -series' domain
Experience with interpretability of deep learning models
Big Data Skills (Azure, Hadoop, Spark, recent deep learning platforms)
Practical experience with statistical analysis
Experience with text mining tools and techniques including in areas of summarization, search (e.g. ELK Stack), entity extraction, training set generation (e.g. Snorkel) and anomaly detection
Expert software development skills lifecycle including developing and maintaining good production quality code
Hands-on Software Development Skills (Python-Preferred)
Experience or educational courses/projects in Machine Learning, and/or Text Mining Algorithms You will wow us even more if you have these skills: - Visualizations/Web Development Skills (e.g. Tableau, D3, etc).
Hands-on experience with prototype development
Hands-on experience with automating data cleansing, formatting, staging, and transforming data human
Hands-on experience applying data analytics
Hands-on experience with intelligent systems and machine learning LInC External Referral Bonus: Ineligible Potential for Telework: No Clearance Level Required: Top Secret/SCI Travel: Yes, 10% of the time Scheduled Weekly Hours: 40 Shift: Day Requisition Category: Professional Job Family: Software Engineering Leidos Leidos is a Fortune 500® information technology, engineering, and science solutions and services leader working to solve the world's toughest challenges in the defense, intelligence, homeland security, civil, and health markets. The company's 33,000 employees support vital missions for government and commercial customers. Headquartered in Reston, Virginia, Leidos reported annual revenues of approximately $10.19 billion for the fiscal year ended December 28, 2018. For more information, visit www.Leidos.com . Pay and Benefits Pay and benefits are fundamental to any career decision. That's why we craft compensation packages that reflect the importance of the work we do for our customers. Employment benefits include competitive compensation, Health and Wellness programs, Income Protection, Paid Leave and Retirement. More details are available here . Securing Your Data Leidos will never ask you to provide payment-related information at any part of the employment application process. And Leidos will communicate with you only through emails that are sent from a Leidos.com email address. If you receive an email purporting to be from Leidos that asks for payment-related information or any other personal information, please report the email to [email protected] . Commitment to Diversity All qualified applicants will receive consideration for employment without regard to sex, race, ethnicity, age, national origin, citizenship, religion, physical or mental disability, medical condition, genetic information, pregnancy, family structure, marital status, ancestry, domestic partner status, sexual orientation, gender identity or expression, veteran or military status, or any other basis prohibited by law. Leidos will also consider for employment qualified applicants with criminal histories consistent with relevant laws.",3.5,"Leidos
3.5","Arlington, VA","Reston, VA",10000+ employees,1969,Company - Public,Aerospace & Defense,Aerospace & Defense,$10+ billion (USD),-1
Software Engineer,"$64K-$132K
(Glassdoor est.)","Every Analyst a Scientist - One of our primary goals is to empower intelligence analysts to be able to study their data like scientists. The tools we develop focus on streamlining intelligence analysis through integrated algorithms and software that provide insight into the geopolitical landscape for use in operational intelligence missions around the world.

The Role:
As a Software Engineer, you will be part of a team that transforms large and complex customer data into real-world, high-impact solutions. You will work with researchers and engineers to design and implement solutions to challenging national security problems. You will be responsible for building the software infrastructure to clean, ingest, and expose datasets and algorithms to both developers and end users. You will deploy algorithms, generate workflows, create engineer-facing tools, and design customer-facing prototype systems. You will occasionally travel to customer sites to engage with end users, demonstrate prototypes, and integrate analytics into customer systems.

If you would like to help intelligence and defense analysts keep pace with technology-driven innovation, then this role is for you!

Who you are:
A U.S. Citizen with the ability to obtain a Security Clearance
A degree in a scientific or engineering field, such as Computer Science, Mathematics, Physics, or Software Engineering
Proficiency with a scientific programming language such as Python, Java, or C++
Experience with database management and common query syntax
Motivated collaborator and excellent communicator of ideas to both technical and non-technical audiences
Knowledge of AWS, Spark, Dask, and/or similar technologies for working with data at scale
Even better:
Active Security Clearance
Track record of architecting, developing, deploying, or maintaining enterprise software
Experience with software development best practices and tools
Understanding of web development and visualization technologies, such as d3, Leaflet, Bootstrap, or others
Familiarity with machine learning or statistical modeling techniques",4.5,"Systems & Technology Research
4.5","Woburn, MA","Woburn, MA",201 to 500 employees,2010,Company - Private,Aerospace & Defense,Aerospace & Defense,$100 to $500 million (USD),-1
Sr. Data Scientist,-1,"Background Information:

Innovative Defense Technologies (IDT), provider of automated software testing, data analysis, and cybersecurity solutions for complex defense systems, is currently accepting applications for an anticipated Sr. Data Scientist role requiring 7+ years of experience for a position in support of its efforts implementing Artificial Intelligence solutions for a variety of customers.

Overview:

The Sr. Data Scientist position offers an engineer the opportunity to utilize his/her knowledge and talents as part of a collaborative team developing AI solutions for a growing company. A few of the responsibilities include supporting feasibility studies, applying modern data storage techniques, discovering explanatory features in high-dimensionality collections of data, and exploring data using scientifically valid techniques to exploit patterns found in the data with state-of-the-art AI/ML/DL solutions.

All applicants must be able to obtain/maintain an active U.S. Security Clearance.

Responsibilities Include:
Lead development of solutions to deliver AI/ML/DL models from problem formulation to a productized, deployable, maintainable capability
Contribute to AI/ML/DL technical roadmap development
Use Deep Learning frameworks such as Tensorflow and Keras to build and validate ML/DL models
Establish and leverage Big Data frameworks to store, extract and analyze relevant data
Ensure development of software solutions meets customer needs and program intent
Work closely with the Program Manager and Chief Engineer to design and implement software requirements and solutions
Determine operational feasibility by evaluating analysis, problem definition, requirements, solution development, and proposed solutions for large, complex systems
Be responsible for a team’s products meeting software design, quality, and performance requirements
Pursue new technology development via the DoD Small Business Innovative Research (SBIR) program
Work with minimal supervision in a collaborative work environment to implement best-in-class solutions
Minimum Required Qualifications:
Bachelor’s Degree in Computer Science, Computer Engineering, Electrical Engineering, Systems Engineering, Physics, or Math Required; PhD in relevant field highly preferred
7+ years of experience in predictive modeling, data science and analysis
Required Skills:
Previous experience in a ML or data scientist role and a track record of building ML or DL models
Extensive experience working with data mining algorithms including decision trees, probability networks, association rules, clustering, and neural networks
Experience using Python (or equivalent)
Experience using ML libraries, such as scikit-learn,
Experience using data visualization tools
Experience handling terabyte size dataset
Experience working with GPUs to develop models
Ability to travel 10% or less
Preferred Skills:
Experience with MapReduce programming (Hadoop)
Skills with programming languages, such as Java or C/C++
Demonstrated ability to develop experimental and analytic plans for data modeling processes, use of strong baselines, ability to accurately determine cause and effect relations
Consulting experience and track record of helping customers with their AI needs
Publications or presentations in recognized Machine Learning, Deep Learning and Data Mining journals/conferences
Combination of deep technical skills and business savvy enough to interface with all levels and disciplines within our customer’s organization
Experience diving into data to discover hidden patterns
Experience with application container platforms
Familiarity with continuous integration/delivery tools (e.g. Jenkins)
Familiarity with version control tools (e.g. Subversion, Git, etc.)
Familiarity with VMware or other virtualization software
Experience developing applications for DOD command and control systems
Competencies:
Solid analytical abilities, coupled with a strong sense of ownership, urgency, and drive
Attention to detail
Initiative, creativity, reliability, teamwork
Ability to deal well with ambiguity, prioritize needs, and deliver results in a dynamic environment
EEO Statement:

IDT is an Equal Opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, creed, sex, sexual orientation, gender identity, national origin, disability, protected Veteran status, or any other basis protected by federal, state, or local law.",-1,Innovative Defense Technologies (IDT),"Mount Laurel, NJ",-1,-1,-1,-1,-1,-1,-1,-1
Full Stack Software Engineer (Python/Vue),-1,"Position Summary Full Stack Software Engineer (Python VueJS) Company Overview Our client is an automated underwriting platform for real estate professionals that was built to disrupt the commercial real estate industry. The software allows investors, brokers, and lenders to analyze rent, operating expenses and returns for multifamily properties by applying machine learning to a database of live multifamily transaction data from every U.S. market. Our client has a creative and entrepreneurial culture ndash everyone on the team interacts directly with customers each day, and we all contribute to the product and planning. If you have an idea to improve something, there is no red tapehellip just build what needs to be built! Innovation and passion for transforming the old-fashioned real estate industry are our highest priorities. Job Description As a full-stack (Python, PostgreSQL and HTMLCSSJavaScript) developer, you'll work on the interface and backend infrastructure of products and features used by hundreds of underwriters and real estate analysts every day. The work is challenging, fast-paced, and always changing. You must have demonstrated analytical skills, an unwavering commitment to quality, a collaborative work ethic, and cutting-edge coding skills. You must display solid proficiency in the fundamentals of Python, PostgreSQL, JavaScript, HTMLCSS, and popular front-end frameworks like Vue.js. The role will include the delivery of reliable, scalable new features to users, developed in Python, interacting with a PostgreSQL database and using the Vue.js frontend framework. You will work with the development team to develop, test and deliver finished, high quality, compelling features and products. Our team includes designers, engineers and data scientists who are passionate about quality, usability, and simplicity. If you are ready to join a company that fosters learning, growth, experimentation and innovation, our client's team is for you. Requirements Qualifications 3-5 years of experience in full stack Python development 1-3 years of experience with PostgreSQL 1-3 years of experience with JavaScript frameworks such as React, Angular or Vue.js (Vue.js is preferred, this is what our client uses), and CSS pre-processing frameworks (Sass or Less) 1-2 years of experience integrating with VBA and Excel integration preferred Experience using GitHub and solid understanding of software version control Familiarity with JIRA or equivalent product management software Familiarity with agile development best practices Driven self-starter able to work on a small team and take initiative on new tasks Familiarity with real estate or finance is a plus Responsibilities Collaborate with interdisciplinary team of data scientists, software engineers and real estate professionals Strive for high quality and rapid output utilizing agile development best practices Support, maintain, and document software functionality Maintain industry standard coding, compliance, security practices Proactively learn product frameworks and code base Our client is a startup company, and as such the responsibilities outlined above may change and evolve over time. Flexibility, curiosity, an entrepreneurial mindset, and strong work ethic are essential for this role. It is encouraged that everyone on the team continually research new technologies and analytical opportunities to improve the platform.",5.0,"CultureFit
5.0","Chicago, IL","Deerfield, IL",1 to 50 employees,1997,Company - Private,Advertising & Marketing,Business Services,$1 to $5 million (USD),-1
AWS Data Engineer,-1,"About Infinitive:

At Infinitive, we do mission-critical work for great companies. We specialize in digital marketing and digital advertising solutions, customer data & analytics, digital & business transformation, and Technology solutions. Our Technology solutions focus on Managed Cloud Services, Cloud Enablement, Digital Operations, Application Development, DevOps, Product Development, Cloud Security, Data Science and Analytics, AI/ML, IoT, and everything in between.

Our experts are results-obsessed, focused and flexible, highly engaged and hugely experienced having sat in our clients seats. Those qualities are what make us different than old-school consulting shops. And surely, they are why clients and partners describe us as the gold standard in client experience.

Infinitive has been named a Best Small Firms to Work For by Consulting Magazine seven times, a Washington Post Top Workplace three times, a Washington Business Journal Best

About this Role:

Infinitive is growing its team in the Northern Virginia area and is currently seeking an Data Scientist to join our growing Technology practice. This person will utilize their experience in analytics, IoT, machine learning, and artificial intelligence advances to create value from structured and unstructured data. The ideal candidate has experience designing novel data analytic methods and workflows, including full data pipelines from raw data through analysis results. They must also have exposure to a variety of data mining/data analysis methods, data tools, building and implementing models, using/creating algorithms, and creating/running simulations.

We are looking for candidates who are accountable, passionate, assertive, proactive, open & honest, results oriented, and adaptable. Each project engagement represents a new challenge that will give you exposure to new clients, business issues, technologies, and people and will involve a range of responsibilities to include:
Developing in Java, Python, R, or other high-level languages.
Managing disparate data sources with varying data structures of content and preparing these for data science and machine learning applications.
Working with distributed scalable Big Data storage, processing, and computation, including AWS EMR, Spark, etc.
Implementation knowledge of, or desire to learn AWS / Azure data science capabilities.
Developing solutions and integrating and extending free and Open-source software (FOSS) or COTS products.
Conduct MapReduce programming with Apache Hadoop, the Hadoop Distributed File System (HDFS), and processing large data stores.
Knowledge of SQL and query languages.
Utilize real-time, large-scale data processing engine, including Apache Spark.
Lead and create Data Science and Analytics methodologies and frameworks for implementation.
Ability to build and develop Data Science demonstrations for clients
Qualifications:
4+ years of development experience (Java, Python, R, SQL)
3+ years of experience with distributed scalable Big Data storage, including AWS EMR, Spark, etc.
Desire to become AWS / Azure Certified architect / engineer.
Experience performing data Management, modeling, and warehousing.
Hands on experience with Amazon analytic tools (preferred)
Interest in being involved internally and growing a small business (entrepreneurial spirit)
Ability to travel (up to 20%) and to work independently
Experience using Agile software development methods in a DevOps environment.
Excellent leadership, peer management, and communication skills
Management consulting experience (preferred)
Bachelor's degree in related field (preferred)
Applicants for employment in the U.S. must possess work authorization which does not require sponsorship by the employer for a visa.

Infinitive is an Equal Opportunity Employer.

Powered by JazzHR",3.4,"Infinitive Inc
3.4","Arlington, VA","Cedar Rapids, IA",201 to 500 employees,1997,Company - Private,Enterprise Software & Network Solutions,Information Technology,$10 to $25 million (USD),-1
"Senior SW Engineer, Data Science ( Kubernetes/ Docker ) Remote USA","$72K-$141K
(Glassdoor est.)","If you dream of a job working in a field where all the hard problems are solved and you get to re-use previous research to get your job done, you need not apply. If, however, you are someone who wants to tackle problems that truly are on the cutting edge, then we encourage you to keep reading.

Data Science is an emerging field within cyber security. FireEye, given its deep expertise and comprehensive view on the advanced threat landscape, is uniquely positioned to enable data scientists to have major impact within our industry, company, and across our customer base. Detecting security breaches using machine learning and data analytics is an unsolved problem (this is not handwriting recognition folks) and has huge potential.

If you are someone who wants to be on the cutting edge of a high profile industry, who wants to make an impact by pushing both fields of data science and cyber security forward, you may be the perfect candidate to help us on our mission.

What you will do:
Develop, and manage data systems to ingest and process data at massive scale
Identify data sources both internally and externally that we can use to find evil.
Contribute towards the architecture and design of software solutions for long-term storage and retrieval.
Identify and implement data exploration technologies. Create dashboards and implement analytical tools for exploration
Work with data scientists to productize ML models and assist product teams with ML model releases into end products.
Collect requirements, design, and build backend components and tools to run ML models, assess ML model efficacy, manage large scale datasets, and generate features for ML models
Contribute to the evolution of coding and design practices within the organization.
Review code base commits and contribute to the growth of team members.
Requirements
Ability to work in an iterative, agile development environment.
Experience implementing ETL processes and building data pipelines
Experience developing reliable distributed systems.
Experience in Data modeling and schema design
Strong knowledge of a variety of operating systems, networking fundamentals, software design and programming best practices.
Experience with use of a wide array of algorithms and data structures.
Deep understanding and experience of going through the entire life cycle of building software platforms and products
Deep knowledge of various AWS services and associated tools
Strong experience developing in Python 3
Experience developing in at least 1 of the following: C, Go or Java
Experience with RDBMS, such as PostgreSQL or MySQL, as well as NoSQL
Experience with Kubernetes and Docker.
Experience deploying products in AWS
Additional Qualification: *
Ability to pick up, work with and explore new analytical tools
Strong experience with DevOps practices and common tooling
Strong communication skills.
Ability to work with loosely defined requirements.
At FireEye we are committed to our #OneTeam approach combining diversity, collaboration, and excellence. All qualified applicants will receive consideration for employment without regard to race, sex, color, religion, sexual orientation, gender identity, national origin, protected veteran status, or on the basis of disability. Requests for accommodation due to disability can be sent directly to .",3.3,"FireEye Inc
3.3","Denver, CO","Milpitas, CA",1001 to 5000 employees,2004,Company - Public,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,"Palo Alto Networks, Tanium"
"Senior SW Engineer, Data Science","$72K-$141K
(Glassdoor est.)","Job Description

If you dream of a job working in a field where all the hard problems are solved and you get to re-use previous research to get your job done, you need not apply. If, however, you are someone who wants to tackle problems that truly are on the cutting edge, then we encourage you to keep reading.

Data Science is an emerging field within cyber security. FireEye, given its deep expertise and comprehensive view on the advanced threat landscape, is uniquely positioned to enable data scientists to have major impact within our industry, company, and across our customer base. Detecting security breaches using machine learning and data analytics is an unsolved problem (this is not handwriting recognition folks) and has huge potential.

If you are someone who wants to be on the cutting edge of a high profile industry, who wants to make an impact by pushing both fields of data science and cyber security forward, you may be the perfect candidate to help us on our mission.

What you will do:
Develop, and manage data systems to ingest and process data at massive scale
Identify data sources both internally and externally that we can use to find evil.
Contribute towards the architecture and design of software solutions for long-term storage and retrieval.
Identify and implement data exploration technologies. Create dashboards and implement analytical tools for exploration
Work with data scientists to productize ML models and assist product teams with ML model releases into end products.
Collect requirements, design, and build backend components and tools to run ML models, assess ML model efficacy, manage large scale datasets, and generate features for ML models
Contribute to the evolution of coding and design practices within the organization.
Review code base commits and contribute to the growth of team members.",3.3,"FireEye Inc
3.3","Denver, CO","Milpitas, CA",1001 to 5000 employees,2004,Company - Public,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,"Palo Alto Networks, Tanium"
"Senior Machine Learning Engineer, Early Stage Pipeline, X",-1,"Senior Machine Learning Engineer, Early Stage Pipeline, X

Software Engineering

Mountain View, CA

We're an early stage team at X with a growing, interdisciplinary portfolio. To prove our path to the moon, we make early contact with the real world through both internal and external partnerships.

In this role, you will be responsible for taking early stage investigations from an idea stage to first prototypes to a full-blown projects. You'll be rapidly iterating through a set of prototypes to evaluate possible product directions. This is an extremely dynamic role and requires high cross-functional communication, organization, and planning. The ideal candidate is a self-starter and has a track record of effectively operating in a dynamic loosely structured environment (e.g. startup, new products within a larger company). The candidate will work on multiple projects/investigations.

Responsibilities:
Identify and implement a set of machine learning prototypes to aggressively de-risk projects building the whole solution: data acquisition, data processing pipelines, ML modeling.
Setup technical direction for investigations/projects working with the early stage leadership team.
Team lead investigations that grow to become projects.
Qualifications:
Hands-on experience with machine learning, one or more of; natural language processing (semantic understanding, sentiment analysis), computer vision, time series analysis.
Experience with building robust data pipelines.
Tech Lead experience.
Startup or early-stage product development experience.
Preferred Qualifications:
Experience with the Google Cloud Platform
About X, the Moonshot Factory

X creates radical new technologies to solve some of the world's biggest problems. We develop uncomfortably ambitious, potentially world-changing new ideas such as self-driving cars, balloon-powered Internet and smart contact lenses. We're a team of makers, entrepreneurs, engineers, designers and scientists with deep technical expertise who love the challenge of the seemingly impossible. We believe that a culture of psychological safety creates the foundation of trust and respect necessary to build moonshots. X was formerly known as Google[x] and is part of Alphabet .

At X, we don't just accept difference - we celebrate it, we support it, and we thrive on it for the benefit of our employees, our products and our community. We are proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements.

If you have a disability or special need that requires accommodation, please contact us at: (see application details) .",-1,"X, the moonshot factory","Mountain View, CA",-1,-1,-1,-1,-1,-1,-1,-1
"Senior/Staff Software Engineer, Data Infrastructure","$116K-$227K
(Glassdoor est.)","Senior/Staff Software Engineer, Data Infrastructure job posting

Every year, while Americans wait for their paychecks, more than $1 trillion of their hard-earned money is held up in the pay cycle. As a result, we accumulate over $50 billion in late and overdraft fees and turn to high-interest loans. Overdraft charges and bank fees often trap people in a cycle of debt that can lead to unhealthy decisions and falling victim to predatory businesses disguised as helpful services. We don't accept that.

Earnin is an app that creates products that help people gain control of their finances. Cash Out lets people get paid as soon as they leave work, with no fees, interest, or hidden costs. With Health Aid, Earnin negotiates on behalf of community members to lower their total unpaid medical bill and work out a budget-friendly payment plan. Cash Back Rewards is a way for members to earn up to 10% cash back on purchases from over a thousand local and national businesses without needing a credit card or having to reach spend thresholds to earn cash rewards — and they can withdraw the money at any time. We also offer free tools to help avoid overdrafts, to remind people when recurring bills are due, and we're working on more! There is never any required cost to use any of these products or services, users can choose to tip what they think is fair to support the service and pay it forward to keep the movement going.

Earnin is supported by funding partners including Andreessen Horowitz, Matrix Partners, Ribbit Capital, Felicis Venture, Thrive Capital, and others. Join us and help build a new financial system focused on fairness and people's needs.

You can help make a difference.

About the Team:

We are a data driven mobile financial tech company. The Data Infrastructure team builds the data services and data infrastructure that powers data science, analytics, and product development throughout Earnin. We are looking for a product-minded, self-driven Senior Software Engineer to own multiple large-scale projects that advance our mission of enabling people to gain access to their paycheck on demand.

What sets us apart:
High impact roles at a relatively small company that's aggressively growing our user base.
We are a collaborative team and genuinely enjoy working with each other.
We believe in empowering our people to be successful.
We're building a product that inspires fairness across the financial world and helps people not get taken advantage of.
As a Senior Engineer you will:
Break down complex problems into their bare essentials, translate this complexity into elegant design and create high quality, maintainable code.
Build massively scalable, production-grade data services.
Champion data quality and governance throughout the organization.
Build a world class data lake and data warehouse.
Design and develop new systems and tools to enable all of Earnin to consume and understand data faster.
Own the end to end design, build, and maintenance of platform services, data pipelines, and data products.
Implement comprehensive monitoring, logging, and alerting across our data infrastructure.
Work cross functionally with other teams (data science, design, product, marketing, and analytics) in high visibility roles as an engineering leader.
Build and deploy the data architecture that supports machine learning model development and actionable analytics.
Work with product engineering and data science teams to design scalable, performance model deployment architectures.
Communicate the tradeoffs of technical decisions to multiple stakeholders, including non-technical audiences.
Collaborate with and mentor other engineers and provide engineering direction to data scientists and analysts.
Actively engage and drive design reviews and code reviews.
Some skills we consider critical to being a Senior Engineer:
BS or MS degree in Computer Science, Engineering, or a related technical field.
8+ years of development experience in a fast-paced environment, especially startups.
5+ years of experience working with data systems.
Strong Python and SQL skills.
Strong programming and architecture skills.
Excellent written and verbal communication skills, including the ability to identify and communicate data driven insight.
Taking pride in your code quality and helping others elevate their own code quality.
Substantial experience with testing, data validation, and data quality assurance.
You can articulate the tradeoffs of different deployment architectures (e.g. streaming vs. batch vs. service-based).
Experience designing data platforms and services on cloud infrastructure, preferably AWS.
Hands-on experience designing and building large-scale solutions with the Hadoop stack and/or Spark.
Experience tuning and optimizing Spark-based applications.
Experience deploying and/or using query engines like AWS Athena, Presto, and Impala.
Experience with AWS analytical services like Redshift.
Hands-on experience working with a varied set of data storage technologies (e.g. Mysql, Postgres, DynamoDB, S3, etc.). You know where and when to use each.
Extensive experience with data modeling for multiple use cases and application styles, including NoSQL data modeling.
Experience working with data formats such as Avro and Parquet.
Experience working with alerting and monitoring tools like DataDog and PagerDuty.
Nice to haves:
You have experience building and deploying machine learning models.
You have experience using Terraform.
You have substantial experience working at a startup.
You have experience with data modeling in Redshift.
Experience with streaming infrastructure like Kafka.
Experience working with Kubernetes.
Experience building and deploying AWS Lambda applications.",3.1,"Earnin
3.1","Palo Alto, CA","Palo Alto, CA",201 to 500 employees,2012,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Engineer (open level),"$43K-$69K
(Glassdoor est.)","Title
Data Engineer (open level)

07/08/2020

What you'll do...
At H&R Block, your contributions will go far beyond any job description. When you join our team, you'll add to the momentum of a forward-thinking company - one that defined an industry and is now leading its transformation.

H&R Block is transforming tax preparation through data to ensure that every client we serve gets the best tax outcome possible.

We are building a new Data Engineering Team in the Data Science & Analytics organization. This new team will own the technology and data capabilities of the end-to-end data-and-analytics function. It will take responsibility for building and maintaining the analytical technologies that the data science teams use, managing data at an enterprise scale, leveraging relationships with IT teams throughout the enterprise, and leading information architecture.

We are looking for talented, curious, and creative data engineers of all levels to help launch this team. You will be a good match for our organization if you are:
Motivated by the idea of building something innovative, transformative, and impactful.
Committed to the idea that data can drive experiences and products that wow our business partners and clients
Obsessed with defying expectations and raising the bar
Driven by an innate sense of ownership for the products you create.
Day to day, you'll...
Design and deploy architecture, solutions, and software to capture, manage, store, and use structured and unstructured data from internal and external sources in both on-prem and cloud environments.
Deploy machine-learning models and other data-science products across the enterprise.
Navigate the balance between business needs, data governance best practices, and technical requirements.
Select or develop tools to cleanse, organize, and transform data and to maintain, defend, and update data structures and integrity on an automated basis.
Develop data products to facilitate self-service capabilities and assist the data teams to increase their efficiency and effectiveness.
Collaborate and communicate effectively within cross-functional teams that span internal Data Science & Analytics teams, IT, business groups, and executive stakeholders.
Be a positive force to cultivate a culture that is passionate about developing data tools as a business driver.
Job ID
368348BR

Address1
ONE H&R BLOCK WAY

City
KANSAS CITY

State
Missouri

Employee Type
Regular

What you'll bring to the team...
Education / work experience should include most of these, depending on level:
Bachelor’s degree in Computer Science or a related technical field (or equivalent work experience and technical skills)
Data warehousing and ETL solutions
APIs in a microservices architecture
Big-data technologies and the Hadoop stack (MapReduce, Hive, Pig, Hbase
NoSQL implementations (MongoDB)
Developing Java-based software solution
At least one scripting language (Python, Perl, JavaScript, Shell
Developing software solutions to solve complex business problems
Working with data scientists and other data users
Posting Title
Data Engineer (open level)

Sponsored Job
#hrbjob

Job Family
Corporate Analytics",3.6,"H&R Block
3.6","Kansas City, MO","Kansas City, MO",10000+ employees,1955,Company - Public,Other Retail Stores,Retail,$2 to $5 billion (USD),"Intuit, Jackson Hewitt, Liberty Tax Service"
Senior Modeling & Simulation Engineer,-1,"Applied Research Associates, Inc. is looking for a Senior Modeling and Simulation Engineer to join our multi-disciplinary team of engineers and scientists in the Capital Area Division, located in Alexandria, VA. The ideal candidate has a passion for predicting the behavior of physical systems in challenging environments and operational impact on mission success. Models will be developed, used, and improved to support a Department of Homeland Security customer to safeguard the nation’s borders and interior from chemical, biological, radiological, nuclear, and explosive materials, equipment, technologies, and their actors. Models may be based on the underlying physics or may be process or agent based to predict operational performance and impact. Modeling and analysis may require the use and development of 3D virtual worlds or geospatial data. Models will be verified and validated, and they will be used in support of test and evaluation activities of systems intended to detect and identify threats. The candidate may participate in test and evaluation activities to support the verification, validation, and overall improvement of models. Models may become part of larger, integrated modeling and simulation activities, and may require the use of high performance computing technologies and federated simulations.

This position is contingent upon award of a contract expected in Summer 2020 supporting the Department of Homeland Security.

Required Qualifications:
Ability to program in a high level programming language, such as Fortran, C++, or Java
Eagerness to learn new tools and techniques
Strong verbal and written communication skills
Must be a U.S. Citizen with the ability to obtain and maintain a security clearance
Bachelor’s degree with minimum of 10 years of experience or greater in a physical science (physics, chemistry, biology), engineering-related discipline (nuclear, chemical, civil, mechanical, electrical), or modeling& simulation disciple (computer modeling, computational science, operations research)
Ability to present to senior leadership on the status and issues associated with research or test efforts in preparation for acquisition decision meetings
Desired Experience and Qualifications:
Experience modeling CBRNE detectors or effects
Experience using multiple software tools such as MCNP, GadRas, SWORD, ExtendSim, Arena, SolidWorks, Fluent, ArcGIS, QGIS, VisIt, ParaView, or Cubit
Experience creating 3D models of systems, i.e., CAD
Experience using high performance computers (i.e., supercomputers)
Experience developing and using discrete event or agent based models and simulations to predict and assess system performance
Experience developing machine learning models
Background in a physical science or engineering discipline, such as Physics, Chemistry, Biology, Mechanical Engineering, Nuclear Engineering
Active DoD Secret or Top Secret clearance, DoE Q clearance, or DHS Suitability
COMPANY INFORMATION:

Applied Research Associates, Inc. is an employee-owned international research and engineering company recognized for providing technically superior solutions to complex and challenging problems in the physical sciences. The company, founded in Albuquerque, NM, in 1979, currently employs over 1200 professionals. ARA offices throughout the United States and Canada provide a broad range of technical expertise in defense technologies, civil technologies, computer software and simulation, systems analysis, environmental technologies, and testing and measurement. The corporation also provides sophisticated technical products for environmental site characterization, pavement analysis, and robotics.

At ARA, employees are our greatest assets. The corporation realizes that employee ownership spawns greater creativity and initiative along with higher performance and customer satisfaction levels. ARA gives its employees the tools, training, and opportunities to take more active roles as owners. The culture is challenging; innovation and experimentation are the norm. Employees are eligible for contributions which not only add to the company’s success, but also their own through the Employee Stock Ownership Plan (ESOP). The motto,“Engineering and Science for Fun and Profit” sums up the ARA experience. For additional information and an opportunity to join this unique workplace, please visit our website atwww.ara.com.",3.5,"Applied Research Associates
3.5","Alexandria, VA","Albuquerque, NM",1001 to 5000 employees,1979,Company - Private,Federal Agencies,Government,$100 to $500 million (USD),-1
Senior Data Engineer,-1,"This is a Data Engineer position for supporting a Navy program located in Quantico, Virginia.

We are seeking a Data Engineer to join our team of committed technical professionals to protect those who serve against criminal, terrorism and emerging threats. Are you passionate about analytics and innovation? Our employees enjoy a fast-paced, collaborative culture and the ability to directly impact our business. You will identify technical issues and opportunities for efficiency and provide technical insights through system design and configuration perspectives. This role is both challenging and rewarding.

You will support the mission through the implementation of a modern, integrated internal data infrastructure with a focus primarily on exploiting the established data foundation to make internal and customer-centric business processes as effective and efficient as possible, laying the foundation for cognitive capabilities that can sense and respond to both internal and external customer data needs. The candidate will also focus on expanding the organization’s data ecosystem to include context-rich data while maintaining the agility needed to spark innovation.

How you will make a difference:
Establish shared operational data and integrated enterprise data, all while managing and/or improving data quality and security through the creation of business-driven governance structures and culture change management.
Establish data policies, standards, and procedures that improve data quality, availability, accessibility, security, usability, and enforcement of enterprise information management (EIM) program requirements.
Establish enterprise standards – including a uniform and repeatable system development lifecycle methodology for Reference Data and Master Data (e.g., a common set of standards for data naming, abbreviations, and acronyms).
Develop a Master Data Management (MDM) Plan that focuses on the technology, tools, and processes ensuring master data is coordinated across the enterprise. MDM is a method used to define and manage the critical data of an organization to provide, with data integration, a single point of reference. The data that is mastered may include reference data – the set of permissible values, and the analytical data supporting decision making. MDM provides a unified master data service intended to provide accurate, consistent and complete master data across the enterprise and to business partners.
Recommend solutions based on performing industry-specific analysis, such as case studies describing data management best practices, identifying trends across the industry.
Make recommendations to improve the efficiency and effectiveness in how the agency acquires, stores, manages, shares and applies its data.
Engage business users and stakeholders for the increased release of actionable high-quality data on key operational and tactical activities at NCIS.
Develop technology solutions to provide the platform, training, and standardized tools enabling querying, data mining, statistical analysis, reporting, scenario modeling, data visualization, and dash-boarding, and processes for a centralized, or analytics as a service model, allowing for the sharing of data across the enterprise from a common hub, facilitates cross-organizational data initiatives due to its enterprise-wide view of data assets and needs.
Basic Qualifications
Required: A bachelor’s or master’s degree in computer science, data science, operations research, statistics, applied mathematics, or a related quantitative field [or equivalent work experience such as, economics, engineering and physics] is [preferred/required]. Alternate experience and education in equivalent areas such as economics, engineering or physics, is acceptable. Experience in more than one area is strongly preferred.
Required: Three to six (midlevel) of relevant project experience in successfully launching, planning, and executing data science projects. Preferably in the domains of risk modelling and quality assessment.
Preferred: Specialization in text analytics, image recognition, graph analysis or other specialized ML techniques such as deep learning, etc.
Preferred: the candidates are adept in agile methodologies and well-versed in applying DevOps/MLOps methods to the construction of ML and data science pipelines.
Coding knowledge and experience in several languages: for example, R, Python, Java, C++, Excel, MATLAB, etc.
Experience with popular database programming languages including SQL, PL/SQL, others for relational databases and upcoming non-relational databases such as NoSQL/Hadoop-oriented databases such as MongoDB, Cassandra, others.
Preferred: Specialized/operational data scientists may need further high-performance computing (HPC)/compute skills; larger data science teams, in particular, may require further degrees of specialization such as:
Experience with distributed data/computing tools such as MapReduce, Hadoop, Hive, Kafka, and MySQL
Experience of working across multiple deployment environments including cloud, on-premises and hybrid environments, multiple operating systems and through containerization techniques such as Docker, Kubernetes, AWS Elastic Container Service, and others.
Experience in one or more of the following commercial/open-source data discovery/analysis platforms: RStudio, Spark, KNIME, RapidMiner, Alteryx, Dataiku, H2O, SAS Enterprise Miner (SAS EM) and/or SAS Visual Data Mining and Machine Learning, Microsoft AzureML, IBM Watson Studio or SPSS Modeler, Amazon SageMaker, Google Cloud ML, SAP Predictive Analytics.
Preferred: Expertise in solving vision, text analytics, credit scoring, and failure prediction problems.
Knowledge and experience in statistical and data mining techniques such as generalized linear model (GLM)/regression, random forest, boosting, trees, text mining, hierarchical clustering, deep learning, convolutional neural network (CNN), recurrent neural network (RNN), T-distributed Stochastic Neighbor Embedding (t-SNE), graph analysis, etc.
Strong documentation skills. Required: Certifications as per Cybersecurity Workforce Management and Qualification Manual, SECNAV M-5239.2.
Required: Eligible AND adjudicated to the Top Secret (TS SCI) clearance level is required to start.
About Inventium.io:

Inventium.io LLC is a technical consulting and software development services company dedicated to protecting and advancing our national defense and scientific capabilities. Based out of the Washington DC area, we rely on innovation to continually advance our employees' skills and provide digital transformation solutions to our customers.

With proven records of successfully delivering quality services and solutions to multiple federal agencies, our technical competencies include Emerging Technology Solutions, DevSecOps, Cloud Migration, Machine Learning, System Modernization, and Technology Management.

Benefits and Perks
Employer paid Health Benefits (Medical, Dental and Vision)
Retirement Plan
Paid Time Off and Federal Holidays
Training and Development
Employee Referral Program
Awards and Recognition",5.0,"inventium.io LLC
5.0","Quantico, VA","Washington, DC",1 to 50 employees,2016,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Senior Software Engineer,-1,"At Pacific Biosciences, our R&D team is committed to developing innovative products that enable scientists to excel in a wide variety of life science research fields, including human biomedical, plant and animal sciences, and microbiology and infectious disease. Our unique Single Molecule, Real-Time (SMRT) sequencing platforms generate true high-quality long reads, giving researchers a more comprehensive view of genomes, transcriptomes, and epigenomes from any organism.

The Primary Analysis group, as part of the larger software engineering team at PacBio, develops algorithms and HPC solutions for decoding the raw data streams, generated through high-speed optical detection of the SMRT sequencing reactions, into DNA sequence reads. We operate at the intersection of cutting-edge nanotechnology and state-of-the-art bioinformatics tools, and our responsibilities span the full product development life cycle in an aggressive time-to-market environment. These include analysis and algorithm development in coordination with chemistry and systems R&D; the development of real-time analysis pipelines; and the development of validation and support infrastructure geared towards product system reliability and internal R&D support. We are seeking a talented algorithm engineer with a strong background in the physical or machine-learning/data sciences who also has a passion for designing and developing performance-critical data analysis solutions.

Responsibilities:

Design, develop, and test signal- and sequence-analysis algorithms that will drive fundamental improvements in basecalling accuracy and yield.
Work collaboratively in a team environment to solve challenging problems in software architecture and scalability of real-time analysis pipelines for our next-generation sequencing platforms.
All listed tasks and responsibilities are deemed as essential functions to this position; however, business conditions may require reasonable accommodations for additional tasks and responsibilities.

Key Skills and Background:

3+ years of experience shipping product software in a scientific or quantitative domain.
Demonstrated skills applying numerical methods, statistical signal processing, or machine-learning techniques to high-throughput, performance-critical analysis applications.
Linux-based systems programming experience with knowledge of OS, toolchain and hardware constraints.
Strong C++ programming experience in applications geared towards performance and scalability; previous experience in CUDA programming for GPU is a plus.
MS, PhD or equivalent experience in a quantitative field (physics, CS, etc.), preferably with an applied math or algorithmic focus.
Engineering instincts to efficiently investigate and solve the problem at hand, from prototype development (Python, R, MATLAB, etc.) to production designs.
Team player, with strong communication skills, and comfortable as a self-starter in an agile, fast-paced development environment.
All qualified applicants will receive consideration for employment without regard to race, sex, color, religion, national origin, protected veteran status, or on the basis of disability, gender identity, and sexual orientation.",3.7,"Pacific Biosciences
3.7","Menlo Park, CA","Menlo Park, CA",201 to 500 employees,2000,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,$50 to $100 million (USD),Illumina
Senior Data Engineer,-1,"ABOUT 605

At 605 we are engineers, analysts, data scientists, media experts, marketing strategists and political operatives. Our team of data scientists pioneered the field of TV data analytics. We offer unique, independent audience measurement and analytics to build better marketing and programming initiatives within the media and entertainment industries.

The Sr. Data Engineer at 605 must have a broad and deep data skillset as well as strong analytical capabilities . In addition to being a hands on individual contributor, the ideal candidate is a productive team player and a mentor to Junior. Data Engineers. Additionally, we are looking for strong technical experts.

Responsibilities include:
Actively participate in team technical discussions in all things data
Identify and address issues with data sets from multiple vendors
Identify and address code and data quality issues
Actively participate in code reviews and grooming sessions
Actively participate in technology architecture discussions for product development
Translate business requirements into strategy
Advocate for software best practices within your team as well as across engineering
Be ultra-responsive and capable of making instant decisions, always kicking the ball forward
Work on unique and interesting data challenges around architecting, building and managing pipelines that securely process hundreds of terabytes of data
Work closely with analysts and statisticians to ensure the validity of our processes
Our engineers are expected to wear a number of hats and have the opportunity to touch all parts of the stack. Our stack includes Apache Spark, Scala, Redshift and an ever-growing list of many other cool technologies.

Requirements
Skillful user of Apache Spark
Experience wrangling terabytes of big, complicated, imperfect data
Experience with AWS products (Redshift, EMR, S3, IAM, RDS, etc)
You have a deep understanding of scalable systems and you have large-scale engineering experience in an Agile development environment
Bachelor's degree in Computer Science or a related field (or 4 additional years of relevant work experience)
A strong understanding of data structures, algorithms, and effective software design
Significant development experience with a major modern language (e.g. Java, Scala, Python, Ruby, C/C++, etc.)
Significant experience working with structured and unstructured data at scale and comfort with a variety of different stores (key-value, document, columnar, etc.) as well as traditional RDBMSes and data warehouses
Experience with or interest in AWS Glue, Redshift Spectrum and any other tools that enable data querying at scale
Experience writing unit, functional and integration tests
Comfort with version control systems (e.g. Git, SVN)
Excellent verbal and written communication skills; must work well in an agile, collaborative team environment
Preferred Qualifications
Master's in Computer Science or a related field
Practical experience with supervised machine learning techniques
Strong background with test-driven development
Basic understanding of statistics and experience with statistical packages such as R, Matlab, SPSS, etc
Benefits

Important and Standard
Comprehensive health, dental and vision insurance for employees and their families
Life & Disability insurance
401k plan with match, eligible for match after one year
Pre-tax flexible compensation plan for medical, transit, parking or dependent care expenses
Up to 15 paid vacation days depending on grade level
7 paid sick days in a calendar year - if you’re sick, you stay home
Other cool benefits
4 work from home days/month
A kitchen stocked with sodas, snacks, yogurt and other goodies
A tight knit start up community who likes to eat! We celebrate everyone’s birthdays, have frequent team lunches, and do events in and out of the office
605 is an active participant in conferences
EEO STATEMENT

At 605, we’re just as passionate about diversity as we are about pioneering the field of TV data analytics. We are committed to cultivating an environment of mutual respect and equal opportunity. All hiring and advancement decisions are made on the basis of qualification, merit, and business need.",-1,605,"New York, NY",-1,-1,-1,-1,-1,-1,-1,-1
Sr Innovation Engineer,"$75K-$134K
(Glassdoor est.)","Company Information

Solid reputation, passionate people and endless opportunities. Thats Travelers. Our superior financial strength and consistent record of strong operating returns mean security for our customers and opportunities for our employees. You will find Travelers to be full of energy and a workplace in which you truly can make a difference.

Target Openings

1

Job Description Summary

Innovation is at the core of everything we do. We continue to ask ourselves, whats next? as we navigate the ever-changing insurance landscape. Continuing our customer journey toward the cutting-edge, we are looking for a forward-thinking individual that thrives in ambiguity, who believes that with every challenge comes a new opportunity for solutions.

As a member of the Innovation Technology team, you will partner with research scientists and product managers to discover, invent, and build solutions at scale. As a team, you will work on challenges in machine perception, data mining, machine learning, and natural language understanding.

We are looking for a hands-on individual with strong foundational knowledge highly scalable architectures and platforms. If you like using a variety of skills in technology and solving complex problems, work collaboratively in a small agile team environment, you might just be the person we need on our team!

Primary Job Duties & Responsibilities
Work closely with Cloud Engineering to build an innovation platform; a collection of reusable and extensible containers and tools specific to developing insurance products and platforms.
Recommend integration strategies, enterprise architectures, platforms and application infrastructure required to successfully implement a complete solution using best practices.
Produce quality output for highly visible IT products, services and future business development.
Assist in hands-on remediation of application stability and performance.
Adopt and communicate new concepts, ideas, techniques.
Manage multiple projects simultaneously.
Provide 'Shrink Wrap' solutions to solve business and technical needs. As part of our innovation process, be able to scale Minimum Viable Product to production systems.
Design and lead integration of analytic data products, including pilots and proof of concepts.
Frequently present and translate complex information in relevant business terms.
Constantly learn new skills within small teams.
No direct HR people management but will lead teams in project & program contexts.
Education, Work Experience, & Knowledge
Bachelors Degree in STEM (Science, Technology, Engineering, Mathematics) related field and 3+ years of experience or 10+ years of experience building highly scalable platforms and reusable components
Job Specific Technical Skills & Competencies
2+ years of experience working with Amazon Web Services (AWS) or equivalent cloud. Must be recent experience.
5+ years of designing and developing on-premise and cloud solutions.
3+ years of experience as a technical lead.
Experience in software engineering with relevant technologies (Java, JavaScript, Python etc.).
Experience with the application delivery process.
End-to-end experience with data, including querying, aggregation, analysis, and visualization.
Preferred Qualifications
AWS certified developer and/or architect
Proven ability to work creatively and analytically in a continuously evolving environment.
Exhibits high levels of learning agility in which they seek out and learn from unfamiliar experiences and then apply those lessons to succeed in the next new situation.
Ability to leverage business knowledge to determine approaches to execution.
Strong communication and presentation skills with the ability to present and translate complex information to leadership and non-technical teams in relevant business terms.
Uses effective listening skills and communication to build relationships across the organization.
Ability to Influence with experience working with matrixed staff to complete tasks in a timely manner.
Environmental / Work Schedules / Other
Travel Required
Equal Employment Opportunity Statement

Travelers is an equal opportunity employer.",4.1,"Travelers
4.1","Hartford, CT","Hartford, CT",10000+ employees,1853,Company - Public,Insurance Carriers,Insurance,$10+ billion (USD),-1
Senior AI Software Engineer,-1,"Company Overview

Calling the adventurers ready to join a company that's pushing the limits of nanotechnology to keep the digital revolution rolling. At KLA, we're making technology advancements that are bigger—and tinier—than the world has ever seen.

Who are we? We research, develop, and manufacture the world's most advanced inspection and measurement equipment for the semiconductor and nanoelectronics industries. We enable the digital age by pushing the boundaries of technology, creating tools capable of finding defects smaller than a wavelength of visible light. We create smarter processes so that technology leaders can manufacture high-performance chips—the kind in that phone in your pocket, the tablet on your desk and nearly every electronic device you own—faster and better. We're passionate about creating solutions that drive progress and help people do what wouldn't be possible without us. The future is calling. Will you answer?

Responsibilities

Group/Division
KLA has always had a close relationship with physics and data. Our optical and electron beam inspection and measurement tools use cutting edge physics models, both for hardware design and as part of their algorithms. AI, including several traditional machine learning techniques and deep learning are routinely used to process this data to meet application requirements.

The AI & Modeling Center of Excellence, centered in KLA’s R&D facility in Ann Arbor, MI, was setup with the mission of advancing KLA’s traditional strengths in physics and data and providing implementation solutions for multiple KLA Inspection and Metrology products targeted at the semiconductor manufacturing industry.

As a part of this group, you will be part of a world class team of physicists, HPC system designers, machine learning and application engineers who build cutting edge solutions for modeling complex imaging techniques and semiconductor processes. You will also work with a data scientists and AI infrastructure engineers whose mission is to build and scale machine learning based solutions for our semiconductor customers.

We are looking for engineers in a few different fields. If you are passionate about Physics Modeling, High Performance Computing - HPC (including GPU), ML, Data, or Cloud technologies – this is the place for you!

Responsibilities:
Software Engineers in the AI and Physics Modeling team may work on a variety of tasks including platform for large scale experimentation, scaleout of physics models, data management and inference solutions for KLA products.

Although familiarity with Machine Learning and Deep Learning solutions would be a big plus, this is primarily a Software Engineering position. Successful candidates are passionate about software, and will have exceptional skills and hands on experience with development in C/C++ and Python in a Unix environment. Deep conceptual understanding of multi threaded and multi process software systems is also necessary.

In addition to the above fundamental software skills, any of the following technical hands-on skills are highly desirable.

1) System Programming and Operating Systems.
2) Distributed systems for data management.
3) Distributed computing infrastructure.
4) Cloud technologies for storage, containerization and compute clusters.
5) Data Structures and algorithms
6) GPU architectures and data management.
7) Traditional machine learning using Random Forest, XG Boost, Logistic Regression.
8) Deep Learning for regression, classification. Generative models.
9) TensorFlow, NumPy, scikit-learn, and other ML and DL frameworks.
10) MPI and similar distributed computing framework.
11) GPU Architectures and CUDA (CuGraph, CuData, CuML etc).
12) GO Systems Programming, Java Programming.

Successful candidates for this position will also demonstrate the following non-technical skills.

1) Capability to formulate creative solutions through analyzing complex data
2) Good communication skills
3) Strong team player and motivated by team success
4) Strong problem solving skills

Minimum Qualifications

Doctorate (Academic) with at least 2 years of experience.
OR
Master's Level Degree with at least 4 years of experience.
OR
Bachelor's Level Degree with at least 5 years of experience.

Equal Employment Opportunity

KLA is an Equal Opportunity Employer. Applicants will be considered for employment without regard to age, race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability, or any other characteristics protected by applicable law.",3.8,"KLA-Tencor
3.8","Ann Arbor, MI","Milpitas, CA",5001 to 10000 employees,1976,Company - Public,Industrial Manufacturing,Manufacturing,$2 to $5 billion (USD),"Applied Materials, Nanometrics"
"Senior SDE, Catalog Big Data and Machine Learning",-1,"Amazon's Catalog DataWorks team is looking for highly motivated engineers. We are embarking on multiple new initiatives to re-organize Amazon's catalog of billions of products, in new and interesting views, that drive several features Amazon's customers love. Today, these views drive hundreds of popular features like product recommendations, clustering of similar products, and shopping with Alexa. We will build a new near real-time Catalog Data Lake on AWS, to enable engineers and scientists across Amazon to solve customer problems faster. Come join us on this exciting journey!

As an engineer on this team, you will own the Catalog Data Lake end-to-end. You will work closely with business partners to synthesize technical requirements. You will design and implement significant parts of the platform. You will learn and use industry standards like Spark and Parquet as well as modern AWS offerings like EMR, Glue, Athena, and Redshift. We are fortunate to be at the cusp of innovation in both the e-commerce business as well as cloud technology. As a key stakeholder, you will constantly learn new patterns, solve key customer problems and strive to make AWS better along the way.Basic Qualifications
Bachelor's degree or higher in computer science or math is required.
Strong computer science fundamentals - algorithms, data structures and design patterns.
At least 8 years of software development experience.
At least 3 years of experience building and operating Big Data systems.
Experience mentoring, guiding and influencing peers.
Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.",-1,Amazon Corporate LLC,"Seattle, WA",-1,-1,-1,-1,-1,-1,-1,-1
SENIOR SOFTWARE ENGINEER & SOFTWARE ARCHITECT,-1,"Job Description
Senior Software Engineer, Software Architect
JOB SUMMARY

The Senior Software Engineer, Software Architect will develop software for Company innovative semiconductor X-Ray inspection system. The Senior Software Engineer will collaborate with Applications, QA, and Algo teams for high performance solutions and optimization per customer issues. It will be important to be comfortable working in a small company environment and a typical startup with engineers and scientists.

ABOUT THE CLIENT

Based in San Jose, California, client was founded in 2013 expressly to bring high speed inspection and metrology technology to the semiconductor packaging industry. Client founders anticipated the need to deploy inline 100% transmissive inspection into the semiconductor packaging manufacturing process and developed the company’s technology with this end in mind. The results, Client’s HR-AXI technology suite brings together the company’s unique data acquisition architecture with proprietary machine learning analysis techniques to provide customers with process monitoring and defect detection capabilities not found on any other products in the market. This job description can be updated at any time.

RESPONSIBILITIES
Designs, develops, troubleshoots, and debugs software programs for enhancements and new products, focused on creating high quality and high-performance solutions while maintaining high-level coding standards.
Develops software and tools in support of design, infrastructure, and technology platforms. Develops software solutions by studying information needs, conferring with users, and studying systems flow, data usage, and work processes
Supports hardware compatibility and/or influences hardware design based on software needs; work as part of cross-functional team to solve and implement system level problems.
Monitor application stability, performance, and availability. Promptly resolve issues impacting operations.
Work with engineering, documentation, and applications departments to ensure successful development and delivery of overall product.
Provide appropriate project feedback to management in a timely and appropriate format.
QUALIFICATIONS AND REQUIRED SKILLS
Education requirement: Bachelor’s degree in Computer Science, Electrical Engineering, or similar technical field required. Master’s or PhD strongly preferred.
Experience requirement: Minimum of 8 years of related experience working in software development.
Strong expertise in C# .NET. WCF, WPF, Database development. In addition, Python experience a plus.
Experience with Image processing algorithms implementations is a plus
Experience with software development for Factory Automation for Semiconductor equipment, a plus.
Self-starter able to think and act independently to translate general objectives into tangible results, with a record of delivering successful designs on schedule.
Demonstrated ability to organize, manage, and complete multiple assignments with challenging timelines independently and effectively.
Demonstrated analytical and problem-solving skills with high attention to detail.
Proactive approach to problem-solving. Build relationships with stakeholders to support successful design, build and testing.
Strong verbal and written communication, good attitude, and work ethic. Ability to communicate technical concepts and results clearly.
Experience with Git and Azure DevOps, a plus.",3.0,"Simple Solutions
3.0","San Jose, CA","Morgantown, WV",1 to 50 employees,2006,Company - Private,IT Services,Information Technology,Less than $1 million (USD),-1
Cloud Engineer,-1,"Job Description
Responsibilities:
Develop and implement technical efforts to design, build, and deploy AWS applications at the direction of lead architects, including large scale data processing, computationally intensive statistical modeling, and advanced analytics
Participate in all aspects of the software development life cycle for AWS solutions, including planning, requirements, development, testing, and quality assurance
Provide guidance, thought leadership and mentorship to development teams to build cloud competencies
Provide innovative thought leadership around Mathematica’s cloud solutions strategy and approach, including AWS best practices and market trends
Position Requirements:

6+ years of experience architecting, designing, developing and implementing cloud solutions on AWS platforms
Demonstrated experience with designing and implementing solutions using AWS platform and tools, such as: EC2, S3, Redshift, API Gateway, Lambda, DynamoDB, CloudFormation, RDS, VPC, IAM and security, QuickSight, CloudTrail, Config, CloudWatch, SNS, AMI generation
Understanding of and experience with the five pillars of a well-architected framework
Knowledge of SQL, R, and Python for data manipulation and statistical analysis is desirable
Familiarity with federal security regulations and standards (e.g. HIPAA, FISMA, FIPS, NIST, and FedRAMP)
Experience with security, especially knowledge of FedRAMP, HIPAA, PII/PHI, is desirable
Experience in several of the following areas: database architecture, ETL, Business Intelligence, Big Data, Machine Learning, Advanced Analytics
Proven ability to work collaboratively with multi-disciplinary teams of business analysts, developers, data scientists, and subject matter experts
Strong written, verbal and interpersonal communication skills
AWS Certifications (such as AWS solutions architect or other specialty certifications) are a plus
Bachelor's degree or equivalent combination of education and experience; degree in computer science, mathematics or related field preferred
Experience with other cloud platforms like Google Cloud Platform (GCP) is a plus",4.8,"RICEFW Technologies Inc
4.8","Princeton, NJ","East Lansing, MI",51 to 200 employees,2009,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Senior Software Engineer / Team Lead,"$112K-$220K
(Glassdoor est.)","Join our team dedicated to developing and executing innovative solutions in support of customer mission success.

Job Description:

Novetta has an exciting opportunity for a self-motivated and accomplished Computer Scientist to lead our entity analytics team. You will work on complex projects involving data analysis, software engineering, and deploying software in a cloud computing environment. The team combines data from disparate sources to visualize the complex relationships between entities. This effort involves large scale data integration and entity resolution leveraging a best in class Novetta product. We are looking for a flexible problem solver with significant technical experience to lead a team providing unique solutions for our customers and stakeholders.

Responsibilities include:
Lead a technical team of software engineers and computer scientists, working within a larger ecosystem delivering an Enterprise capability.
Navigate customer and prime environment, manage resources within and across team, and assist team with professional and technical growth.
Deploy applications on a large-scale data processing cluster using AWS technologies.
Design and implement entity correlation strategies that are tailored to mission needs and unique data qualities.
Develop algorithms and visualization tools to help stakeholders understand their data and prioritize new data sources.
Develop and integrate applications to automate ingestion, processing and monitoring of data
Develop and maintain tools to support operations and maintenance of production and development computing clusters.
Basic Qualifications:
Experience leading a team of software engineers.
A Bachelor's degree in computer science or related field and a minimum of 5 years of experience; or a Master's degree in computer science or related field and a minimum of 3 years of experience.
Experience in software development/engineering including requirements analysis, software development, installation, integration, evaluation, enhancement, maintenance, testing and problem diagnosis/resolution.
Software development experience on Linux-based systems in Python or shell scripting or JavaScript.
Experience developing against full-featured REST APIs and using a command line interface
Desired Skills:

Should meet a minimum of 3:
Software development experience with JavaScript, Python, or other modern programming languages.
Hands-on experience with Spark.
Experience working with Databricks
Interest in statistical analysis, machine learning, or data science.
Experience with entity resolution products or a background in data matching theory and technologies.
Experience developing applications in AWS.
Security Clearance:
The candidate must have a TS/SCI with Poly.
Novetta, from complexity to clarity.

Novetta delivers highly scalable advanced analytics and secure technology solutions to address challenges of national and global significance. Focused on mission success, Novetta pioneers disruptive technologies in machine learning, data analytics, full-spectrum cyber, cloud engineering, open source analytics, and multi-INT fusion for Defense, Intelligence Community, and Federal Law Enforcement customers. Novetta is headquartered in McLean, VA with over 1,000 employees across the U.S.

Our culture is shaped by a commitment to our core values:

Integrity • We hold ourselves accountable to the highest standards of integrity and ethics.

Customer Success • We strive daily to exceed expectations and achieve customer mission success.

Employee Focus • We invest in our employees' professional development and training, respecting individuality and fostering a culture of diversity and inclusion.

Innovation • We know that discovering new and innovative ways to solve problems is critical to our success and makes us a great company.

Excellence in Execution • We take pride in flawless execution as we build a company that is best in class.

Earn a REFERRAL BONUS for the qualified people you know.

For more details, or to submit a referral: bit.ly/NovettaReferrals

Novetta is an equal opportunity/affirmative action employer.

All qualified applicants will receive consideration for employment without regard to sex, gender identity, sexual orientation, race, color, religion, national origin, disability, protected veteran status, age, or any other characteristic protected by law.",4.5,"Novetta
4.5","Chantilly, VA","Mc Lean, VA",501 to 1000 employees,2012,Company - Private,Enterprise Software & Network Solutions,Information Technology,$100 to $500 million (USD),"Leidos, CACI International, Booz Allen Hamilton"
Data Fusion Engineer with Security Clearance,"$48K-$109K
(Glassdoor est.)","Description Job Description: Looking for work-life balance? Leidos offers generous leave and accommodating flex-time to help you juggle your personal and professional life. Are you a Software Engineer with experience finding and aligning signals across multiple modalities (image, video, audio, lidar, etc..)? Do you want to implement and customize algorithms to fusion multiple data modalities? If so we are looking for you, our next Data Fusion Engineer to work in Arlington, VA. We need you to be competent in Python and have the ability to read code in other programming languages like Java and C++ as well as have experience working with ML libraries like SciKit Learn, TensorFlow, Keras along with experience implementing solutions with those libraries on both CPU and GPU compute architectures. Like what you are reading so far? Keep going. We want you to be intellectually adaptive, inquisitive, good at expressing your needs, and able to self-manage when necessary. Work alongside software/system engineers and research/data scientists with expertise in multi-modal information retrieval, UI development, computer vision, metrics, information science, artificial intelligence, and autonomous systems. The Department of Defense and the Intelligence Community will be the main recipients your hard work. Fun stuff you will do on the job: - Use cases requiring identifying entity/objects, determining object association, object disambiguation, anomaly detection, state estimations, etc.
Develop and maintain data models (both physical and logical)
Get to be responsible for extraction, transform, and load (ETL) tasks related to the different modalities and algorithms being applied. This data ETL includes identifying the data's relevant metadata to ensure consistency, quality, accuracy, integrity, and information assurance and security.
Performing anomaly detection using various AI/ML techniques
Use algorithms to identify complex patterns across multiple modalities
Increasing the efficiency and quality data alignment and fusion
Enhance and maintain analysis tools, including automation of current processes using AI/ML algorithms
Conduct quantitative data analysis including developing retrieval, processing, fusion, analysis, and visualization of various datasets Skills required to be successful in this role: - Bachelor's Degree in Aerospace Engineering, Computer Science, Mathematics, Statistics, Physics, Electrical Engineering, Computer Engineering or related fields with 5 years of relevant experience
Must be able to obtain and maintain a TS/SCI security clearance
Experience with Deep Learning Frameworks such as Keras, Tensorflow, PyTorch, Mxnet, etc. - Ability to apply these frameworks to real problems in the 'time -series' domain
Experience with interpretability of deep learning models
Big Data Skills (Azure, Hadoop, Spark, recent deep learning platforms)
Practical experience with statistical analysis
Experience with text mining tools and techniques including in areas of summarization, search (e.g. ELK Stack), entity extraction, training set generation (e.g. Snorkel) and anomaly detection
Expert software development skills lifecycle including developing and maintaining good production quality code
Hands-on Software Development Skills (Python-Preferred)
Experience or educational courses/projects in Machine Learning, and/or Text Mining Algorithms You will wow us even more if you have these skills: - Visualizations/Web Development Skills (e.g. Tableau, D3, etc).
Hands-on experience with prototype development
Hands-on experience with automating data cleansing, formatting, staging, and transforming data human
Hands-on experience applying data analytics
Hands-on experience with intelligent systems and machine learning LInC External Referral Bonus: Ineligible Potential for Telework: No Clearance Level Required: Top Secret/SCI Travel: Yes, 10% of the time Scheduled Weekly Hours: 40 Shift: Day Requisition Category: Professional Job Family: Software Engineering Leidos Leidos is a Fortune 500® information technology, engineering, and science solutions and services leader working to solve the world's toughest challenges in the defense, intelligence, homeland security, civil, and health markets. The company's 33,000 employees support vital missions for government and commercial customers. Headquartered in Reston, Virginia, Leidos reported annual revenues of approximately $10.19 billion for the fiscal year ended December 28, 2018. For more information, visit www.Leidos.com . Pay and Benefits Pay and benefits are fundamental to any career decision. That's why we craft compensation packages that reflect the importance of the work we do for our customers. Employment benefits include competitive compensation, Health and Wellness programs, Income Protection, Paid Leave and Retirement. More details are available here . Securing Your Data Leidos will never ask you to provide payment-related information at any part of the employment application process. And Leidos will communicate with you only through emails that are sent from a Leidos.com email address. If you receive an email purporting to be from Leidos that asks for payment-related information or any other personal information, please report the email to [email protected] . Commitment to Diversity All qualified applicants will receive consideration for employment without regard to sex, race, ethnicity, age, national origin, citizenship, religion, physical or mental disability, medical condition, genetic information, pregnancy, family structure, marital status, ancestry, domestic partner status, sexual orientation, gender identity or expression, veteran or military status, or any other basis prohibited by law. Leidos will also consider for employment qualified applicants with criminal histories consistent with relevant laws.",3.5,"Leidos
3.5","Arlington, VA","Reston, VA",10000+ employees,1969,Company - Public,Aerospace & Defense,Aerospace & Defense,$10+ billion (USD),-1
Software Engineer,"$64K-$132K
(Glassdoor est.)","Every Analyst a Scientist - One of our primary goals is to empower intelligence analysts to be able to study their data like scientists. The tools we develop focus on streamlining intelligence analysis through integrated algorithms and software that provide insight into the geopolitical landscape for use in operational intelligence missions around the world.

The Role:
As a Software Engineer, you will be part of a team that transforms large and complex customer data into real-world, high-impact solutions. You will work with researchers and engineers to design and implement solutions to challenging national security problems. You will be responsible for building the software infrastructure to clean, ingest, and expose datasets and algorithms to both developers and end users. You will deploy algorithms, generate workflows, create engineer-facing tools, and design customer-facing prototype systems. You will occasionally travel to customer sites to engage with end users, demonstrate prototypes, and integrate analytics into customer systems.

If you would like to help intelligence and defense analysts keep pace with technology-driven innovation, then this role is for you!

Who you are:
A U.S. Citizen with the ability to obtain a Security Clearance
A degree in a scientific or engineering field, such as Computer Science, Mathematics, Physics, or Software Engineering
Proficiency with a scientific programming language such as Python, Java, or C++
Experience with database management and common query syntax
Motivated collaborator and excellent communicator of ideas to both technical and non-technical audiences
Knowledge of AWS, Spark, Dask, and/or similar technologies for working with data at scale
Even better:
Active Security Clearance
Track record of architecting, developing, deploying, or maintaining enterprise software
Experience with software development best practices and tools
Understanding of web development and visualization technologies, such as d3, Leaflet, Bootstrap, or others
Familiarity with machine learning or statistical modeling techniques",4.5,"Systems & Technology Research
4.5","Woburn, MA","Woburn, MA",201 to 500 employees,2010,Company - Private,Aerospace & Defense,Aerospace & Defense,$100 to $500 million (USD),-1
Sr. Data Scientist,-1,"Background Information:

Innovative Defense Technologies (IDT), provider of automated software testing, data analysis, and cybersecurity solutions for complex defense systems, is currently accepting applications for an anticipated Sr. Data Scientist role requiring 7+ years of experience for a position in support of its efforts implementing Artificial Intelligence solutions for a variety of customers.

Overview:

The Sr. Data Scientist position offers an engineer the opportunity to utilize his/her knowledge and talents as part of a collaborative team developing AI solutions for a growing company. A few of the responsibilities include supporting feasibility studies, applying modern data storage techniques, discovering explanatory features in high-dimensionality collections of data, and exploring data using scientifically valid techniques to exploit patterns found in the data with state-of-the-art AI/ML/DL solutions.

All applicants must be able to obtain/maintain an active U.S. Security Clearance.

Responsibilities Include:
Lead development of solutions to deliver AI/ML/DL models from problem formulation to a productized, deployable, maintainable capability
Contribute to AI/ML/DL technical roadmap development
Use Deep Learning frameworks such as Tensorflow and Keras to build and validate ML/DL models
Establish and leverage Big Data frameworks to store, extract and analyze relevant data
Ensure development of software solutions meets customer needs and program intent
Work closely with the Program Manager and Chief Engineer to design and implement software requirements and solutions
Determine operational feasibility by evaluating analysis, problem definition, requirements, solution development, and proposed solutions for large, complex systems
Be responsible for a team’s products meeting software design, quality, and performance requirements
Pursue new technology development via the DoD Small Business Innovative Research (SBIR) program
Work with minimal supervision in a collaborative work environment to implement best-in-class solutions
Minimum Required Qualifications:
Bachelor’s Degree in Computer Science, Computer Engineering, Electrical Engineering, Systems Engineering, Physics, or Math Required; PhD in relevant field highly preferred
7+ years of experience in predictive modeling, data science and analysis
Required Skills:
Previous experience in a ML or data scientist role and a track record of building ML or DL models
Extensive experience working with data mining algorithms including decision trees, probability networks, association rules, clustering, and neural networks
Experience using Python (or equivalent)
Experience using ML libraries, such as scikit-learn,
Experience using data visualization tools
Experience handling terabyte size dataset
Experience working with GPUs to develop models
Ability to travel 10% or less
Preferred Skills:
Experience with MapReduce programming (Hadoop)
Skills with programming languages, such as Java or C/C++
Demonstrated ability to develop experimental and analytic plans for data modeling processes, use of strong baselines, ability to accurately determine cause and effect relations
Consulting experience and track record of helping customers with their AI needs
Publications or presentations in recognized Machine Learning, Deep Learning and Data Mining journals/conferences
Combination of deep technical skills and business savvy enough to interface with all levels and disciplines within our customer’s organization
Experience diving into data to discover hidden patterns
Experience with application container platforms
Familiarity with continuous integration/delivery tools (e.g. Jenkins)
Familiarity with version control tools (e.g. Subversion, Git, etc.)
Familiarity with VMware or other virtualization software
Experience developing applications for DOD command and control systems
Competencies:
Solid analytical abilities, coupled with a strong sense of ownership, urgency, and drive
Attention to detail
Initiative, creativity, reliability, teamwork
Ability to deal well with ambiguity, prioritize needs, and deliver results in a dynamic environment
EEO Statement:

IDT is an Equal Opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, creed, sex, sexual orientation, gender identity, national origin, disability, protected Veteran status, or any other basis protected by federal, state, or local law.",-1,Innovative Defense Technologies (IDT),"Mount Laurel, NJ",-1,-1,-1,-1,-1,-1,-1,-1
Full Stack Software Engineer (Python/Vue),-1,"Position Summary Full Stack Software Engineer (Python VueJS) Company Overview Our client is an automated underwriting platform for real estate professionals that was built to disrupt the commercial real estate industry. The software allows investors, brokers, and lenders to analyze rent, operating expenses and returns for multifamily properties by applying machine learning to a database of live multifamily transaction data from every U.S. market. Our client has a creative and entrepreneurial culture ndash everyone on the team interacts directly with customers each day, and we all contribute to the product and planning. If you have an idea to improve something, there is no red tapehellip just build what needs to be built! Innovation and passion for transforming the old-fashioned real estate industry are our highest priorities. Job Description As a full-stack (Python, PostgreSQL and HTMLCSSJavaScript) developer, you'll work on the interface and backend infrastructure of products and features used by hundreds of underwriters and real estate analysts every day. The work is challenging, fast-paced, and always changing. You must have demonstrated analytical skills, an unwavering commitment to quality, a collaborative work ethic, and cutting-edge coding skills. You must display solid proficiency in the fundamentals of Python, PostgreSQL, JavaScript, HTMLCSS, and popular front-end frameworks like Vue.js. The role will include the delivery of reliable, scalable new features to users, developed in Python, interacting with a PostgreSQL database and using the Vue.js frontend framework. You will work with the development team to develop, test and deliver finished, high quality, compelling features and products. Our team includes designers, engineers and data scientists who are passionate about quality, usability, and simplicity. If you are ready to join a company that fosters learning, growth, experimentation and innovation, our client's team is for you. Requirements Qualifications 3-5 years of experience in full stack Python development 1-3 years of experience with PostgreSQL 1-3 years of experience with JavaScript frameworks such as React, Angular or Vue.js (Vue.js is preferred, this is what our client uses), and CSS pre-processing frameworks (Sass or Less) 1-2 years of experience integrating with VBA and Excel integration preferred Experience using GitHub and solid understanding of software version control Familiarity with JIRA or equivalent product management software Familiarity with agile development best practices Driven self-starter able to work on a small team and take initiative on new tasks Familiarity with real estate or finance is a plus Responsibilities Collaborate with interdisciplinary team of data scientists, software engineers and real estate professionals Strive for high quality and rapid output utilizing agile development best practices Support, maintain, and document software functionality Maintain industry standard coding, compliance, security practices Proactively learn product frameworks and code base Our client is a startup company, and as such the responsibilities outlined above may change and evolve over time. Flexibility, curiosity, an entrepreneurial mindset, and strong work ethic are essential for this role. It is encouraged that everyone on the team continually research new technologies and analytical opportunities to improve the platform.",5.0,"CultureFit
5.0","Chicago, IL","Deerfield, IL",1 to 50 employees,1997,Company - Private,Advertising & Marketing,Business Services,$1 to $5 million (USD),-1
AWS Data Engineer,-1,"About Infinitive:

At Infinitive, we do mission-critical work for great companies. We specialize in digital marketing and digital advertising solutions, customer data & analytics, digital & business transformation, and Technology solutions. Our Technology solutions focus on Managed Cloud Services, Cloud Enablement, Digital Operations, Application Development, DevOps, Product Development, Cloud Security, Data Science and Analytics, AI/ML, IoT, and everything in between.

Our experts are results-obsessed, focused and flexible, highly engaged and hugely experienced having sat in our clients seats. Those qualities are what make us different than old-school consulting shops. And surely, they are why clients and partners describe us as the gold standard in client experience.

Infinitive has been named a Best Small Firms to Work For by Consulting Magazine seven times, a Washington Post Top Workplace three times, a Washington Business Journal Best

About this Role:

Infinitive is growing its team in the Northern Virginia area and is currently seeking an Data Scientist to join our growing Technology practice. This person will utilize their experience in analytics, IoT, machine learning, and artificial intelligence advances to create value from structured and unstructured data. The ideal candidate has experience designing novel data analytic methods and workflows, including full data pipelines from raw data through analysis results. They must also have exposure to a variety of data mining/data analysis methods, data tools, building and implementing models, using/creating algorithms, and creating/running simulations.

We are looking for candidates who are accountable, passionate, assertive, proactive, open & honest, results oriented, and adaptable. Each project engagement represents a new challenge that will give you exposure to new clients, business issues, technologies, and people and will involve a range of responsibilities to include:
Developing in Java, Python, R, or other high-level languages.
Managing disparate data sources with varying data structures of content and preparing these for data science and machine learning applications.
Working with distributed scalable Big Data storage, processing, and computation, including AWS EMR, Spark, etc.
Implementation knowledge of, or desire to learn AWS / Azure data science capabilities.
Developing solutions and integrating and extending free and Open-source software (FOSS) or COTS products.
Conduct MapReduce programming with Apache Hadoop, the Hadoop Distributed File System (HDFS), and processing large data stores.
Knowledge of SQL and query languages.
Utilize real-time, large-scale data processing engine, including Apache Spark.
Lead and create Data Science and Analytics methodologies and frameworks for implementation.
Ability to build and develop Data Science demonstrations for clients
Qualifications:
4+ years of development experience (Java, Python, R, SQL)
3+ years of experience with distributed scalable Big Data storage, including AWS EMR, Spark, etc.
Desire to become AWS / Azure Certified architect / engineer.
Experience performing data Management, modeling, and warehousing.
Hands on experience with Amazon analytic tools (preferred)
Interest in being involved internally and growing a small business (entrepreneurial spirit)
Ability to travel (up to 20%) and to work independently
Experience using Agile software development methods in a DevOps environment.
Excellent leadership, peer management, and communication skills
Management consulting experience (preferred)
Bachelor's degree in related field (preferred)
Applicants for employment in the U.S. must possess work authorization which does not require sponsorship by the employer for a visa.

Infinitive is an Equal Opportunity Employer.

Powered by JazzHR",3.4,"Infinitive Inc
3.4","Arlington, VA","Cedar Rapids, IA",201 to 500 employees,1997,Company - Private,Enterprise Software & Network Solutions,Information Technology,$10 to $25 million (USD),-1
"Senior SW Engineer, Data Science ( Kubernetes/ Docker ) Remote USA","$72K-$141K
(Glassdoor est.)","If you dream of a job working in a field where all the hard problems are solved and you get to re-use previous research to get your job done, you need not apply. If, however, you are someone who wants to tackle problems that truly are on the cutting edge, then we encourage you to keep reading.

Data Science is an emerging field within cyber security. FireEye, given its deep expertise and comprehensive view on the advanced threat landscape, is uniquely positioned to enable data scientists to have major impact within our industry, company, and across our customer base. Detecting security breaches using machine learning and data analytics is an unsolved problem (this is not handwriting recognition folks) and has huge potential.

If you are someone who wants to be on the cutting edge of a high profile industry, who wants to make an impact by pushing both fields of data science and cyber security forward, you may be the perfect candidate to help us on our mission.

What you will do:
Develop, and manage data systems to ingest and process data at massive scale
Identify data sources both internally and externally that we can use to find evil.
Contribute towards the architecture and design of software solutions for long-term storage and retrieval.
Identify and implement data exploration technologies. Create dashboards and implement analytical tools for exploration
Work with data scientists to productize ML models and assist product teams with ML model releases into end products.
Collect requirements, design, and build backend components and tools to run ML models, assess ML model efficacy, manage large scale datasets, and generate features for ML models
Contribute to the evolution of coding and design practices within the organization.
Review code base commits and contribute to the growth of team members.
Requirements
Ability to work in an iterative, agile development environment.
Experience implementing ETL processes and building data pipelines
Experience developing reliable distributed systems.
Experience in Data modeling and schema design
Strong knowledge of a variety of operating systems, networking fundamentals, software design and programming best practices.
Experience with use of a wide array of algorithms and data structures.
Deep understanding and experience of going through the entire life cycle of building software platforms and products
Deep knowledge of various AWS services and associated tools
Strong experience developing in Python 3
Experience developing in at least 1 of the following: C, Go or Java
Experience with RDBMS, such as PostgreSQL or MySQL, as well as NoSQL
Experience with Kubernetes and Docker.
Experience deploying products in AWS
Additional Qualification: *
Ability to pick up, work with and explore new analytical tools
Strong experience with DevOps practices and common tooling
Strong communication skills.
Ability to work with loosely defined requirements.
At FireEye we are committed to our #OneTeam approach combining diversity, collaboration, and excellence. All qualified applicants will receive consideration for employment without regard to race, sex, color, religion, sexual orientation, gender identity, national origin, protected veteran status, or on the basis of disability. Requests for accommodation due to disability can be sent directly to .",3.3,"FireEye Inc
3.3","Denver, CO","Milpitas, CA",1001 to 5000 employees,2004,Company - Public,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,"Palo Alto Networks, Tanium"
"Senior SW Engineer, Data Science","$72K-$141K
(Glassdoor est.)","Job Description

If you dream of a job working in a field where all the hard problems are solved and you get to re-use previous research to get your job done, you need not apply. If, however, you are someone who wants to tackle problems that truly are on the cutting edge, then we encourage you to keep reading.

Data Science is an emerging field within cyber security. FireEye, given its deep expertise and comprehensive view on the advanced threat landscape, is uniquely positioned to enable data scientists to have major impact within our industry, company, and across our customer base. Detecting security breaches using machine learning and data analytics is an unsolved problem (this is not handwriting recognition folks) and has huge potential.

If you are someone who wants to be on the cutting edge of a high profile industry, who wants to make an impact by pushing both fields of data science and cyber security forward, you may be the perfect candidate to help us on our mission.

What you will do:
Develop, and manage data systems to ingest and process data at massive scale
Identify data sources both internally and externally that we can use to find evil.
Contribute towards the architecture and design of software solutions for long-term storage and retrieval.
Identify and implement data exploration technologies. Create dashboards and implement analytical tools for exploration
Work with data scientists to productize ML models and assist product teams with ML model releases into end products.
Collect requirements, design, and build backend components and tools to run ML models, assess ML model efficacy, manage large scale datasets, and generate features for ML models
Contribute to the evolution of coding and design practices within the organization.
Review code base commits and contribute to the growth of team members.",3.3,"FireEye Inc
3.3","Denver, CO","Milpitas, CA",1001 to 5000 employees,2004,Company - Public,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,"Palo Alto Networks, Tanium"
"Senior Machine Learning Engineer, Early Stage Pipeline, X",-1,"Senior Machine Learning Engineer, Early Stage Pipeline, X

Software Engineering

Mountain View, CA

We're an early stage team at X with a growing, interdisciplinary portfolio. To prove our path to the moon, we make early contact with the real world through both internal and external partnerships.

In this role, you will be responsible for taking early stage investigations from an idea stage to first prototypes to a full-blown projects. You'll be rapidly iterating through a set of prototypes to evaluate possible product directions. This is an extremely dynamic role and requires high cross-functional communication, organization, and planning. The ideal candidate is a self-starter and has a track record of effectively operating in a dynamic loosely structured environment (e.g. startup, new products within a larger company). The candidate will work on multiple projects/investigations.

Responsibilities:
Identify and implement a set of machine learning prototypes to aggressively de-risk projects building the whole solution: data acquisition, data processing pipelines, ML modeling.
Setup technical direction for investigations/projects working with the early stage leadership team.
Team lead investigations that grow to become projects.
Qualifications:
Hands-on experience with machine learning, one or more of; natural language processing (semantic understanding, sentiment analysis), computer vision, time series analysis.
Experience with building robust data pipelines.
Tech Lead experience.
Startup or early-stage product development experience.
Preferred Qualifications:
Experience with the Google Cloud Platform
About X, the Moonshot Factory

X creates radical new technologies to solve some of the world's biggest problems. We develop uncomfortably ambitious, potentially world-changing new ideas such as self-driving cars, balloon-powered Internet and smart contact lenses. We're a team of makers, entrepreneurs, engineers, designers and scientists with deep technical expertise who love the challenge of the seemingly impossible. We believe that a culture of psychological safety creates the foundation of trust and respect necessary to build moonshots. X was formerly known as Google[x] and is part of Alphabet .

At X, we don't just accept difference - we celebrate it, we support it, and we thrive on it for the benefit of our employees, our products and our community. We are proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements.

If you have a disability or special need that requires accommodation, please contact us at: (see application details) .",-1,"X, the moonshot factory","Mountain View, CA",-1,-1,-1,-1,-1,-1,-1,-1
"Senior/Staff Software Engineer, Data Infrastructure","$116K-$227K
(Glassdoor est.)","Senior/Staff Software Engineer, Data Infrastructure job posting

Every year, while Americans wait for their paychecks, more than $1 trillion of their hard-earned money is held up in the pay cycle. As a result, we accumulate over $50 billion in late and overdraft fees and turn to high-interest loans. Overdraft charges and bank fees often trap people in a cycle of debt that can lead to unhealthy decisions and falling victim to predatory businesses disguised as helpful services. We don't accept that.

Earnin is an app that creates products that help people gain control of their finances. Cash Out lets people get paid as soon as they leave work, with no fees, interest, or hidden costs. With Health Aid, Earnin negotiates on behalf of community members to lower their total unpaid medical bill and work out a budget-friendly payment plan. Cash Back Rewards is a way for members to earn up to 10% cash back on purchases from over a thousand local and national businesses without needing a credit card or having to reach spend thresholds to earn cash rewards — and they can withdraw the money at any time. We also offer free tools to help avoid overdrafts, to remind people when recurring bills are due, and we're working on more! There is never any required cost to use any of these products or services, users can choose to tip what they think is fair to support the service and pay it forward to keep the movement going.

Earnin is supported by funding partners including Andreessen Horowitz, Matrix Partners, Ribbit Capital, Felicis Venture, Thrive Capital, and others. Join us and help build a new financial system focused on fairness and people's needs.

You can help make a difference.

About the Team:

We are a data driven mobile financial tech company. The Data Infrastructure team builds the data services and data infrastructure that powers data science, analytics, and product development throughout Earnin. We are looking for a product-minded, self-driven Senior Software Engineer to own multiple large-scale projects that advance our mission of enabling people to gain access to their paycheck on demand.

What sets us apart:
High impact roles at a relatively small company that's aggressively growing our user base.
We are a collaborative team and genuinely enjoy working with each other.
We believe in empowering our people to be successful.
We're building a product that inspires fairness across the financial world and helps people not get taken advantage of.
As a Senior Engineer you will:
Break down complex problems into their bare essentials, translate this complexity into elegant design and create high quality, maintainable code.
Build massively scalable, production-grade data services.
Champion data quality and governance throughout the organization.
Build a world class data lake and data warehouse.
Design and develop new systems and tools to enable all of Earnin to consume and understand data faster.
Own the end to end design, build, and maintenance of platform services, data pipelines, and data products.
Implement comprehensive monitoring, logging, and alerting across our data infrastructure.
Work cross functionally with other teams (data science, design, product, marketing, and analytics) in high visibility roles as an engineering leader.
Build and deploy the data architecture that supports machine learning model development and actionable analytics.
Work with product engineering and data science teams to design scalable, performance model deployment architectures.
Communicate the tradeoffs of technical decisions to multiple stakeholders, including non-technical audiences.
Collaborate with and mentor other engineers and provide engineering direction to data scientists and analysts.
Actively engage and drive design reviews and code reviews.
Some skills we consider critical to being a Senior Engineer:
BS or MS degree in Computer Science, Engineering, or a related technical field.
8+ years of development experience in a fast-paced environment, especially startups.
5+ years of experience working with data systems.
Strong Python and SQL skills.
Strong programming and architecture skills.
Excellent written and verbal communication skills, including the ability to identify and communicate data driven insight.
Taking pride in your code quality and helping others elevate their own code quality.
Substantial experience with testing, data validation, and data quality assurance.
You can articulate the tradeoffs of different deployment architectures (e.g. streaming vs. batch vs. service-based).
Experience designing data platforms and services on cloud infrastructure, preferably AWS.
Hands-on experience designing and building large-scale solutions with the Hadoop stack and/or Spark.
Experience tuning and optimizing Spark-based applications.
Experience deploying and/or using query engines like AWS Athena, Presto, and Impala.
Experience with AWS analytical services like Redshift.
Hands-on experience working with a varied set of data storage technologies (e.g. Mysql, Postgres, DynamoDB, S3, etc.). You know where and when to use each.
Extensive experience with data modeling for multiple use cases and application styles, including NoSQL data modeling.
Experience working with data formats such as Avro and Parquet.
Experience working with alerting and monitoring tools like DataDog and PagerDuty.
Nice to haves:
You have experience building and deploying machine learning models.
You have experience using Terraform.
You have substantial experience working at a startup.
You have experience with data modeling in Redshift.
Experience with streaming infrastructure like Kafka.
Experience working with Kubernetes.
Experience building and deploying AWS Lambda applications.",3.1,"Earnin
3.1","Palo Alto, CA","Palo Alto, CA",201 to 500 employees,2012,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Engineer (open level),"$43K-$69K
(Glassdoor est.)","Title
Data Engineer (open level)

07/08/2020

What you'll do...
At H&R Block, your contributions will go far beyond any job description. When you join our team, you'll add to the momentum of a forward-thinking company - one that defined an industry and is now leading its transformation.

H&R Block is transforming tax preparation through data to ensure that every client we serve gets the best tax outcome possible.

We are building a new Data Engineering Team in the Data Science & Analytics organization. This new team will own the technology and data capabilities of the end-to-end data-and-analytics function. It will take responsibility for building and maintaining the analytical technologies that the data science teams use, managing data at an enterprise scale, leveraging relationships with IT teams throughout the enterprise, and leading information architecture.

We are looking for talented, curious, and creative data engineers of all levels to help launch this team. You will be a good match for our organization if you are:
Motivated by the idea of building something innovative, transformative, and impactful.
Committed to the idea that data can drive experiences and products that wow our business partners and clients
Obsessed with defying expectations and raising the bar
Driven by an innate sense of ownership for the products you create.
Day to day, you'll...
Design and deploy architecture, solutions, and software to capture, manage, store, and use structured and unstructured data from internal and external sources in both on-prem and cloud environments.
Deploy machine-learning models and other data-science products across the enterprise.
Navigate the balance between business needs, data governance best practices, and technical requirements.
Select or develop tools to cleanse, organize, and transform data and to maintain, defend, and update data structures and integrity on an automated basis.
Develop data products to facilitate self-service capabilities and assist the data teams to increase their efficiency and effectiveness.
Collaborate and communicate effectively within cross-functional teams that span internal Data Science & Analytics teams, IT, business groups, and executive stakeholders.
Be a positive force to cultivate a culture that is passionate about developing data tools as a business driver.
Job ID
368348BR

Address1
ONE H&R BLOCK WAY

City
KANSAS CITY

State
Missouri

Employee Type
Regular

What you'll bring to the team...
Education / work experience should include most of these, depending on level:
Bachelor’s degree in Computer Science or a related technical field (or equivalent work experience and technical skills)
Data warehousing and ETL solutions
APIs in a microservices architecture
Big-data technologies and the Hadoop stack (MapReduce, Hive, Pig, Hbase
NoSQL implementations (MongoDB)
Developing Java-based software solution
At least one scripting language (Python, Perl, JavaScript, Shell
Developing software solutions to solve complex business problems
Working with data scientists and other data users
Posting Title
Data Engineer (open level)

Sponsored Job
#hrbjob

Job Family
Corporate Analytics",3.6,"H&R Block
3.6","Kansas City, MO","Kansas City, MO",10000+ employees,1955,Company - Public,Other Retail Stores,Retail,$2 to $5 billion (USD),"Intuit, Jackson Hewitt, Liberty Tax Service"
Senior Modeling & Simulation Engineer,-1,"Applied Research Associates, Inc. is looking for a Senior Modeling and Simulation Engineer to join our multi-disciplinary team of engineers and scientists in the Capital Area Division, located in Alexandria, VA. The ideal candidate has a passion for predicting the behavior of physical systems in challenging environments and operational impact on mission success. Models will be developed, used, and improved to support a Department of Homeland Security customer to safeguard the nation’s borders and interior from chemical, biological, radiological, nuclear, and explosive materials, equipment, technologies, and their actors. Models may be based on the underlying physics or may be process or agent based to predict operational performance and impact. Modeling and analysis may require the use and development of 3D virtual worlds or geospatial data. Models will be verified and validated, and they will be used in support of test and evaluation activities of systems intended to detect and identify threats. The candidate may participate in test and evaluation activities to support the verification, validation, and overall improvement of models. Models may become part of larger, integrated modeling and simulation activities, and may require the use of high performance computing technologies and federated simulations.

This position is contingent upon award of a contract expected in Summer 2020 supporting the Department of Homeland Security.

Required Qualifications:
Ability to program in a high level programming language, such as Fortran, C++, or Java
Eagerness to learn new tools and techniques
Strong verbal and written communication skills
Must be a U.S. Citizen with the ability to obtain and maintain a security clearance
Bachelor’s degree with minimum of 10 years of experience or greater in a physical science (physics, chemistry, biology), engineering-related discipline (nuclear, chemical, civil, mechanical, electrical), or modeling& simulation disciple (computer modeling, computational science, operations research)
Ability to present to senior leadership on the status and issues associated with research or test efforts in preparation for acquisition decision meetings
Desired Experience and Qualifications:
Experience modeling CBRNE detectors or effects
Experience using multiple software tools such as MCNP, GadRas, SWORD, ExtendSim, Arena, SolidWorks, Fluent, ArcGIS, QGIS, VisIt, ParaView, or Cubit
Experience creating 3D models of systems, i.e., CAD
Experience using high performance computers (i.e., supercomputers)
Experience developing and using discrete event or agent based models and simulations to predict and assess system performance
Experience developing machine learning models
Background in a physical science or engineering discipline, such as Physics, Chemistry, Biology, Mechanical Engineering, Nuclear Engineering
Active DoD Secret or Top Secret clearance, DoE Q clearance, or DHS Suitability
COMPANY INFORMATION:

Applied Research Associates, Inc. is an employee-owned international research and engineering company recognized for providing technically superior solutions to complex and challenging problems in the physical sciences. The company, founded in Albuquerque, NM, in 1979, currently employs over 1200 professionals. ARA offices throughout the United States and Canada provide a broad range of technical expertise in defense technologies, civil technologies, computer software and simulation, systems analysis, environmental technologies, and testing and measurement. The corporation also provides sophisticated technical products for environmental site characterization, pavement analysis, and robotics.

At ARA, employees are our greatest assets. The corporation realizes that employee ownership spawns greater creativity and initiative along with higher performance and customer satisfaction levels. ARA gives its employees the tools, training, and opportunities to take more active roles as owners. The culture is challenging; innovation and experimentation are the norm. Employees are eligible for contributions which not only add to the company’s success, but also their own through the Employee Stock Ownership Plan (ESOP). The motto,“Engineering and Science for Fun and Profit” sums up the ARA experience. For additional information and an opportunity to join this unique workplace, please visit our website atwww.ara.com.",3.5,"Applied Research Associates
3.5","Alexandria, VA","Albuquerque, NM",1001 to 5000 employees,1979,Company - Private,Federal Agencies,Government,$100 to $500 million (USD),-1
Senior Data Engineer,-1,"This is a Data Engineer position for supporting a Navy program located in Quantico, Virginia.

We are seeking a Data Engineer to join our team of committed technical professionals to protect those who serve against criminal, terrorism and emerging threats. Are you passionate about analytics and innovation? Our employees enjoy a fast-paced, collaborative culture and the ability to directly impact our business. You will identify technical issues and opportunities for efficiency and provide technical insights through system design and configuration perspectives. This role is both challenging and rewarding.

You will support the mission through the implementation of a modern, integrated internal data infrastructure with a focus primarily on exploiting the established data foundation to make internal and customer-centric business processes as effective and efficient as possible, laying the foundation for cognitive capabilities that can sense and respond to both internal and external customer data needs. The candidate will also focus on expanding the organization’s data ecosystem to include context-rich data while maintaining the agility needed to spark innovation.

How you will make a difference:
Establish shared operational data and integrated enterprise data, all while managing and/or improving data quality and security through the creation of business-driven governance structures and culture change management.
Establish data policies, standards, and procedures that improve data quality, availability, accessibility, security, usability, and enforcement of enterprise information management (EIM) program requirements.
Establish enterprise standards – including a uniform and repeatable system development lifecycle methodology for Reference Data and Master Data (e.g., a common set of standards for data naming, abbreviations, and acronyms).
Develop a Master Data Management (MDM) Plan that focuses on the technology, tools, and processes ensuring master data is coordinated across the enterprise. MDM is a method used to define and manage the critical data of an organization to provide, with data integration, a single point of reference. The data that is mastered may include reference data – the set of permissible values, and the analytical data supporting decision making. MDM provides a unified master data service intended to provide accurate, consistent and complete master data across the enterprise and to business partners.
Recommend solutions based on performing industry-specific analysis, such as case studies describing data management best practices, identifying trends across the industry.
Make recommendations to improve the efficiency and effectiveness in how the agency acquires, stores, manages, shares and applies its data.
Engage business users and stakeholders for the increased release of actionable high-quality data on key operational and tactical activities at NCIS.
Develop technology solutions to provide the platform, training, and standardized tools enabling querying, data mining, statistical analysis, reporting, scenario modeling, data visualization, and dash-boarding, and processes for a centralized, or analytics as a service model, allowing for the sharing of data across the enterprise from a common hub, facilitates cross-organizational data initiatives due to its enterprise-wide view of data assets and needs.
Basic Qualifications
Required: A bachelor’s or master’s degree in computer science, data science, operations research, statistics, applied mathematics, or a related quantitative field [or equivalent work experience such as, economics, engineering and physics] is [preferred/required]. Alternate experience and education in equivalent areas such as economics, engineering or physics, is acceptable. Experience in more than one area is strongly preferred.
Required: Three to six (midlevel) of relevant project experience in successfully launching, planning, and executing data science projects. Preferably in the domains of risk modelling and quality assessment.
Preferred: Specialization in text analytics, image recognition, graph analysis or other specialized ML techniques such as deep learning, etc.
Preferred: the candidates are adept in agile methodologies and well-versed in applying DevOps/MLOps methods to the construction of ML and data science pipelines.
Coding knowledge and experience in several languages: for example, R, Python, Java, C++, Excel, MATLAB, etc.
Experience with popular database programming languages including SQL, PL/SQL, others for relational databases and upcoming non-relational databases such as NoSQL/Hadoop-oriented databases such as MongoDB, Cassandra, others.
Preferred: Specialized/operational data scientists may need further high-performance computing (HPC)/compute skills; larger data science teams, in particular, may require further degrees of specialization such as:
Experience with distributed data/computing tools such as MapReduce, Hadoop, Hive, Kafka, and MySQL
Experience of working across multiple deployment environments including cloud, on-premises and hybrid environments, multiple operating systems and through containerization techniques such as Docker, Kubernetes, AWS Elastic Container Service, and others.
Experience in one or more of the following commercial/open-source data discovery/analysis platforms: RStudio, Spark, KNIME, RapidMiner, Alteryx, Dataiku, H2O, SAS Enterprise Miner (SAS EM) and/or SAS Visual Data Mining and Machine Learning, Microsoft AzureML, IBM Watson Studio or SPSS Modeler, Amazon SageMaker, Google Cloud ML, SAP Predictive Analytics.
Preferred: Expertise in solving vision, text analytics, credit scoring, and failure prediction problems.
Knowledge and experience in statistical and data mining techniques such as generalized linear model (GLM)/regression, random forest, boosting, trees, text mining, hierarchical clustering, deep learning, convolutional neural network (CNN), recurrent neural network (RNN), T-distributed Stochastic Neighbor Embedding (t-SNE), graph analysis, etc.
Strong documentation skills. Required: Certifications as per Cybersecurity Workforce Management and Qualification Manual, SECNAV M-5239.2.
Required: Eligible AND adjudicated to the Top Secret (TS SCI) clearance level is required to start.
About Inventium.io:

Inventium.io LLC is a technical consulting and software development services company dedicated to protecting and advancing our national defense and scientific capabilities. Based out of the Washington DC area, we rely on innovation to continually advance our employees' skills and provide digital transformation solutions to our customers.

With proven records of successfully delivering quality services and solutions to multiple federal agencies, our technical competencies include Emerging Technology Solutions, DevSecOps, Cloud Migration, Machine Learning, System Modernization, and Technology Management.

Benefits and Perks
Employer paid Health Benefits (Medical, Dental and Vision)
Retirement Plan
Paid Time Off and Federal Holidays
Training and Development
Employee Referral Program
Awards and Recognition",5.0,"inventium.io LLC
5.0","Quantico, VA","Washington, DC",1 to 50 employees,2016,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Senior Software Engineer,-1,"At Pacific Biosciences, our R&D team is committed to developing innovative products that enable scientists to excel in a wide variety of life science research fields, including human biomedical, plant and animal sciences, and microbiology and infectious disease. Our unique Single Molecule, Real-Time (SMRT) sequencing platforms generate true high-quality long reads, giving researchers a more comprehensive view of genomes, transcriptomes, and epigenomes from any organism.

The Primary Analysis group, as part of the larger software engineering team at PacBio, develops algorithms and HPC solutions for decoding the raw data streams, generated through high-speed optical detection of the SMRT sequencing reactions, into DNA sequence reads. We operate at the intersection of cutting-edge nanotechnology and state-of-the-art bioinformatics tools, and our responsibilities span the full product development life cycle in an aggressive time-to-market environment. These include analysis and algorithm development in coordination with chemistry and systems R&D; the development of real-time analysis pipelines; and the development of validation and support infrastructure geared towards product system reliability and internal R&D support. We are seeking a talented algorithm engineer with a strong background in the physical or machine-learning/data sciences who also has a passion for designing and developing performance-critical data analysis solutions.

Responsibilities:

Design, develop, and test signal- and sequence-analysis algorithms that will drive fundamental improvements in basecalling accuracy and yield.
Work collaboratively in a team environment to solve challenging problems in software architecture and scalability of real-time analysis pipelines for our next-generation sequencing platforms.
All listed tasks and responsibilities are deemed as essential functions to this position; however, business conditions may require reasonable accommodations for additional tasks and responsibilities.

Key Skills and Background:

3+ years of experience shipping product software in a scientific or quantitative domain.
Demonstrated skills applying numerical methods, statistical signal processing, or machine-learning techniques to high-throughput, performance-critical analysis applications.
Linux-based systems programming experience with knowledge of OS, toolchain and hardware constraints.
Strong C++ programming experience in applications geared towards performance and scalability; previous experience in CUDA programming for GPU is a plus.
MS, PhD or equivalent experience in a quantitative field (physics, CS, etc.), preferably with an applied math or algorithmic focus.
Engineering instincts to efficiently investigate and solve the problem at hand, from prototype development (Python, R, MATLAB, etc.) to production designs.
Team player, with strong communication skills, and comfortable as a self-starter in an agile, fast-paced development environment.
All qualified applicants will receive consideration for employment without regard to race, sex, color, religion, national origin, protected veteran status, or on the basis of disability, gender identity, and sexual orientation.",3.7,"Pacific Biosciences
3.7","Menlo Park, CA","Menlo Park, CA",201 to 500 employees,2000,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,$50 to $100 million (USD),Illumina
Senior Data Engineer,-1,"ABOUT 605

At 605 we are engineers, analysts, data scientists, media experts, marketing strategists and political operatives. Our team of data scientists pioneered the field of TV data analytics. We offer unique, independent audience measurement and analytics to build better marketing and programming initiatives within the media and entertainment industries.

The Sr. Data Engineer at 605 must have a broad and deep data skillset as well as strong analytical capabilities . In addition to being a hands on individual contributor, the ideal candidate is a productive team player and a mentor to Junior. Data Engineers. Additionally, we are looking for strong technical experts.

Responsibilities include:
Actively participate in team technical discussions in all things data
Identify and address issues with data sets from multiple vendors
Identify and address code and data quality issues
Actively participate in code reviews and grooming sessions
Actively participate in technology architecture discussions for product development
Translate business requirements into strategy
Advocate for software best practices within your team as well as across engineering
Be ultra-responsive and capable of making instant decisions, always kicking the ball forward
Work on unique and interesting data challenges around architecting, building and managing pipelines that securely process hundreds of terabytes of data
Work closely with analysts and statisticians to ensure the validity of our processes
Our engineers are expected to wear a number of hats and have the opportunity to touch all parts of the stack. Our stack includes Apache Spark, Scala, Redshift and an ever-growing list of many other cool technologies.

Requirements
Skillful user of Apache Spark
Experience wrangling terabytes of big, complicated, imperfect data
Experience with AWS products (Redshift, EMR, S3, IAM, RDS, etc)
You have a deep understanding of scalable systems and you have large-scale engineering experience in an Agile development environment
Bachelor's degree in Computer Science or a related field (or 4 additional years of relevant work experience)
A strong understanding of data structures, algorithms, and effective software design
Significant development experience with a major modern language (e.g. Java, Scala, Python, Ruby, C/C++, etc.)
Significant experience working with structured and unstructured data at scale and comfort with a variety of different stores (key-value, document, columnar, etc.) as well as traditional RDBMSes and data warehouses
Experience with or interest in AWS Glue, Redshift Spectrum and any other tools that enable data querying at scale
Experience writing unit, functional and integration tests
Comfort with version control systems (e.g. Git, SVN)
Excellent verbal and written communication skills; must work well in an agile, collaborative team environment
Preferred Qualifications
Master's in Computer Science or a related field
Practical experience with supervised machine learning techniques
Strong background with test-driven development
Basic understanding of statistics and experience with statistical packages such as R, Matlab, SPSS, etc
Benefits

Important and Standard
Comprehensive health, dental and vision insurance for employees and their families
Life & Disability insurance
401k plan with match, eligible for match after one year
Pre-tax flexible compensation plan for medical, transit, parking or dependent care expenses
Up to 15 paid vacation days depending on grade level
7 paid sick days in a calendar year - if you’re sick, you stay home
Other cool benefits
4 work from home days/month
A kitchen stocked with sodas, snacks, yogurt and other goodies
A tight knit start up community who likes to eat! We celebrate everyone’s birthdays, have frequent team lunches, and do events in and out of the office
605 is an active participant in conferences
EEO STATEMENT

At 605, we’re just as passionate about diversity as we are about pioneering the field of TV data analytics. We are committed to cultivating an environment of mutual respect and equal opportunity. All hiring and advancement decisions are made on the basis of qualification, merit, and business need.",-1,605,"New York, NY",-1,-1,-1,-1,-1,-1,-1,-1
Sr Innovation Engineer,"$75K-$134K
(Glassdoor est.)","Company Information

Solid reputation, passionate people and endless opportunities. Thats Travelers. Our superior financial strength and consistent record of strong operating returns mean security for our customers and opportunities for our employees. You will find Travelers to be full of energy and a workplace in which you truly can make a difference.

Target Openings

1

Job Description Summary

Innovation is at the core of everything we do. We continue to ask ourselves, whats next? as we navigate the ever-changing insurance landscape. Continuing our customer journey toward the cutting-edge, we are looking for a forward-thinking individual that thrives in ambiguity, who believes that with every challenge comes a new opportunity for solutions.

As a member of the Innovation Technology team, you will partner with research scientists and product managers to discover, invent, and build solutions at scale. As a team, you will work on challenges in machine perception, data mining, machine learning, and natural language understanding.

We are looking for a hands-on individual with strong foundational knowledge highly scalable architectures and platforms. If you like using a variety of skills in technology and solving complex problems, work collaboratively in a small agile team environment, you might just be the person we need on our team!

Primary Job Duties & Responsibilities
Work closely with Cloud Engineering to build an innovation platform; a collection of reusable and extensible containers and tools specific to developing insurance products and platforms.
Recommend integration strategies, enterprise architectures, platforms and application infrastructure required to successfully implement a complete solution using best practices.
Produce quality output for highly visible IT products, services and future business development.
Assist in hands-on remediation of application stability and performance.
Adopt and communicate new concepts, ideas, techniques.
Manage multiple projects simultaneously.
Provide 'Shrink Wrap' solutions to solve business and technical needs. As part of our innovation process, be able to scale Minimum Viable Product to production systems.
Design and lead integration of analytic data products, including pilots and proof of concepts.
Frequently present and translate complex information in relevant business terms.
Constantly learn new skills within small teams.
No direct HR people management but will lead teams in project & program contexts.
Education, Work Experience, & Knowledge
Bachelors Degree in STEM (Science, Technology, Engineering, Mathematics) related field and 3+ years of experience or 10+ years of experience building highly scalable platforms and reusable components
Job Specific Technical Skills & Competencies
2+ years of experience working with Amazon Web Services (AWS) or equivalent cloud. Must be recent experience.
5+ years of designing and developing on-premise and cloud solutions.
3+ years of experience as a technical lead.
Experience in software engineering with relevant technologies (Java, JavaScript, Python etc.).
Experience with the application delivery process.
End-to-end experience with data, including querying, aggregation, analysis, and visualization.
Preferred Qualifications
AWS certified developer and/or architect
Proven ability to work creatively and analytically in a continuously evolving environment.
Exhibits high levels of learning agility in which they seek out and learn from unfamiliar experiences and then apply those lessons to succeed in the next new situation.
Ability to leverage business knowledge to determine approaches to execution.
Strong communication and presentation skills with the ability to present and translate complex information to leadership and non-technical teams in relevant business terms.
Uses effective listening skills and communication to build relationships across the organization.
Ability to Influence with experience working with matrixed staff to complete tasks in a timely manner.
Environmental / Work Schedules / Other
Travel Required
Equal Employment Opportunity Statement

Travelers is an equal opportunity employer.",4.1,"Travelers
4.1","Hartford, CT","Hartford, CT",10000+ employees,1853,Company - Public,Insurance Carriers,Insurance,$10+ billion (USD),-1
Senior AI Software Engineer,-1,"Company Overview

Calling the adventurers ready to join a company that's pushing the limits of nanotechnology to keep the digital revolution rolling. At KLA, we're making technology advancements that are bigger—and tinier—than the world has ever seen.

Who are we? We research, develop, and manufacture the world's most advanced inspection and measurement equipment for the semiconductor and nanoelectronics industries. We enable the digital age by pushing the boundaries of technology, creating tools capable of finding defects smaller than a wavelength of visible light. We create smarter processes so that technology leaders can manufacture high-performance chips—the kind in that phone in your pocket, the tablet on your desk and nearly every electronic device you own—faster and better. We're passionate about creating solutions that drive progress and help people do what wouldn't be possible without us. The future is calling. Will you answer?

Responsibilities

Group/Division
KLA has always had a close relationship with physics and data. Our optical and electron beam inspection and measurement tools use cutting edge physics models, both for hardware design and as part of their algorithms. AI, including several traditional machine learning techniques and deep learning are routinely used to process this data to meet application requirements.

The AI & Modeling Center of Excellence, centered in KLA’s R&D facility in Ann Arbor, MI, was setup with the mission of advancing KLA’s traditional strengths in physics and data and providing implementation solutions for multiple KLA Inspection and Metrology products targeted at the semiconductor manufacturing industry.

As a part of this group, you will be part of a world class team of physicists, HPC system designers, machine learning and application engineers who build cutting edge solutions for modeling complex imaging techniques and semiconductor processes. You will also work with a data scientists and AI infrastructure engineers whose mission is to build and scale machine learning based solutions for our semiconductor customers.

We are looking for engineers in a few different fields. If you are passionate about Physics Modeling, High Performance Computing - HPC (including GPU), ML, Data, or Cloud technologies – this is the place for you!

Responsibilities:
Software Engineers in the AI and Physics Modeling team may work on a variety of tasks including platform for large scale experimentation, scaleout of physics models, data management and inference solutions for KLA products.

Although familiarity with Machine Learning and Deep Learning solutions would be a big plus, this is primarily a Software Engineering position. Successful candidates are passionate about software, and will have exceptional skills and hands on experience with development in C/C++ and Python in a Unix environment. Deep conceptual understanding of multi threaded and multi process software systems is also necessary.

In addition to the above fundamental software skills, any of the following technical hands-on skills are highly desirable.

1) System Programming and Operating Systems.
2) Distributed systems for data management.
3) Distributed computing infrastructure.
4) Cloud technologies for storage, containerization and compute clusters.
5) Data Structures and algorithms
6) GPU architectures and data management.
7) Traditional machine learning using Random Forest, XG Boost, Logistic Regression.
8) Deep Learning for regression, classification. Generative models.
9) TensorFlow, NumPy, scikit-learn, and other ML and DL frameworks.
10) MPI and similar distributed computing framework.
11) GPU Architectures and CUDA (CuGraph, CuData, CuML etc).
12) GO Systems Programming, Java Programming.

Successful candidates for this position will also demonstrate the following non-technical skills.

1) Capability to formulate creative solutions through analyzing complex data
2) Good communication skills
3) Strong team player and motivated by team success
4) Strong problem solving skills

Minimum Qualifications

Doctorate (Academic) with at least 2 years of experience.
OR
Master's Level Degree with at least 4 years of experience.
OR
Bachelor's Level Degree with at least 5 years of experience.

Equal Employment Opportunity

KLA is an Equal Opportunity Employer. Applicants will be considered for employment without regard to age, race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability, or any other characteristics protected by applicable law.",3.8,"KLA-Tencor
3.8","Ann Arbor, MI","Milpitas, CA",5001 to 10000 employees,1976,Company - Public,Industrial Manufacturing,Manufacturing,$2 to $5 billion (USD),"Applied Materials, Nanometrics"
"Senior SDE, Catalog Big Data and Machine Learning",-1,"Amazon's Catalog DataWorks team is looking for highly motivated engineers. We are embarking on multiple new initiatives to re-organize Amazon's catalog of billions of products, in new and interesting views, that drive several features Amazon's customers love. Today, these views drive hundreds of popular features like product recommendations, clustering of similar products, and shopping with Alexa. We will build a new near real-time Catalog Data Lake on AWS, to enable engineers and scientists across Amazon to solve customer problems faster. Come join us on this exciting journey!

As an engineer on this team, you will own the Catalog Data Lake end-to-end. You will work closely with business partners to synthesize technical requirements. You will design and implement significant parts of the platform. You will learn and use industry standards like Spark and Parquet as well as modern AWS offerings like EMR, Glue, Athena, and Redshift. We are fortunate to be at the cusp of innovation in both the e-commerce business as well as cloud technology. As a key stakeholder, you will constantly learn new patterns, solve key customer problems and strive to make AWS better along the way.Basic Qualifications
Bachelor's degree or higher in computer science or math is required.
Strong computer science fundamentals - algorithms, data structures and design patterns.
At least 8 years of software development experience.
At least 3 years of experience building and operating Big Data systems.
Experience mentoring, guiding and influencing peers.
Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.",-1,Amazon Corporate LLC,"Seattle, WA",-1,-1,-1,-1,-1,-1,-1,-1
SENIOR SOFTWARE ENGINEER & SOFTWARE ARCHITECT,-1,"Job Description
Senior Software Engineer, Software Architect
JOB SUMMARY

The Senior Software Engineer, Software Architect will develop software for Company innovative semiconductor X-Ray inspection system. The Senior Software Engineer will collaborate with Applications, QA, and Algo teams for high performance solutions and optimization per customer issues. It will be important to be comfortable working in a small company environment and a typical startup with engineers and scientists.

ABOUT THE CLIENT

Based in San Jose, California, client was founded in 2013 expressly to bring high speed inspection and metrology technology to the semiconductor packaging industry. Client founders anticipated the need to deploy inline 100% transmissive inspection into the semiconductor packaging manufacturing process and developed the company’s technology with this end in mind. The results, Client’s HR-AXI technology suite brings together the company’s unique data acquisition architecture with proprietary machine learning analysis techniques to provide customers with process monitoring and defect detection capabilities not found on any other products in the market. This job description can be updated at any time.

RESPONSIBILITIES
Designs, develops, troubleshoots, and debugs software programs for enhancements and new products, focused on creating high quality and high-performance solutions while maintaining high-level coding standards.
Develops software and tools in support of design, infrastructure, and technology platforms. Develops software solutions by studying information needs, conferring with users, and studying systems flow, data usage, and work processes
Supports hardware compatibility and/or influences hardware design based on software needs; work as part of cross-functional team to solve and implement system level problems.
Monitor application stability, performance, and availability. Promptly resolve issues impacting operations.
Work with engineering, documentation, and applications departments to ensure successful development and delivery of overall product.
Provide appropriate project feedback to management in a timely and appropriate format.
QUALIFICATIONS AND REQUIRED SKILLS
Education requirement: Bachelor’s degree in Computer Science, Electrical Engineering, or similar technical field required. Master’s or PhD strongly preferred.
Experience requirement: Minimum of 8 years of related experience working in software development.
Strong expertise in C# .NET. WCF, WPF, Database development. In addition, Python experience a plus.
Experience with Image processing algorithms implementations is a plus
Experience with software development for Factory Automation for Semiconductor equipment, a plus.
Self-starter able to think and act independently to translate general objectives into tangible results, with a record of delivering successful designs on schedule.
Demonstrated ability to organize, manage, and complete multiple assignments with challenging timelines independently and effectively.
Demonstrated analytical and problem-solving skills with high attention to detail.
Proactive approach to problem-solving. Build relationships with stakeholders to support successful design, build and testing.
Strong verbal and written communication, good attitude, and work ethic. Ability to communicate technical concepts and results clearly.
Experience with Git and Azure DevOps, a plus.",3.0,"Simple Solutions
3.0","San Jose, CA","Morgantown, WV",1 to 50 employees,2006,Company - Private,IT Services,Information Technology,Less than $1 million (USD),-1
Cloud Engineer,-1,"Job Description
Responsibilities:
Develop and implement technical efforts to design, build, and deploy AWS applications at the direction of lead architects, including large scale data processing, computationally intensive statistical modeling, and advanced analytics
Participate in all aspects of the software development life cycle for AWS solutions, including planning, requirements, development, testing, and quality assurance
Provide guidance, thought leadership and mentorship to development teams to build cloud competencies
Provide innovative thought leadership around Mathematica’s cloud solutions strategy and approach, including AWS best practices and market trends
Position Requirements:

6+ years of experience architecting, designing, developing and implementing cloud solutions on AWS platforms
Demonstrated experience with designing and implementing solutions using AWS platform and tools, such as: EC2, S3, Redshift, API Gateway, Lambda, DynamoDB, CloudFormation, RDS, VPC, IAM and security, QuickSight, CloudTrail, Config, CloudWatch, SNS, AMI generation
Understanding of and experience with the five pillars of a well-architected framework
Knowledge of SQL, R, and Python for data manipulation and statistical analysis is desirable
Familiarity with federal security regulations and standards (e.g. HIPAA, FISMA, FIPS, NIST, and FedRAMP)
Experience with security, especially knowledge of FedRAMP, HIPAA, PII/PHI, is desirable
Experience in several of the following areas: database architecture, ETL, Business Intelligence, Big Data, Machine Learning, Advanced Analytics
Proven ability to work collaboratively with multi-disciplinary teams of business analysts, developers, data scientists, and subject matter experts
Strong written, verbal and interpersonal communication skills
AWS Certifications (such as AWS solutions architect or other specialty certifications) are a plus
Bachelor's degree or equivalent combination of education and experience; degree in computer science, mathematics or related field preferred
Experience with other cloud platforms like Google Cloud Platform (GCP) is a plus",4.8,"RICEFW Technologies Inc
4.8","Princeton, NJ","East Lansing, MI",51 to 200 employees,2009,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Senior Software Engineer / Team Lead,"$112K-$220K
(Glassdoor est.)","Join our team dedicated to developing and executing innovative solutions in support of customer mission success.

Job Description:

Novetta has an exciting opportunity for a self-motivated and accomplished Computer Scientist to lead our entity analytics team. You will work on complex projects involving data analysis, software engineering, and deploying software in a cloud computing environment. The team combines data from disparate sources to visualize the complex relationships between entities. This effort involves large scale data integration and entity resolution leveraging a best in class Novetta product. We are looking for a flexible problem solver with significant technical experience to lead a team providing unique solutions for our customers and stakeholders.

Responsibilities include:
Lead a technical team of software engineers and computer scientists, working within a larger ecosystem delivering an Enterprise capability.
Navigate customer and prime environment, manage resources within and across team, and assist team with professional and technical growth.
Deploy applications on a large-scale data processing cluster using AWS technologies.
Design and implement entity correlation strategies that are tailored to mission needs and unique data qualities.
Develop algorithms and visualization tools to help stakeholders understand their data and prioritize new data sources.
Develop and integrate applications to automate ingestion, processing and monitoring of data
Develop and maintain tools to support operations and maintenance of production and development computing clusters.
Basic Qualifications:
Experience leading a team of software engineers.
A Bachelor's degree in computer science or related field and a minimum of 5 years of experience; or a Master's degree in computer science or related field and a minimum of 3 years of experience.
Experience in software development/engineering including requirements analysis, software development, installation, integration, evaluation, enhancement, maintenance, testing and problem diagnosis/resolution.
Software development experience on Linux-based systems in Python or shell scripting or JavaScript.
Experience developing against full-featured REST APIs and using a command line interface
Desired Skills:

Should meet a minimum of 3:
Software development experience with JavaScript, Python, or other modern programming languages.
Hands-on experience with Spark.
Experience working with Databricks
Interest in statistical analysis, machine learning, or data science.
Experience with entity resolution products or a background in data matching theory and technologies.
Experience developing applications in AWS.
Security Clearance:
The candidate must have a TS/SCI with Poly.
Novetta, from complexity to clarity.

Novetta delivers highly scalable advanced analytics and secure technology solutions to address challenges of national and global significance. Focused on mission success, Novetta pioneers disruptive technologies in machine learning, data analytics, full-spectrum cyber, cloud engineering, open source analytics, and multi-INT fusion for Defense, Intelligence Community, and Federal Law Enforcement customers. Novetta is headquartered in McLean, VA with over 1,000 employees across the U.S.

Our culture is shaped by a commitment to our core values:

Integrity • We hold ourselves accountable to the highest standards of integrity and ethics.

Customer Success • We strive daily to exceed expectations and achieve customer mission success.

Employee Focus • We invest in our employees' professional development and training, respecting individuality and fostering a culture of diversity and inclusion.

Innovation • We know that discovering new and innovative ways to solve problems is critical to our success and makes us a great company.

Excellence in Execution • We take pride in flawless execution as we build a company that is best in class.

Earn a REFERRAL BONUS for the qualified people you know.

For more details, or to submit a referral: bit.ly/NovettaReferrals

Novetta is an equal opportunity/affirmative action employer.

All qualified applicants will receive consideration for employment without regard to sex, gender identity, sexual orientation, race, color, religion, national origin, disability, protected veteran status, age, or any other characteristic protected by law.",4.5,"Novetta
4.5","Chantilly, VA","Mc Lean, VA",501 to 1000 employees,2012,Company - Private,Enterprise Software & Network Solutions,Information Technology,$100 to $500 million (USD),"Leidos, CACI International, Booz Allen Hamilton"
Data Fusion Engineer with Security Clearance,"$48K-$109K
(Glassdoor est.)","Description Job Description: Looking for work-life balance? Leidos offers generous leave and accommodating flex-time to help you juggle your personal and professional life. Are you a Software Engineer with experience finding and aligning signals across multiple modalities (image, video, audio, lidar, etc..)? Do you want to implement and customize algorithms to fusion multiple data modalities? If so we are looking for you, our next Data Fusion Engineer to work in Arlington, VA. We need you to be competent in Python and have the ability to read code in other programming languages like Java and C++ as well as have experience working with ML libraries like SciKit Learn, TensorFlow, Keras along with experience implementing solutions with those libraries on both CPU and GPU compute architectures. Like what you are reading so far? Keep going. We want you to be intellectually adaptive, inquisitive, good at expressing your needs, and able to self-manage when necessary. Work alongside software/system engineers and research/data scientists with expertise in multi-modal information retrieval, UI development, computer vision, metrics, information science, artificial intelligence, and autonomous systems. The Department of Defense and the Intelligence Community will be the main recipients your hard work. Fun stuff you will do on the job: - Use cases requiring identifying entity/objects, determining object association, object disambiguation, anomaly detection, state estimations, etc.
Develop and maintain data models (both physical and logical)
Get to be responsible for extraction, transform, and load (ETL) tasks related to the different modalities and algorithms being applied. This data ETL includes identifying the data's relevant metadata to ensure consistency, quality, accuracy, integrity, and information assurance and security.
Performing anomaly detection using various AI/ML techniques
Use algorithms to identify complex patterns across multiple modalities
Increasing the efficiency and quality data alignment and fusion
Enhance and maintain analysis tools, including automation of current processes using AI/ML algorithms
Conduct quantitative data analysis including developing retrieval, processing, fusion, analysis, and visualization of various datasets Skills required to be successful in this role: - Bachelor's Degree in Aerospace Engineering, Computer Science, Mathematics, Statistics, Physics, Electrical Engineering, Computer Engineering or related fields with 5 years of relevant experience
Must be able to obtain and maintain a TS/SCI security clearance
Experience with Deep Learning Frameworks such as Keras, Tensorflow, PyTorch, Mxnet, etc. - Ability to apply these frameworks to real problems in the 'time -series' domain
Experience with interpretability of deep learning models
Big Data Skills (Azure, Hadoop, Spark, recent deep learning platforms)
Practical experience with statistical analysis
Experience with text mining tools and techniques including in areas of summarization, search (e.g. ELK Stack), entity extraction, training set generation (e.g. Snorkel) and anomaly detection
Expert software development skills lifecycle including developing and maintaining good production quality code
Hands-on Software Development Skills (Python-Preferred)
Experience or educational courses/projects in Machine Learning, and/or Text Mining Algorithms You will wow us even more if you have these skills: - Visualizations/Web Development Skills (e.g. Tableau, D3, etc).
Hands-on experience with prototype development
Hands-on experience with automating data cleansing, formatting, staging, and transforming data human
Hands-on experience applying data analytics
Hands-on experience with intelligent systems and machine learning LInC External Referral Bonus: Ineligible Potential for Telework: No Clearance Level Required: Top Secret/SCI Travel: Yes, 10% of the time Scheduled Weekly Hours: 40 Shift: Day Requisition Category: Professional Job Family: Software Engineering Leidos Leidos is a Fortune 500® information technology, engineering, and science solutions and services leader working to solve the world's toughest challenges in the defense, intelligence, homeland security, civil, and health markets. The company's 33,000 employees support vital missions for government and commercial customers. Headquartered in Reston, Virginia, Leidos reported annual revenues of approximately $10.19 billion for the fiscal year ended December 28, 2018. For more information, visit www.Leidos.com . Pay and Benefits Pay and benefits are fundamental to any career decision. That's why we craft compensation packages that reflect the importance of the work we do for our customers. Employment benefits include competitive compensation, Health and Wellness programs, Income Protection, Paid Leave and Retirement. More details are available here . Securing Your Data Leidos will never ask you to provide payment-related information at any part of the employment application process. And Leidos will communicate with you only through emails that are sent from a Leidos.com email address. If you receive an email purporting to be from Leidos that asks for payment-related information or any other personal information, please report the email to [email protected] . Commitment to Diversity All qualified applicants will receive consideration for employment without regard to sex, race, ethnicity, age, national origin, citizenship, religion, physical or mental disability, medical condition, genetic information, pregnancy, family structure, marital status, ancestry, domestic partner status, sexual orientation, gender identity or expression, veteran or military status, or any other basis prohibited by law. Leidos will also consider for employment qualified applicants with criminal histories consistent with relevant laws.",3.5,"Leidos
3.5","Arlington, VA","Reston, VA",10000+ employees,1969,Company - Public,Aerospace & Defense,Aerospace & Defense,$10+ billion (USD),-1
Software Engineer,"$64K-$132K
(Glassdoor est.)","Every Analyst a Scientist - One of our primary goals is to empower intelligence analysts to be able to study their data like scientists. The tools we develop focus on streamlining intelligence analysis through integrated algorithms and software that provide insight into the geopolitical landscape for use in operational intelligence missions around the world.

The Role:
As a Software Engineer, you will be part of a team that transforms large and complex customer data into real-world, high-impact solutions. You will work with researchers and engineers to design and implement solutions to challenging national security problems. You will be responsible for building the software infrastructure to clean, ingest, and expose datasets and algorithms to both developers and end users. You will deploy algorithms, generate workflows, create engineer-facing tools, and design customer-facing prototype systems. You will occasionally travel to customer sites to engage with end users, demonstrate prototypes, and integrate analytics into customer systems.

If you would like to help intelligence and defense analysts keep pace with technology-driven innovation, then this role is for you!

Who you are:
A U.S. Citizen with the ability to obtain a Security Clearance
A degree in a scientific or engineering field, such as Computer Science, Mathematics, Physics, or Software Engineering
Proficiency with a scientific programming language such as Python, Java, or C++
Experience with database management and common query syntax
Motivated collaborator and excellent communicator of ideas to both technical and non-technical audiences
Knowledge of AWS, Spark, Dask, and/or similar technologies for working with data at scale
Even better:
Active Security Clearance
Track record of architecting, developing, deploying, or maintaining enterprise software
Experience with software development best practices and tools
Understanding of web development and visualization technologies, such as d3, Leaflet, Bootstrap, or others
Familiarity with machine learning or statistical modeling techniques",4.5,"Systems & Technology Research
4.5","Woburn, MA","Woburn, MA",201 to 500 employees,2010,Company - Private,Aerospace & Defense,Aerospace & Defense,$100 to $500 million (USD),-1
Sr. Data Scientist,-1,"Background Information:

Innovative Defense Technologies (IDT), provider of automated software testing, data analysis, and cybersecurity solutions for complex defense systems, is currently accepting applications for an anticipated Sr. Data Scientist role requiring 7+ years of experience for a position in support of its efforts implementing Artificial Intelligence solutions for a variety of customers.

Overview:

The Sr. Data Scientist position offers an engineer the opportunity to utilize his/her knowledge and talents as part of a collaborative team developing AI solutions for a growing company. A few of the responsibilities include supporting feasibility studies, applying modern data storage techniques, discovering explanatory features in high-dimensionality collections of data, and exploring data using scientifically valid techniques to exploit patterns found in the data with state-of-the-art AI/ML/DL solutions.

All applicants must be able to obtain/maintain an active U.S. Security Clearance.

Responsibilities Include:
Lead development of solutions to deliver AI/ML/DL models from problem formulation to a productized, deployable, maintainable capability
Contribute to AI/ML/DL technical roadmap development
Use Deep Learning frameworks such as Tensorflow and Keras to build and validate ML/DL models
Establish and leverage Big Data frameworks to store, extract and analyze relevant data
Ensure development of software solutions meets customer needs and program intent
Work closely with the Program Manager and Chief Engineer to design and implement software requirements and solutions
Determine operational feasibility by evaluating analysis, problem definition, requirements, solution development, and proposed solutions for large, complex systems
Be responsible for a team’s products meeting software design, quality, and performance requirements
Pursue new technology development via the DoD Small Business Innovative Research (SBIR) program
Work with minimal supervision in a collaborative work environment to implement best-in-class solutions
Minimum Required Qualifications:
Bachelor’s Degree in Computer Science, Computer Engineering, Electrical Engineering, Systems Engineering, Physics, or Math Required; PhD in relevant field highly preferred
7+ years of experience in predictive modeling, data science and analysis
Required Skills:
Previous experience in a ML or data scientist role and a track record of building ML or DL models
Extensive experience working with data mining algorithms including decision trees, probability networks, association rules, clustering, and neural networks
Experience using Python (or equivalent)
Experience using ML libraries, such as scikit-learn,
Experience using data visualization tools
Experience handling terabyte size dataset
Experience working with GPUs to develop models
Ability to travel 10% or less
Preferred Skills:
Experience with MapReduce programming (Hadoop)
Skills with programming languages, such as Java or C/C++
Demonstrated ability to develop experimental and analytic plans for data modeling processes, use of strong baselines, ability to accurately determine cause and effect relations
Consulting experience and track record of helping customers with their AI needs
Publications or presentations in recognized Machine Learning, Deep Learning and Data Mining journals/conferences
Combination of deep technical skills and business savvy enough to interface with all levels and disciplines within our customer’s organization
Experience diving into data to discover hidden patterns
Experience with application container platforms
Familiarity with continuous integration/delivery tools (e.g. Jenkins)
Familiarity with version control tools (e.g. Subversion, Git, etc.)
Familiarity with VMware or other virtualization software
Experience developing applications for DOD command and control systems
Competencies:
Solid analytical abilities, coupled with a strong sense of ownership, urgency, and drive
Attention to detail
Initiative, creativity, reliability, teamwork
Ability to deal well with ambiguity, prioritize needs, and deliver results in a dynamic environment
EEO Statement:

IDT is an Equal Opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, creed, sex, sexual orientation, gender identity, national origin, disability, protected Veteran status, or any other basis protected by federal, state, or local law.",-1,Innovative Defense Technologies (IDT),"Mount Laurel, NJ",-1,-1,-1,-1,-1,-1,-1,-1
Full Stack Software Engineer (Python/Vue),-1,"Position Summary Full Stack Software Engineer (Python VueJS) Company Overview Our client is an automated underwriting platform for real estate professionals that was built to disrupt the commercial real estate industry. The software allows investors, brokers, and lenders to analyze rent, operating expenses and returns for multifamily properties by applying machine learning to a database of live multifamily transaction data from every U.S. market. Our client has a creative and entrepreneurial culture ndash everyone on the team interacts directly with customers each day, and we all contribute to the product and planning. If you have an idea to improve something, there is no red tapehellip just build what needs to be built! Innovation and passion for transforming the old-fashioned real estate industry are our highest priorities. Job Description As a full-stack (Python, PostgreSQL and HTMLCSSJavaScript) developer, you'll work on the interface and backend infrastructure of products and features used by hundreds of underwriters and real estate analysts every day. The work is challenging, fast-paced, and always changing. You must have demonstrated analytical skills, an unwavering commitment to quality, a collaborative work ethic, and cutting-edge coding skills. You must display solid proficiency in the fundamentals of Python, PostgreSQL, JavaScript, HTMLCSS, and popular front-end frameworks like Vue.js. The role will include the delivery of reliable, scalable new features to users, developed in Python, interacting with a PostgreSQL database and using the Vue.js frontend framework. You will work with the development team to develop, test and deliver finished, high quality, compelling features and products. Our team includes designers, engineers and data scientists who are passionate about quality, usability, and simplicity. If you are ready to join a company that fosters learning, growth, experimentation and innovation, our client's team is for you. Requirements Qualifications 3-5 years of experience in full stack Python development 1-3 years of experience with PostgreSQL 1-3 years of experience with JavaScript frameworks such as React, Angular or Vue.js (Vue.js is preferred, this is what our client uses), and CSS pre-processing frameworks (Sass or Less) 1-2 years of experience integrating with VBA and Excel integration preferred Experience using GitHub and solid understanding of software version control Familiarity with JIRA or equivalent product management software Familiarity with agile development best practices Driven self-starter able to work on a small team and take initiative on new tasks Familiarity with real estate or finance is a plus Responsibilities Collaborate with interdisciplinary team of data scientists, software engineers and real estate professionals Strive for high quality and rapid output utilizing agile development best practices Support, maintain, and document software functionality Maintain industry standard coding, compliance, security practices Proactively learn product frameworks and code base Our client is a startup company, and as such the responsibilities outlined above may change and evolve over time. Flexibility, curiosity, an entrepreneurial mindset, and strong work ethic are essential for this role. It is encouraged that everyone on the team continually research new technologies and analytical opportunities to improve the platform.",5.0,"CultureFit
5.0","Chicago, IL","Deerfield, IL",1 to 50 employees,1997,Company - Private,Advertising & Marketing,Business Services,$1 to $5 million (USD),-1
AWS Data Engineer,-1,"About Infinitive:

At Infinitive, we do mission-critical work for great companies. We specialize in digital marketing and digital advertising solutions, customer data & analytics, digital & business transformation, and Technology solutions. Our Technology solutions focus on Managed Cloud Services, Cloud Enablement, Digital Operations, Application Development, DevOps, Product Development, Cloud Security, Data Science and Analytics, AI/ML, IoT, and everything in between.

Our experts are results-obsessed, focused and flexible, highly engaged and hugely experienced having sat in our clients seats. Those qualities are what make us different than old-school consulting shops. And surely, they are why clients and partners describe us as the gold standard in client experience.

Infinitive has been named a Best Small Firms to Work For by Consulting Magazine seven times, a Washington Post Top Workplace three times, a Washington Business Journal Best

About this Role:

Infinitive is growing its team in the Northern Virginia area and is currently seeking an Data Scientist to join our growing Technology practice. This person will utilize their experience in analytics, IoT, machine learning, and artificial intelligence advances to create value from structured and unstructured data. The ideal candidate has experience designing novel data analytic methods and workflows, including full data pipelines from raw data through analysis results. They must also have exposure to a variety of data mining/data analysis methods, data tools, building and implementing models, using/creating algorithms, and creating/running simulations.

We are looking for candidates who are accountable, passionate, assertive, proactive, open & honest, results oriented, and adaptable. Each project engagement represents a new challenge that will give you exposure to new clients, business issues, technologies, and people and will involve a range of responsibilities to include:
Developing in Java, Python, R, or other high-level languages.
Managing disparate data sources with varying data structures of content and preparing these for data science and machine learning applications.
Working with distributed scalable Big Data storage, processing, and computation, including AWS EMR, Spark, etc.
Implementation knowledge of, or desire to learn AWS / Azure data science capabilities.
Developing solutions and integrating and extending free and Open-source software (FOSS) or COTS products.
Conduct MapReduce programming with Apache Hadoop, the Hadoop Distributed File System (HDFS), and processing large data stores.
Knowledge of SQL and query languages.
Utilize real-time, large-scale data processing engine, including Apache Spark.
Lead and create Data Science and Analytics methodologies and frameworks for implementation.
Ability to build and develop Data Science demonstrations for clients
Qualifications:
4+ years of development experience (Java, Python, R, SQL)
3+ years of experience with distributed scalable Big Data storage, including AWS EMR, Spark, etc.
Desire to become AWS / Azure Certified architect / engineer.
Experience performing data Management, modeling, and warehousing.
Hands on experience with Amazon analytic tools (preferred)
Interest in being involved internally and growing a small business (entrepreneurial spirit)
Ability to travel (up to 20%) and to work independently
Experience using Agile software development methods in a DevOps environment.
Excellent leadership, peer management, and communication skills
Management consulting experience (preferred)
Bachelor's degree in related field (preferred)
Applicants for employment in the U.S. must possess work authorization which does not require sponsorship by the employer for a visa.

Infinitive is an Equal Opportunity Employer.

Powered by JazzHR",3.4,"Infinitive Inc
3.4","Arlington, VA","Cedar Rapids, IA",201 to 500 employees,1997,Company - Private,Enterprise Software & Network Solutions,Information Technology,$10 to $25 million (USD),-1
"Senior SW Engineer, Data Science ( Kubernetes/ Docker ) Remote USA","$72K-$141K
(Glassdoor est.)","If you dream of a job working in a field where all the hard problems are solved and you get to re-use previous research to get your job done, you need not apply. If, however, you are someone who wants to tackle problems that truly are on the cutting edge, then we encourage you to keep reading.

Data Science is an emerging field within cyber security. FireEye, given its deep expertise and comprehensive view on the advanced threat landscape, is uniquely positioned to enable data scientists to have major impact within our industry, company, and across our customer base. Detecting security breaches using machine learning and data analytics is an unsolved problem (this is not handwriting recognition folks) and has huge potential.

If you are someone who wants to be on the cutting edge of a high profile industry, who wants to make an impact by pushing both fields of data science and cyber security forward, you may be the perfect candidate to help us on our mission.

What you will do:
Develop, and manage data systems to ingest and process data at massive scale
Identify data sources both internally and externally that we can use to find evil.
Contribute towards the architecture and design of software solutions for long-term storage and retrieval.
Identify and implement data exploration technologies. Create dashboards and implement analytical tools for exploration
Work with data scientists to productize ML models and assist product teams with ML model releases into end products.
Collect requirements, design, and build backend components and tools to run ML models, assess ML model efficacy, manage large scale datasets, and generate features for ML models
Contribute to the evolution of coding and design practices within the organization.
Review code base commits and contribute to the growth of team members.
Requirements
Ability to work in an iterative, agile development environment.
Experience implementing ETL processes and building data pipelines
Experience developing reliable distributed systems.
Experience in Data modeling and schema design
Strong knowledge of a variety of operating systems, networking fundamentals, software design and programming best practices.
Experience with use of a wide array of algorithms and data structures.
Deep understanding and experience of going through the entire life cycle of building software platforms and products
Deep knowledge of various AWS services and associated tools
Strong experience developing in Python 3
Experience developing in at least 1 of the following: C, Go or Java
Experience with RDBMS, such as PostgreSQL or MySQL, as well as NoSQL
Experience with Kubernetes and Docker.
Experience deploying products in AWS
Additional Qualification: *
Ability to pick up, work with and explore new analytical tools
Strong experience with DevOps practices and common tooling
Strong communication skills.
Ability to work with loosely defined requirements.
At FireEye we are committed to our #OneTeam approach combining diversity, collaboration, and excellence. All qualified applicants will receive consideration for employment without regard to race, sex, color, religion, sexual orientation, gender identity, national origin, protected veteran status, or on the basis of disability. Requests for accommodation due to disability can be sent directly to .",3.3,"FireEye Inc
3.3","Denver, CO","Milpitas, CA",1001 to 5000 employees,2004,Company - Public,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,"Palo Alto Networks, Tanium"
"Senior SW Engineer, Data Science","$72K-$141K
(Glassdoor est.)","Job Description

If you dream of a job working in a field where all the hard problems are solved and you get to re-use previous research to get your job done, you need not apply. If, however, you are someone who wants to tackle problems that truly are on the cutting edge, then we encourage you to keep reading.

Data Science is an emerging field within cyber security. FireEye, given its deep expertise and comprehensive view on the advanced threat landscape, is uniquely positioned to enable data scientists to have major impact within our industry, company, and across our customer base. Detecting security breaches using machine learning and data analytics is an unsolved problem (this is not handwriting recognition folks) and has huge potential.

If you are someone who wants to be on the cutting edge of a high profile industry, who wants to make an impact by pushing both fields of data science and cyber security forward, you may be the perfect candidate to help us on our mission.

What you will do:
Develop, and manage data systems to ingest and process data at massive scale
Identify data sources both internally and externally that we can use to find evil.
Contribute towards the architecture and design of software solutions for long-term storage and retrieval.
Identify and implement data exploration technologies. Create dashboards and implement analytical tools for exploration
Work with data scientists to productize ML models and assist product teams with ML model releases into end products.
Collect requirements, design, and build backend components and tools to run ML models, assess ML model efficacy, manage large scale datasets, and generate features for ML models
Contribute to the evolution of coding and design practices within the organization.
Review code base commits and contribute to the growth of team members.",3.3,"FireEye Inc
3.3","Denver, CO","Milpitas, CA",1001 to 5000 employees,2004,Company - Public,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,"Palo Alto Networks, Tanium"
"Senior Machine Learning Engineer, Early Stage Pipeline, X",-1,"Senior Machine Learning Engineer, Early Stage Pipeline, X

Software Engineering

Mountain View, CA

We're an early stage team at X with a growing, interdisciplinary portfolio. To prove our path to the moon, we make early contact with the real world through both internal and external partnerships.

In this role, you will be responsible for taking early stage investigations from an idea stage to first prototypes to a full-blown projects. You'll be rapidly iterating through a set of prototypes to evaluate possible product directions. This is an extremely dynamic role and requires high cross-functional communication, organization, and planning. The ideal candidate is a self-starter and has a track record of effectively operating in a dynamic loosely structured environment (e.g. startup, new products within a larger company). The candidate will work on multiple projects/investigations.

Responsibilities:
Identify and implement a set of machine learning prototypes to aggressively de-risk projects building the whole solution: data acquisition, data processing pipelines, ML modeling.
Setup technical direction for investigations/projects working with the early stage leadership team.
Team lead investigations that grow to become projects.
Qualifications:
Hands-on experience with machine learning, one or more of; natural language processing (semantic understanding, sentiment analysis), computer vision, time series analysis.
Experience with building robust data pipelines.
Tech Lead experience.
Startup or early-stage product development experience.
Preferred Qualifications:
Experience with the Google Cloud Platform
About X, the Moonshot Factory

X creates radical new technologies to solve some of the world's biggest problems. We develop uncomfortably ambitious, potentially world-changing new ideas such as self-driving cars, balloon-powered Internet and smart contact lenses. We're a team of makers, entrepreneurs, engineers, designers and scientists with deep technical expertise who love the challenge of the seemingly impossible. We believe that a culture of psychological safety creates the foundation of trust and respect necessary to build moonshots. X was formerly known as Google[x] and is part of Alphabet .

At X, we don't just accept difference - we celebrate it, we support it, and we thrive on it for the benefit of our employees, our products and our community. We are proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements.

If you have a disability or special need that requires accommodation, please contact us at: (see application details) .",-1,"X, the moonshot factory","Mountain View, CA",-1,-1,-1,-1,-1,-1,-1,-1
"Senior/Staff Software Engineer, Data Infrastructure","$116K-$227K
(Glassdoor est.)","Senior/Staff Software Engineer, Data Infrastructure job posting

Every year, while Americans wait for their paychecks, more than $1 trillion of their hard-earned money is held up in the pay cycle. As a result, we accumulate over $50 billion in late and overdraft fees and turn to high-interest loans. Overdraft charges and bank fees often trap people in a cycle of debt that can lead to unhealthy decisions and falling victim to predatory businesses disguised as helpful services. We don't accept that.

Earnin is an app that creates products that help people gain control of their finances. Cash Out lets people get paid as soon as they leave work, with no fees, interest, or hidden costs. With Health Aid, Earnin negotiates on behalf of community members to lower their total unpaid medical bill and work out a budget-friendly payment plan. Cash Back Rewards is a way for members to earn up to 10% cash back on purchases from over a thousand local and national businesses without needing a credit card or having to reach spend thresholds to earn cash rewards — and they can withdraw the money at any time. We also offer free tools to help avoid overdrafts, to remind people when recurring bills are due, and we're working on more! There is never any required cost to use any of these products or services, users can choose to tip what they think is fair to support the service and pay it forward to keep the movement going.

Earnin is supported by funding partners including Andreessen Horowitz, Matrix Partners, Ribbit Capital, Felicis Venture, Thrive Capital, and others. Join us and help build a new financial system focused on fairness and people's needs.

You can help make a difference.

About the Team:

We are a data driven mobile financial tech company. The Data Infrastructure team builds the data services and data infrastructure that powers data science, analytics, and product development throughout Earnin. We are looking for a product-minded, self-driven Senior Software Engineer to own multiple large-scale projects that advance our mission of enabling people to gain access to their paycheck on demand.

What sets us apart:
High impact roles at a relatively small company that's aggressively growing our user base.
We are a collaborative team and genuinely enjoy working with each other.
We believe in empowering our people to be successful.
We're building a product that inspires fairness across the financial world and helps people not get taken advantage of.
As a Senior Engineer you will:
Break down complex problems into their bare essentials, translate this complexity into elegant design and create high quality, maintainable code.
Build massively scalable, production-grade data services.
Champion data quality and governance throughout the organization.
Build a world class data lake and data warehouse.
Design and develop new systems and tools to enable all of Earnin to consume and understand data faster.
Own the end to end design, build, and maintenance of platform services, data pipelines, and data products.
Implement comprehensive monitoring, logging, and alerting across our data infrastructure.
Work cross functionally with other teams (data science, design, product, marketing, and analytics) in high visibility roles as an engineering leader.
Build and deploy the data architecture that supports machine learning model development and actionable analytics.
Work with product engineering and data science teams to design scalable, performance model deployment architectures.
Communicate the tradeoffs of technical decisions to multiple stakeholders, including non-technical audiences.
Collaborate with and mentor other engineers and provide engineering direction to data scientists and analysts.
Actively engage and drive design reviews and code reviews.
Some skills we consider critical to being a Senior Engineer:
BS or MS degree in Computer Science, Engineering, or a related technical field.
8+ years of development experience in a fast-paced environment, especially startups.
5+ years of experience working with data systems.
Strong Python and SQL skills.
Strong programming and architecture skills.
Excellent written and verbal communication skills, including the ability to identify and communicate data driven insight.
Taking pride in your code quality and helping others elevate their own code quality.
Substantial experience with testing, data validation, and data quality assurance.
You can articulate the tradeoffs of different deployment architectures (e.g. streaming vs. batch vs. service-based).
Experience designing data platforms and services on cloud infrastructure, preferably AWS.
Hands-on experience designing and building large-scale solutions with the Hadoop stack and/or Spark.
Experience tuning and optimizing Spark-based applications.
Experience deploying and/or using query engines like AWS Athena, Presto, and Impala.
Experience with AWS analytical services like Redshift.
Hands-on experience working with a varied set of data storage technologies (e.g. Mysql, Postgres, DynamoDB, S3, etc.). You know where and when to use each.
Extensive experience with data modeling for multiple use cases and application styles, including NoSQL data modeling.
Experience working with data formats such as Avro and Parquet.
Experience working with alerting and monitoring tools like DataDog and PagerDuty.
Nice to haves:
You have experience building and deploying machine learning models.
You have experience using Terraform.
You have substantial experience working at a startup.
You have experience with data modeling in Redshift.
Experience with streaming infrastructure like Kafka.
Experience working with Kubernetes.
Experience building and deploying AWS Lambda applications.",3.1,"Earnin
3.1","Palo Alto, CA","Palo Alto, CA",201 to 500 employees,2012,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Engineer (open level),"$43K-$69K
(Glassdoor est.)","Title
Data Engineer (open level)

07/08/2020

What you'll do...
At H&R Block, your contributions will go far beyond any job description. When you join our team, you'll add to the momentum of a forward-thinking company - one that defined an industry and is now leading its transformation.

H&R Block is transforming tax preparation through data to ensure that every client we serve gets the best tax outcome possible.

We are building a new Data Engineering Team in the Data Science & Analytics organization. This new team will own the technology and data capabilities of the end-to-end data-and-analytics function. It will take responsibility for building and maintaining the analytical technologies that the data science teams use, managing data at an enterprise scale, leveraging relationships with IT teams throughout the enterprise, and leading information architecture.

We are looking for talented, curious, and creative data engineers of all levels to help launch this team. You will be a good match for our organization if you are:
Motivated by the idea of building something innovative, transformative, and impactful.
Committed to the idea that data can drive experiences and products that wow our business partners and clients
Obsessed with defying expectations and raising the bar
Driven by an innate sense of ownership for the products you create.
Day to day, you'll...
Design and deploy architecture, solutions, and software to capture, manage, store, and use structured and unstructured data from internal and external sources in both on-prem and cloud environments.
Deploy machine-learning models and other data-science products across the enterprise.
Navigate the balance between business needs, data governance best practices, and technical requirements.
Select or develop tools to cleanse, organize, and transform data and to maintain, defend, and update data structures and integrity on an automated basis.
Develop data products to facilitate self-service capabilities and assist the data teams to increase their efficiency and effectiveness.
Collaborate and communicate effectively within cross-functional teams that span internal Data Science & Analytics teams, IT, business groups, and executive stakeholders.
Be a positive force to cultivate a culture that is passionate about developing data tools as a business driver.
Job ID
368348BR

Address1
ONE H&R BLOCK WAY

City
KANSAS CITY

State
Missouri

Employee Type
Regular

What you'll bring to the team...
Education / work experience should include most of these, depending on level:
Bachelor’s degree in Computer Science or a related technical field (or equivalent work experience and technical skills)
Data warehousing and ETL solutions
APIs in a microservices architecture
Big-data technologies and the Hadoop stack (MapReduce, Hive, Pig, Hbase
NoSQL implementations (MongoDB)
Developing Java-based software solution
At least one scripting language (Python, Perl, JavaScript, Shell
Developing software solutions to solve complex business problems
Working with data scientists and other data users
Posting Title
Data Engineer (open level)

Sponsored Job
#hrbjob

Job Family
Corporate Analytics",3.6,"H&R Block
3.6","Kansas City, MO","Kansas City, MO",10000+ employees,1955,Company - Public,Other Retail Stores,Retail,$2 to $5 billion (USD),"Intuit, Jackson Hewitt, Liberty Tax Service"
Senior Modeling & Simulation Engineer,-1,"Applied Research Associates, Inc. is looking for a Senior Modeling and Simulation Engineer to join our multi-disciplinary team of engineers and scientists in the Capital Area Division, located in Alexandria, VA. The ideal candidate has a passion for predicting the behavior of physical systems in challenging environments and operational impact on mission success. Models will be developed, used, and improved to support a Department of Homeland Security customer to safeguard the nation’s borders and interior from chemical, biological, radiological, nuclear, and explosive materials, equipment, technologies, and their actors. Models may be based on the underlying physics or may be process or agent based to predict operational performance and impact. Modeling and analysis may require the use and development of 3D virtual worlds or geospatial data. Models will be verified and validated, and they will be used in support of test and evaluation activities of systems intended to detect and identify threats. The candidate may participate in test and evaluation activities to support the verification, validation, and overall improvement of models. Models may become part of larger, integrated modeling and simulation activities, and may require the use of high performance computing technologies and federated simulations.

This position is contingent upon award of a contract expected in Summer 2020 supporting the Department of Homeland Security.

Required Qualifications:
Ability to program in a high level programming language, such as Fortran, C++, or Java
Eagerness to learn new tools and techniques
Strong verbal and written communication skills
Must be a U.S. Citizen with the ability to obtain and maintain a security clearance
Bachelor’s degree with minimum of 10 years of experience or greater in a physical science (physics, chemistry, biology), engineering-related discipline (nuclear, chemical, civil, mechanical, electrical), or modeling& simulation disciple (computer modeling, computational science, operations research)
Ability to present to senior leadership on the status and issues associated with research or test efforts in preparation for acquisition decision meetings
Desired Experience and Qualifications:
Experience modeling CBRNE detectors or effects
Experience using multiple software tools such as MCNP, GadRas, SWORD, ExtendSim, Arena, SolidWorks, Fluent, ArcGIS, QGIS, VisIt, ParaView, or Cubit
Experience creating 3D models of systems, i.e., CAD
Experience using high performance computers (i.e., supercomputers)
Experience developing and using discrete event or agent based models and simulations to predict and assess system performance
Experience developing machine learning models
Background in a physical science or engineering discipline, such as Physics, Chemistry, Biology, Mechanical Engineering, Nuclear Engineering
Active DoD Secret or Top Secret clearance, DoE Q clearance, or DHS Suitability
COMPANY INFORMATION:

Applied Research Associates, Inc. is an employee-owned international research and engineering company recognized for providing technically superior solutions to complex and challenging problems in the physical sciences. The company, founded in Albuquerque, NM, in 1979, currently employs over 1200 professionals. ARA offices throughout the United States and Canada provide a broad range of technical expertise in defense technologies, civil technologies, computer software and simulation, systems analysis, environmental technologies, and testing and measurement. The corporation also provides sophisticated technical products for environmental site characterization, pavement analysis, and robotics.

At ARA, employees are our greatest assets. The corporation realizes that employee ownership spawns greater creativity and initiative along with higher performance and customer satisfaction levels. ARA gives its employees the tools, training, and opportunities to take more active roles as owners. The culture is challenging; innovation and experimentation are the norm. Employees are eligible for contributions which not only add to the company’s success, but also their own through the Employee Stock Ownership Plan (ESOP). The motto,“Engineering and Science for Fun and Profit” sums up the ARA experience. For additional information and an opportunity to join this unique workplace, please visit our website atwww.ara.com.",3.5,"Applied Research Associates
3.5","Alexandria, VA","Albuquerque, NM",1001 to 5000 employees,1979,Company - Private,Federal Agencies,Government,$100 to $500 million (USD),-1
